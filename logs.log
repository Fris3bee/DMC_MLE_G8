2025-10-07 21:21:57,417:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-07 21:21:57,417:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-07 21:21:57,418:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-07 21:21:57,418:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-07 21:33:29,006:INFO:PyCaret RegressionExperiment
2025-10-07 21:33:29,006:INFO:Logging name: reg-default-name
2025-10-07 21:33:29,006:INFO:ML Usecase: MLUsecase.REGRESSION
2025-10-07 21:33:29,066:INFO:version 3.3.2
2025-10-07 21:33:29,066:INFO:Initializing setup()
2025-10-07 21:33:29,066:INFO:self.USI: 1442
2025-10-07 21:33:29,066:INFO:self._variable_keys: {'gpu_n_jobs_param', 'y', 'fold_generator', 'transform_target_param', 'X_train', 'exp_name_log', 'gpu_param', 'fold_shuffle_param', 'n_jobs_param', 'logging_param', 'data', 'exp_id', '_available_plots', 'target_param', 'y_test', 'idx', 'seed', 'log_plots_param', 'pipeline', '_ml_usecase', 'X', 'USI', 'X_test', 'memory', 'y_train', 'html_param', 'fold_groups_param'}
2025-10-07 21:33:29,066:INFO:Checking environment
2025-10-07 21:33:29,066:INFO:python_version: 3.11.0
2025-10-07 21:33:29,066:INFO:python_build: ('main', 'Oct 24 2022 18:26:48')
2025-10-07 21:33:29,066:INFO:machine: AMD64
2025-10-07 21:33:29,066:INFO:platform: Windows-10-10.0.26100-SP0
2025-10-07 21:33:29,073:INFO:Memory: svmem(total=34211835904, available=16665333760, percent=51.3, used=17546502144, free=16665333760)
2025-10-07 21:33:29,073:INFO:Physical Core: 6
2025-10-07 21:33:29,075:INFO:Logical Core: 12
2025-10-07 21:33:29,075:INFO:Checking libraries
2025-10-07 21:33:29,075:INFO:System:
2025-10-07 21:33:29,075:INFO:    python: 3.11.0 (main, Oct 24 2022, 18:26:48) [MSC v.1933 64 bit (AMD64)]
2025-10-07 21:33:29,075:INFO:executable: c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\python.exe
2025-10-07 21:33:29,075:INFO:   machine: Windows-10-10.0.26100-SP0
2025-10-07 21:33:29,075:INFO:PyCaret required dependencies:
2025-10-07 21:33:29,188:INFO:                 pip: 22.3
2025-10-07 21:33:29,188:INFO:          setuptools: 65.5.0
2025-10-07 21:33:29,188:INFO:             pycaret: 3.3.2
2025-10-07 21:33:29,188:INFO:             IPython: 9.6.0
2025-10-07 21:33:29,188:INFO:          ipywidgets: 8.1.7
2025-10-07 21:33:29,188:INFO:                tqdm: 4.67.1
2025-10-07 21:33:29,188:INFO:               numpy: 1.26.4
2025-10-07 21:33:29,188:INFO:              pandas: 2.1.4
2025-10-07 21:33:29,188:INFO:              jinja2: 3.1.6
2025-10-07 21:33:29,188:INFO:               scipy: 1.11.4
2025-10-07 21:33:29,188:INFO:              joblib: 1.3.2
2025-10-07 21:33:29,188:INFO:             sklearn: 1.4.2
2025-10-07 21:33:29,188:INFO:                pyod: 2.0.5
2025-10-07 21:33:29,188:INFO:            imblearn: 0.14.0
2025-10-07 21:33:29,188:INFO:   category_encoders: 2.7.0
2025-10-07 21:33:29,189:INFO:            lightgbm: 4.6.0
2025-10-07 21:33:29,189:INFO:               numba: 0.62.1
2025-10-07 21:33:29,189:INFO:            requests: 2.32.5
2025-10-07 21:33:29,189:INFO:          matplotlib: 3.7.5
2025-10-07 21:33:29,189:INFO:          scikitplot: 0.3.7
2025-10-07 21:33:29,189:INFO:         yellowbrick: 1.5
2025-10-07 21:33:29,189:INFO:              plotly: 6.3.1
2025-10-07 21:33:29,189:INFO:    plotly-resampler: Not installed
2025-10-07 21:33:29,189:INFO:             kaleido: 1.1.0
2025-10-07 21:33:29,189:INFO:           schemdraw: 0.15
2025-10-07 21:33:29,189:INFO:         statsmodels: 0.14.5
2025-10-07 21:33:29,189:INFO:              sktime: 0.26.0
2025-10-07 21:33:29,189:INFO:               tbats: 1.1.3
2025-10-07 21:33:29,189:INFO:            pmdarima: 2.0.4
2025-10-07 21:33:29,189:INFO:              psutil: 7.1.0
2025-10-07 21:33:29,189:INFO:          markupsafe: 3.0.3
2025-10-07 21:33:29,189:INFO:             pickle5: Not installed
2025-10-07 21:33:29,189:INFO:         cloudpickle: 3.1.1
2025-10-07 21:33:29,189:INFO:         deprecation: 2.1.0
2025-10-07 21:33:29,190:INFO:              xxhash: 3.6.0
2025-10-07 21:33:29,190:INFO:           wurlitzer: Not installed
2025-10-07 21:33:29,190:INFO:PyCaret optional dependencies:
2025-10-07 21:33:29,209:INFO:                shap: Not installed
2025-10-07 21:33:29,209:INFO:           interpret: Not installed
2025-10-07 21:33:29,209:INFO:                umap: Not installed
2025-10-07 21:33:29,209:INFO:     ydata_profiling: Not installed
2025-10-07 21:33:29,210:INFO:  explainerdashboard: Not installed
2025-10-07 21:33:29,210:INFO:             autoviz: Not installed
2025-10-07 21:33:29,210:INFO:           fairlearn: Not installed
2025-10-07 21:33:29,210:INFO:          deepchecks: Not installed
2025-10-07 21:33:29,210:INFO:             xgboost: Not installed
2025-10-07 21:33:29,210:INFO:            catboost: Not installed
2025-10-07 21:33:29,210:INFO:              kmodes: Not installed
2025-10-07 21:33:29,210:INFO:             mlxtend: Not installed
2025-10-07 21:33:29,210:INFO:       statsforecast: Not installed
2025-10-07 21:33:29,210:INFO:        tune_sklearn: Not installed
2025-10-07 21:33:29,210:INFO:                 ray: Not installed
2025-10-07 21:33:29,210:INFO:            hyperopt: Not installed
2025-10-07 21:33:29,210:INFO:              optuna: Not installed
2025-10-07 21:33:29,210:INFO:               skopt: Not installed
2025-10-07 21:33:29,210:INFO:              mlflow: Not installed
2025-10-07 21:33:29,210:INFO:              gradio: Not installed
2025-10-07 21:33:29,210:INFO:             fastapi: Not installed
2025-10-07 21:33:29,210:INFO:             uvicorn: Not installed
2025-10-07 21:33:29,210:INFO:              m2cgen: Not installed
2025-10-07 21:33:29,210:INFO:           evidently: Not installed
2025-10-07 21:33:29,210:INFO:               fugue: Not installed
2025-10-07 21:33:29,210:INFO:           streamlit: Not installed
2025-10-07 21:33:29,210:INFO:             prophet: Not installed
2025-10-07 21:33:29,210:INFO:None
2025-10-07 21:33:29,210:INFO:Set up data.
2025-10-07 21:33:29,220:INFO:Set up folding strategy.
2025-10-07 21:33:29,220:INFO:Set up train/test split.
2025-10-07 21:33:29,266:INFO:Set up index.
2025-10-07 21:33:29,268:INFO:Assigning column types.
2025-10-07 21:33:29,272:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-07 21:33:29,272:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-10-07 21:33:29,278:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-07 21:33:29,282:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-07 21:33:29,343:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-07 21:33:29,394:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-07 21:33:29,394:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-07 21:33:29,395:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-07 21:33:29,395:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-10-07 21:33:29,399:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-07 21:33:29,404:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-07 21:33:29,464:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-07 21:33:29,513:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-07 21:33:29,513:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-07 21:33:29,513:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-07 21:33:29,515:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-10-07 21:33:29,520:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-07 21:33:29,523:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-07 21:33:29,586:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-07 21:33:29,637:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-07 21:33:29,638:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-07 21:33:29,638:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-07 21:33:29,642:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-07 21:33:29,648:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-07 21:33:29,720:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-07 21:33:29,766:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-07 21:33:29,769:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-07 21:33:29,769:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-07 21:33:29,769:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-10-07 21:33:29,779:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-07 21:33:29,849:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-07 21:33:29,897:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-07 21:33:29,898:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-07 21:33:29,899:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-07 21:33:29,911:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-07 21:33:29,997:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-07 21:33:30,053:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-07 21:33:30,054:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-07 21:33:30,054:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-07 21:33:30,054:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-10-07 21:33:30,135:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-07 21:33:30,198:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-07 21:33:30,200:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-07 21:33:30,201:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-07 21:33:30,307:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-07 21:33:30,381:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-07 21:33:30,382:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-07 21:33:30,382:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-07 21:33:30,383:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-07 21:33:30,492:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-07 21:33:30,541:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-07 21:33:30,542:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-07 21:33:30,618:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-07 21:33:30,668:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-07 21:33:30,668:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-07 21:33:30,668:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-10-07 21:33:30,803:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-07 21:33:30,804:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-07 21:33:30,956:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-07 21:33:30,957:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-07 21:33:30,958:INFO:Preparing preprocessing pipeline...
2025-10-07 21:33:30,959:INFO:Set up simple imputation.
2025-10-07 21:33:30,964:INFO:Set up encoding of categorical features.
2025-10-07 21:33:30,964:INFO:Set up feature normalization.
2025-10-07 21:33:31,071:INFO:Finished creating preprocessing pipeline.
2025-10-07 21:33:31,083:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\ARNALDO\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['area_m2', 'num_habitaciones',
                                             'num_banos', 'antiguedad_anos',
                                             'vista_mar'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['distrito'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['distrito'],
                                    transformer=OneHotEncoder(cols=['distrito'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2025-10-07 21:33:31,083:INFO:Creating final display dataframe.
2025-10-07 21:33:31,318:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            precio
2                   Target type        Regression
3           Original data shape          (100, 7)
4        Transformed data shape         (100, 10)
5   Transformed train set shape          (70, 10)
6    Transformed test set shape          (30, 10)
7              Numeric features                 5
8          Categorical features                 1
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                    Normalize              True
16             Normalize method            zscore
17               Fold Generator             KFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  reg-default-name
23                          USI              1442
2025-10-07 21:33:31,471:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-07 21:33:31,471:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-07 21:33:31,617:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-07 21:33:31,617:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-07 21:33:31,618:INFO:setup() successfully completed in 2.62s...............
2025-10-07 21:38:21,148:INFO:Initializing compare_models()
2025-10-07 21:38:21,148:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024057715E90>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x0000024057715E90>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2025-10-07 21:38:21,148:INFO:Checking exceptions
2025-10-07 21:38:21,151:INFO:Preparing display monitor
2025-10-07 21:38:21,183:INFO:Initializing Linear Regression
2025-10-07 21:38:21,183:INFO:Total runtime is 0.0 minutes
2025-10-07 21:38:21,190:INFO:SubProcess create_model() called ==================================
2025-10-07 21:38:21,190:INFO:Initializing create_model()
2025-10-07 21:38:21,190:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024057715E90>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024057139BD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-07 21:38:21,190:INFO:Checking exceptions
2025-10-07 21:38:21,190:INFO:Importing libraries
2025-10-07 21:38:21,190:INFO:Copying training dataset
2025-10-07 21:38:21,198:INFO:Defining folds
2025-10-07 21:38:21,199:INFO:Declaring metric variables
2025-10-07 21:38:21,207:INFO:Importing untrained model
2025-10-07 21:38:21,212:INFO:Linear Regression Imported successfully
2025-10-07 21:38:21,228:INFO:Starting cross validation
2025-10-07 21:38:21,254:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-07 21:38:31,032:INFO:Calculating mean and std
2025-10-07 21:38:31,034:INFO:Creating metrics dataframe
2025-10-07 21:38:31,040:INFO:Uploading results into container
2025-10-07 21:38:31,045:INFO:Uploading model into container now
2025-10-07 21:38:31,046:INFO:_master_model_container: 1
2025-10-07 21:38:31,046:INFO:_display_container: 2
2025-10-07 21:38:31,046:INFO:LinearRegression(n_jobs=-1)
2025-10-07 21:38:31,046:INFO:create_model() successfully completed......................................
2025-10-07 21:38:31,199:INFO:SubProcess create_model() end ==================================
2025-10-07 21:38:31,201:INFO:Creating metrics dataframe
2025-10-07 21:38:31,209:INFO:Initializing Lasso Regression
2025-10-07 21:38:31,209:INFO:Total runtime is 0.1671063184738159 minutes
2025-10-07 21:38:31,216:INFO:SubProcess create_model() called ==================================
2025-10-07 21:38:31,217:INFO:Initializing create_model()
2025-10-07 21:38:31,217:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024057715E90>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024057139BD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-07 21:38:31,217:INFO:Checking exceptions
2025-10-07 21:38:31,217:INFO:Importing libraries
2025-10-07 21:38:31,217:INFO:Copying training dataset
2025-10-07 21:38:31,231:INFO:Defining folds
2025-10-07 21:38:31,231:INFO:Declaring metric variables
2025-10-07 21:38:31,236:INFO:Importing untrained model
2025-10-07 21:38:31,243:INFO:Lasso Regression Imported successfully
2025-10-07 21:38:31,257:INFO:Starting cross validation
2025-10-07 21:38:31,259:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-07 21:38:35,646:INFO:Calculating mean and std
2025-10-07 21:38:35,648:INFO:Creating metrics dataframe
2025-10-07 21:38:35,653:INFO:Uploading results into container
2025-10-07 21:38:35,654:INFO:Uploading model into container now
2025-10-07 21:38:35,657:INFO:_master_model_container: 2
2025-10-07 21:38:35,657:INFO:_display_container: 2
2025-10-07 21:38:35,659:INFO:Lasso(random_state=123)
2025-10-07 21:38:35,659:INFO:create_model() successfully completed......................................
2025-10-07 21:38:35,826:INFO:SubProcess create_model() end ==================================
2025-10-07 21:38:35,826:INFO:Creating metrics dataframe
2025-10-07 21:38:35,838:INFO:Initializing Ridge Regression
2025-10-07 21:38:35,838:INFO:Total runtime is 0.2442510962486267 minutes
2025-10-07 21:38:35,843:INFO:SubProcess create_model() called ==================================
2025-10-07 21:38:35,844:INFO:Initializing create_model()
2025-10-07 21:38:35,844:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024057715E90>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024057139BD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-07 21:38:35,844:INFO:Checking exceptions
2025-10-07 21:38:35,844:INFO:Importing libraries
2025-10-07 21:38:35,844:INFO:Copying training dataset
2025-10-07 21:38:35,851:INFO:Defining folds
2025-10-07 21:38:35,852:INFO:Declaring metric variables
2025-10-07 21:38:35,857:INFO:Importing untrained model
2025-10-07 21:38:35,863:INFO:Ridge Regression Imported successfully
2025-10-07 21:38:35,877:INFO:Starting cross validation
2025-10-07 21:38:35,879:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-07 21:38:36,099:INFO:Calculating mean and std
2025-10-07 21:38:36,100:INFO:Creating metrics dataframe
2025-10-07 21:38:36,103:INFO:Uploading results into container
2025-10-07 21:38:36,104:INFO:Uploading model into container now
2025-10-07 21:38:36,105:INFO:_master_model_container: 3
2025-10-07 21:38:36,105:INFO:_display_container: 2
2025-10-07 21:38:36,105:INFO:Ridge(random_state=123)
2025-10-07 21:38:36,106:INFO:create_model() successfully completed......................................
2025-10-07 21:38:36,228:INFO:SubProcess create_model() end ==================================
2025-10-07 21:38:36,229:INFO:Creating metrics dataframe
2025-10-07 21:38:36,241:INFO:Initializing Elastic Net
2025-10-07 21:38:36,241:INFO:Total runtime is 0.2509597380956014 minutes
2025-10-07 21:38:36,246:INFO:SubProcess create_model() called ==================================
2025-10-07 21:38:36,247:INFO:Initializing create_model()
2025-10-07 21:38:36,247:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024057715E90>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024057139BD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-07 21:38:36,247:INFO:Checking exceptions
2025-10-07 21:38:36,248:INFO:Importing libraries
2025-10-07 21:38:36,248:INFO:Copying training dataset
2025-10-07 21:38:36,255:INFO:Defining folds
2025-10-07 21:38:36,256:INFO:Declaring metric variables
2025-10-07 21:38:36,263:INFO:Importing untrained model
2025-10-07 21:38:36,271:INFO:Elastic Net Imported successfully
2025-10-07 21:38:36,283:INFO:Starting cross validation
2025-10-07 21:38:36,284:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-07 21:38:36,509:INFO:Calculating mean and std
2025-10-07 21:38:36,511:INFO:Creating metrics dataframe
2025-10-07 21:38:36,517:INFO:Uploading results into container
2025-10-07 21:38:36,517:INFO:Uploading model into container now
2025-10-07 21:38:36,518:INFO:_master_model_container: 4
2025-10-07 21:38:36,518:INFO:_display_container: 2
2025-10-07 21:38:36,519:INFO:ElasticNet(random_state=123)
2025-10-07 21:38:36,519:INFO:create_model() successfully completed......................................
2025-10-07 21:38:36,643:INFO:SubProcess create_model() end ==================================
2025-10-07 21:38:36,643:INFO:Creating metrics dataframe
2025-10-07 21:38:36,652:INFO:Initializing Least Angle Regression
2025-10-07 21:38:36,652:INFO:Total runtime is 0.25781492789586385 minutes
2025-10-07 21:38:36,658:INFO:SubProcess create_model() called ==================================
2025-10-07 21:38:36,658:INFO:Initializing create_model()
2025-10-07 21:38:36,658:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024057715E90>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024057139BD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-07 21:38:36,659:INFO:Checking exceptions
2025-10-07 21:38:36,659:INFO:Importing libraries
2025-10-07 21:38:36,659:INFO:Copying training dataset
2025-10-07 21:38:36,663:INFO:Defining folds
2025-10-07 21:38:36,665:INFO:Declaring metric variables
2025-10-07 21:38:36,673:INFO:Importing untrained model
2025-10-07 21:38:36,679:INFO:Least Angle Regression Imported successfully
2025-10-07 21:38:36,687:INFO:Starting cross validation
2025-10-07 21:38:36,689:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-07 21:38:36,885:INFO:Calculating mean and std
2025-10-07 21:38:36,886:INFO:Creating metrics dataframe
2025-10-07 21:38:36,889:INFO:Uploading results into container
2025-10-07 21:38:36,889:INFO:Uploading model into container now
2025-10-07 21:38:36,891:INFO:_master_model_container: 5
2025-10-07 21:38:36,892:INFO:_display_container: 2
2025-10-07 21:38:36,893:INFO:Lars(random_state=123)
2025-10-07 21:38:36,893:INFO:create_model() successfully completed......................................
2025-10-07 21:38:37,018:INFO:SubProcess create_model() end ==================================
2025-10-07 21:38:37,018:INFO:Creating metrics dataframe
2025-10-07 21:38:37,027:INFO:Initializing Lasso Least Angle Regression
2025-10-07 21:38:37,027:INFO:Total runtime is 0.2640717585881551 minutes
2025-10-07 21:38:37,033:INFO:SubProcess create_model() called ==================================
2025-10-07 21:38:37,034:INFO:Initializing create_model()
2025-10-07 21:38:37,034:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024057715E90>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024057139BD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-07 21:38:37,034:INFO:Checking exceptions
2025-10-07 21:38:37,034:INFO:Importing libraries
2025-10-07 21:38:37,034:INFO:Copying training dataset
2025-10-07 21:38:37,042:INFO:Defining folds
2025-10-07 21:38:37,043:INFO:Declaring metric variables
2025-10-07 21:38:37,055:INFO:Importing untrained model
2025-10-07 21:38:37,066:INFO:Lasso Least Angle Regression Imported successfully
2025-10-07 21:38:37,090:INFO:Starting cross validation
2025-10-07 21:38:37,095:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-07 21:38:37,323:INFO:Calculating mean and std
2025-10-07 21:38:37,324:INFO:Creating metrics dataframe
2025-10-07 21:38:37,327:INFO:Uploading results into container
2025-10-07 21:38:37,328:INFO:Uploading model into container now
2025-10-07 21:38:37,329:INFO:_master_model_container: 6
2025-10-07 21:38:37,329:INFO:_display_container: 2
2025-10-07 21:38:37,331:INFO:LassoLars(random_state=123)
2025-10-07 21:38:37,331:INFO:create_model() successfully completed......................................
2025-10-07 21:38:37,456:INFO:SubProcess create_model() end ==================================
2025-10-07 21:38:37,456:INFO:Creating metrics dataframe
2025-10-07 21:38:37,467:INFO:Initializing Orthogonal Matching Pursuit
2025-10-07 21:38:37,467:INFO:Total runtime is 0.2714057048161825 minutes
2025-10-07 21:38:37,472:INFO:SubProcess create_model() called ==================================
2025-10-07 21:38:37,473:INFO:Initializing create_model()
2025-10-07 21:38:37,473:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024057715E90>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024057139BD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-07 21:38:37,473:INFO:Checking exceptions
2025-10-07 21:38:37,473:INFO:Importing libraries
2025-10-07 21:38:37,473:INFO:Copying training dataset
2025-10-07 21:38:37,482:INFO:Defining folds
2025-10-07 21:38:37,482:INFO:Declaring metric variables
2025-10-07 21:38:37,486:INFO:Importing untrained model
2025-10-07 21:38:37,490:INFO:Orthogonal Matching Pursuit Imported successfully
2025-10-07 21:38:37,500:INFO:Starting cross validation
2025-10-07 21:38:37,502:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-07 21:38:37,714:INFO:Calculating mean and std
2025-10-07 21:38:37,715:INFO:Creating metrics dataframe
2025-10-07 21:38:37,718:INFO:Uploading results into container
2025-10-07 21:38:37,719:INFO:Uploading model into container now
2025-10-07 21:38:37,719:INFO:_master_model_container: 7
2025-10-07 21:38:37,719:INFO:_display_container: 2
2025-10-07 21:38:37,720:INFO:OrthogonalMatchingPursuit()
2025-10-07 21:38:37,720:INFO:create_model() successfully completed......................................
2025-10-07 21:38:37,839:INFO:SubProcess create_model() end ==================================
2025-10-07 21:38:37,839:INFO:Creating metrics dataframe
2025-10-07 21:38:37,849:INFO:Initializing Bayesian Ridge
2025-10-07 21:38:37,849:INFO:Total runtime is 0.27777260541915894 minutes
2025-10-07 21:38:37,853:INFO:SubProcess create_model() called ==================================
2025-10-07 21:38:37,854:INFO:Initializing create_model()
2025-10-07 21:38:37,854:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024057715E90>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024057139BD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-07 21:38:37,854:INFO:Checking exceptions
2025-10-07 21:38:37,854:INFO:Importing libraries
2025-10-07 21:38:37,854:INFO:Copying training dataset
2025-10-07 21:38:37,861:INFO:Defining folds
2025-10-07 21:38:37,861:INFO:Declaring metric variables
2025-10-07 21:38:37,871:INFO:Importing untrained model
2025-10-07 21:38:37,877:INFO:Bayesian Ridge Imported successfully
2025-10-07 21:38:37,885:INFO:Starting cross validation
2025-10-07 21:38:37,887:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-07 21:38:38,099:INFO:Calculating mean and std
2025-10-07 21:38:38,101:INFO:Creating metrics dataframe
2025-10-07 21:38:38,103:INFO:Uploading results into container
2025-10-07 21:38:38,103:INFO:Uploading model into container now
2025-10-07 21:38:38,104:INFO:_master_model_container: 8
2025-10-07 21:38:38,104:INFO:_display_container: 2
2025-10-07 21:38:38,105:INFO:BayesianRidge()
2025-10-07 21:38:38,105:INFO:create_model() successfully completed......................................
2025-10-07 21:38:38,224:INFO:SubProcess create_model() end ==================================
2025-10-07 21:38:38,224:INFO:Creating metrics dataframe
2025-10-07 21:38:38,239:INFO:Initializing Passive Aggressive Regressor
2025-10-07 21:38:38,239:INFO:Total runtime is 0.2842717369397481 minutes
2025-10-07 21:38:38,243:INFO:SubProcess create_model() called ==================================
2025-10-07 21:38:38,245:INFO:Initializing create_model()
2025-10-07 21:38:38,245:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024057715E90>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024057139BD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-07 21:38:38,246:INFO:Checking exceptions
2025-10-07 21:38:38,246:INFO:Importing libraries
2025-10-07 21:38:38,247:INFO:Copying training dataset
2025-10-07 21:38:38,253:INFO:Defining folds
2025-10-07 21:38:38,253:INFO:Declaring metric variables
2025-10-07 21:38:38,261:INFO:Importing untrained model
2025-10-07 21:38:38,269:INFO:Passive Aggressive Regressor Imported successfully
2025-10-07 21:38:38,282:INFO:Starting cross validation
2025-10-07 21:38:38,283:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-07 21:38:38,426:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-10-07 21:38:38,426:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-10-07 21:38:38,426:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-10-07 21:38:38,427:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-10-07 21:38:38,427:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-10-07 21:38:38,427:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-10-07 21:38:38,442:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-10-07 21:38:38,444:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-10-07 21:38:38,494:INFO:Calculating mean and std
2025-10-07 21:38:38,495:INFO:Creating metrics dataframe
2025-10-07 21:38:38,498:INFO:Uploading results into container
2025-10-07 21:38:38,498:INFO:Uploading model into container now
2025-10-07 21:38:38,499:INFO:_master_model_container: 9
2025-10-07 21:38:38,499:INFO:_display_container: 2
2025-10-07 21:38:38,499:INFO:PassiveAggressiveRegressor(random_state=123)
2025-10-07 21:38:38,500:INFO:create_model() successfully completed......................................
2025-10-07 21:38:38,628:INFO:SubProcess create_model() end ==================================
2025-10-07 21:38:38,628:INFO:Creating metrics dataframe
2025-10-07 21:38:38,639:INFO:Initializing Huber Regressor
2025-10-07 21:38:38,639:INFO:Total runtime is 0.2909395058949788 minutes
2025-10-07 21:38:38,644:INFO:SubProcess create_model() called ==================================
2025-10-07 21:38:38,644:INFO:Initializing create_model()
2025-10-07 21:38:38,644:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024057715E90>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024057139BD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-07 21:38:38,645:INFO:Checking exceptions
2025-10-07 21:38:38,645:INFO:Importing libraries
2025-10-07 21:38:38,645:INFO:Copying training dataset
2025-10-07 21:38:38,651:INFO:Defining folds
2025-10-07 21:38:38,651:INFO:Declaring metric variables
2025-10-07 21:38:38,657:INFO:Importing untrained model
2025-10-07 21:38:38,662:INFO:Huber Regressor Imported successfully
2025-10-07 21:38:38,675:INFO:Starting cross validation
2025-10-07 21:38:38,679:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-07 21:38:38,926:INFO:Calculating mean and std
2025-10-07 21:38:38,928:INFO:Creating metrics dataframe
2025-10-07 21:38:38,931:INFO:Uploading results into container
2025-10-07 21:38:38,932:INFO:Uploading model into container now
2025-10-07 21:38:38,933:INFO:_master_model_container: 10
2025-10-07 21:38:38,933:INFO:_display_container: 2
2025-10-07 21:38:38,934:INFO:HuberRegressor()
2025-10-07 21:38:38,934:INFO:create_model() successfully completed......................................
2025-10-07 21:38:39,081:INFO:SubProcess create_model() end ==================================
2025-10-07 21:38:39,082:INFO:Creating metrics dataframe
2025-10-07 21:38:39,095:INFO:Initializing K Neighbors Regressor
2025-10-07 21:38:39,095:INFO:Total runtime is 0.29854038556416823 minutes
2025-10-07 21:38:39,103:INFO:SubProcess create_model() called ==================================
2025-10-07 21:38:39,104:INFO:Initializing create_model()
2025-10-07 21:38:39,104:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024057715E90>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024057139BD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-07 21:38:39,104:INFO:Checking exceptions
2025-10-07 21:38:39,104:INFO:Importing libraries
2025-10-07 21:38:39,104:INFO:Copying training dataset
2025-10-07 21:38:39,116:INFO:Defining folds
2025-10-07 21:38:39,117:INFO:Declaring metric variables
2025-10-07 21:38:39,126:INFO:Importing untrained model
2025-10-07 21:38:39,133:INFO:K Neighbors Regressor Imported successfully
2025-10-07 21:38:39,157:INFO:Starting cross validation
2025-10-07 21:38:39,159:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-07 21:38:39,449:INFO:Calculating mean and std
2025-10-07 21:38:39,451:INFO:Creating metrics dataframe
2025-10-07 21:38:39,455:INFO:Uploading results into container
2025-10-07 21:38:39,456:INFO:Uploading model into container now
2025-10-07 21:38:39,457:INFO:_master_model_container: 11
2025-10-07 21:38:39,458:INFO:_display_container: 2
2025-10-07 21:38:39,458:INFO:KNeighborsRegressor(n_jobs=-1)
2025-10-07 21:38:39,459:INFO:create_model() successfully completed......................................
2025-10-07 21:38:39,603:INFO:SubProcess create_model() end ==================================
2025-10-07 21:38:39,603:INFO:Creating metrics dataframe
2025-10-07 21:38:39,619:INFO:Initializing Decision Tree Regressor
2025-10-07 21:38:39,619:INFO:Total runtime is 0.30726772149403886 minutes
2025-10-07 21:38:39,625:INFO:SubProcess create_model() called ==================================
2025-10-07 21:38:39,626:INFO:Initializing create_model()
2025-10-07 21:38:39,626:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024057715E90>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024057139BD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-07 21:38:39,626:INFO:Checking exceptions
2025-10-07 21:38:39,626:INFO:Importing libraries
2025-10-07 21:38:39,626:INFO:Copying training dataset
2025-10-07 21:38:39,633:INFO:Defining folds
2025-10-07 21:38:39,633:INFO:Declaring metric variables
2025-10-07 21:38:39,639:INFO:Importing untrained model
2025-10-07 21:38:39,649:INFO:Decision Tree Regressor Imported successfully
2025-10-07 21:38:39,659:INFO:Starting cross validation
2025-10-07 21:38:39,662:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-07 21:38:39,909:INFO:Calculating mean and std
2025-10-07 21:38:39,911:INFO:Creating metrics dataframe
2025-10-07 21:38:39,915:INFO:Uploading results into container
2025-10-07 21:38:39,917:INFO:Uploading model into container now
2025-10-07 21:38:39,919:INFO:_master_model_container: 12
2025-10-07 21:38:39,919:INFO:_display_container: 2
2025-10-07 21:38:39,920:INFO:DecisionTreeRegressor(random_state=123)
2025-10-07 21:38:39,920:INFO:create_model() successfully completed......................................
2025-10-07 21:38:40,067:INFO:SubProcess create_model() end ==================================
2025-10-07 21:38:40,067:INFO:Creating metrics dataframe
2025-10-07 21:38:40,085:INFO:Initializing Random Forest Regressor
2025-10-07 21:38:40,085:INFO:Total runtime is 0.3150411287943522 minutes
2025-10-07 21:38:40,091:INFO:SubProcess create_model() called ==================================
2025-10-07 21:38:40,091:INFO:Initializing create_model()
2025-10-07 21:38:40,092:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024057715E90>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024057139BD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-07 21:38:40,092:INFO:Checking exceptions
2025-10-07 21:38:40,092:INFO:Importing libraries
2025-10-07 21:38:40,092:INFO:Copying training dataset
2025-10-07 21:38:40,099:INFO:Defining folds
2025-10-07 21:38:40,101:INFO:Declaring metric variables
2025-10-07 21:38:40,107:INFO:Importing untrained model
2025-10-07 21:38:40,117:INFO:Random Forest Regressor Imported successfully
2025-10-07 21:38:40,135:INFO:Starting cross validation
2025-10-07 21:38:40,137:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-07 21:38:40,778:INFO:Calculating mean and std
2025-10-07 21:38:40,780:INFO:Creating metrics dataframe
2025-10-07 21:38:40,782:INFO:Uploading results into container
2025-10-07 21:38:40,783:INFO:Uploading model into container now
2025-10-07 21:38:40,783:INFO:_master_model_container: 13
2025-10-07 21:38:40,783:INFO:_display_container: 2
2025-10-07 21:38:40,784:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-10-07 21:38:40,784:INFO:create_model() successfully completed......................................
2025-10-07 21:38:40,909:INFO:SubProcess create_model() end ==================================
2025-10-07 21:38:40,910:INFO:Creating metrics dataframe
2025-10-07 21:38:40,924:INFO:Initializing Extra Trees Regressor
2025-10-07 21:38:40,924:INFO:Total runtime is 0.32901705900828043 minutes
2025-10-07 21:38:40,932:INFO:SubProcess create_model() called ==================================
2025-10-07 21:38:40,932:INFO:Initializing create_model()
2025-10-07 21:38:40,933:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024057715E90>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024057139BD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-07 21:38:40,933:INFO:Checking exceptions
2025-10-07 21:38:40,933:INFO:Importing libraries
2025-10-07 21:38:40,933:INFO:Copying training dataset
2025-10-07 21:38:40,941:INFO:Defining folds
2025-10-07 21:38:40,941:INFO:Declaring metric variables
2025-10-07 21:38:40,946:INFO:Importing untrained model
2025-10-07 21:38:40,955:INFO:Extra Trees Regressor Imported successfully
2025-10-07 21:38:40,969:INFO:Starting cross validation
2025-10-07 21:38:40,972:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-07 21:38:41,598:INFO:Calculating mean and std
2025-10-07 21:38:41,600:INFO:Creating metrics dataframe
2025-10-07 21:38:41,603:INFO:Uploading results into container
2025-10-07 21:38:41,604:INFO:Uploading model into container now
2025-10-07 21:38:41,605:INFO:_master_model_container: 14
2025-10-07 21:38:41,605:INFO:_display_container: 2
2025-10-07 21:38:41,605:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-10-07 21:38:41,605:INFO:create_model() successfully completed......................................
2025-10-07 21:38:41,813:INFO:SubProcess create_model() end ==================================
2025-10-07 21:38:41,813:INFO:Creating metrics dataframe
2025-10-07 21:38:41,835:INFO:Initializing AdaBoost Regressor
2025-10-07 21:38:41,836:INFO:Total runtime is 0.3442215085029602 minutes
2025-10-07 21:38:41,846:INFO:SubProcess create_model() called ==================================
2025-10-07 21:38:41,847:INFO:Initializing create_model()
2025-10-07 21:38:41,847:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024057715E90>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024057139BD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-07 21:38:41,847:INFO:Checking exceptions
2025-10-07 21:38:41,847:INFO:Importing libraries
2025-10-07 21:38:41,847:INFO:Copying training dataset
2025-10-07 21:38:41,858:INFO:Defining folds
2025-10-07 21:38:41,858:INFO:Declaring metric variables
2025-10-07 21:38:41,867:INFO:Importing untrained model
2025-10-07 21:38:41,877:INFO:AdaBoost Regressor Imported successfully
2025-10-07 21:38:41,896:INFO:Starting cross validation
2025-10-07 21:38:41,898:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-07 21:38:42,416:INFO:Calculating mean and std
2025-10-07 21:38:42,419:INFO:Creating metrics dataframe
2025-10-07 21:38:42,423:INFO:Uploading results into container
2025-10-07 21:38:42,425:INFO:Uploading model into container now
2025-10-07 21:38:42,426:INFO:_master_model_container: 15
2025-10-07 21:38:42,426:INFO:_display_container: 2
2025-10-07 21:38:42,427:INFO:AdaBoostRegressor(random_state=123)
2025-10-07 21:38:42,428:INFO:create_model() successfully completed......................................
2025-10-07 21:38:42,609:INFO:SubProcess create_model() end ==================================
2025-10-07 21:38:42,609:INFO:Creating metrics dataframe
2025-10-07 21:38:42,625:INFO:Initializing Gradient Boosting Regressor
2025-10-07 21:38:42,625:INFO:Total runtime is 0.3573730071385701 minutes
2025-10-07 21:38:42,634:INFO:SubProcess create_model() called ==================================
2025-10-07 21:38:42,634:INFO:Initializing create_model()
2025-10-07 21:38:42,635:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024057715E90>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024057139BD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-07 21:38:42,635:INFO:Checking exceptions
2025-10-07 21:38:42,635:INFO:Importing libraries
2025-10-07 21:38:42,635:INFO:Copying training dataset
2025-10-07 21:38:42,641:INFO:Defining folds
2025-10-07 21:38:42,641:INFO:Declaring metric variables
2025-10-07 21:38:42,649:INFO:Importing untrained model
2025-10-07 21:38:42,659:INFO:Gradient Boosting Regressor Imported successfully
2025-10-07 21:38:42,673:INFO:Starting cross validation
2025-10-07 21:38:42,675:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-07 21:38:43,024:INFO:Calculating mean and std
2025-10-07 21:38:43,025:INFO:Creating metrics dataframe
2025-10-07 21:38:43,027:INFO:Uploading results into container
2025-10-07 21:38:43,028:INFO:Uploading model into container now
2025-10-07 21:38:43,028:INFO:_master_model_container: 16
2025-10-07 21:38:43,029:INFO:_display_container: 2
2025-10-07 21:38:43,029:INFO:GradientBoostingRegressor(random_state=123)
2025-10-07 21:38:43,031:INFO:create_model() successfully completed......................................
2025-10-07 21:38:43,155:INFO:SubProcess create_model() end ==================================
2025-10-07 21:38:43,155:INFO:Creating metrics dataframe
2025-10-07 21:38:43,183:INFO:Initializing Light Gradient Boosting Machine
2025-10-07 21:38:43,184:INFO:Total runtime is 0.3666888276735941 minutes
2025-10-07 21:38:43,191:INFO:SubProcess create_model() called ==================================
2025-10-07 21:38:43,192:INFO:Initializing create_model()
2025-10-07 21:38:43,193:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024057715E90>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024057139BD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-07 21:38:43,193:INFO:Checking exceptions
2025-10-07 21:38:43,193:INFO:Importing libraries
2025-10-07 21:38:43,193:INFO:Copying training dataset
2025-10-07 21:38:43,202:INFO:Defining folds
2025-10-07 21:38:43,203:INFO:Declaring metric variables
2025-10-07 21:38:43,211:INFO:Importing untrained model
2025-10-07 21:38:43,219:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-07 21:38:43,234:INFO:Starting cross validation
2025-10-07 21:38:43,238:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-07 21:38:43,803:INFO:Calculating mean and std
2025-10-07 21:38:43,807:INFO:Creating metrics dataframe
2025-10-07 21:38:43,811:INFO:Uploading results into container
2025-10-07 21:38:43,812:INFO:Uploading model into container now
2025-10-07 21:38:43,813:INFO:_master_model_container: 17
2025-10-07 21:38:43,813:INFO:_display_container: 2
2025-10-07 21:38:43,816:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-10-07 21:38:43,816:INFO:create_model() successfully completed......................................
2025-10-07 21:38:43,966:INFO:SubProcess create_model() end ==================================
2025-10-07 21:38:43,966:INFO:Creating metrics dataframe
2025-10-07 21:38:43,981:INFO:Initializing Dummy Regressor
2025-10-07 21:38:43,982:INFO:Total runtime is 0.379983119169871 minutes
2025-10-07 21:38:43,990:INFO:SubProcess create_model() called ==================================
2025-10-07 21:38:43,991:INFO:Initializing create_model()
2025-10-07 21:38:43,991:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024057715E90>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024057139BD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-07 21:38:43,991:INFO:Checking exceptions
2025-10-07 21:38:43,991:INFO:Importing libraries
2025-10-07 21:38:43,991:INFO:Copying training dataset
2025-10-07 21:38:43,997:INFO:Defining folds
2025-10-07 21:38:43,997:INFO:Declaring metric variables
2025-10-07 21:38:44,005:INFO:Importing untrained model
2025-10-07 21:38:44,011:INFO:Dummy Regressor Imported successfully
2025-10-07 21:38:44,025:INFO:Starting cross validation
2025-10-07 21:38:44,027:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-07 21:38:44,228:INFO:Calculating mean and std
2025-10-07 21:38:44,229:INFO:Creating metrics dataframe
2025-10-07 21:38:44,232:INFO:Uploading results into container
2025-10-07 21:38:44,233:INFO:Uploading model into container now
2025-10-07 21:38:44,233:INFO:_master_model_container: 18
2025-10-07 21:38:44,233:INFO:_display_container: 2
2025-10-07 21:38:44,234:INFO:DummyRegressor()
2025-10-07 21:38:44,234:INFO:create_model() successfully completed......................................
2025-10-07 21:38:44,357:INFO:SubProcess create_model() end ==================================
2025-10-07 21:38:44,358:INFO:Creating metrics dataframe
2025-10-07 21:38:44,376:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-10-07 21:38:44,388:INFO:Initializing create_model()
2025-10-07 21:38:44,388:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024057715E90>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-07 21:38:44,388:INFO:Checking exceptions
2025-10-07 21:38:44,392:INFO:Importing libraries
2025-10-07 21:38:44,392:INFO:Copying training dataset
2025-10-07 21:38:44,399:INFO:Defining folds
2025-10-07 21:38:44,399:INFO:Declaring metric variables
2025-10-07 21:38:44,399:INFO:Importing untrained model
2025-10-07 21:38:44,399:INFO:Declaring custom model
2025-10-07 21:38:44,401:INFO:Linear Regression Imported successfully
2025-10-07 21:38:44,403:INFO:Cross validation set to False
2025-10-07 21:38:44,403:INFO:Fitting Model
2025-10-07 21:38:44,463:INFO:LinearRegression(n_jobs=-1)
2025-10-07 21:38:44,463:INFO:create_model() successfully completed......................................
2025-10-07 21:38:44,649:INFO:_master_model_container: 18
2025-10-07 21:38:44,649:INFO:_display_container: 2
2025-10-07 21:38:44,651:INFO:LinearRegression(n_jobs=-1)
2025-10-07 21:38:44,651:INFO:compare_models() successfully completed......................................
2025-10-07 21:48:59,108:INFO:Initializing create_model()
2025-10-07 21:48:59,108:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024057715E90>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-07 21:48:59,110:INFO:Checking exceptions
2025-10-07 21:48:59,135:INFO:Importing libraries
2025-10-07 21:48:59,136:INFO:Copying training dataset
2025-10-07 21:48:59,145:INFO:Defining folds
2025-10-07 21:48:59,145:INFO:Declaring metric variables
2025-10-07 21:48:59,151:INFO:Importing untrained model
2025-10-07 21:48:59,162:INFO:Linear Regression Imported successfully
2025-10-07 21:48:59,178:INFO:Starting cross validation
2025-10-07 21:48:59,181:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-07 21:49:09,055:INFO:Calculating mean and std
2025-10-07 21:49:09,062:INFO:Creating metrics dataframe
2025-10-07 21:49:09,078:INFO:Finalizing model
2025-10-07 21:49:09,174:INFO:Uploading results into container
2025-10-07 21:49:09,174:INFO:Uploading model into container now
2025-10-07 21:49:09,193:INFO:_master_model_container: 19
2025-10-07 21:49:09,193:INFO:_display_container: 3
2025-10-07 21:49:09,194:INFO:LinearRegression(n_jobs=-1)
2025-10-07 21:49:09,194:INFO:create_model() successfully completed......................................
2025-10-07 21:52:12,455:INFO:Initializing tune_model()
2025-10-07 21:52:12,455:INFO:tune_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024057715E90>, estimator=LinearRegression(n_jobs=-1), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-10-07 21:52:12,455:INFO:Checking exceptions
2025-10-07 21:52:12,485:INFO:Copying training dataset
2025-10-07 21:52:12,489:INFO:Checking base model
2025-10-07 21:52:12,489:INFO:Base model : Linear Regression
2025-10-07 21:52:12,496:INFO:Declaring metric variables
2025-10-07 21:52:12,501:INFO:Defining Hyperparameters
2025-10-07 21:52:12,501:INFO:10 is bigger than total combinations 2, setting search algorithm to grid
2025-10-07 21:52:12,650:INFO:Tuning with n_jobs=-1
2025-10-07 21:52:12,650:INFO:Initializing GridSearchCV
2025-10-07 21:52:16,931:INFO:best_params: {'actual_estimator__fit_intercept': True}
2025-10-07 21:52:16,933:INFO:Hyperparameter search completed
2025-10-07 21:52:16,934:INFO:SubProcess create_model() called ==================================
2025-10-07 21:52:16,934:INFO:Initializing create_model()
2025-10-07 21:52:17,031:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024057715E90>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024057643FD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'fit_intercept': True})
2025-10-07 21:52:17,031:INFO:Checking exceptions
2025-10-07 21:52:17,031:INFO:Importing libraries
2025-10-07 21:52:17,031:INFO:Copying training dataset
2025-10-07 21:52:17,038:INFO:Defining folds
2025-10-07 21:52:17,038:INFO:Declaring metric variables
2025-10-07 21:52:17,045:INFO:Importing untrained model
2025-10-07 21:52:17,045:INFO:Declaring custom model
2025-10-07 21:52:17,049:INFO:Linear Regression Imported successfully
2025-10-07 21:52:17,060:INFO:Starting cross validation
2025-10-07 21:52:17,063:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-07 21:52:17,272:INFO:Calculating mean and std
2025-10-07 21:52:17,274:INFO:Creating metrics dataframe
2025-10-07 21:52:17,285:INFO:Finalizing model
2025-10-07 21:52:17,340:INFO:Uploading results into container
2025-10-07 21:52:17,341:INFO:Uploading model into container now
2025-10-07 21:52:17,341:INFO:_master_model_container: 20
2025-10-07 21:52:17,341:INFO:_display_container: 4
2025-10-07 21:52:17,343:INFO:LinearRegression(n_jobs=-1)
2025-10-07 21:52:17,343:INFO:create_model() successfully completed......................................
2025-10-07 21:52:17,476:INFO:SubProcess create_model() end ==================================
2025-10-07 21:52:17,476:INFO:choose_better activated
2025-10-07 21:52:17,480:INFO:SubProcess create_model() called ==================================
2025-10-07 21:52:17,481:INFO:Initializing create_model()
2025-10-07 21:52:17,481:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024057715E90>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-07 21:52:17,483:INFO:Checking exceptions
2025-10-07 21:52:17,486:INFO:Importing libraries
2025-10-07 21:52:17,487:INFO:Copying training dataset
2025-10-07 21:52:17,493:INFO:Defining folds
2025-10-07 21:52:17,493:INFO:Declaring metric variables
2025-10-07 21:52:17,494:INFO:Importing untrained model
2025-10-07 21:52:17,494:INFO:Declaring custom model
2025-10-07 21:52:17,495:INFO:Linear Regression Imported successfully
2025-10-07 21:52:17,495:INFO:Starting cross validation
2025-10-07 21:52:17,497:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-07 21:52:17,682:INFO:Calculating mean and std
2025-10-07 21:52:17,682:INFO:Creating metrics dataframe
2025-10-07 21:52:17,684:INFO:Finalizing model
2025-10-07 21:52:17,723:INFO:Uploading results into container
2025-10-07 21:52:17,724:INFO:Uploading model into container now
2025-10-07 21:52:17,724:INFO:_master_model_container: 21
2025-10-07 21:52:17,724:INFO:_display_container: 5
2025-10-07 21:52:17,724:INFO:LinearRegression(n_jobs=-1)
2025-10-07 21:52:17,724:INFO:create_model() successfully completed......................................
2025-10-07 21:52:17,856:INFO:SubProcess create_model() end ==================================
2025-10-07 21:52:17,856:INFO:LinearRegression(n_jobs=-1) result for R2 is 0.9593
2025-10-07 21:52:17,857:INFO:LinearRegression(n_jobs=-1) result for R2 is 0.9593
2025-10-07 21:52:17,857:INFO:LinearRegression(n_jobs=-1) is best model
2025-10-07 21:52:17,857:INFO:choose_better completed
2025-10-07 21:52:17,857:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-10-07 21:52:17,870:INFO:_master_model_container: 21
2025-10-07 21:52:17,870:INFO:_display_container: 4
2025-10-07 21:52:17,871:INFO:LinearRegression(n_jobs=-1)
2025-10-07 21:52:17,871:INFO:tune_model() successfully completed......................................
2025-10-07 21:54:33,473:INFO:Initializing evaluate_model()
2025-10-07 21:54:33,473:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024057715E90>, estimator=<function tune_model at 0x0000024055AD0900>, fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-10-07 21:54:33,495:INFO:Initializing plot_model()
2025-10-07 21:54:33,495:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024057715E90>, estimator=<function tune_model at 0x0000024055AD0900>, plot=pipeline, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-07 21:54:33,495:INFO:Checking exceptions
2025-10-07 21:54:42,067:INFO:Initializing plot_model()
2025-10-07 21:54:42,067:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024057715E90>, estimator=<function tune_model at 0x0000024055AD0900>, plot=parameter, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-07 21:54:42,067:INFO:Checking exceptions
2025-10-07 21:54:43,092:INFO:Initializing plot_model()
2025-10-07 21:54:43,092:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024057715E90>, estimator=<function tune_model at 0x0000024055AD0900>, plot=pipeline, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-07 21:54:43,092:INFO:Checking exceptions
2025-10-07 21:55:01,302:INFO:Initializing evaluate_model()
2025-10-07 21:55:01,302:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024057715E90>, estimator=LinearRegression(n_jobs=-1), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-10-07 21:55:01,316:INFO:Initializing plot_model()
2025-10-07 21:55:01,316:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024057715E90>, estimator=LinearRegression(n_jobs=-1), plot=pipeline, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-07 21:55:01,317:INFO:Checking exceptions
2025-10-07 21:55:01,318:INFO:Preloading libraries
2025-10-07 21:55:01,318:INFO:Copying training dataset
2025-10-07 21:55:01,318:INFO:Plot type: pipeline
2025-10-07 21:55:01,604:INFO:Visual Rendered Successfully
2025-10-07 21:55:01,731:INFO:plot_model() successfully completed......................................
2025-10-07 21:55:25,105:INFO:Initializing plot_model()
2025-10-07 21:55:25,106:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024057715E90>, estimator=LinearRegression(n_jobs=-1), plot=parameter, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-07 21:55:25,106:INFO:Checking exceptions
2025-10-07 21:55:25,109:INFO:Preloading libraries
2025-10-07 21:55:25,110:INFO:Copying training dataset
2025-10-07 21:55:25,110:INFO:Plot type: parameter
2025-10-07 21:55:25,112:INFO:Visual Rendered Successfully
2025-10-07 21:55:25,211:INFO:plot_model() successfully completed......................................
2025-10-07 21:55:29,684:INFO:Initializing plot_model()
2025-10-07 21:55:29,684:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024057715E90>, estimator=LinearRegression(n_jobs=-1), plot=residuals, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-07 21:55:29,685:INFO:Checking exceptions
2025-10-07 21:55:29,687:INFO:Preloading libraries
2025-10-07 21:55:29,689:INFO:Copying training dataset
2025-10-07 21:55:29,689:INFO:Plot type: residuals
2025-10-07 21:55:29,881:INFO:Fitting Model
2025-10-07 21:55:29,897:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names
  warnings.warn(

2025-10-07 21:55:29,929:INFO:Scoring test/hold-out set
2025-10-07 21:55:30,439:INFO:Visual Rendered Successfully
2025-10-07 21:55:30,564:INFO:plot_model() successfully completed......................................
2025-10-07 21:55:41,021:INFO:Initializing plot_model()
2025-10-07 21:55:41,023:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024057715E90>, estimator=LinearRegression(n_jobs=-1), plot=error, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-07 21:55:41,023:INFO:Checking exceptions
2025-10-07 21:55:41,025:INFO:Preloading libraries
2025-10-07 21:55:41,025:INFO:Copying training dataset
2025-10-07 21:55:41,025:INFO:Plot type: error
2025-10-07 21:55:41,167:INFO:Fitting Model
2025-10-07 21:55:41,167:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names
  warnings.warn(

2025-10-07 21:55:41,167:INFO:Scoring test/hold-out set
2025-10-07 21:55:41,374:INFO:Visual Rendered Successfully
2025-10-07 21:55:41,511:INFO:plot_model() successfully completed......................................
2025-10-07 21:55:47,343:INFO:Initializing plot_model()
2025-10-07 21:55:47,343:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024057715E90>, estimator=LinearRegression(n_jobs=-1), plot=cooks, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-07 21:55:47,343:INFO:Checking exceptions
2025-10-07 21:55:47,345:INFO:Preloading libraries
2025-10-07 21:55:47,345:INFO:Copying training dataset
2025-10-07 21:55:47,346:INFO:Plot type: cooks
2025-10-07 21:55:47,489:INFO:Fitting Model
2025-10-07 21:55:47,658:INFO:Visual Rendered Successfully
2025-10-07 21:55:47,791:INFO:plot_model() successfully completed......................................
2025-10-07 21:56:00,034:INFO:Initializing plot_model()
2025-10-07 21:56:00,034:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024057715E90>, estimator=LinearRegression(n_jobs=-1), plot=rfe, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-07 21:56:00,034:INFO:Checking exceptions
2025-10-07 21:56:00,037:INFO:Preloading libraries
2025-10-07 21:56:00,038:INFO:Copying training dataset
2025-10-07 21:56:00,038:INFO:Plot type: rfe
2025-10-07 21:56:00,211:INFO:Fitting Model
2025-10-07 21:56:00,847:INFO:Visual Rendered Successfully
2025-10-07 21:56:00,975:INFO:plot_model() successfully completed......................................
2025-10-07 21:56:49,244:INFO:Initializing plot_model()
2025-10-07 21:56:49,244:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024057715E90>, estimator=LinearRegression(n_jobs=-1), plot=learning, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-07 21:56:49,244:INFO:Checking exceptions
2025-10-07 21:56:49,248:INFO:Preloading libraries
2025-10-07 21:56:49,248:INFO:Copying training dataset
2025-10-07 21:56:49,248:INFO:Plot type: learning
2025-10-07 21:56:49,392:INFO:Fitting Model
2025-10-07 21:56:49,686:INFO:Visual Rendered Successfully
2025-10-07 21:56:49,819:INFO:plot_model() successfully completed......................................
2025-10-07 21:56:57,107:INFO:Initializing plot_model()
2025-10-07 21:56:57,107:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024057715E90>, estimator=LinearRegression(n_jobs=-1), plot=feature, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-07 21:56:57,107:INFO:Checking exceptions
2025-10-07 21:56:57,111:INFO:Preloading libraries
2025-10-07 21:56:57,111:INFO:Copying training dataset
2025-10-07 21:56:57,111:INFO:Plot type: feature
2025-10-07 21:56:57,301:INFO:Visual Rendered Successfully
2025-10-07 21:56:57,387:INFO:plot_model() successfully completed......................................
2025-10-07 21:57:42,940:INFO:Initializing plot_model()
2025-10-07 21:57:42,940:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024057715E90>, estimator=LinearRegression(n_jobs=-1), plot=feature_all, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-07 21:57:42,940:INFO:Checking exceptions
2025-10-07 21:57:42,943:INFO:Preloading libraries
2025-10-07 21:57:42,943:INFO:Copying training dataset
2025-10-07 21:57:42,943:INFO:Plot type: feature_all
2025-10-07 21:57:43,140:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\_tight_bbox.py:67: RuntimeWarning: divide by zero encountered in scalar divide
  fig.patch.set_bounds(x0 / w1, y0 / h1,

2025-10-07 21:57:43,140:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\_tight_bbox.py:68: RuntimeWarning: divide by zero encountered in scalar divide
  fig.bbox.width / w1, fig.bbox.height / h1)

2025-10-07 21:57:43,161:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\patches.py:739: RuntimeWarning: invalid value encountered in scalar add
  y1 = self.convert_yunits(self._y0 + self._height)

2025-10-07 21:57:43,179:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\transforms.py:2050: RuntimeWarning: invalid value encountered in scalar add
  self._mtx[1, 2] += ty

2025-10-07 21:57:43,211:INFO:Visual Rendered Successfully
2025-10-07 21:57:43,301:INFO:plot_model() successfully completed......................................
2025-10-07 21:57:47,396:INFO:Initializing plot_model()
2025-10-07 21:57:47,397:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024057715E90>, estimator=LinearRegression(n_jobs=-1), plot=feature, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-07 21:57:47,397:INFO:Checking exceptions
2025-10-07 21:57:47,399:INFO:Preloading libraries
2025-10-07 21:57:47,399:INFO:Copying training dataset
2025-10-07 21:57:47,399:INFO:Plot type: feature
2025-10-07 21:57:47,625:INFO:Visual Rendered Successfully
2025-10-07 21:57:47,751:INFO:plot_model() successfully completed......................................
2025-10-07 21:58:02,934:INFO:Initializing plot_model()
2025-10-07 21:58:02,935:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024057715E90>, estimator=LinearRegression(n_jobs=-1), plot=tree, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-07 21:58:02,935:INFO:Checking exceptions
2025-10-07 21:58:04,697:INFO:Initializing plot_model()
2025-10-07 21:58:04,697:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024057715E90>, estimator=LinearRegression(n_jobs=-1), plot=feature_all, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-07 21:58:04,697:INFO:Checking exceptions
2025-10-07 21:58:04,700:INFO:Preloading libraries
2025-10-07 21:58:04,701:INFO:Copying training dataset
2025-10-07 21:58:04,701:INFO:Plot type: feature_all
2025-10-07 21:58:04,901:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\_tight_bbox.py:67: RuntimeWarning: divide by zero encountered in scalar divide
  fig.patch.set_bounds(x0 / w1, y0 / h1,

2025-10-07 21:58:04,902:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\_tight_bbox.py:68: RuntimeWarning: divide by zero encountered in scalar divide
  fig.bbox.width / w1, fig.bbox.height / h1)

2025-10-07 21:58:04,902:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\patches.py:739: RuntimeWarning: invalid value encountered in scalar add
  y1 = self.convert_yunits(self._y0 + self._height)

2025-10-07 21:58:04,902:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\transforms.py:2050: RuntimeWarning: invalid value encountered in scalar add
  self._mtx[1, 2] += ty

2025-10-07 21:58:04,944:INFO:Visual Rendered Successfully
2025-10-07 21:58:05,064:INFO:plot_model() successfully completed......................................
2025-10-07 21:58:06,230:INFO:Initializing plot_model()
2025-10-07 21:58:06,230:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024057715E90>, estimator=LinearRegression(n_jobs=-1), plot=feature, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-07 21:58:06,231:INFO:Checking exceptions
2025-10-07 21:58:06,233:INFO:Preloading libraries
2025-10-07 21:58:06,234:INFO:Copying training dataset
2025-10-07 21:58:06,234:INFO:Plot type: feature
2025-10-07 21:58:06,425:INFO:Visual Rendered Successfully
2025-10-07 21:58:06,520:INFO:plot_model() successfully completed......................................
2025-10-07 21:59:11,367:INFO:Initializing predict_model()
2025-10-07 21:59:11,367:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024057715E90>, estimator=LinearRegression(n_jobs=-1), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000240580DA700>)
2025-10-07 21:59:11,367:INFO:Checking exceptions
2025-10-07 21:59:11,367:INFO:Preloading libraries
2025-10-07 21:59:11,568:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(

2025-10-07 21:59:24,365:INFO:Initializing predict_model()
2025-10-07 21:59:24,366:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024057715E90>, estimator=LinearRegression(n_jobs=-1), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000024057B2BA60>)
2025-10-07 21:59:24,366:INFO:Checking exceptions
2025-10-07 21:59:24,366:INFO:Preloading libraries
2025-10-07 21:59:24,496:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(

2025-10-07 22:01:34,540:INFO:Initializing save_model()
2025-10-07 22:01:34,540:INFO:save_model(model=LinearRegression(n_jobs=-1), model_name=modelo_precio_final, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\ARNALDO\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['area_m2', 'num_habitaciones',
                                             'num_banos', 'antiguedad_anos',
                                             'vista_mar'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['distrito'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['distrito'],
                                    transformer=OneHotEncoder(cols=['distrito'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-10-07 22:01:34,540:INFO:Adding model into prep_pipe
2025-10-07 22:01:34,549:INFO:modelo_precio_final.pkl saved in current working directory
2025-10-07 22:01:34,563:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['area_m2', 'num_habitaciones',
                                             'num_banos', 'antiguedad_anos',
                                             'vista_mar'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['distrito'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['distrito'],
                                    transformer=OneHotEncoder(cols=['distrito'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('trained_model', LinearRegression(n_jobs=-1))])
2025-10-07 22:01:34,563:INFO:save_model() successfully completed......................................
2025-10-09 20:15:26,276:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-09 20:15:26,607:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-09 20:15:26,607:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-09 20:15:26,607:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-09 20:23:14,361:INFO:PyCaret ClassificationExperiment
2025-10-09 20:23:14,361:INFO:Logging name: clf-default-name
2025-10-09 20:23:14,361:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-10-09 20:23:14,361:INFO:version 3.3.2
2025-10-09 20:23:14,361:INFO:Initializing setup()
2025-10-09 20:23:14,362:INFO:self.USI: 3ab0
2025-10-09 20:23:14,362:INFO:self._variable_keys: {'fold_generator', 'gpu_n_jobs_param', '_ml_usecase', 'X', 'X_test', 'y_train', 'y', 'is_multiclass', 'memory', 'fix_imbalance', 'X_train', 'exp_name_log', 'target_param', 'exp_id', 'idx', 'logging_param', 'fold_groups_param', 'data', 'n_jobs_param', 'y_test', 'seed', 'gpu_param', 'html_param', '_available_plots', 'fold_shuffle_param', 'log_plots_param', 'pipeline', 'USI'}
2025-10-09 20:23:14,362:INFO:Checking environment
2025-10-09 20:23:14,362:INFO:python_version: 3.11.0
2025-10-09 20:23:14,362:INFO:python_build: ('main', 'Oct 24 2022 18:26:48')
2025-10-09 20:23:14,362:INFO:machine: AMD64
2025-10-09 20:23:14,362:INFO:platform: Windows-10-10.0.26100-SP0
2025-10-09 20:23:14,389:INFO:Memory: svmem(total=34211835904, available=17682657280, percent=48.3, used=16529178624, free=17682657280)
2025-10-09 20:23:14,391:INFO:Physical Core: 6
2025-10-09 20:23:14,391:INFO:Logical Core: 12
2025-10-09 20:23:14,391:INFO:Checking libraries
2025-10-09 20:23:14,391:INFO:System:
2025-10-09 20:23:14,391:INFO:    python: 3.11.0 (main, Oct 24 2022, 18:26:48) [MSC v.1933 64 bit (AMD64)]
2025-10-09 20:23:14,391:INFO:executable: c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\python.exe
2025-10-09 20:23:14,391:INFO:   machine: Windows-10-10.0.26100-SP0
2025-10-09 20:23:14,391:INFO:PyCaret required dependencies:
2025-10-09 20:23:14,538:INFO:                 pip: 22.3
2025-10-09 20:23:14,538:INFO:          setuptools: 65.5.0
2025-10-09 20:23:14,538:INFO:             pycaret: 3.3.2
2025-10-09 20:23:14,538:INFO:             IPython: 9.6.0
2025-10-09 20:23:14,538:INFO:          ipywidgets: 8.1.7
2025-10-09 20:23:14,538:INFO:                tqdm: 4.67.1
2025-10-09 20:23:14,538:INFO:               numpy: 1.26.4
2025-10-09 20:23:14,538:INFO:              pandas: 2.1.4
2025-10-09 20:23:14,538:INFO:              jinja2: 3.1.6
2025-10-09 20:23:14,538:INFO:               scipy: 1.11.4
2025-10-09 20:23:14,538:INFO:              joblib: 1.3.2
2025-10-09 20:23:14,538:INFO:             sklearn: 1.4.2
2025-10-09 20:23:14,538:INFO:                pyod: 2.0.5
2025-10-09 20:23:14,538:INFO:            imblearn: 0.14.0
2025-10-09 20:23:14,538:INFO:   category_encoders: 2.7.0
2025-10-09 20:23:14,538:INFO:            lightgbm: 4.6.0
2025-10-09 20:23:14,539:INFO:               numba: 0.62.1
2025-10-09 20:23:14,539:INFO:            requests: 2.32.5
2025-10-09 20:23:14,539:INFO:          matplotlib: 3.7.5
2025-10-09 20:23:14,539:INFO:          scikitplot: 0.3.7
2025-10-09 20:23:14,539:INFO:         yellowbrick: 1.5
2025-10-09 20:23:14,539:INFO:              plotly: 6.3.1
2025-10-09 20:23:14,539:INFO:    plotly-resampler: Not installed
2025-10-09 20:23:14,539:INFO:             kaleido: 1.1.0
2025-10-09 20:23:14,539:INFO:           schemdraw: 0.15
2025-10-09 20:23:14,539:INFO:         statsmodels: 0.14.5
2025-10-09 20:23:14,539:INFO:              sktime: 0.26.0
2025-10-09 20:23:14,539:INFO:               tbats: 1.1.3
2025-10-09 20:23:14,539:INFO:            pmdarima: 2.0.4
2025-10-09 20:23:14,539:INFO:              psutil: 7.1.0
2025-10-09 20:23:14,539:INFO:          markupsafe: 3.0.3
2025-10-09 20:23:14,539:INFO:             pickle5: Not installed
2025-10-09 20:23:14,539:INFO:         cloudpickle: 3.1.1
2025-10-09 20:23:14,539:INFO:         deprecation: 2.1.0
2025-10-09 20:23:14,539:INFO:              xxhash: 3.6.0
2025-10-09 20:23:14,539:INFO:           wurlitzer: Not installed
2025-10-09 20:23:14,540:INFO:PyCaret optional dependencies:
2025-10-09 20:23:14,557:INFO:                shap: Not installed
2025-10-09 20:23:14,557:INFO:           interpret: Not installed
2025-10-09 20:23:14,557:INFO:                umap: Not installed
2025-10-09 20:23:14,557:INFO:     ydata_profiling: Not installed
2025-10-09 20:23:14,557:INFO:  explainerdashboard: Not installed
2025-10-09 20:23:14,557:INFO:             autoviz: Not installed
2025-10-09 20:23:14,557:INFO:           fairlearn: Not installed
2025-10-09 20:23:14,557:INFO:          deepchecks: Not installed
2025-10-09 20:23:14,557:INFO:             xgboost: Not installed
2025-10-09 20:23:14,557:INFO:            catboost: Not installed
2025-10-09 20:23:14,557:INFO:              kmodes: Not installed
2025-10-09 20:23:14,557:INFO:             mlxtend: Not installed
2025-10-09 20:23:14,557:INFO:       statsforecast: Not installed
2025-10-09 20:23:14,557:INFO:        tune_sklearn: Not installed
2025-10-09 20:23:14,557:INFO:                 ray: Not installed
2025-10-09 20:23:14,558:INFO:            hyperopt: Not installed
2025-10-09 20:23:14,558:INFO:              optuna: Not installed
2025-10-09 20:23:14,558:INFO:               skopt: Not installed
2025-10-09 20:23:14,558:INFO:              mlflow: Not installed
2025-10-09 20:23:14,558:INFO:              gradio: Not installed
2025-10-09 20:23:14,558:INFO:             fastapi: Not installed
2025-10-09 20:23:14,558:INFO:             uvicorn: Not installed
2025-10-09 20:23:14,558:INFO:              m2cgen: Not installed
2025-10-09 20:23:14,558:INFO:           evidently: Not installed
2025-10-09 20:23:14,558:INFO:               fugue: Not installed
2025-10-09 20:23:14,558:INFO:           streamlit: Not installed
2025-10-09 20:23:14,558:INFO:             prophet: Not installed
2025-10-09 20:23:14,558:INFO:None
2025-10-09 20:23:14,558:INFO:Set up data.
2025-10-09 20:23:14,569:INFO:Set up folding strategy.
2025-10-09 20:23:14,569:INFO:Set up train/test split.
2025-10-09 20:23:14,618:INFO:Set up index.
2025-10-09 20:23:14,619:INFO:Assigning column types.
2025-10-09 20:23:14,625:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-09 20:23:14,673:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-09 20:23:14,679:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-09 20:23:14,719:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 20:23:14,719:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 20:23:14,768:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-09 20:23:14,769:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-09 20:23:14,794:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 20:23:14,794:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 20:23:14,795:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-09 20:23:14,841:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-09 20:23:14,874:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 20:23:14,874:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 20:23:14,923:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-09 20:23:14,952:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 20:23:14,953:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 20:23:14,954:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-10-09 20:23:15,037:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 20:23:15,037:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 20:23:15,118:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 20:23:15,119:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 20:23:15,121:INFO:Preparing preprocessing pipeline...
2025-10-09 20:23:15,124:INFO:Set up simple imputation.
2025-10-09 20:23:15,129:INFO:Set up encoding of ordinal features.
2025-10-09 20:23:15,130:INFO:Set up encoding of categorical features.
2025-10-09 20:23:15,130:INFO:Set up feature normalization.
2025-10-09 20:23:15,256:INFO:Finished creating preprocessing pipeline.
2025-10-09 20:23:15,284:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\ARNALDO\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'meses_como_cliente',
                                             'frecuencia_uso',
                                             'soporte_llamadas'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),...
                 TransformerWrapper(exclude=None, include=['tipo_plan'],
                                    transformer=OneHotEncoder(cols=['tipo_plan'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2025-10-09 20:23:15,284:INFO:Creating final display dataframe.
2025-10-09 20:23:15,555:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target             churn
2                   Target type            Binary
3           Original data shape          (300, 7)
4        Transformed data shape          (300, 9)
5   Transformed train set shape          (210, 9)
6    Transformed test set shape           (90, 9)
7              Numeric features                 4
8          Categorical features                 2
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                    Normalize              True
16             Normalize method            zscore
17               Fold Generator   StratifiedKFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  clf-default-name
23                          USI              3ab0
2025-10-09 20:23:15,665:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 20:23:15,677:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 20:23:15,765:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 20:23:15,765:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 20:23:15,766:INFO:setup() successfully completed in 1.41s...............
2025-10-09 20:24:38,207:INFO:Initializing compare_models()
2025-10-09 20:24:38,207:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-10-09 20:24:38,207:INFO:Checking exceptions
2025-10-09 20:24:38,212:INFO:Preparing display monitor
2025-10-09 20:24:38,250:INFO:Initializing Logistic Regression
2025-10-09 20:24:38,250:INFO:Total runtime is 0.0 minutes
2025-10-09 20:24:38,256:INFO:SubProcess create_model() called ==================================
2025-10-09 20:24:38,257:INFO:Initializing create_model()
2025-10-09 20:24:38,257:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000205BE928D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 20:24:38,257:INFO:Checking exceptions
2025-10-09 20:24:38,257:INFO:Importing libraries
2025-10-09 20:24:38,257:INFO:Copying training dataset
2025-10-09 20:24:38,266:INFO:Defining folds
2025-10-09 20:24:38,266:INFO:Declaring metric variables
2025-10-09 20:24:38,269:INFO:Importing untrained model
2025-10-09 20:24:38,273:INFO:Logistic Regression Imported successfully
2025-10-09 20:24:38,283:INFO:Starting cross validation
2025-10-09 20:24:38,285:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 20:24:48,066:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 20:24:48,346:INFO:Calculating mean and std
2025-10-09 20:24:48,348:INFO:Creating metrics dataframe
2025-10-09 20:24:48,355:INFO:Uploading results into container
2025-10-09 20:24:48,356:INFO:Uploading model into container now
2025-10-09 20:24:48,356:INFO:_master_model_container: 1
2025-10-09 20:24:48,357:INFO:_display_container: 2
2025-10-09 20:24:48,357:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-09 20:24:48,357:INFO:create_model() successfully completed......................................
2025-10-09 20:24:48,496:INFO:SubProcess create_model() end ==================================
2025-10-09 20:24:48,496:INFO:Creating metrics dataframe
2025-10-09 20:24:48,505:INFO:Initializing K Neighbors Classifier
2025-10-09 20:24:48,505:INFO:Total runtime is 0.17092710733413696 minutes
2025-10-09 20:24:48,510:INFO:SubProcess create_model() called ==================================
2025-10-09 20:24:48,511:INFO:Initializing create_model()
2025-10-09 20:24:48,511:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000205BE928D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 20:24:48,511:INFO:Checking exceptions
2025-10-09 20:24:48,511:INFO:Importing libraries
2025-10-09 20:24:48,511:INFO:Copying training dataset
2025-10-09 20:24:48,517:INFO:Defining folds
2025-10-09 20:24:48,518:INFO:Declaring metric variables
2025-10-09 20:24:48,523:INFO:Importing untrained model
2025-10-09 20:24:48,529:INFO:K Neighbors Classifier Imported successfully
2025-10-09 20:24:48,544:INFO:Starting cross validation
2025-10-09 20:24:48,548:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 20:24:53,584:INFO:Calculating mean and std
2025-10-09 20:24:53,588:INFO:Creating metrics dataframe
2025-10-09 20:24:53,597:INFO:Uploading results into container
2025-10-09 20:24:53,600:INFO:Uploading model into container now
2025-10-09 20:24:53,601:INFO:_master_model_container: 2
2025-10-09 20:24:53,602:INFO:_display_container: 2
2025-10-09 20:24:53,603:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-10-09 20:24:53,603:INFO:create_model() successfully completed......................................
2025-10-09 20:24:53,797:INFO:SubProcess create_model() end ==================================
2025-10-09 20:24:53,798:INFO:Creating metrics dataframe
2025-10-09 20:24:53,809:INFO:Initializing Naive Bayes
2025-10-09 20:24:53,809:INFO:Total runtime is 0.2593216300010681 minutes
2025-10-09 20:24:53,817:INFO:SubProcess create_model() called ==================================
2025-10-09 20:24:53,818:INFO:Initializing create_model()
2025-10-09 20:24:53,818:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000205BE928D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 20:24:53,818:INFO:Checking exceptions
2025-10-09 20:24:53,818:INFO:Importing libraries
2025-10-09 20:24:53,818:INFO:Copying training dataset
2025-10-09 20:24:53,826:INFO:Defining folds
2025-10-09 20:24:53,826:INFO:Declaring metric variables
2025-10-09 20:24:53,833:INFO:Importing untrained model
2025-10-09 20:24:53,840:INFO:Naive Bayes Imported successfully
2025-10-09 20:24:53,854:INFO:Starting cross validation
2025-10-09 20:24:53,857:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 20:24:54,202:INFO:Calculating mean and std
2025-10-09 20:24:54,205:INFO:Creating metrics dataframe
2025-10-09 20:24:54,208:INFO:Uploading results into container
2025-10-09 20:24:54,210:INFO:Uploading model into container now
2025-10-09 20:24:54,212:INFO:_master_model_container: 3
2025-10-09 20:24:54,212:INFO:_display_container: 2
2025-10-09 20:24:54,213:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-10-09 20:24:54,213:INFO:create_model() successfully completed......................................
2025-10-09 20:24:54,331:INFO:SubProcess create_model() end ==================================
2025-10-09 20:24:54,331:INFO:Creating metrics dataframe
2025-10-09 20:24:54,341:INFO:Initializing Decision Tree Classifier
2025-10-09 20:24:54,341:INFO:Total runtime is 0.268177608648936 minutes
2025-10-09 20:24:54,349:INFO:SubProcess create_model() called ==================================
2025-10-09 20:24:54,349:INFO:Initializing create_model()
2025-10-09 20:24:54,349:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000205BE928D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 20:24:54,349:INFO:Checking exceptions
2025-10-09 20:24:54,350:INFO:Importing libraries
2025-10-09 20:24:54,350:INFO:Copying training dataset
2025-10-09 20:24:54,358:INFO:Defining folds
2025-10-09 20:24:54,358:INFO:Declaring metric variables
2025-10-09 20:24:54,364:INFO:Importing untrained model
2025-10-09 20:24:54,370:INFO:Decision Tree Classifier Imported successfully
2025-10-09 20:24:54,382:INFO:Starting cross validation
2025-10-09 20:24:54,384:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 20:24:54,661:INFO:Calculating mean and std
2025-10-09 20:24:54,663:INFO:Creating metrics dataframe
2025-10-09 20:24:54,666:INFO:Uploading results into container
2025-10-09 20:24:54,667:INFO:Uploading model into container now
2025-10-09 20:24:54,667:INFO:_master_model_container: 4
2025-10-09 20:24:54,667:INFO:_display_container: 2
2025-10-09 20:24:54,668:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-10-09 20:24:54,668:INFO:create_model() successfully completed......................................
2025-10-09 20:24:54,780:INFO:SubProcess create_model() end ==================================
2025-10-09 20:24:54,781:INFO:Creating metrics dataframe
2025-10-09 20:24:54,810:INFO:Initializing SVM - Linear Kernel
2025-10-09 20:24:54,810:INFO:Total runtime is 0.27600163221359253 minutes
2025-10-09 20:24:54,818:INFO:SubProcess create_model() called ==================================
2025-10-09 20:24:54,818:INFO:Initializing create_model()
2025-10-09 20:24:54,819:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000205BE928D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 20:24:54,819:INFO:Checking exceptions
2025-10-09 20:24:54,819:INFO:Importing libraries
2025-10-09 20:24:54,819:INFO:Copying training dataset
2025-10-09 20:24:54,831:INFO:Defining folds
2025-10-09 20:24:54,833:INFO:Declaring metric variables
2025-10-09 20:24:54,838:INFO:Importing untrained model
2025-10-09 20:24:54,846:INFO:SVM - Linear Kernel Imported successfully
2025-10-09 20:24:54,862:INFO:Starting cross validation
2025-10-09 20:24:54,864:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 20:24:55,149:INFO:Calculating mean and std
2025-10-09 20:24:55,151:INFO:Creating metrics dataframe
2025-10-09 20:24:55,156:INFO:Uploading results into container
2025-10-09 20:24:55,157:INFO:Uploading model into container now
2025-10-09 20:24:55,157:INFO:_master_model_container: 5
2025-10-09 20:24:55,158:INFO:_display_container: 2
2025-10-09 20:24:55,158:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-10-09 20:24:55,158:INFO:create_model() successfully completed......................................
2025-10-09 20:24:55,273:INFO:SubProcess create_model() end ==================================
2025-10-09 20:24:55,273:INFO:Creating metrics dataframe
2025-10-09 20:24:55,283:INFO:Initializing Ridge Classifier
2025-10-09 20:24:55,284:INFO:Total runtime is 0.28391056855519614 minutes
2025-10-09 20:24:55,291:INFO:SubProcess create_model() called ==================================
2025-10-09 20:24:55,293:INFO:Initializing create_model()
2025-10-09 20:24:55,294:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000205BE928D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 20:24:55,294:INFO:Checking exceptions
2025-10-09 20:24:55,294:INFO:Importing libraries
2025-10-09 20:24:55,294:INFO:Copying training dataset
2025-10-09 20:24:55,300:INFO:Defining folds
2025-10-09 20:24:55,300:INFO:Declaring metric variables
2025-10-09 20:24:55,310:INFO:Importing untrained model
2025-10-09 20:24:55,316:INFO:Ridge Classifier Imported successfully
2025-10-09 20:24:55,325:INFO:Starting cross validation
2025-10-09 20:24:55,328:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 20:24:55,584:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 20:24:55,608:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 20:24:55,621:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 20:24:55,656:INFO:Calculating mean and std
2025-10-09 20:24:55,658:INFO:Creating metrics dataframe
2025-10-09 20:24:55,660:INFO:Uploading results into container
2025-10-09 20:24:55,661:INFO:Uploading model into container now
2025-10-09 20:24:55,662:INFO:_master_model_container: 6
2025-10-09 20:24:55,662:INFO:_display_container: 2
2025-10-09 20:24:55,663:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-10-09 20:24:55,663:INFO:create_model() successfully completed......................................
2025-10-09 20:24:55,792:INFO:SubProcess create_model() end ==================================
2025-10-09 20:24:55,793:INFO:Creating metrics dataframe
2025-10-09 20:24:55,805:INFO:Initializing Random Forest Classifier
2025-10-09 20:24:55,806:INFO:Total runtime is 0.2926106492678325 minutes
2025-10-09 20:24:55,812:INFO:SubProcess create_model() called ==================================
2025-10-09 20:24:55,813:INFO:Initializing create_model()
2025-10-09 20:24:55,813:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000205BE928D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 20:24:55,813:INFO:Checking exceptions
2025-10-09 20:24:55,813:INFO:Importing libraries
2025-10-09 20:24:55,813:INFO:Copying training dataset
2025-10-09 20:24:55,823:INFO:Defining folds
2025-10-09 20:24:55,823:INFO:Declaring metric variables
2025-10-09 20:24:55,833:INFO:Importing untrained model
2025-10-09 20:24:55,840:INFO:Random Forest Classifier Imported successfully
2025-10-09 20:24:55,852:INFO:Starting cross validation
2025-10-09 20:24:55,854:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 20:24:56,569:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 20:24:56,694:INFO:Calculating mean and std
2025-10-09 20:24:56,695:INFO:Creating metrics dataframe
2025-10-09 20:24:56,699:INFO:Uploading results into container
2025-10-09 20:24:56,700:INFO:Uploading model into container now
2025-10-09 20:24:56,701:INFO:_master_model_container: 7
2025-10-09 20:24:56,701:INFO:_display_container: 2
2025-10-09 20:24:56,702:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-10-09 20:24:56,702:INFO:create_model() successfully completed......................................
2025-10-09 20:24:56,832:INFO:SubProcess create_model() end ==================================
2025-10-09 20:24:56,832:INFO:Creating metrics dataframe
2025-10-09 20:24:56,847:INFO:Initializing Quadratic Discriminant Analysis
2025-10-09 20:24:56,847:INFO:Total runtime is 0.3099442521731059 minutes
2025-10-09 20:24:56,855:INFO:SubProcess create_model() called ==================================
2025-10-09 20:24:56,855:INFO:Initializing create_model()
2025-10-09 20:24:56,855:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000205BE928D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 20:24:56,855:INFO:Checking exceptions
2025-10-09 20:24:56,856:INFO:Importing libraries
2025-10-09 20:24:56,856:INFO:Copying training dataset
2025-10-09 20:24:56,861:INFO:Defining folds
2025-10-09 20:24:56,863:INFO:Declaring metric variables
2025-10-09 20:24:56,871:INFO:Importing untrained model
2025-10-09 20:24:56,879:INFO:Quadratic Discriminant Analysis Imported successfully
2025-10-09 20:24:56,892:INFO:Starting cross validation
2025-10-09 20:24:56,896:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 20:24:57,122:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 20:24:57,122:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 20:24:57,122:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 20:24:57,122:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 20:24:57,122:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 20:24:57,122:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 20:24:57,123:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 20:24:57,139:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 20:24:57,275:INFO:Calculating mean and std
2025-10-09 20:24:57,276:INFO:Creating metrics dataframe
2025-10-09 20:24:57,279:INFO:Uploading results into container
2025-10-09 20:24:57,281:INFO:Uploading model into container now
2025-10-09 20:24:57,282:INFO:_master_model_container: 8
2025-10-09 20:24:57,283:INFO:_display_container: 2
2025-10-09 20:24:57,283:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-10-09 20:24:57,284:INFO:create_model() successfully completed......................................
2025-10-09 20:24:57,459:INFO:SubProcess create_model() end ==================================
2025-10-09 20:24:57,459:INFO:Creating metrics dataframe
2025-10-09 20:24:57,479:INFO:Initializing Ada Boost Classifier
2025-10-09 20:24:57,479:INFO:Total runtime is 0.3204890807469686 minutes
2025-10-09 20:24:57,489:INFO:SubProcess create_model() called ==================================
2025-10-09 20:24:57,490:INFO:Initializing create_model()
2025-10-09 20:24:57,490:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000205BE928D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 20:24:57,490:INFO:Checking exceptions
2025-10-09 20:24:57,491:INFO:Importing libraries
2025-10-09 20:24:57,491:INFO:Copying training dataset
2025-10-09 20:24:57,505:INFO:Defining folds
2025-10-09 20:24:57,506:INFO:Declaring metric variables
2025-10-09 20:24:57,516:INFO:Importing untrained model
2025-10-09 20:24:57,525:INFO:Ada Boost Classifier Imported successfully
2025-10-09 20:24:57,543:INFO:Starting cross validation
2025-10-09 20:24:57,546:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 20:24:57,755:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 20:24:57,755:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 20:24:57,755:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 20:24:57,755:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 20:24:57,757:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 20:24:57,761:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 20:24:57,762:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 20:24:57,778:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 20:24:58,097:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 20:24:58,169:INFO:Calculating mean and std
2025-10-09 20:24:58,170:INFO:Creating metrics dataframe
2025-10-09 20:24:58,174:INFO:Uploading results into container
2025-10-09 20:24:58,176:INFO:Uploading model into container now
2025-10-09 20:24:58,176:INFO:_master_model_container: 9
2025-10-09 20:24:58,176:INFO:_display_container: 2
2025-10-09 20:24:58,177:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-10-09 20:24:58,178:INFO:create_model() successfully completed......................................
2025-10-09 20:24:58,361:INFO:SubProcess create_model() end ==================================
2025-10-09 20:24:58,361:INFO:Creating metrics dataframe
2025-10-09 20:24:58,376:INFO:Initializing Gradient Boosting Classifier
2025-10-09 20:24:58,376:INFO:Total runtime is 0.3354297399520874 minutes
2025-10-09 20:24:58,383:INFO:SubProcess create_model() called ==================================
2025-10-09 20:24:58,384:INFO:Initializing create_model()
2025-10-09 20:24:58,384:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000205BE928D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 20:24:58,384:INFO:Checking exceptions
2025-10-09 20:24:58,384:INFO:Importing libraries
2025-10-09 20:24:58,384:INFO:Copying training dataset
2025-10-09 20:24:58,391:INFO:Defining folds
2025-10-09 20:24:58,391:INFO:Declaring metric variables
2025-10-09 20:24:58,399:INFO:Importing untrained model
2025-10-09 20:24:58,407:INFO:Gradient Boosting Classifier Imported successfully
2025-10-09 20:24:58,423:INFO:Starting cross validation
2025-10-09 20:24:58,426:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 20:24:59,132:INFO:Calculating mean and std
2025-10-09 20:24:59,134:INFO:Creating metrics dataframe
2025-10-09 20:24:59,138:INFO:Uploading results into container
2025-10-09 20:24:59,140:INFO:Uploading model into container now
2025-10-09 20:24:59,141:INFO:_master_model_container: 10
2025-10-09 20:24:59,141:INFO:_display_container: 2
2025-10-09 20:24:59,141:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-09 20:24:59,142:INFO:create_model() successfully completed......................................
2025-10-09 20:24:59,269:INFO:SubProcess create_model() end ==================================
2025-10-09 20:24:59,269:INFO:Creating metrics dataframe
2025-10-09 20:24:59,280:INFO:Initializing Linear Discriminant Analysis
2025-10-09 20:24:59,280:INFO:Total runtime is 0.35049999952316285 minutes
2025-10-09 20:24:59,287:INFO:SubProcess create_model() called ==================================
2025-10-09 20:24:59,287:INFO:Initializing create_model()
2025-10-09 20:24:59,287:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000205BE928D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 20:24:59,288:INFO:Checking exceptions
2025-10-09 20:24:59,288:INFO:Importing libraries
2025-10-09 20:24:59,288:INFO:Copying training dataset
2025-10-09 20:24:59,298:INFO:Defining folds
2025-10-09 20:24:59,299:INFO:Declaring metric variables
2025-10-09 20:24:59,306:INFO:Importing untrained model
2025-10-09 20:24:59,314:INFO:Linear Discriminant Analysis Imported successfully
2025-10-09 20:24:59,325:INFO:Starting cross validation
2025-10-09 20:24:59,328:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 20:24:59,550:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 20:24:59,574:INFO:Calculating mean and std
2025-10-09 20:24:59,575:INFO:Creating metrics dataframe
2025-10-09 20:24:59,578:INFO:Uploading results into container
2025-10-09 20:24:59,578:INFO:Uploading model into container now
2025-10-09 20:24:59,579:INFO:_master_model_container: 11
2025-10-09 20:24:59,579:INFO:_display_container: 2
2025-10-09 20:24:59,579:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-09 20:24:59,580:INFO:create_model() successfully completed......................................
2025-10-09 20:24:59,702:INFO:SubProcess create_model() end ==================================
2025-10-09 20:24:59,703:INFO:Creating metrics dataframe
2025-10-09 20:24:59,715:INFO:Initializing Extra Trees Classifier
2025-10-09 20:24:59,715:INFO:Total runtime is 0.3577470382054647 minutes
2025-10-09 20:24:59,721:INFO:SubProcess create_model() called ==================================
2025-10-09 20:24:59,721:INFO:Initializing create_model()
2025-10-09 20:24:59,721:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000205BE928D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 20:24:59,722:INFO:Checking exceptions
2025-10-09 20:24:59,722:INFO:Importing libraries
2025-10-09 20:24:59,722:INFO:Copying training dataset
2025-10-09 20:24:59,728:INFO:Defining folds
2025-10-09 20:24:59,728:INFO:Declaring metric variables
2025-10-09 20:24:59,733:INFO:Importing untrained model
2025-10-09 20:24:59,742:INFO:Extra Trees Classifier Imported successfully
2025-10-09 20:24:59,751:INFO:Starting cross validation
2025-10-09 20:24:59,756:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 20:25:00,512:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 20:25:00,627:INFO:Calculating mean and std
2025-10-09 20:25:00,629:INFO:Creating metrics dataframe
2025-10-09 20:25:00,632:INFO:Uploading results into container
2025-10-09 20:25:00,632:INFO:Uploading model into container now
2025-10-09 20:25:00,633:INFO:_master_model_container: 12
2025-10-09 20:25:00,633:INFO:_display_container: 2
2025-10-09 20:25:00,635:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-10-09 20:25:00,635:INFO:create_model() successfully completed......................................
2025-10-09 20:25:00,786:INFO:SubProcess create_model() end ==================================
2025-10-09 20:25:00,786:INFO:Creating metrics dataframe
2025-10-09 20:25:00,806:INFO:Initializing Light Gradient Boosting Machine
2025-10-09 20:25:00,807:INFO:Total runtime is 0.3759469827016195 minutes
2025-10-09 20:25:00,814:INFO:SubProcess create_model() called ==================================
2025-10-09 20:25:00,814:INFO:Initializing create_model()
2025-10-09 20:25:00,815:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000205BE928D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 20:25:00,815:INFO:Checking exceptions
2025-10-09 20:25:00,815:INFO:Importing libraries
2025-10-09 20:25:00,815:INFO:Copying training dataset
2025-10-09 20:25:00,821:INFO:Defining folds
2025-10-09 20:25:00,821:INFO:Declaring metric variables
2025-10-09 20:25:00,828:INFO:Importing untrained model
2025-10-09 20:25:00,834:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-09 20:25:00,845:INFO:Starting cross validation
2025-10-09 20:25:00,850:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 20:25:01,774:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 20:25:01,827:INFO:Calculating mean and std
2025-10-09 20:25:01,830:INFO:Creating metrics dataframe
2025-10-09 20:25:01,835:INFO:Uploading results into container
2025-10-09 20:25:01,836:INFO:Uploading model into container now
2025-10-09 20:25:01,837:INFO:_master_model_container: 13
2025-10-09 20:25:01,837:INFO:_display_container: 2
2025-10-09 20:25:01,839:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-09 20:25:01,839:INFO:create_model() successfully completed......................................
2025-10-09 20:25:01,988:INFO:SubProcess create_model() end ==================================
2025-10-09 20:25:01,989:INFO:Creating metrics dataframe
2025-10-09 20:25:02,006:INFO:Initializing Dummy Classifier
2025-10-09 20:25:02,007:INFO:Total runtime is 0.39594955046971647 minutes
2025-10-09 20:25:02,013:INFO:SubProcess create_model() called ==================================
2025-10-09 20:25:02,013:INFO:Initializing create_model()
2025-10-09 20:25:02,014:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000205BE928D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 20:25:02,014:INFO:Checking exceptions
2025-10-09 20:25:02,014:INFO:Importing libraries
2025-10-09 20:25:02,014:INFO:Copying training dataset
2025-10-09 20:25:02,020:INFO:Defining folds
2025-10-09 20:25:02,021:INFO:Declaring metric variables
2025-10-09 20:25:02,027:INFO:Importing untrained model
2025-10-09 20:25:02,035:INFO:Dummy Classifier Imported successfully
2025-10-09 20:25:02,049:INFO:Starting cross validation
2025-10-09 20:25:02,053:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 20:25:02,272:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 20:25:02,273:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 20:25:02,273:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 20:25:02,274:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 20:25:02,278:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 20:25:02,280:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 20:25:02,284:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 20:25:02,288:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 20:25:02,288:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 20:25:02,290:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 20:25:02,310:INFO:Calculating mean and std
2025-10-09 20:25:02,312:INFO:Creating metrics dataframe
2025-10-09 20:25:02,314:INFO:Uploading results into container
2025-10-09 20:25:02,315:INFO:Uploading model into container now
2025-10-09 20:25:02,316:INFO:_master_model_container: 14
2025-10-09 20:25:02,316:INFO:_display_container: 2
2025-10-09 20:25:02,316:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-10-09 20:25:02,316:INFO:create_model() successfully completed......................................
2025-10-09 20:25:02,443:INFO:SubProcess create_model() end ==================================
2025-10-09 20:25:02,443:INFO:Creating metrics dataframe
2025-10-09 20:25:02,464:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-10-09 20:25:02,481:INFO:Initializing create_model()
2025-10-09 20:25:02,481:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 20:25:02,482:INFO:Checking exceptions
2025-10-09 20:25:02,484:INFO:Importing libraries
2025-10-09 20:25:02,484:INFO:Copying training dataset
2025-10-09 20:25:02,490:INFO:Defining folds
2025-10-09 20:25:02,490:INFO:Declaring metric variables
2025-10-09 20:25:02,490:INFO:Importing untrained model
2025-10-09 20:25:02,490:INFO:Declaring custom model
2025-10-09 20:25:02,491:INFO:Ridge Classifier Imported successfully
2025-10-09 20:25:02,493:INFO:Cross validation set to False
2025-10-09 20:25:02,493:INFO:Fitting Model
2025-10-09 20:25:02,558:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-10-09 20:25:02,558:INFO:create_model() successfully completed......................................
2025-10-09 20:25:02,733:INFO:_master_model_container: 14
2025-10-09 20:25:02,733:INFO:_display_container: 2
2025-10-09 20:25:02,735:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-10-09 20:25:02,735:INFO:compare_models() successfully completed......................................
2025-10-09 20:25:31,390:INFO:Initializing compare_models()
2025-10-09 20:25:31,390:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-10-09 20:25:31,391:INFO:Checking exceptions
2025-10-09 20:25:31,393:INFO:Preparing display monitor
2025-10-09 20:25:31,438:INFO:Initializing Logistic Regression
2025-10-09 20:25:31,438:INFO:Total runtime is 0.0 minutes
2025-10-09 20:25:31,450:INFO:SubProcess create_model() called ==================================
2025-10-09 20:25:31,451:INFO:Initializing create_model()
2025-10-09 20:25:31,451:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000205BCE83A90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 20:25:31,452:INFO:Checking exceptions
2025-10-09 20:25:31,452:INFO:Importing libraries
2025-10-09 20:25:31,452:INFO:Copying training dataset
2025-10-09 20:25:31,460:INFO:Defining folds
2025-10-09 20:25:31,460:INFO:Declaring metric variables
2025-10-09 20:25:31,467:INFO:Importing untrained model
2025-10-09 20:25:31,477:INFO:Logistic Regression Imported successfully
2025-10-09 20:25:31,494:INFO:Starting cross validation
2025-10-09 20:25:31,499:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 20:25:31,827:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 20:25:31,869:INFO:Calculating mean and std
2025-10-09 20:25:31,870:INFO:Creating metrics dataframe
2025-10-09 20:25:31,871:INFO:Uploading results into container
2025-10-09 20:25:31,872:INFO:Uploading model into container now
2025-10-09 20:25:31,872:INFO:_master_model_container: 15
2025-10-09 20:25:31,872:INFO:_display_container: 3
2025-10-09 20:25:31,873:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-09 20:25:31,873:INFO:create_model() successfully completed......................................
2025-10-09 20:25:31,997:INFO:SubProcess create_model() end ==================================
2025-10-09 20:25:31,997:INFO:Creating metrics dataframe
2025-10-09 20:25:32,005:INFO:Initializing K Neighbors Classifier
2025-10-09 20:25:32,005:INFO:Total runtime is 0.009451361497243245 minutes
2025-10-09 20:25:32,016:INFO:SubProcess create_model() called ==================================
2025-10-09 20:25:32,016:INFO:Initializing create_model()
2025-10-09 20:25:32,017:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000205BCE83A90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 20:25:32,017:INFO:Checking exceptions
2025-10-09 20:25:32,017:INFO:Importing libraries
2025-10-09 20:25:32,017:INFO:Copying training dataset
2025-10-09 20:25:32,021:INFO:Defining folds
2025-10-09 20:25:32,021:INFO:Declaring metric variables
2025-10-09 20:25:32,024:INFO:Importing untrained model
2025-10-09 20:25:32,030:INFO:K Neighbors Classifier Imported successfully
2025-10-09 20:25:32,047:INFO:Starting cross validation
2025-10-09 20:25:32,050:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 20:25:32,398:INFO:Calculating mean and std
2025-10-09 20:25:32,399:INFO:Creating metrics dataframe
2025-10-09 20:25:32,401:INFO:Uploading results into container
2025-10-09 20:25:32,402:INFO:Uploading model into container now
2025-10-09 20:25:32,402:INFO:_master_model_container: 16
2025-10-09 20:25:32,402:INFO:_display_container: 3
2025-10-09 20:25:32,402:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-10-09 20:25:32,403:INFO:create_model() successfully completed......................................
2025-10-09 20:25:32,527:INFO:SubProcess create_model() end ==================================
2025-10-09 20:25:32,527:INFO:Creating metrics dataframe
2025-10-09 20:25:32,538:INFO:Initializing Naive Bayes
2025-10-09 20:25:32,538:INFO:Total runtime is 0.018327180544535318 minutes
2025-10-09 20:25:32,544:INFO:SubProcess create_model() called ==================================
2025-10-09 20:25:32,544:INFO:Initializing create_model()
2025-10-09 20:25:32,544:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000205BCE83A90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 20:25:32,544:INFO:Checking exceptions
2025-10-09 20:25:32,544:INFO:Importing libraries
2025-10-09 20:25:32,544:INFO:Copying training dataset
2025-10-09 20:25:32,553:INFO:Defining folds
2025-10-09 20:25:32,554:INFO:Declaring metric variables
2025-10-09 20:25:32,559:INFO:Importing untrained model
2025-10-09 20:25:32,566:INFO:Naive Bayes Imported successfully
2025-10-09 20:25:32,582:INFO:Starting cross validation
2025-10-09 20:25:32,583:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 20:25:32,855:INFO:Calculating mean and std
2025-10-09 20:25:32,857:INFO:Creating metrics dataframe
2025-10-09 20:25:32,860:INFO:Uploading results into container
2025-10-09 20:25:32,861:INFO:Uploading model into container now
2025-10-09 20:25:32,861:INFO:_master_model_container: 17
2025-10-09 20:25:32,862:INFO:_display_container: 3
2025-10-09 20:25:32,862:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-10-09 20:25:32,862:INFO:create_model() successfully completed......................................
2025-10-09 20:25:32,979:INFO:SubProcess create_model() end ==================================
2025-10-09 20:25:32,979:INFO:Creating metrics dataframe
2025-10-09 20:25:32,987:INFO:Initializing Decision Tree Classifier
2025-10-09 20:25:32,987:INFO:Total runtime is 0.025815467039744057 minutes
2025-10-09 20:25:32,992:INFO:SubProcess create_model() called ==================================
2025-10-09 20:25:32,992:INFO:Initializing create_model()
2025-10-09 20:25:32,992:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000205BCE83A90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 20:25:32,992:INFO:Checking exceptions
2025-10-09 20:25:32,992:INFO:Importing libraries
2025-10-09 20:25:32,992:INFO:Copying training dataset
2025-10-09 20:25:33,002:INFO:Defining folds
2025-10-09 20:25:33,003:INFO:Declaring metric variables
2025-10-09 20:25:33,008:INFO:Importing untrained model
2025-10-09 20:25:33,016:INFO:Decision Tree Classifier Imported successfully
2025-10-09 20:25:33,028:INFO:Starting cross validation
2025-10-09 20:25:33,032:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 20:25:33,288:INFO:Calculating mean and std
2025-10-09 20:25:33,290:INFO:Creating metrics dataframe
2025-10-09 20:25:33,293:INFO:Uploading results into container
2025-10-09 20:25:33,295:INFO:Uploading model into container now
2025-10-09 20:25:33,295:INFO:_master_model_container: 18
2025-10-09 20:25:33,296:INFO:_display_container: 3
2025-10-09 20:25:33,296:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-10-09 20:25:33,297:INFO:create_model() successfully completed......................................
2025-10-09 20:25:33,421:INFO:SubProcess create_model() end ==================================
2025-10-09 20:25:33,421:INFO:Creating metrics dataframe
2025-10-09 20:25:33,434:INFO:Initializing SVM - Linear Kernel
2025-10-09 20:25:33,434:INFO:Total runtime is 0.03326046069463094 minutes
2025-10-09 20:25:33,438:INFO:SubProcess create_model() called ==================================
2025-10-09 20:25:33,439:INFO:Initializing create_model()
2025-10-09 20:25:33,439:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000205BCE83A90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 20:25:33,439:INFO:Checking exceptions
2025-10-09 20:25:33,440:INFO:Importing libraries
2025-10-09 20:25:33,440:INFO:Copying training dataset
2025-10-09 20:25:33,446:INFO:Defining folds
2025-10-09 20:25:33,446:INFO:Declaring metric variables
2025-10-09 20:25:33,454:INFO:Importing untrained model
2025-10-09 20:25:33,460:INFO:SVM - Linear Kernel Imported successfully
2025-10-09 20:25:33,475:INFO:Starting cross validation
2025-10-09 20:25:33,478:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 20:25:33,735:INFO:Calculating mean and std
2025-10-09 20:25:33,737:INFO:Creating metrics dataframe
2025-10-09 20:25:33,739:INFO:Uploading results into container
2025-10-09 20:25:33,740:INFO:Uploading model into container now
2025-10-09 20:25:33,740:INFO:_master_model_container: 19
2025-10-09 20:25:33,740:INFO:_display_container: 3
2025-10-09 20:25:33,741:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-10-09 20:25:33,741:INFO:create_model() successfully completed......................................
2025-10-09 20:25:33,862:INFO:SubProcess create_model() end ==================================
2025-10-09 20:25:33,862:INFO:Creating metrics dataframe
2025-10-09 20:25:33,872:INFO:Initializing Ridge Classifier
2025-10-09 20:25:33,872:INFO:Total runtime is 0.04055364529291789 minutes
2025-10-09 20:25:33,877:INFO:SubProcess create_model() called ==================================
2025-10-09 20:25:33,878:INFO:Initializing create_model()
2025-10-09 20:25:33,878:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000205BCE83A90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 20:25:33,879:INFO:Checking exceptions
2025-10-09 20:25:33,881:INFO:Importing libraries
2025-10-09 20:25:33,881:INFO:Copying training dataset
2025-10-09 20:25:33,887:INFO:Defining folds
2025-10-09 20:25:33,887:INFO:Declaring metric variables
2025-10-09 20:25:33,891:INFO:Importing untrained model
2025-10-09 20:25:33,896:INFO:Ridge Classifier Imported successfully
2025-10-09 20:25:33,907:INFO:Starting cross validation
2025-10-09 20:25:33,910:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 20:25:34,130:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 20:25:34,134:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 20:25:34,135:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 20:25:34,173:INFO:Calculating mean and std
2025-10-09 20:25:34,174:INFO:Creating metrics dataframe
2025-10-09 20:25:34,178:INFO:Uploading results into container
2025-10-09 20:25:34,179:INFO:Uploading model into container now
2025-10-09 20:25:34,179:INFO:_master_model_container: 20
2025-10-09 20:25:34,180:INFO:_display_container: 3
2025-10-09 20:25:34,180:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-10-09 20:25:34,180:INFO:create_model() successfully completed......................................
2025-10-09 20:25:34,305:INFO:SubProcess create_model() end ==================================
2025-10-09 20:25:34,306:INFO:Creating metrics dataframe
2025-10-09 20:25:34,320:INFO:Initializing Random Forest Classifier
2025-10-09 20:25:34,320:INFO:Total runtime is 0.04802547693252564 minutes
2025-10-09 20:25:34,324:INFO:SubProcess create_model() called ==================================
2025-10-09 20:25:34,324:INFO:Initializing create_model()
2025-10-09 20:25:34,324:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000205BCE83A90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 20:25:34,324:INFO:Checking exceptions
2025-10-09 20:25:34,325:INFO:Importing libraries
2025-10-09 20:25:34,326:INFO:Copying training dataset
2025-10-09 20:25:34,338:INFO:Defining folds
2025-10-09 20:25:34,338:INFO:Declaring metric variables
2025-10-09 20:25:34,345:INFO:Importing untrained model
2025-10-09 20:25:34,351:INFO:Random Forest Classifier Imported successfully
2025-10-09 20:25:34,365:INFO:Starting cross validation
2025-10-09 20:25:34,367:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 20:25:35,071:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 20:25:35,147:INFO:Calculating mean and std
2025-10-09 20:25:35,148:INFO:Creating metrics dataframe
2025-10-09 20:25:35,152:INFO:Uploading results into container
2025-10-09 20:25:35,152:INFO:Uploading model into container now
2025-10-09 20:25:35,153:INFO:_master_model_container: 21
2025-10-09 20:25:35,153:INFO:_display_container: 3
2025-10-09 20:25:35,154:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-10-09 20:25:35,154:INFO:create_model() successfully completed......................................
2025-10-09 20:25:35,294:INFO:SubProcess create_model() end ==================================
2025-10-09 20:25:35,294:INFO:Creating metrics dataframe
2025-10-09 20:25:35,305:INFO:Initializing Quadratic Discriminant Analysis
2025-10-09 20:25:35,306:INFO:Total runtime is 0.06446104844411214 minutes
2025-10-09 20:25:35,310:INFO:SubProcess create_model() called ==================================
2025-10-09 20:25:35,311:INFO:Initializing create_model()
2025-10-09 20:25:35,311:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000205BCE83A90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 20:25:35,311:INFO:Checking exceptions
2025-10-09 20:25:35,311:INFO:Importing libraries
2025-10-09 20:25:35,311:INFO:Copying training dataset
2025-10-09 20:25:35,318:INFO:Defining folds
2025-10-09 20:25:35,319:INFO:Declaring metric variables
2025-10-09 20:25:35,326:INFO:Importing untrained model
2025-10-09 20:25:35,335:INFO:Quadratic Discriminant Analysis Imported successfully
2025-10-09 20:25:35,346:INFO:Starting cross validation
2025-10-09 20:25:35,351:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 20:25:35,490:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 20:25:35,497:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 20:25:35,497:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 20:25:35,506:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 20:25:35,511:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 20:25:35,520:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 20:25:35,530:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 20:25:35,546:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 20:25:35,552:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 20:25:35,652:INFO:Calculating mean and std
2025-10-09 20:25:35,654:INFO:Creating metrics dataframe
2025-10-09 20:25:35,656:INFO:Uploading results into container
2025-10-09 20:25:35,657:INFO:Uploading model into container now
2025-10-09 20:25:35,658:INFO:_master_model_container: 22
2025-10-09 20:25:35,658:INFO:_display_container: 3
2025-10-09 20:25:35,658:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-10-09 20:25:35,658:INFO:create_model() successfully completed......................................
2025-10-09 20:25:35,786:INFO:SubProcess create_model() end ==================================
2025-10-09 20:25:35,786:INFO:Creating metrics dataframe
2025-10-09 20:25:35,798:INFO:Initializing Ada Boost Classifier
2025-10-09 20:25:35,798:INFO:Total runtime is 0.07266511519749959 minutes
2025-10-09 20:25:35,802:INFO:SubProcess create_model() called ==================================
2025-10-09 20:25:35,802:INFO:Initializing create_model()
2025-10-09 20:25:35,802:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000205BCE83A90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 20:25:35,802:INFO:Checking exceptions
2025-10-09 20:25:35,802:INFO:Importing libraries
2025-10-09 20:25:35,803:INFO:Copying training dataset
2025-10-09 20:25:35,808:INFO:Defining folds
2025-10-09 20:25:35,808:INFO:Declaring metric variables
2025-10-09 20:25:35,816:INFO:Importing untrained model
2025-10-09 20:25:35,822:INFO:Ada Boost Classifier Imported successfully
2025-10-09 20:25:35,831:INFO:Starting cross validation
2025-10-09 20:25:35,832:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 20:25:35,974:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 20:25:36,001:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 20:25:36,001:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 20:25:36,005:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 20:25:36,013:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 20:25:36,017:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 20:25:36,031:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 20:25:36,033:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 20:25:36,035:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 20:25:36,040:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 20:25:36,338:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 20:25:36,347:INFO:Calculating mean and std
2025-10-09 20:25:36,348:INFO:Creating metrics dataframe
2025-10-09 20:25:36,351:INFO:Uploading results into container
2025-10-09 20:25:36,352:INFO:Uploading model into container now
2025-10-09 20:25:36,352:INFO:_master_model_container: 23
2025-10-09 20:25:36,352:INFO:_display_container: 3
2025-10-09 20:25:36,352:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-10-09 20:25:36,352:INFO:create_model() successfully completed......................................
2025-10-09 20:25:36,470:INFO:SubProcess create_model() end ==================================
2025-10-09 20:25:36,472:INFO:Creating metrics dataframe
2025-10-09 20:25:36,487:INFO:Initializing Gradient Boosting Classifier
2025-10-09 20:25:36,487:INFO:Total runtime is 0.08414574861526489 minutes
2025-10-09 20:25:36,491:INFO:SubProcess create_model() called ==================================
2025-10-09 20:25:36,492:INFO:Initializing create_model()
2025-10-09 20:25:36,492:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000205BCE83A90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 20:25:36,492:INFO:Checking exceptions
2025-10-09 20:25:36,492:INFO:Importing libraries
2025-10-09 20:25:36,492:INFO:Copying training dataset
2025-10-09 20:25:36,501:INFO:Defining folds
2025-10-09 20:25:36,501:INFO:Declaring metric variables
2025-10-09 20:25:36,506:INFO:Importing untrained model
2025-10-09 20:25:36,512:INFO:Gradient Boosting Classifier Imported successfully
2025-10-09 20:25:36,521:INFO:Starting cross validation
2025-10-09 20:25:36,523:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 20:25:37,071:INFO:Calculating mean and std
2025-10-09 20:25:37,072:INFO:Creating metrics dataframe
2025-10-09 20:25:37,075:INFO:Uploading results into container
2025-10-09 20:25:37,075:INFO:Uploading model into container now
2025-10-09 20:25:37,076:INFO:_master_model_container: 24
2025-10-09 20:25:37,076:INFO:_display_container: 3
2025-10-09 20:25:37,077:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-09 20:25:37,077:INFO:create_model() successfully completed......................................
2025-10-09 20:25:37,203:INFO:SubProcess create_model() end ==================================
2025-10-09 20:25:37,204:INFO:Creating metrics dataframe
2025-10-09 20:25:37,218:INFO:Initializing Linear Discriminant Analysis
2025-10-09 20:25:37,218:INFO:Total runtime is 0.09633065462112426 minutes
2025-10-09 20:25:37,224:INFO:SubProcess create_model() called ==================================
2025-10-09 20:25:37,225:INFO:Initializing create_model()
2025-10-09 20:25:37,225:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000205BCE83A90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 20:25:37,225:INFO:Checking exceptions
2025-10-09 20:25:37,225:INFO:Importing libraries
2025-10-09 20:25:37,225:INFO:Copying training dataset
2025-10-09 20:25:37,233:INFO:Defining folds
2025-10-09 20:25:37,234:INFO:Declaring metric variables
2025-10-09 20:25:37,241:INFO:Importing untrained model
2025-10-09 20:25:37,247:INFO:Linear Discriminant Analysis Imported successfully
2025-10-09 20:25:37,260:INFO:Starting cross validation
2025-10-09 20:25:37,262:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 20:25:37,483:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 20:25:37,520:INFO:Calculating mean and std
2025-10-09 20:25:37,521:INFO:Creating metrics dataframe
2025-10-09 20:25:37,524:INFO:Uploading results into container
2025-10-09 20:25:37,525:INFO:Uploading model into container now
2025-10-09 20:25:37,525:INFO:_master_model_container: 25
2025-10-09 20:25:37,525:INFO:_display_container: 3
2025-10-09 20:25:37,526:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-09 20:25:37,526:INFO:create_model() successfully completed......................................
2025-10-09 20:25:37,649:INFO:SubProcess create_model() end ==================================
2025-10-09 20:25:37,649:INFO:Creating metrics dataframe
2025-10-09 20:25:37,663:INFO:Initializing Extra Trees Classifier
2025-10-09 20:25:37,663:INFO:Total runtime is 0.10375000635782877 minutes
2025-10-09 20:25:37,667:INFO:SubProcess create_model() called ==================================
2025-10-09 20:25:37,667:INFO:Initializing create_model()
2025-10-09 20:25:37,667:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000205BCE83A90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 20:25:37,667:INFO:Checking exceptions
2025-10-09 20:25:37,667:INFO:Importing libraries
2025-10-09 20:25:37,667:INFO:Copying training dataset
2025-10-09 20:25:37,673:INFO:Defining folds
2025-10-09 20:25:37,674:INFO:Declaring metric variables
2025-10-09 20:25:37,680:INFO:Importing untrained model
2025-10-09 20:25:37,686:INFO:Extra Trees Classifier Imported successfully
2025-10-09 20:25:37,697:INFO:Starting cross validation
2025-10-09 20:25:37,699:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 20:25:38,362:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 20:25:38,412:INFO:Calculating mean and std
2025-10-09 20:25:38,415:INFO:Creating metrics dataframe
2025-10-09 20:25:38,419:INFO:Uploading results into container
2025-10-09 20:25:38,421:INFO:Uploading model into container now
2025-10-09 20:25:38,421:INFO:_master_model_container: 26
2025-10-09 20:25:38,421:INFO:_display_container: 3
2025-10-09 20:25:38,422:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-10-09 20:25:38,422:INFO:create_model() successfully completed......................................
2025-10-09 20:25:38,546:INFO:SubProcess create_model() end ==================================
2025-10-09 20:25:38,547:INFO:Creating metrics dataframe
2025-10-09 20:25:38,558:INFO:Initializing Light Gradient Boosting Machine
2025-10-09 20:25:38,558:INFO:Total runtime is 0.11866337855656942 minutes
2025-10-09 20:25:38,565:INFO:SubProcess create_model() called ==================================
2025-10-09 20:25:38,565:INFO:Initializing create_model()
2025-10-09 20:25:38,566:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000205BCE83A90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 20:25:38,566:INFO:Checking exceptions
2025-10-09 20:25:38,566:INFO:Importing libraries
2025-10-09 20:25:38,566:INFO:Copying training dataset
2025-10-09 20:25:38,572:INFO:Defining folds
2025-10-09 20:25:38,572:INFO:Declaring metric variables
2025-10-09 20:25:38,580:INFO:Importing untrained model
2025-10-09 20:25:38,587:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-09 20:25:38,597:INFO:Starting cross validation
2025-10-09 20:25:38,600:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 20:25:39,367:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 20:25:39,500:INFO:Calculating mean and std
2025-10-09 20:25:39,503:INFO:Creating metrics dataframe
2025-10-09 20:25:39,507:INFO:Uploading results into container
2025-10-09 20:25:39,508:INFO:Uploading model into container now
2025-10-09 20:25:39,510:INFO:_master_model_container: 27
2025-10-09 20:25:39,511:INFO:_display_container: 3
2025-10-09 20:25:39,512:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-09 20:25:39,513:INFO:create_model() successfully completed......................................
2025-10-09 20:25:39,655:INFO:SubProcess create_model() end ==================================
2025-10-09 20:25:39,655:INFO:Creating metrics dataframe
2025-10-09 20:25:39,669:INFO:Initializing Dummy Classifier
2025-10-09 20:25:39,669:INFO:Total runtime is 0.13716872135798136 minutes
2025-10-09 20:25:39,674:INFO:SubProcess create_model() called ==================================
2025-10-09 20:25:39,675:INFO:Initializing create_model()
2025-10-09 20:25:39,675:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000205BCE83A90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 20:25:39,675:INFO:Checking exceptions
2025-10-09 20:25:39,675:INFO:Importing libraries
2025-10-09 20:25:39,675:INFO:Copying training dataset
2025-10-09 20:25:39,683:INFO:Defining folds
2025-10-09 20:25:39,684:INFO:Declaring metric variables
2025-10-09 20:25:39,689:INFO:Importing untrained model
2025-10-09 20:25:39,696:INFO:Dummy Classifier Imported successfully
2025-10-09 20:25:39,708:INFO:Starting cross validation
2025-10-09 20:25:39,712:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 20:25:39,912:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 20:25:39,918:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 20:25:39,922:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 20:25:39,924:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 20:25:39,924:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 20:25:39,927:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 20:25:39,933:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 20:25:39,937:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 20:25:39,937:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 20:25:39,939:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 20:25:39,957:INFO:Calculating mean and std
2025-10-09 20:25:39,959:INFO:Creating metrics dataframe
2025-10-09 20:25:39,964:INFO:Uploading results into container
2025-10-09 20:25:39,965:INFO:Uploading model into container now
2025-10-09 20:25:39,965:INFO:_master_model_container: 28
2025-10-09 20:25:39,966:INFO:_display_container: 3
2025-10-09 20:25:39,966:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-10-09 20:25:39,967:INFO:create_model() successfully completed......................................
2025-10-09 20:25:40,098:INFO:SubProcess create_model() end ==================================
2025-10-09 20:25:40,098:INFO:Creating metrics dataframe
2025-10-09 20:25:40,112:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-10-09 20:25:40,126:INFO:Initializing create_model()
2025-10-09 20:25:40,127:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 20:25:40,127:INFO:Checking exceptions
2025-10-09 20:25:40,131:INFO:Importing libraries
2025-10-09 20:25:40,131:INFO:Copying training dataset
2025-10-09 20:25:40,138:INFO:Defining folds
2025-10-09 20:25:40,138:INFO:Declaring metric variables
2025-10-09 20:25:40,138:INFO:Importing untrained model
2025-10-09 20:25:40,138:INFO:Declaring custom model
2025-10-09 20:25:40,139:INFO:Ridge Classifier Imported successfully
2025-10-09 20:25:40,140:INFO:Cross validation set to False
2025-10-09 20:25:40,140:INFO:Fitting Model
2025-10-09 20:25:40,195:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-10-09 20:25:40,195:INFO:create_model() successfully completed......................................
2025-10-09 20:25:40,359:INFO:_master_model_container: 28
2025-10-09 20:25:40,360:INFO:_display_container: 3
2025-10-09 20:25:40,360:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-10-09 20:25:40,360:INFO:compare_models() successfully completed......................................
2025-10-09 20:26:14,512:INFO:Initializing compare_models()
2025-10-09 20:26:14,512:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-10-09 20:26:14,512:INFO:Checking exceptions
2025-10-09 20:26:14,518:INFO:Preparing display monitor
2025-10-09 20:26:14,566:INFO:Initializing Logistic Regression
2025-10-09 20:26:14,567:INFO:Total runtime is 1.6585985819498697e-05 minutes
2025-10-09 20:26:14,574:INFO:SubProcess create_model() called ==================================
2025-10-09 20:26:14,575:INFO:Initializing create_model()
2025-10-09 20:26:14,576:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000205BCE24AD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 20:26:14,576:INFO:Checking exceptions
2025-10-09 20:26:14,577:INFO:Importing libraries
2025-10-09 20:26:14,577:INFO:Copying training dataset
2025-10-09 20:26:14,584:INFO:Defining folds
2025-10-09 20:26:14,585:INFO:Declaring metric variables
2025-10-09 20:26:14,592:INFO:Importing untrained model
2025-10-09 20:26:14,600:INFO:Logistic Regression Imported successfully
2025-10-09 20:26:14,615:INFO:Starting cross validation
2025-10-09 20:26:14,618:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 20:26:14,923:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 20:26:14,979:INFO:Calculating mean and std
2025-10-09 20:26:14,979:INFO:Creating metrics dataframe
2025-10-09 20:26:14,982:INFO:Uploading results into container
2025-10-09 20:26:14,982:INFO:Uploading model into container now
2025-10-09 20:26:14,983:INFO:_master_model_container: 29
2025-10-09 20:26:14,983:INFO:_display_container: 4
2025-10-09 20:26:14,983:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-09 20:26:14,983:INFO:create_model() successfully completed......................................
2025-10-09 20:26:15,096:INFO:SubProcess create_model() end ==================================
2025-10-09 20:26:15,097:INFO:Creating metrics dataframe
2025-10-09 20:26:15,106:INFO:Initializing K Neighbors Classifier
2025-10-09 20:26:15,106:INFO:Total runtime is 0.008995262781778972 minutes
2025-10-09 20:26:15,113:INFO:SubProcess create_model() called ==================================
2025-10-09 20:26:15,113:INFO:Initializing create_model()
2025-10-09 20:26:15,113:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000205BCE24AD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 20:26:15,114:INFO:Checking exceptions
2025-10-09 20:26:15,114:INFO:Importing libraries
2025-10-09 20:26:15,114:INFO:Copying training dataset
2025-10-09 20:26:15,120:INFO:Defining folds
2025-10-09 20:26:15,120:INFO:Declaring metric variables
2025-10-09 20:26:15,124:INFO:Importing untrained model
2025-10-09 20:26:15,130:INFO:K Neighbors Classifier Imported successfully
2025-10-09 20:26:15,147:INFO:Starting cross validation
2025-10-09 20:26:15,150:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 20:26:15,550:INFO:Calculating mean and std
2025-10-09 20:26:15,552:INFO:Creating metrics dataframe
2025-10-09 20:26:15,556:INFO:Uploading results into container
2025-10-09 20:26:15,557:INFO:Uploading model into container now
2025-10-09 20:26:15,559:INFO:_master_model_container: 30
2025-10-09 20:26:15,559:INFO:_display_container: 4
2025-10-09 20:26:15,560:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-10-09 20:26:15,560:INFO:create_model() successfully completed......................................
2025-10-09 20:26:15,728:INFO:SubProcess create_model() end ==================================
2025-10-09 20:26:15,728:INFO:Creating metrics dataframe
2025-10-09 20:26:15,739:INFO:Initializing Naive Bayes
2025-10-09 20:26:15,739:INFO:Total runtime is 0.019547224044799805 minutes
2025-10-09 20:26:15,747:INFO:SubProcess create_model() called ==================================
2025-10-09 20:26:15,748:INFO:Initializing create_model()
2025-10-09 20:26:15,748:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000205BCE24AD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 20:26:15,748:INFO:Checking exceptions
2025-10-09 20:26:15,748:INFO:Importing libraries
2025-10-09 20:26:15,749:INFO:Copying training dataset
2025-10-09 20:26:15,757:INFO:Defining folds
2025-10-09 20:26:15,757:INFO:Declaring metric variables
2025-10-09 20:26:15,765:INFO:Importing untrained model
2025-10-09 20:26:15,773:INFO:Naive Bayes Imported successfully
2025-10-09 20:26:15,789:INFO:Starting cross validation
2025-10-09 20:26:15,791:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 20:26:16,055:INFO:Calculating mean and std
2025-10-09 20:26:16,056:INFO:Creating metrics dataframe
2025-10-09 20:26:16,059:INFO:Uploading results into container
2025-10-09 20:26:16,059:INFO:Uploading model into container now
2025-10-09 20:26:16,059:INFO:_master_model_container: 31
2025-10-09 20:26:16,061:INFO:_display_container: 4
2025-10-09 20:26:16,061:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-10-09 20:26:16,061:INFO:create_model() successfully completed......................................
2025-10-09 20:26:16,189:INFO:SubProcess create_model() end ==================================
2025-10-09 20:26:16,189:INFO:Creating metrics dataframe
2025-10-09 20:26:16,198:INFO:Initializing Decision Tree Classifier
2025-10-09 20:26:16,199:INFO:Total runtime is 0.02721715768178304 minutes
2025-10-09 20:26:16,206:INFO:SubProcess create_model() called ==================================
2025-10-09 20:26:16,207:INFO:Initializing create_model()
2025-10-09 20:26:16,207:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000205BCE24AD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 20:26:16,208:INFO:Checking exceptions
2025-10-09 20:26:16,208:INFO:Importing libraries
2025-10-09 20:26:16,208:INFO:Copying training dataset
2025-10-09 20:26:16,214:INFO:Defining folds
2025-10-09 20:26:16,214:INFO:Declaring metric variables
2025-10-09 20:26:16,223:INFO:Importing untrained model
2025-10-09 20:26:16,233:INFO:Decision Tree Classifier Imported successfully
2025-10-09 20:26:16,246:INFO:Starting cross validation
2025-10-09 20:26:16,249:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 20:26:16,534:INFO:Calculating mean and std
2025-10-09 20:26:16,536:INFO:Creating metrics dataframe
2025-10-09 20:26:16,539:INFO:Uploading results into container
2025-10-09 20:26:16,539:INFO:Uploading model into container now
2025-10-09 20:26:16,541:INFO:_master_model_container: 32
2025-10-09 20:26:16,541:INFO:_display_container: 4
2025-10-09 20:26:16,542:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-10-09 20:26:16,542:INFO:create_model() successfully completed......................................
2025-10-09 20:26:16,666:INFO:SubProcess create_model() end ==================================
2025-10-09 20:26:16,667:INFO:Creating metrics dataframe
2025-10-09 20:26:16,678:INFO:Initializing SVM - Linear Kernel
2025-10-09 20:26:16,678:INFO:Total runtime is 0.035192271073659256 minutes
2025-10-09 20:26:16,682:INFO:SubProcess create_model() called ==================================
2025-10-09 20:26:16,682:INFO:Initializing create_model()
2025-10-09 20:26:16,682:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000205BCE24AD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 20:26:16,682:INFO:Checking exceptions
2025-10-09 20:26:16,682:INFO:Importing libraries
2025-10-09 20:26:16,682:INFO:Copying training dataset
2025-10-09 20:26:16,691:INFO:Defining folds
2025-10-09 20:26:16,691:INFO:Declaring metric variables
2025-10-09 20:26:16,698:INFO:Importing untrained model
2025-10-09 20:26:16,706:INFO:SVM - Linear Kernel Imported successfully
2025-10-09 20:26:16,715:INFO:Starting cross validation
2025-10-09 20:26:16,717:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 20:26:16,973:INFO:Calculating mean and std
2025-10-09 20:26:16,974:INFO:Creating metrics dataframe
2025-10-09 20:26:16,976:INFO:Uploading results into container
2025-10-09 20:26:16,977:INFO:Uploading model into container now
2025-10-09 20:26:16,978:INFO:_master_model_container: 33
2025-10-09 20:26:16,978:INFO:_display_container: 4
2025-10-09 20:26:16,978:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-10-09 20:26:16,979:INFO:create_model() successfully completed......................................
2025-10-09 20:26:17,104:INFO:SubProcess create_model() end ==================================
2025-10-09 20:26:17,104:INFO:Creating metrics dataframe
2025-10-09 20:26:17,115:INFO:Initializing Ridge Classifier
2025-10-09 20:26:17,115:INFO:Total runtime is 0.04247663418451945 minutes
2025-10-09 20:26:17,121:INFO:SubProcess create_model() called ==================================
2025-10-09 20:26:17,121:INFO:Initializing create_model()
2025-10-09 20:26:17,122:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000205BCE24AD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 20:26:17,122:INFO:Checking exceptions
2025-10-09 20:26:17,122:INFO:Importing libraries
2025-10-09 20:26:17,122:INFO:Copying training dataset
2025-10-09 20:26:17,129:INFO:Defining folds
2025-10-09 20:26:17,129:INFO:Declaring metric variables
2025-10-09 20:26:17,135:INFO:Importing untrained model
2025-10-09 20:26:17,142:INFO:Ridge Classifier Imported successfully
2025-10-09 20:26:17,152:INFO:Starting cross validation
2025-10-09 20:26:17,155:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 20:26:17,388:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 20:26:17,389:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 20:26:17,392:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 20:26:17,411:INFO:Calculating mean and std
2025-10-09 20:26:17,413:INFO:Creating metrics dataframe
2025-10-09 20:26:17,415:INFO:Uploading results into container
2025-10-09 20:26:17,416:INFO:Uploading model into container now
2025-10-09 20:26:17,417:INFO:_master_model_container: 34
2025-10-09 20:26:17,417:INFO:_display_container: 4
2025-10-09 20:26:17,417:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-10-09 20:26:17,417:INFO:create_model() successfully completed......................................
2025-10-09 20:26:17,539:INFO:SubProcess create_model() end ==================================
2025-10-09 20:26:17,539:INFO:Creating metrics dataframe
2025-10-09 20:26:17,549:INFO:Initializing Random Forest Classifier
2025-10-09 20:26:17,551:INFO:Total runtime is 0.04973925352096557 minutes
2025-10-09 20:26:17,556:INFO:SubProcess create_model() called ==================================
2025-10-09 20:26:17,557:INFO:Initializing create_model()
2025-10-09 20:26:17,557:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000205BCE24AD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 20:26:17,557:INFO:Checking exceptions
2025-10-09 20:26:17,557:INFO:Importing libraries
2025-10-09 20:26:17,557:INFO:Copying training dataset
2025-10-09 20:26:17,563:INFO:Defining folds
2025-10-09 20:26:17,563:INFO:Declaring metric variables
2025-10-09 20:26:17,568:INFO:Importing untrained model
2025-10-09 20:26:17,576:INFO:Random Forest Classifier Imported successfully
2025-10-09 20:26:17,588:INFO:Starting cross validation
2025-10-09 20:26:17,590:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 20:26:18,361:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 20:26:18,438:INFO:Calculating mean and std
2025-10-09 20:26:18,439:INFO:Creating metrics dataframe
2025-10-09 20:26:18,442:INFO:Uploading results into container
2025-10-09 20:26:18,443:INFO:Uploading model into container now
2025-10-09 20:26:18,444:INFO:_master_model_container: 35
2025-10-09 20:26:18,444:INFO:_display_container: 4
2025-10-09 20:26:18,445:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-10-09 20:26:18,446:INFO:create_model() successfully completed......................................
2025-10-09 20:26:18,582:INFO:SubProcess create_model() end ==================================
2025-10-09 20:26:18,583:INFO:Creating metrics dataframe
2025-10-09 20:26:18,597:INFO:Initializing Quadratic Discriminant Analysis
2025-10-09 20:26:18,598:INFO:Total runtime is 0.06719510555267333 minutes
2025-10-09 20:26:18,604:INFO:SubProcess create_model() called ==================================
2025-10-09 20:26:18,605:INFO:Initializing create_model()
2025-10-09 20:26:18,605:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000205BCE24AD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 20:26:18,605:INFO:Checking exceptions
2025-10-09 20:26:18,605:INFO:Importing libraries
2025-10-09 20:26:18,606:INFO:Copying training dataset
2025-10-09 20:26:18,612:INFO:Defining folds
2025-10-09 20:26:18,612:INFO:Declaring metric variables
2025-10-09 20:26:18,623:INFO:Importing untrained model
2025-10-09 20:26:18,628:INFO:Quadratic Discriminant Analysis Imported successfully
2025-10-09 20:26:18,640:INFO:Starting cross validation
2025-10-09 20:26:18,644:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 20:26:18,809:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 20:26:18,811:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 20:26:18,812:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 20:26:18,815:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 20:26:18,820:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 20:26:18,823:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 20:26:18,823:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 20:26:18,826:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 20:26:18,830:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 20:26:18,836:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 20:26:18,933:INFO:Calculating mean and std
2025-10-09 20:26:18,937:INFO:Creating metrics dataframe
2025-10-09 20:26:18,943:INFO:Uploading results into container
2025-10-09 20:26:18,944:INFO:Uploading model into container now
2025-10-09 20:26:18,945:INFO:_master_model_container: 36
2025-10-09 20:26:18,945:INFO:_display_container: 4
2025-10-09 20:26:18,946:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-10-09 20:26:18,946:INFO:create_model() successfully completed......................................
2025-10-09 20:26:19,069:INFO:SubProcess create_model() end ==================================
2025-10-09 20:26:19,069:INFO:Creating metrics dataframe
2025-10-09 20:26:19,083:INFO:Initializing Ada Boost Classifier
2025-10-09 20:26:19,083:INFO:Total runtime is 0.07526959578196207 minutes
2025-10-09 20:26:19,089:INFO:SubProcess create_model() called ==================================
2025-10-09 20:26:19,089:INFO:Initializing create_model()
2025-10-09 20:26:19,089:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000205BCE24AD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 20:26:19,090:INFO:Checking exceptions
2025-10-09 20:26:19,090:INFO:Importing libraries
2025-10-09 20:26:19,090:INFO:Copying training dataset
2025-10-09 20:26:19,097:INFO:Defining folds
2025-10-09 20:26:19,097:INFO:Declaring metric variables
2025-10-09 20:26:19,104:INFO:Importing untrained model
2025-10-09 20:26:19,109:INFO:Ada Boost Classifier Imported successfully
2025-10-09 20:26:19,121:INFO:Starting cross validation
2025-10-09 20:26:19,123:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 20:26:19,259:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 20:26:19,269:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 20:26:19,273:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 20:26:19,279:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 20:26:19,282:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 20:26:19,289:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 20:26:19,292:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 20:26:19,304:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 20:26:19,324:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 20:26:19,632:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 20:26:19,646:INFO:Calculating mean and std
2025-10-09 20:26:19,648:INFO:Creating metrics dataframe
2025-10-09 20:26:19,651:INFO:Uploading results into container
2025-10-09 20:26:19,652:INFO:Uploading model into container now
2025-10-09 20:26:19,652:INFO:_master_model_container: 37
2025-10-09 20:26:19,653:INFO:_display_container: 4
2025-10-09 20:26:19,653:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-10-09 20:26:19,653:INFO:create_model() successfully completed......................................
2025-10-09 20:26:19,791:INFO:SubProcess create_model() end ==================================
2025-10-09 20:26:19,791:INFO:Creating metrics dataframe
2025-10-09 20:26:19,804:INFO:Initializing Gradient Boosting Classifier
2025-10-09 20:26:19,805:INFO:Total runtime is 0.08731635411580403 minutes
2025-10-09 20:26:19,813:INFO:SubProcess create_model() called ==================================
2025-10-09 20:26:19,814:INFO:Initializing create_model()
2025-10-09 20:26:19,814:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000205BCE24AD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 20:26:19,814:INFO:Checking exceptions
2025-10-09 20:26:19,815:INFO:Importing libraries
2025-10-09 20:26:19,815:INFO:Copying training dataset
2025-10-09 20:26:19,827:INFO:Defining folds
2025-10-09 20:26:19,827:INFO:Declaring metric variables
2025-10-09 20:26:19,833:INFO:Importing untrained model
2025-10-09 20:26:19,840:INFO:Gradient Boosting Classifier Imported successfully
2025-10-09 20:26:19,850:INFO:Starting cross validation
2025-10-09 20:26:19,853:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 20:26:20,394:INFO:Calculating mean and std
2025-10-09 20:26:20,395:INFO:Creating metrics dataframe
2025-10-09 20:26:20,399:INFO:Uploading results into container
2025-10-09 20:26:20,399:INFO:Uploading model into container now
2025-10-09 20:26:20,402:INFO:_master_model_container: 38
2025-10-09 20:26:20,402:INFO:_display_container: 4
2025-10-09 20:26:20,403:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-09 20:26:20,404:INFO:create_model() successfully completed......................................
2025-10-09 20:26:20,534:INFO:SubProcess create_model() end ==================================
2025-10-09 20:26:20,535:INFO:Creating metrics dataframe
2025-10-09 20:26:20,548:INFO:Initializing Linear Discriminant Analysis
2025-10-09 20:26:20,548:INFO:Total runtime is 0.0996969183286031 minutes
2025-10-09 20:26:20,554:INFO:SubProcess create_model() called ==================================
2025-10-09 20:26:20,555:INFO:Initializing create_model()
2025-10-09 20:26:20,556:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000205BCE24AD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 20:26:20,556:INFO:Checking exceptions
2025-10-09 20:26:20,556:INFO:Importing libraries
2025-10-09 20:26:20,556:INFO:Copying training dataset
2025-10-09 20:26:20,563:INFO:Defining folds
2025-10-09 20:26:20,563:INFO:Declaring metric variables
2025-10-09 20:26:20,567:INFO:Importing untrained model
2025-10-09 20:26:20,579:INFO:Linear Discriminant Analysis Imported successfully
2025-10-09 20:26:20,593:INFO:Starting cross validation
2025-10-09 20:26:20,597:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 20:26:20,879:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 20:26:20,952:INFO:Calculating mean and std
2025-10-09 20:26:20,953:INFO:Creating metrics dataframe
2025-10-09 20:26:20,957:INFO:Uploading results into container
2025-10-09 20:26:20,958:INFO:Uploading model into container now
2025-10-09 20:26:20,959:INFO:_master_model_container: 39
2025-10-09 20:26:20,959:INFO:_display_container: 4
2025-10-09 20:26:20,961:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-09 20:26:20,961:INFO:create_model() successfully completed......................................
2025-10-09 20:26:21,081:INFO:SubProcess create_model() end ==================================
2025-10-09 20:26:21,081:INFO:Creating metrics dataframe
2025-10-09 20:26:21,093:INFO:Initializing Extra Trees Classifier
2025-10-09 20:26:21,093:INFO:Total runtime is 0.1087704300880432 minutes
2025-10-09 20:26:21,098:INFO:SubProcess create_model() called ==================================
2025-10-09 20:26:21,099:INFO:Initializing create_model()
2025-10-09 20:26:21,100:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000205BCE24AD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 20:26:21,100:INFO:Checking exceptions
2025-10-09 20:26:21,100:INFO:Importing libraries
2025-10-09 20:26:21,100:INFO:Copying training dataset
2025-10-09 20:26:21,106:INFO:Defining folds
2025-10-09 20:26:21,106:INFO:Declaring metric variables
2025-10-09 20:26:21,110:INFO:Importing untrained model
2025-10-09 20:26:21,119:INFO:Extra Trees Classifier Imported successfully
2025-10-09 20:26:21,137:INFO:Starting cross validation
2025-10-09 20:26:21,142:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 20:26:21,829:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 20:26:21,904:INFO:Calculating mean and std
2025-10-09 20:26:21,907:INFO:Creating metrics dataframe
2025-10-09 20:26:21,911:INFO:Uploading results into container
2025-10-09 20:26:21,912:INFO:Uploading model into container now
2025-10-09 20:26:21,913:INFO:_master_model_container: 40
2025-10-09 20:26:21,914:INFO:_display_container: 4
2025-10-09 20:26:21,917:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-10-09 20:26:21,918:INFO:create_model() successfully completed......................................
2025-10-09 20:26:22,064:INFO:SubProcess create_model() end ==================================
2025-10-09 20:26:22,064:INFO:Creating metrics dataframe
2025-10-09 20:26:22,077:INFO:Initializing Light Gradient Boosting Machine
2025-10-09 20:26:22,077:INFO:Total runtime is 0.12518468300501503 minutes
2025-10-09 20:26:22,082:INFO:SubProcess create_model() called ==================================
2025-10-09 20:26:22,083:INFO:Initializing create_model()
2025-10-09 20:26:22,084:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000205BCE24AD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 20:26:22,084:INFO:Checking exceptions
2025-10-09 20:26:22,084:INFO:Importing libraries
2025-10-09 20:26:22,085:INFO:Copying training dataset
2025-10-09 20:26:22,094:INFO:Defining folds
2025-10-09 20:26:22,094:INFO:Declaring metric variables
2025-10-09 20:26:22,099:INFO:Importing untrained model
2025-10-09 20:26:22,104:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-09 20:26:22,123:INFO:Starting cross validation
2025-10-09 20:26:22,127:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 20:26:23,113:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 20:26:23,131:INFO:Calculating mean and std
2025-10-09 20:26:23,134:INFO:Creating metrics dataframe
2025-10-09 20:26:23,139:INFO:Uploading results into container
2025-10-09 20:26:23,141:INFO:Uploading model into container now
2025-10-09 20:26:23,143:INFO:_master_model_container: 41
2025-10-09 20:26:23,143:INFO:_display_container: 4
2025-10-09 20:26:23,146:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-09 20:26:23,146:INFO:create_model() successfully completed......................................
2025-10-09 20:26:23,325:INFO:SubProcess create_model() end ==================================
2025-10-09 20:26:23,326:INFO:Creating metrics dataframe
2025-10-09 20:26:23,350:INFO:Initializing Dummy Classifier
2025-10-09 20:26:23,351:INFO:Total runtime is 0.14639891386032103 minutes
2025-10-09 20:26:23,356:INFO:SubProcess create_model() called ==================================
2025-10-09 20:26:23,357:INFO:Initializing create_model()
2025-10-09 20:26:23,358:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000205BCE24AD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 20:26:23,358:INFO:Checking exceptions
2025-10-09 20:26:23,358:INFO:Importing libraries
2025-10-09 20:26:23,359:INFO:Copying training dataset
2025-10-09 20:26:23,368:INFO:Defining folds
2025-10-09 20:26:23,369:INFO:Declaring metric variables
2025-10-09 20:26:23,380:INFO:Importing untrained model
2025-10-09 20:26:23,387:INFO:Dummy Classifier Imported successfully
2025-10-09 20:26:23,412:INFO:Starting cross validation
2025-10-09 20:26:23,415:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 20:26:23,628:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 20:26:23,637:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 20:26:23,643:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 20:26:23,648:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 20:26:23,658:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 20:26:23,664:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 20:26:23,668:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 20:26:23,673:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 20:26:23,673:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 20:26:23,698:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 20:26:23,707:INFO:Calculating mean and std
2025-10-09 20:26:23,708:INFO:Creating metrics dataframe
2025-10-09 20:26:23,711:INFO:Uploading results into container
2025-10-09 20:26:23,711:INFO:Uploading model into container now
2025-10-09 20:26:23,712:INFO:_master_model_container: 42
2025-10-09 20:26:23,712:INFO:_display_container: 4
2025-10-09 20:26:23,712:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-10-09 20:26:23,713:INFO:create_model() successfully completed......................................
2025-10-09 20:26:23,845:INFO:SubProcess create_model() end ==================================
2025-10-09 20:26:23,845:INFO:Creating metrics dataframe
2025-10-09 20:26:23,862:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-10-09 20:26:23,872:INFO:Initializing create_model()
2025-10-09 20:26:23,872:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=DummyClassifier(constant=None, random_state=123, strategy='prior'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 20:26:23,872:INFO:Checking exceptions
2025-10-09 20:26:23,875:INFO:Importing libraries
2025-10-09 20:26:23,875:INFO:Copying training dataset
2025-10-09 20:26:23,883:INFO:Defining folds
2025-10-09 20:26:23,883:INFO:Declaring metric variables
2025-10-09 20:26:23,883:INFO:Importing untrained model
2025-10-09 20:26:23,883:INFO:Declaring custom model
2025-10-09 20:26:23,883:INFO:Dummy Classifier Imported successfully
2025-10-09 20:26:23,886:INFO:Cross validation set to False
2025-10-09 20:26:23,886:INFO:Fitting Model
2025-10-09 20:26:23,957:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-10-09 20:26:23,957:INFO:create_model() successfully completed......................................
2025-10-09 20:26:24,143:INFO:_master_model_container: 42
2025-10-09 20:26:24,143:INFO:_display_container: 4
2025-10-09 20:26:24,144:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-10-09 20:26:24,144:INFO:compare_models() successfully completed......................................
2025-10-09 20:27:49,699:INFO:Initializing compare_models()
2025-10-09 20:27:49,700:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-10-09 20:27:49,700:INFO:Checking exceptions
2025-10-09 20:27:49,704:INFO:Preparing display monitor
2025-10-09 20:27:49,750:INFO:Initializing Logistic Regression
2025-10-09 20:27:49,751:INFO:Total runtime is 1.6820430755615234e-05 minutes
2025-10-09 20:27:49,758:INFO:SubProcess create_model() called ==================================
2025-10-09 20:27:49,759:INFO:Initializing create_model()
2025-10-09 20:27:49,759:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000205BEB78D10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 20:27:49,759:INFO:Checking exceptions
2025-10-09 20:27:49,759:INFO:Importing libraries
2025-10-09 20:27:49,759:INFO:Copying training dataset
2025-10-09 20:27:49,770:INFO:Defining folds
2025-10-09 20:27:49,770:INFO:Declaring metric variables
2025-10-09 20:27:49,778:INFO:Importing untrained model
2025-10-09 20:27:49,783:INFO:Logistic Regression Imported successfully
2025-10-09 20:27:49,795:INFO:Starting cross validation
2025-10-09 20:27:49,797:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 20:27:50,053:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 20:27:50,081:INFO:Calculating mean and std
2025-10-09 20:27:50,081:INFO:Creating metrics dataframe
2025-10-09 20:27:50,084:INFO:Uploading results into container
2025-10-09 20:27:50,085:INFO:Uploading model into container now
2025-10-09 20:27:50,085:INFO:_master_model_container: 43
2025-10-09 20:27:50,085:INFO:_display_container: 5
2025-10-09 20:27:50,086:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-09 20:27:50,086:INFO:create_model() successfully completed......................................
2025-10-09 20:27:50,197:INFO:SubProcess create_model() end ==================================
2025-10-09 20:27:50,197:INFO:Creating metrics dataframe
2025-10-09 20:27:50,205:INFO:Initializing K Neighbors Classifier
2025-10-09 20:27:50,205:INFO:Total runtime is 0.007573548952738444 minutes
2025-10-09 20:27:50,210:INFO:SubProcess create_model() called ==================================
2025-10-09 20:27:50,211:INFO:Initializing create_model()
2025-10-09 20:27:50,211:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000205BEB78D10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 20:27:50,211:INFO:Checking exceptions
2025-10-09 20:27:50,211:INFO:Importing libraries
2025-10-09 20:27:50,211:INFO:Copying training dataset
2025-10-09 20:27:50,219:INFO:Defining folds
2025-10-09 20:27:50,219:INFO:Declaring metric variables
2025-10-09 20:27:50,223:INFO:Importing untrained model
2025-10-09 20:27:50,226:INFO:K Neighbors Classifier Imported successfully
2025-10-09 20:27:50,235:INFO:Starting cross validation
2025-10-09 20:27:50,237:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 20:27:50,575:INFO:Calculating mean and std
2025-10-09 20:27:50,576:INFO:Creating metrics dataframe
2025-10-09 20:27:50,578:INFO:Uploading results into container
2025-10-09 20:27:50,579:INFO:Uploading model into container now
2025-10-09 20:27:50,579:INFO:_master_model_container: 44
2025-10-09 20:27:50,579:INFO:_display_container: 5
2025-10-09 20:27:50,580:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-10-09 20:27:50,580:INFO:create_model() successfully completed......................................
2025-10-09 20:27:50,701:INFO:SubProcess create_model() end ==================================
2025-10-09 20:27:50,701:INFO:Creating metrics dataframe
2025-10-09 20:27:50,713:INFO:Initializing Naive Bayes
2025-10-09 20:27:50,713:INFO:Total runtime is 0.016044012705485024 minutes
2025-10-09 20:27:50,718:INFO:SubProcess create_model() called ==================================
2025-10-09 20:27:50,719:INFO:Initializing create_model()
2025-10-09 20:27:50,719:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000205BEB78D10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 20:27:50,719:INFO:Checking exceptions
2025-10-09 20:27:50,720:INFO:Importing libraries
2025-10-09 20:27:50,720:INFO:Copying training dataset
2025-10-09 20:27:50,730:INFO:Defining folds
2025-10-09 20:27:50,731:INFO:Declaring metric variables
2025-10-09 20:27:50,736:INFO:Importing untrained model
2025-10-09 20:27:50,741:INFO:Naive Bayes Imported successfully
2025-10-09 20:27:50,752:INFO:Starting cross validation
2025-10-09 20:27:50,757:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 20:27:51,013:INFO:Calculating mean and std
2025-10-09 20:27:51,014:INFO:Creating metrics dataframe
2025-10-09 20:27:51,017:INFO:Uploading results into container
2025-10-09 20:27:51,018:INFO:Uploading model into container now
2025-10-09 20:27:51,018:INFO:_master_model_container: 45
2025-10-09 20:27:51,018:INFO:_display_container: 5
2025-10-09 20:27:51,019:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-10-09 20:27:51,019:INFO:create_model() successfully completed......................................
2025-10-09 20:27:51,146:INFO:SubProcess create_model() end ==================================
2025-10-09 20:27:51,146:INFO:Creating metrics dataframe
2025-10-09 20:27:51,156:INFO:Initializing Decision Tree Classifier
2025-10-09 20:27:51,156:INFO:Total runtime is 0.023435962200164792 minutes
2025-10-09 20:27:51,160:INFO:SubProcess create_model() called ==================================
2025-10-09 20:27:51,161:INFO:Initializing create_model()
2025-10-09 20:27:51,161:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000205BEB78D10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 20:27:51,161:INFO:Checking exceptions
2025-10-09 20:27:51,161:INFO:Importing libraries
2025-10-09 20:27:51,161:INFO:Copying training dataset
2025-10-09 20:27:51,168:INFO:Defining folds
2025-10-09 20:27:51,169:INFO:Declaring metric variables
2025-10-09 20:27:51,177:INFO:Importing untrained model
2025-10-09 20:27:51,183:INFO:Decision Tree Classifier Imported successfully
2025-10-09 20:27:51,195:INFO:Starting cross validation
2025-10-09 20:27:51,198:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 20:27:51,517:INFO:Calculating mean and std
2025-10-09 20:27:51,519:INFO:Creating metrics dataframe
2025-10-09 20:27:51,521:INFO:Uploading results into container
2025-10-09 20:27:51,522:INFO:Uploading model into container now
2025-10-09 20:27:51,522:INFO:_master_model_container: 46
2025-10-09 20:27:51,522:INFO:_display_container: 5
2025-10-09 20:27:51,523:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-10-09 20:27:51,523:INFO:create_model() successfully completed......................................
2025-10-09 20:27:51,652:INFO:SubProcess create_model() end ==================================
2025-10-09 20:27:51,652:INFO:Creating metrics dataframe
2025-10-09 20:27:51,664:INFO:Initializing SVM - Linear Kernel
2025-10-09 20:27:51,664:INFO:Total runtime is 0.031904582182566324 minutes
2025-10-09 20:27:51,669:INFO:SubProcess create_model() called ==================================
2025-10-09 20:27:51,670:INFO:Initializing create_model()
2025-10-09 20:27:51,670:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000205BEB78D10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 20:27:51,670:INFO:Checking exceptions
2025-10-09 20:27:51,670:INFO:Importing libraries
2025-10-09 20:27:51,670:INFO:Copying training dataset
2025-10-09 20:27:51,680:INFO:Defining folds
2025-10-09 20:27:51,680:INFO:Declaring metric variables
2025-10-09 20:27:51,686:INFO:Importing untrained model
2025-10-09 20:27:51,691:INFO:SVM - Linear Kernel Imported successfully
2025-10-09 20:27:51,702:INFO:Starting cross validation
2025-10-09 20:27:51,706:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 20:27:51,979:INFO:Calculating mean and std
2025-10-09 20:27:51,981:INFO:Creating metrics dataframe
2025-10-09 20:27:51,983:INFO:Uploading results into container
2025-10-09 20:27:51,984:INFO:Uploading model into container now
2025-10-09 20:27:51,985:INFO:_master_model_container: 47
2025-10-09 20:27:51,985:INFO:_display_container: 5
2025-10-09 20:27:51,985:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-10-09 20:27:51,985:INFO:create_model() successfully completed......................................
2025-10-09 20:27:52,110:INFO:SubProcess create_model() end ==================================
2025-10-09 20:27:52,110:INFO:Creating metrics dataframe
2025-10-09 20:27:52,120:INFO:Initializing Ridge Classifier
2025-10-09 20:27:52,120:INFO:Total runtime is 0.03950030406316121 minutes
2025-10-09 20:27:52,124:INFO:SubProcess create_model() called ==================================
2025-10-09 20:27:52,125:INFO:Initializing create_model()
2025-10-09 20:27:52,126:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000205BEB78D10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 20:27:52,127:INFO:Checking exceptions
2025-10-09 20:27:52,127:INFO:Importing libraries
2025-10-09 20:27:52,127:INFO:Copying training dataset
2025-10-09 20:27:52,135:INFO:Defining folds
2025-10-09 20:27:52,135:INFO:Declaring metric variables
2025-10-09 20:27:52,141:INFO:Importing untrained model
2025-10-09 20:27:52,147:INFO:Ridge Classifier Imported successfully
2025-10-09 20:27:52,162:INFO:Starting cross validation
2025-10-09 20:27:52,164:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 20:27:52,397:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 20:27:52,398:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 20:27:52,410:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 20:27:52,439:INFO:Calculating mean and std
2025-10-09 20:27:52,441:INFO:Creating metrics dataframe
2025-10-09 20:27:52,444:INFO:Uploading results into container
2025-10-09 20:27:52,444:INFO:Uploading model into container now
2025-10-09 20:27:52,445:INFO:_master_model_container: 48
2025-10-09 20:27:52,445:INFO:_display_container: 5
2025-10-09 20:27:52,446:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-10-09 20:27:52,446:INFO:create_model() successfully completed......................................
2025-10-09 20:27:52,577:INFO:SubProcess create_model() end ==================================
2025-10-09 20:27:52,577:INFO:Creating metrics dataframe
2025-10-09 20:27:52,589:INFO:Initializing Random Forest Classifier
2025-10-09 20:27:52,589:INFO:Total runtime is 0.0473123033841451 minutes
2025-10-09 20:27:52,597:INFO:SubProcess create_model() called ==================================
2025-10-09 20:27:52,598:INFO:Initializing create_model()
2025-10-09 20:27:52,598:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000205BEB78D10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 20:27:52,598:INFO:Checking exceptions
2025-10-09 20:27:52,599:INFO:Importing libraries
2025-10-09 20:27:52,599:INFO:Copying training dataset
2025-10-09 20:27:52,604:INFO:Defining folds
2025-10-09 20:27:52,605:INFO:Declaring metric variables
2025-10-09 20:27:52,609:INFO:Importing untrained model
2025-10-09 20:27:52,619:INFO:Random Forest Classifier Imported successfully
2025-10-09 20:27:52,632:INFO:Starting cross validation
2025-10-09 20:27:52,634:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 20:27:53,396:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 20:27:53,440:INFO:Calculating mean and std
2025-10-09 20:27:53,441:INFO:Creating metrics dataframe
2025-10-09 20:27:53,448:INFO:Uploading results into container
2025-10-09 20:27:53,449:INFO:Uploading model into container now
2025-10-09 20:27:53,451:INFO:_master_model_container: 49
2025-10-09 20:27:53,451:INFO:_display_container: 5
2025-10-09 20:27:53,452:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-10-09 20:27:53,452:INFO:create_model() successfully completed......................................
2025-10-09 20:27:53,584:INFO:SubProcess create_model() end ==================================
2025-10-09 20:27:53,584:INFO:Creating metrics dataframe
2025-10-09 20:27:53,593:INFO:Initializing Quadratic Discriminant Analysis
2025-10-09 20:27:53,593:INFO:Total runtime is 0.06404218673706054 minutes
2025-10-09 20:27:53,599:INFO:SubProcess create_model() called ==================================
2025-10-09 20:27:53,600:INFO:Initializing create_model()
2025-10-09 20:27:53,600:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000205BEB78D10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 20:27:53,600:INFO:Checking exceptions
2025-10-09 20:27:53,600:INFO:Importing libraries
2025-10-09 20:27:53,600:INFO:Copying training dataset
2025-10-09 20:27:53,608:INFO:Defining folds
2025-10-09 20:27:53,608:INFO:Declaring metric variables
2025-10-09 20:27:53,614:INFO:Importing untrained model
2025-10-09 20:27:53,621:INFO:Quadratic Discriminant Analysis Imported successfully
2025-10-09 20:27:53,634:INFO:Starting cross validation
2025-10-09 20:27:53,636:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 20:27:53,786:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 20:27:53,786:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 20:27:53,790:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 20:27:53,790:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 20:27:53,791:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 20:27:53,794:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 20:27:53,801:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 20:27:53,805:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 20:27:53,807:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 20:27:53,903:INFO:Calculating mean and std
2025-10-09 20:27:53,905:INFO:Creating metrics dataframe
2025-10-09 20:27:53,907:INFO:Uploading results into container
2025-10-09 20:27:53,908:INFO:Uploading model into container now
2025-10-09 20:27:53,909:INFO:_master_model_container: 50
2025-10-09 20:27:53,909:INFO:_display_container: 5
2025-10-09 20:27:53,909:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-10-09 20:27:53,909:INFO:create_model() successfully completed......................................
2025-10-09 20:27:54,029:INFO:SubProcess create_model() end ==================================
2025-10-09 20:27:54,029:INFO:Creating metrics dataframe
2025-10-09 20:27:54,041:INFO:Initializing Ada Boost Classifier
2025-10-09 20:27:54,041:INFO:Total runtime is 0.07151469786961873 minutes
2025-10-09 20:27:54,045:INFO:SubProcess create_model() called ==================================
2025-10-09 20:27:54,046:INFO:Initializing create_model()
2025-10-09 20:27:54,047:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000205BEB78D10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 20:27:54,047:INFO:Checking exceptions
2025-10-09 20:27:54,047:INFO:Importing libraries
2025-10-09 20:27:54,047:INFO:Copying training dataset
2025-10-09 20:27:54,055:INFO:Defining folds
2025-10-09 20:27:54,055:INFO:Declaring metric variables
2025-10-09 20:27:54,061:INFO:Importing untrained model
2025-10-09 20:27:54,068:INFO:Ada Boost Classifier Imported successfully
2025-10-09 20:27:54,078:INFO:Starting cross validation
2025-10-09 20:27:54,092:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 20:27:54,237:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 20:27:54,245:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 20:27:54,246:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 20:27:54,247:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 20:27:54,250:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 20:27:54,252:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 20:27:54,252:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 20:27:54,252:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 20:27:54,263:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 20:27:54,265:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 20:27:54,562:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 20:27:54,607:INFO:Calculating mean and std
2025-10-09 20:27:54,609:INFO:Creating metrics dataframe
2025-10-09 20:27:54,614:INFO:Uploading results into container
2025-10-09 20:27:54,615:INFO:Uploading model into container now
2025-10-09 20:27:54,616:INFO:_master_model_container: 51
2025-10-09 20:27:54,616:INFO:_display_container: 5
2025-10-09 20:27:54,617:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-10-09 20:27:54,617:INFO:create_model() successfully completed......................................
2025-10-09 20:27:54,731:INFO:SubProcess create_model() end ==================================
2025-10-09 20:27:54,731:INFO:Creating metrics dataframe
2025-10-09 20:27:54,744:INFO:Initializing Gradient Boosting Classifier
2025-10-09 20:27:54,744:INFO:Total runtime is 0.08322373628616332 minutes
2025-10-09 20:27:54,750:INFO:SubProcess create_model() called ==================================
2025-10-09 20:27:54,750:INFO:Initializing create_model()
2025-10-09 20:27:54,750:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000205BEB78D10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 20:27:54,750:INFO:Checking exceptions
2025-10-09 20:27:54,751:INFO:Importing libraries
2025-10-09 20:27:54,751:INFO:Copying training dataset
2025-10-09 20:27:54,757:INFO:Defining folds
2025-10-09 20:27:54,757:INFO:Declaring metric variables
2025-10-09 20:27:54,763:INFO:Importing untrained model
2025-10-09 20:27:54,775:INFO:Gradient Boosting Classifier Imported successfully
2025-10-09 20:27:54,789:INFO:Starting cross validation
2025-10-09 20:27:54,791:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 20:27:55,322:INFO:Calculating mean and std
2025-10-09 20:27:55,323:INFO:Creating metrics dataframe
2025-10-09 20:27:55,326:INFO:Uploading results into container
2025-10-09 20:27:55,327:INFO:Uploading model into container now
2025-10-09 20:27:55,329:INFO:_master_model_container: 52
2025-10-09 20:27:55,330:INFO:_display_container: 5
2025-10-09 20:27:55,330:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-09 20:27:55,331:INFO:create_model() successfully completed......................................
2025-10-09 20:27:55,453:INFO:SubProcess create_model() end ==================================
2025-10-09 20:27:55,454:INFO:Creating metrics dataframe
2025-10-09 20:27:55,466:INFO:Initializing Linear Discriminant Analysis
2025-10-09 20:27:55,466:INFO:Total runtime is 0.09526944160461424 minutes
2025-10-09 20:27:55,471:INFO:SubProcess create_model() called ==================================
2025-10-09 20:27:55,473:INFO:Initializing create_model()
2025-10-09 20:27:55,473:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000205BEB78D10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 20:27:55,473:INFO:Checking exceptions
2025-10-09 20:27:55,473:INFO:Importing libraries
2025-10-09 20:27:55,473:INFO:Copying training dataset
2025-10-09 20:27:55,480:INFO:Defining folds
2025-10-09 20:27:55,480:INFO:Declaring metric variables
2025-10-09 20:27:55,487:INFO:Importing untrained model
2025-10-09 20:27:55,495:INFO:Linear Discriminant Analysis Imported successfully
2025-10-09 20:27:55,506:INFO:Starting cross validation
2025-10-09 20:27:55,509:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 20:27:55,718:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 20:27:55,757:INFO:Calculating mean and std
2025-10-09 20:27:55,758:INFO:Creating metrics dataframe
2025-10-09 20:27:55,761:INFO:Uploading results into container
2025-10-09 20:27:55,763:INFO:Uploading model into container now
2025-10-09 20:27:55,764:INFO:_master_model_container: 53
2025-10-09 20:27:55,764:INFO:_display_container: 5
2025-10-09 20:27:55,765:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-09 20:27:55,765:INFO:create_model() successfully completed......................................
2025-10-09 20:27:55,887:INFO:SubProcess create_model() end ==================================
2025-10-09 20:27:55,888:INFO:Creating metrics dataframe
2025-10-09 20:27:55,904:INFO:Initializing Extra Trees Classifier
2025-10-09 20:27:55,904:INFO:Total runtime is 0.10255629221598306 minutes
2025-10-09 20:27:55,908:INFO:SubProcess create_model() called ==================================
2025-10-09 20:27:55,908:INFO:Initializing create_model()
2025-10-09 20:27:55,909:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000205BEB78D10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 20:27:55,909:INFO:Checking exceptions
2025-10-09 20:27:55,909:INFO:Importing libraries
2025-10-09 20:27:55,909:INFO:Copying training dataset
2025-10-09 20:27:55,917:INFO:Defining folds
2025-10-09 20:27:55,917:INFO:Declaring metric variables
2025-10-09 20:27:55,920:INFO:Importing untrained model
2025-10-09 20:27:55,926:INFO:Extra Trees Classifier Imported successfully
2025-10-09 20:27:55,939:INFO:Starting cross validation
2025-10-09 20:27:55,942:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 20:27:56,743:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 20:27:56,761:INFO:Calculating mean and std
2025-10-09 20:27:56,763:INFO:Creating metrics dataframe
2025-10-09 20:27:56,767:INFO:Uploading results into container
2025-10-09 20:27:56,769:INFO:Uploading model into container now
2025-10-09 20:27:56,769:INFO:_master_model_container: 54
2025-10-09 20:27:56,769:INFO:_display_container: 5
2025-10-09 20:27:56,770:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-10-09 20:27:56,770:INFO:create_model() successfully completed......................................
2025-10-09 20:27:56,901:INFO:SubProcess create_model() end ==================================
2025-10-09 20:27:56,901:INFO:Creating metrics dataframe
2025-10-09 20:27:56,917:INFO:Initializing Light Gradient Boosting Machine
2025-10-09 20:27:56,917:INFO:Total runtime is 0.11944502194722492 minutes
2025-10-09 20:27:56,923:INFO:SubProcess create_model() called ==================================
2025-10-09 20:27:56,923:INFO:Initializing create_model()
2025-10-09 20:27:56,924:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000205BEB78D10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 20:27:56,924:INFO:Checking exceptions
2025-10-09 20:27:56,924:INFO:Importing libraries
2025-10-09 20:27:56,924:INFO:Copying training dataset
2025-10-09 20:27:56,934:INFO:Defining folds
2025-10-09 20:27:56,934:INFO:Declaring metric variables
2025-10-09 20:27:56,941:INFO:Importing untrained model
2025-10-09 20:27:56,946:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-09 20:27:56,959:INFO:Starting cross validation
2025-10-09 20:27:56,961:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 20:27:57,770:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 20:27:57,876:INFO:Calculating mean and std
2025-10-09 20:27:57,880:INFO:Creating metrics dataframe
2025-10-09 20:27:57,885:INFO:Uploading results into container
2025-10-09 20:27:57,888:INFO:Uploading model into container now
2025-10-09 20:27:57,890:INFO:_master_model_container: 55
2025-10-09 20:27:57,892:INFO:_display_container: 5
2025-10-09 20:27:57,895:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-09 20:27:57,895:INFO:create_model() successfully completed......................................
2025-10-09 20:27:58,033:INFO:SubProcess create_model() end ==================================
2025-10-09 20:27:58,033:INFO:Creating metrics dataframe
2025-10-09 20:27:58,047:INFO:Initializing Dummy Classifier
2025-10-09 20:27:58,047:INFO:Total runtime is 0.1382796843846639 minutes
2025-10-09 20:27:58,052:INFO:SubProcess create_model() called ==================================
2025-10-09 20:27:58,052:INFO:Initializing create_model()
2025-10-09 20:27:58,053:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000205BEB78D10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 20:27:58,053:INFO:Checking exceptions
2025-10-09 20:27:58,053:INFO:Importing libraries
2025-10-09 20:27:58,053:INFO:Copying training dataset
2025-10-09 20:27:58,061:INFO:Defining folds
2025-10-09 20:27:58,061:INFO:Declaring metric variables
2025-10-09 20:27:58,065:INFO:Importing untrained model
2025-10-09 20:27:58,072:INFO:Dummy Classifier Imported successfully
2025-10-09 20:27:58,084:INFO:Starting cross validation
2025-10-09 20:27:58,087:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 20:27:58,298:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 20:27:58,305:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 20:27:58,305:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 20:27:58,306:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 20:27:58,307:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 20:27:58,313:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 20:27:58,320:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 20:27:58,321:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 20:27:58,326:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 20:27:58,326:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 20:27:58,337:INFO:Calculating mean and std
2025-10-09 20:27:58,338:INFO:Creating metrics dataframe
2025-10-09 20:27:58,341:INFO:Uploading results into container
2025-10-09 20:27:58,341:INFO:Uploading model into container now
2025-10-09 20:27:58,342:INFO:_master_model_container: 56
2025-10-09 20:27:58,343:INFO:_display_container: 5
2025-10-09 20:27:58,343:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-10-09 20:27:58,344:INFO:create_model() successfully completed......................................
2025-10-09 20:27:58,474:INFO:SubProcess create_model() end ==================================
2025-10-09 20:27:58,474:INFO:Creating metrics dataframe
2025-10-09 20:27:58,489:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-10-09 20:27:58,505:INFO:Initializing create_model()
2025-10-09 20:27:58,505:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 20:27:58,505:INFO:Checking exceptions
2025-10-09 20:27:58,507:INFO:Importing libraries
2025-10-09 20:27:58,507:INFO:Copying training dataset
2025-10-09 20:27:58,515:INFO:Defining folds
2025-10-09 20:27:58,515:INFO:Declaring metric variables
2025-10-09 20:27:58,516:INFO:Importing untrained model
2025-10-09 20:27:58,516:INFO:Declaring custom model
2025-10-09 20:27:58,516:INFO:Ridge Classifier Imported successfully
2025-10-09 20:27:58,518:INFO:Cross validation set to False
2025-10-09 20:27:58,518:INFO:Fitting Model
2025-10-09 20:27:58,593:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-10-09 20:27:58,593:INFO:create_model() successfully completed......................................
2025-10-09 20:27:58,760:INFO:_master_model_container: 56
2025-10-09 20:27:58,760:INFO:_display_container: 5
2025-10-09 20:27:58,761:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-10-09 20:27:58,761:INFO:compare_models() successfully completed......................................
2025-10-09 20:44:36,196:INFO:Initializing create_model()
2025-10-09 20:44:36,196:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=nb, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 20:44:36,196:INFO:Checking exceptions
2025-10-09 20:44:36,222:INFO:Importing libraries
2025-10-09 20:44:36,224:INFO:Copying training dataset
2025-10-09 20:44:36,233:INFO:Defining folds
2025-10-09 20:44:36,233:INFO:Declaring metric variables
2025-10-09 20:44:36,242:INFO:Importing untrained model
2025-10-09 20:44:36,248:INFO:Naive Bayes Imported successfully
2025-10-09 20:44:36,258:INFO:Starting cross validation
2025-10-09 20:44:36,261:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 20:44:58,208:INFO:Calculating mean and std
2025-10-09 20:44:58,215:INFO:Creating metrics dataframe
2025-10-09 20:44:58,234:INFO:Finalizing model
2025-10-09 20:44:58,446:INFO:Uploading results into container
2025-10-09 20:44:58,447:INFO:Uploading model into container now
2025-10-09 20:44:58,462:INFO:_master_model_container: 57
2025-10-09 20:44:58,462:INFO:_display_container: 6
2025-10-09 20:44:58,462:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-10-09 20:44:58,462:INFO:create_model() successfully completed......................................
2025-10-09 20:51:48,056:INFO:Initializing tune_model()
2025-10-09 20:51:48,056:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-10-09 20:51:48,056:INFO:Checking exceptions
2025-10-09 20:51:48,090:INFO:Copying training dataset
2025-10-09 20:51:48,097:INFO:Checking base model
2025-10-09 20:51:48,097:INFO:Base model : Naive Bayes
2025-10-09 20:51:48,105:INFO:Declaring metric variables
2025-10-09 20:51:48,114:INFO:Defining Hyperparameters
2025-10-09 20:51:48,324:INFO:Tuning with n_jobs=-1
2025-10-09 20:51:48,324:INFO:Initializing RandomizedSearchCV
2025-10-09 20:52:01,643:INFO:best_params: {'actual_estimator__var_smoothing': 1}
2025-10-09 20:52:01,645:INFO:Hyperparameter search completed
2025-10-09 20:52:01,646:INFO:SubProcess create_model() called ==================================
2025-10-09 20:52:01,647:INFO:Initializing create_model()
2025-10-09 20:52:01,647:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000205BE4D6790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'var_smoothing': 1})
2025-10-09 20:52:01,647:INFO:Checking exceptions
2025-10-09 20:52:01,648:INFO:Importing libraries
2025-10-09 20:52:01,648:INFO:Copying training dataset
2025-10-09 20:52:01,656:INFO:Defining folds
2025-10-09 20:52:01,656:INFO:Declaring metric variables
2025-10-09 20:52:01,663:INFO:Importing untrained model
2025-10-09 20:52:01,663:INFO:Declaring custom model
2025-10-09 20:52:01,671:INFO:Naive Bayes Imported successfully
2025-10-09 20:52:01,688:INFO:Starting cross validation
2025-10-09 20:52:01,692:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 20:52:02,035:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 20:52:02,035:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 20:52:02,035:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 20:52:02,044:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 20:52:02,061:INFO:Calculating mean and std
2025-10-09 20:52:02,062:INFO:Creating metrics dataframe
2025-10-09 20:52:02,073:INFO:Finalizing model
2025-10-09 20:52:02,169:INFO:Uploading results into container
2025-10-09 20:52:02,170:INFO:Uploading model into container now
2025-10-09 20:52:02,172:INFO:_master_model_container: 58
2025-10-09 20:52:02,172:INFO:_display_container: 7
2025-10-09 20:52:02,172:INFO:GaussianNB(priors=None, var_smoothing=1)
2025-10-09 20:52:02,173:INFO:create_model() successfully completed......................................
2025-10-09 20:52:02,318:INFO:SubProcess create_model() end ==================================
2025-10-09 20:52:02,318:INFO:choose_better activated
2025-10-09 20:52:02,323:INFO:SubProcess create_model() called ==================================
2025-10-09 20:52:02,323:INFO:Initializing create_model()
2025-10-09 20:52:02,324:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 20:52:02,324:INFO:Checking exceptions
2025-10-09 20:52:02,326:INFO:Importing libraries
2025-10-09 20:52:02,326:INFO:Copying training dataset
2025-10-09 20:52:02,332:INFO:Defining folds
2025-10-09 20:52:02,332:INFO:Declaring metric variables
2025-10-09 20:52:02,334:INFO:Importing untrained model
2025-10-09 20:52:02,334:INFO:Declaring custom model
2025-10-09 20:52:02,334:INFO:Naive Bayes Imported successfully
2025-10-09 20:52:02,334:INFO:Starting cross validation
2025-10-09 20:52:02,335:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 20:52:02,644:INFO:Calculating mean and std
2025-10-09 20:52:02,644:INFO:Creating metrics dataframe
2025-10-09 20:52:02,649:INFO:Finalizing model
2025-10-09 20:52:02,711:INFO:Uploading results into container
2025-10-09 20:52:02,713:INFO:Uploading model into container now
2025-10-09 20:52:02,713:INFO:_master_model_container: 59
2025-10-09 20:52:02,714:INFO:_display_container: 8
2025-10-09 20:52:02,714:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-10-09 20:52:02,714:INFO:create_model() successfully completed......................................
2025-10-09 20:52:02,847:INFO:SubProcess create_model() end ==================================
2025-10-09 20:52:02,848:INFO:GaussianNB(priors=None, var_smoothing=1e-09) result for Accuracy is 0.7
2025-10-09 20:52:02,848:INFO:GaussianNB(priors=None, var_smoothing=1) result for Accuracy is 0.7238
2025-10-09 20:52:02,848:INFO:GaussianNB(priors=None, var_smoothing=1) is best model
2025-10-09 20:52:02,848:INFO:choose_better completed
2025-10-09 20:52:02,865:INFO:_master_model_container: 59
2025-10-09 20:52:02,866:INFO:_display_container: 7
2025-10-09 20:52:02,867:INFO:GaussianNB(priors=None, var_smoothing=1)
2025-10-09 20:52:02,867:INFO:tune_model() successfully completed......................................
2025-10-09 20:53:07,063:INFO:Initializing evaluate_model()
2025-10-09 20:53:07,063:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=GaussianNB(priors=None, var_smoothing=1), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-10-09 20:53:07,081:INFO:Initializing plot_model()
2025-10-09 20:53:07,082:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=GaussianNB(priors=None, var_smoothing=1), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-09 20:53:07,082:INFO:Checking exceptions
2025-10-09 20:53:07,086:INFO:Preloading libraries
2025-10-09 20:53:07,086:INFO:Copying training dataset
2025-10-09 20:53:07,086:INFO:Plot type: pipeline
2025-10-09 20:53:07,399:INFO:Visual Rendered Successfully
2025-10-09 20:53:07,508:INFO:plot_model() successfully completed......................................
2025-10-09 20:53:28,894:INFO:Initializing plot_model()
2025-10-09 20:53:28,894:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=GaussianNB(priors=None, var_smoothing=1), plot=auc, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-09 20:53:28,895:INFO:Checking exceptions
2025-10-09 20:53:28,898:INFO:Preloading libraries
2025-10-09 20:53:28,899:INFO:Copying training dataset
2025-10-09 20:53:28,899:INFO:Plot type: auc
2025-10-09 20:53:29,195:INFO:Fitting Model
2025-10-09 20:53:29,218:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but GaussianNB was fitted with feature names
  warnings.warn(

2025-10-09 20:53:29,218:INFO:Scoring test/hold-out set
2025-10-09 20:53:29,473:INFO:Visual Rendered Successfully
2025-10-09 20:53:29,555:INFO:plot_model() successfully completed......................................
2025-10-09 20:53:38,827:INFO:Initializing plot_model()
2025-10-09 20:53:38,827:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=GaussianNB(priors=None, var_smoothing=1), plot=parameter, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-09 20:53:38,827:INFO:Checking exceptions
2025-10-09 20:53:38,831:INFO:Preloading libraries
2025-10-09 20:53:38,832:INFO:Copying training dataset
2025-10-09 20:53:38,832:INFO:Plot type: parameter
2025-10-09 20:53:38,838:INFO:Visual Rendered Successfully
2025-10-09 20:53:38,924:INFO:plot_model() successfully completed......................................
2025-10-09 20:53:42,142:INFO:Initializing plot_model()
2025-10-09 20:53:42,142:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=GaussianNB(priors=None, var_smoothing=1), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-09 20:53:42,142:INFO:Checking exceptions
2025-10-09 20:53:42,146:INFO:Preloading libraries
2025-10-09 20:53:42,146:INFO:Copying training dataset
2025-10-09 20:53:42,147:INFO:Plot type: pipeline
2025-10-09 20:53:42,301:INFO:Visual Rendered Successfully
2025-10-09 20:53:42,426:INFO:plot_model() successfully completed......................................
2025-10-09 20:53:44,002:INFO:Initializing plot_model()
2025-10-09 20:53:44,002:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=GaussianNB(priors=None, var_smoothing=1), plot=auc, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-09 20:53:44,002:INFO:Checking exceptions
2025-10-09 20:53:44,004:INFO:Preloading libraries
2025-10-09 20:53:44,004:INFO:Copying training dataset
2025-10-09 20:53:44,005:INFO:Plot type: auc
2025-10-09 20:53:44,235:INFO:Fitting Model
2025-10-09 20:53:44,236:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but GaussianNB was fitted with feature names
  warnings.warn(

2025-10-09 20:53:44,236:INFO:Scoring test/hold-out set
2025-10-09 20:53:44,497:INFO:Visual Rendered Successfully
2025-10-09 20:53:44,626:INFO:plot_model() successfully completed......................................
2025-10-09 20:53:45,343:INFO:Initializing plot_model()
2025-10-09 20:53:45,344:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=GaussianNB(priors=None, var_smoothing=1), plot=confusion_matrix, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-09 20:53:45,344:INFO:Checking exceptions
2025-10-09 20:53:45,348:INFO:Preloading libraries
2025-10-09 20:53:45,348:INFO:Copying training dataset
2025-10-09 20:53:45,348:INFO:Plot type: confusion_matrix
2025-10-09 20:53:45,549:INFO:Fitting Model
2025-10-09 20:53:45,549:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but GaussianNB was fitted with feature names
  warnings.warn(

2025-10-09 20:53:45,550:INFO:Scoring test/hold-out set
2025-10-09 20:53:45,645:INFO:Visual Rendered Successfully
2025-10-09 20:53:45,727:INFO:plot_model() successfully completed......................................
2025-10-09 20:54:10,628:INFO:Initializing plot_model()
2025-10-09 20:54:10,629:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=GaussianNB(priors=None, var_smoothing=1), plot=threshold, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-09 20:54:10,630:INFO:Checking exceptions
2025-10-09 20:54:10,635:INFO:Preloading libraries
2025-10-09 20:54:10,635:INFO:Copying training dataset
2025-10-09 20:54:10,636:INFO:Plot type: threshold
2025-10-09 20:54:10,976:INFO:Fitting Model
2025-10-09 20:54:11,196:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but GaussianNB was fitted with feature names
  warnings.warn(

2025-10-09 20:54:11,216:INFO:Scoring test/hold-out set
2025-10-09 20:54:11,581:INFO:Visual Rendered Successfully
2025-10-09 20:54:11,714:INFO:plot_model() successfully completed......................................
2025-10-09 20:54:11,953:INFO:Initializing plot_model()
2025-10-09 20:54:11,953:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=GaussianNB(priors=None, var_smoothing=1), plot=pr, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-09 20:54:11,954:INFO:Checking exceptions
2025-10-09 20:54:11,956:INFO:Preloading libraries
2025-10-09 20:54:11,956:INFO:Copying training dataset
2025-10-09 20:54:11,957:INFO:Plot type: pr
2025-10-09 20:54:12,188:INFO:Fitting Model
2025-10-09 20:54:12,188:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but GaussianNB was fitted with feature names
  warnings.warn(

2025-10-09 20:54:12,190:INFO:Scoring test/hold-out set
2025-10-09 20:54:12,348:INFO:Visual Rendered Successfully
2025-10-09 20:54:12,427:INFO:plot_model() successfully completed......................................
2025-10-09 20:54:13,657:INFO:Initializing plot_model()
2025-10-09 20:54:13,658:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=GaussianNB(priors=None, var_smoothing=1), plot=threshold, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-09 20:54:13,658:INFO:Checking exceptions
2025-10-09 20:54:13,660:INFO:Preloading libraries
2025-10-09 20:54:13,661:INFO:Copying training dataset
2025-10-09 20:54:13,661:INFO:Plot type: threshold
2025-10-09 20:54:13,842:INFO:Fitting Model
2025-10-09 20:54:14,026:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but GaussianNB was fitted with feature names
  warnings.warn(

2025-10-09 20:54:14,042:INFO:Scoring test/hold-out set
2025-10-09 20:54:14,223:INFO:Visual Rendered Successfully
2025-10-09 20:54:14,305:INFO:plot_model() successfully completed......................................
2025-10-09 20:54:22,158:INFO:Initializing plot_model()
2025-10-09 20:54:22,159:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=GaussianNB(priors=None, var_smoothing=1), plot=pr, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-09 20:54:22,159:INFO:Checking exceptions
2025-10-09 20:54:22,161:INFO:Preloading libraries
2025-10-09 20:54:22,161:INFO:Copying training dataset
2025-10-09 20:54:22,161:INFO:Plot type: pr
2025-10-09 20:54:22,333:INFO:Fitting Model
2025-10-09 20:54:22,333:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but GaussianNB was fitted with feature names
  warnings.warn(

2025-10-09 20:54:22,333:INFO:Scoring test/hold-out set
2025-10-09 20:54:22,478:INFO:Visual Rendered Successfully
2025-10-09 20:54:22,616:INFO:plot_model() successfully completed......................................
2025-10-09 20:54:24,855:INFO:Initializing plot_model()
2025-10-09 20:54:24,855:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=GaussianNB(priors=None, var_smoothing=1), plot=class_report, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-09 20:54:24,855:INFO:Checking exceptions
2025-10-09 20:54:24,859:INFO:Preloading libraries
2025-10-09 20:54:24,860:INFO:Copying training dataset
2025-10-09 20:54:24,860:INFO:Plot type: class_report
2025-10-09 20:54:25,040:INFO:Fitting Model
2025-10-09 20:54:25,040:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but GaussianNB was fitted with feature names
  warnings.warn(

2025-10-09 20:54:25,040:INFO:Scoring test/hold-out set
2025-10-09 20:54:25,045:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 20:54:25,233:INFO:Visual Rendered Successfully
2025-10-09 20:54:25,363:INFO:plot_model() successfully completed......................................
2025-10-09 20:54:27,368:INFO:Initializing plot_model()
2025-10-09 20:54:27,369:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=GaussianNB(priors=None, var_smoothing=1), plot=confusion_matrix, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-09 20:54:27,369:INFO:Checking exceptions
2025-10-09 20:54:27,373:INFO:Preloading libraries
2025-10-09 20:54:27,373:INFO:Copying training dataset
2025-10-09 20:54:27,373:INFO:Plot type: confusion_matrix
2025-10-09 20:54:27,554:INFO:Fitting Model
2025-10-09 20:54:27,554:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but GaussianNB was fitted with feature names
  warnings.warn(

2025-10-09 20:54:27,554:INFO:Scoring test/hold-out set
2025-10-09 20:54:27,660:INFO:Visual Rendered Successfully
2025-10-09 20:54:27,799:INFO:plot_model() successfully completed......................................
2025-10-09 20:55:33,998:INFO:Initializing plot_model()
2025-10-09 20:55:33,998:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=GaussianNB(priors=None, var_smoothing=1), plot=auc, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-09 20:55:33,998:INFO:Checking exceptions
2025-10-09 20:55:34,001:INFO:Preloading libraries
2025-10-09 20:55:34,002:INFO:Copying training dataset
2025-10-09 20:55:34,002:INFO:Plot type: auc
2025-10-09 20:55:34,184:INFO:Fitting Model
2025-10-09 20:55:34,185:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but GaussianNB was fitted with feature names
  warnings.warn(

2025-10-09 20:55:34,185:INFO:Scoring test/hold-out set
2025-10-09 20:55:34,356:INFO:Visual Rendered Successfully
2025-10-09 20:55:34,501:INFO:plot_model() successfully completed......................................
2025-10-09 20:55:39,143:INFO:Initializing plot_model()
2025-10-09 20:55:39,143:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=GaussianNB(priors=None, var_smoothing=1), plot=confusion_matrix, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-09 20:55:39,143:INFO:Checking exceptions
2025-10-09 20:55:39,145:INFO:Preloading libraries
2025-10-09 20:55:39,145:INFO:Copying training dataset
2025-10-09 20:55:39,145:INFO:Plot type: confusion_matrix
2025-10-09 20:55:39,312:INFO:Fitting Model
2025-10-09 20:55:39,313:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but GaussianNB was fitted with feature names
  warnings.warn(

2025-10-09 20:55:39,313:INFO:Scoring test/hold-out set
2025-10-09 20:55:39,402:INFO:Visual Rendered Successfully
2025-10-09 20:55:39,517:INFO:plot_model() successfully completed......................................
2025-10-09 20:56:09,504:INFO:Initializing evaluate_model()
2025-10-09 20:56:09,504:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-10-09 20:56:09,523:INFO:Initializing plot_model()
2025-10-09 20:56:09,523:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-09 20:56:09,524:INFO:Checking exceptions
2025-10-09 20:56:09,527:INFO:Preloading libraries
2025-10-09 20:56:09,527:INFO:Copying training dataset
2025-10-09 20:56:09,527:INFO:Plot type: pipeline
2025-10-09 20:56:09,694:INFO:Visual Rendered Successfully
2025-10-09 20:56:09,811:INFO:plot_model() successfully completed......................................
2025-10-09 20:56:12,375:INFO:Initializing plot_model()
2025-10-09 20:56:12,376:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), plot=confusion_matrix, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-09 20:56:12,376:INFO:Checking exceptions
2025-10-09 20:56:12,381:INFO:Preloading libraries
2025-10-09 20:56:12,381:INFO:Copying training dataset
2025-10-09 20:56:12,381:INFO:Plot type: confusion_matrix
2025-10-09 20:56:12,683:INFO:Fitting Model
2025-10-09 20:56:12,684:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but GaussianNB was fitted with feature names
  warnings.warn(

2025-10-09 20:56:12,684:INFO:Scoring test/hold-out set
2025-10-09 20:56:12,798:INFO:Visual Rendered Successfully
2025-10-09 20:56:12,931:INFO:plot_model() successfully completed......................................
2025-10-09 20:56:17,430:INFO:Initializing plot_model()
2025-10-09 20:56:17,430:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), plot=auc, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-09 20:56:17,430:INFO:Checking exceptions
2025-10-09 20:56:17,433:INFO:Preloading libraries
2025-10-09 20:56:17,433:INFO:Copying training dataset
2025-10-09 20:56:17,433:INFO:Plot type: auc
2025-10-09 20:56:17,631:INFO:Fitting Model
2025-10-09 20:56:17,631:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but GaussianNB was fitted with feature names
  warnings.warn(

2025-10-09 20:56:17,631:INFO:Scoring test/hold-out set
2025-10-09 20:56:17,868:INFO:Visual Rendered Successfully
2025-10-09 20:56:18,028:INFO:plot_model() successfully completed......................................
2025-10-09 20:56:22,716:INFO:Initializing plot_model()
2025-10-09 20:56:22,717:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), plot=threshold, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-09 20:56:22,717:INFO:Checking exceptions
2025-10-09 20:56:22,721:INFO:Preloading libraries
2025-10-09 20:56:22,721:INFO:Copying training dataset
2025-10-09 20:56:22,721:INFO:Plot type: threshold
2025-10-09 20:56:22,936:INFO:Fitting Model
2025-10-09 20:56:23,155:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but GaussianNB was fitted with feature names
  warnings.warn(

2025-10-09 20:56:23,171:INFO:Scoring test/hold-out set
2025-10-09 20:56:23,342:INFO:Visual Rendered Successfully
2025-10-09 20:56:23,487:INFO:plot_model() successfully completed......................................
2025-10-09 20:56:31,297:INFO:Initializing plot_model()
2025-10-09 20:56:31,297:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), plot=pr, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-09 20:56:31,398:INFO:Checking exceptions
2025-10-09 20:56:31,399:INFO:Preloading libraries
2025-10-09 20:56:31,399:INFO:Copying training dataset
2025-10-09 20:56:31,399:INFO:Plot type: pr
2025-10-09 20:56:31,624:INFO:Fitting Model
2025-10-09 20:56:31,624:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but GaussianNB was fitted with feature names
  warnings.warn(

2025-10-09 20:56:31,624:INFO:Scoring test/hold-out set
2025-10-09 20:56:31,776:INFO:Visual Rendered Successfully
2025-10-09 20:56:31,909:INFO:plot_model() successfully completed......................................
2025-10-09 20:56:37,260:INFO:Initializing plot_model()
2025-10-09 20:56:37,260:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), plot=class_report, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-09 20:56:37,260:INFO:Checking exceptions
2025-10-09 20:56:37,264:INFO:Preloading libraries
2025-10-09 20:56:37,265:INFO:Copying training dataset
2025-10-09 20:56:37,265:INFO:Plot type: class_report
2025-10-09 20:56:37,450:INFO:Fitting Model
2025-10-09 20:56:37,451:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but GaussianNB was fitted with feature names
  warnings.warn(

2025-10-09 20:56:37,451:INFO:Scoring test/hold-out set
2025-10-09 20:56:37,634:INFO:Visual Rendered Successfully
2025-10-09 20:56:37,718:INFO:plot_model() successfully completed......................................
2025-10-09 20:56:52,904:INFO:Initializing plot_model()
2025-10-09 20:56:52,904:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), plot=auc, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-09 20:56:52,905:INFO:Checking exceptions
2025-10-09 20:56:52,909:INFO:Preloading libraries
2025-10-09 20:56:52,909:INFO:Copying training dataset
2025-10-09 20:56:52,909:INFO:Plot type: auc
2025-10-09 20:56:53,086:INFO:Fitting Model
2025-10-09 20:56:53,087:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but GaussianNB was fitted with feature names
  warnings.warn(

2025-10-09 20:56:53,087:INFO:Scoring test/hold-out set
2025-10-09 20:56:53,327:INFO:Visual Rendered Successfully
2025-10-09 20:56:53,466:INFO:plot_model() successfully completed......................................
2025-10-09 20:57:02,539:INFO:Initializing plot_model()
2025-10-09 20:57:02,539:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), plot=confusion_matrix, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-09 20:57:02,539:INFO:Checking exceptions
2025-10-09 20:57:02,541:INFO:Preloading libraries
2025-10-09 20:57:02,543:INFO:Copying training dataset
2025-10-09 20:57:02,543:INFO:Plot type: confusion_matrix
2025-10-09 20:57:02,738:INFO:Fitting Model
2025-10-09 20:57:02,738:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but GaussianNB was fitted with feature names
  warnings.warn(

2025-10-09 20:57:02,740:INFO:Scoring test/hold-out set
2025-10-09 20:57:02,833:INFO:Visual Rendered Successfully
2025-10-09 20:57:02,996:INFO:plot_model() successfully completed......................................
2025-10-09 20:57:19,522:INFO:Initializing plot_model()
2025-10-09 20:57:19,523:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), plot=threshold, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-09 20:57:19,523:INFO:Checking exceptions
2025-10-09 20:57:19,526:INFO:Preloading libraries
2025-10-09 20:57:19,526:INFO:Copying training dataset
2025-10-09 20:57:19,527:INFO:Plot type: threshold
2025-10-09 20:57:19,700:INFO:Fitting Model
2025-10-09 20:57:19,931:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but GaussianNB was fitted with feature names
  warnings.warn(

2025-10-09 20:57:19,947:INFO:Scoring test/hold-out set
2025-10-09 20:57:20,118:INFO:Visual Rendered Successfully
2025-10-09 20:57:20,257:INFO:plot_model() successfully completed......................................
2025-10-09 20:57:28,145:INFO:Initializing plot_model()
2025-10-09 20:57:28,146:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), plot=pr, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-09 20:57:28,146:INFO:Checking exceptions
2025-10-09 20:57:28,148:INFO:Preloading libraries
2025-10-09 20:57:28,148:INFO:Copying training dataset
2025-10-09 20:57:28,148:INFO:Plot type: pr
2025-10-09 20:57:28,366:INFO:Fitting Model
2025-10-09 20:57:28,366:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but GaussianNB was fitted with feature names
  warnings.warn(

2025-10-09 20:57:28,366:INFO:Scoring test/hold-out set
2025-10-09 20:57:28,565:INFO:Visual Rendered Successfully
2025-10-09 20:57:28,684:INFO:plot_model() successfully completed......................................
2025-10-09 20:57:35,534:INFO:Initializing plot_model()
2025-10-09 20:57:35,535:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), plot=vc, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-09 20:57:35,535:INFO:Checking exceptions
2025-10-09 20:57:35,538:INFO:Preloading libraries
2025-10-09 20:57:35,539:INFO:Copying training dataset
2025-10-09 20:57:35,539:INFO:Plot type: vc
2025-10-09 20:57:35,539:INFO:Determining param_name
2025-10-09 20:57:35,540:INFO:param_name: var_smoothing
2025-10-09 20:57:35,732:INFO:Fitting Model
2025-10-09 20:57:40,375:INFO:Visual Rendered Successfully
2025-10-09 20:57:40,506:INFO:plot_model() successfully completed......................................
2025-10-09 20:57:40,586:INFO:Initializing plot_model()
2025-10-09 20:57:40,586:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), plot=dimension, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-09 20:57:40,587:INFO:Checking exceptions
2025-10-09 20:57:40,589:INFO:Preloading libraries
2025-10-09 20:57:40,589:INFO:Copying training dataset
2025-10-09 20:57:40,589:INFO:Plot type: dimension
2025-10-09 20:57:40,692:INFO:Fitting StandardScaler()
2025-10-09 20:57:40,741:INFO:Fitting PCA()
2025-10-09 20:57:40,924:INFO:Fitting & Transforming Model
2025-10-09 20:57:41,070:INFO:Visual Rendered Successfully
2025-10-09 20:57:41,215:INFO:plot_model() successfully completed......................................
2025-10-09 20:57:41,383:INFO:Initializing plot_model()
2025-10-09 20:57:41,383:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), plot=vc, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-09 20:57:41,384:INFO:Checking exceptions
2025-10-09 20:57:41,388:INFO:Preloading libraries
2025-10-09 20:57:41,389:INFO:Copying training dataset
2025-10-09 20:57:41,389:INFO:Plot type: vc
2025-10-09 20:57:41,389:INFO:Determining param_name
2025-10-09 20:57:41,390:INFO:param_name: var_smoothing
2025-10-09 20:57:41,591:INFO:Fitting Model
2025-10-09 20:57:43,292:INFO:Visual Rendered Successfully
2025-10-09 20:57:43,374:INFO:plot_model() successfully completed......................................
2025-10-09 20:57:57,604:INFO:Initializing plot_model()
2025-10-09 20:57:57,604:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), plot=feature, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-09 20:57:57,604:INFO:Checking exceptions
2025-10-09 20:57:59,127:INFO:Initializing plot_model()
2025-10-09 20:57:59,128:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), plot=feature_all, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-09 20:57:59,128:INFO:Checking exceptions
2025-10-09 20:58:04,380:INFO:Initializing plot_model()
2025-10-09 20:58:04,380:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), plot=rfe, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-09 20:58:04,380:INFO:Checking exceptions
2025-10-09 20:58:09,771:INFO:Initializing plot_model()
2025-10-09 20:58:09,772:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), plot=feature_all, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-09 20:58:09,772:INFO:Checking exceptions
2025-10-09 20:58:11,013:INFO:Initializing plot_model()
2025-10-09 20:58:11,013:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), plot=feature, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-09 20:58:11,013:INFO:Checking exceptions
2025-10-09 20:58:13,222:INFO:Initializing plot_model()
2025-10-09 20:58:13,222:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), plot=feature_all, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-09 20:58:13,223:INFO:Checking exceptions
2025-10-09 20:58:14,291:INFO:Initializing plot_model()
2025-10-09 20:58:14,292:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), plot=boundary, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-09 20:58:14,292:INFO:Checking exceptions
2025-10-09 20:58:14,294:INFO:Preloading libraries
2025-10-09 20:58:14,294:INFO:Copying training dataset
2025-10-09 20:58:14,294:INFO:Plot type: boundary
2025-10-09 20:58:14,388:INFO:Fitting StandardScaler()
2025-10-09 20:58:14,390:INFO:Fitting PCA()
2025-10-09 20:58:14,476:INFO:Fitting Model
2025-10-09 20:58:15,458:INFO:Visual Rendered Successfully
2025-10-09 20:58:15,605:INFO:plot_model() successfully completed......................................
2025-10-09 20:58:16,993:INFO:Initializing plot_model()
2025-10-09 20:58:16,993:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), plot=feature_all, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-09 20:58:16,993:INFO:Checking exceptions
2025-10-09 20:58:29,350:INFO:Initializing plot_model()
2025-10-09 20:58:29,350:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), plot=feature, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-09 20:58:29,350:INFO:Checking exceptions
2025-10-09 20:58:44,204:INFO:Initializing plot_model()
2025-10-09 20:58:44,204:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), plot=class_report, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-09 20:58:44,205:INFO:Checking exceptions
2025-10-09 20:58:44,208:INFO:Preloading libraries
2025-10-09 20:58:44,209:INFO:Copying training dataset
2025-10-09 20:58:44,209:INFO:Plot type: class_report
2025-10-09 20:58:44,382:INFO:Fitting Model
2025-10-09 20:58:44,382:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but GaussianNB was fitted with feature names
  warnings.warn(

2025-10-09 20:58:44,382:INFO:Scoring test/hold-out set
2025-10-09 20:58:44,595:INFO:Visual Rendered Successfully
2025-10-09 20:58:44,734:INFO:plot_model() successfully completed......................................
2025-10-09 20:58:46,387:INFO:Initializing plot_model()
2025-10-09 20:58:46,387:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), plot=parameter, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-09 20:58:46,387:INFO:Checking exceptions
2025-10-09 20:58:46,391:INFO:Preloading libraries
2025-10-09 20:58:46,391:INFO:Copying training dataset
2025-10-09 20:58:46,391:INFO:Plot type: parameter
2025-10-09 20:58:46,396:INFO:Visual Rendered Successfully
2025-10-09 20:58:46,498:INFO:plot_model() successfully completed......................................
2025-10-09 20:58:50,285:INFO:Initializing plot_model()
2025-10-09 20:58:50,285:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), plot=lift, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-09 20:58:50,286:INFO:Checking exceptions
2025-10-09 20:58:50,289:INFO:Preloading libraries
2025-10-09 20:58:50,289:INFO:Copying training dataset
2025-10-09 20:58:50,289:INFO:Plot type: lift
2025-10-09 20:58:50,289:INFO:Generating predictions / predict_proba on X_test
2025-10-09 20:58:50,575:INFO:Visual Rendered Successfully
2025-10-09 20:58:50,699:INFO:plot_model() successfully completed......................................
2025-10-09 20:58:52,791:INFO:Initializing plot_model()
2025-10-09 20:58:52,791:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), plot=gain, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-09 20:58:52,791:INFO:Checking exceptions
2025-10-09 20:58:52,794:INFO:Preloading libraries
2025-10-09 20:58:52,794:INFO:Copying training dataset
2025-10-09 20:58:52,794:INFO:Plot type: gain
2025-10-09 20:58:52,795:INFO:Generating predictions / predict_proba on X_test
2025-10-09 20:58:53,029:INFO:Visual Rendered Successfully
2025-10-09 20:58:53,116:INFO:plot_model() successfully completed......................................
2025-10-09 20:58:59,039:INFO:Initializing plot_model()
2025-10-09 20:58:59,040:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), plot=tree, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-09 20:58:59,040:INFO:Checking exceptions
2025-10-09 20:59:00,845:INFO:Initializing plot_model()
2025-10-09 20:59:00,845:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), plot=ks, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-09 20:59:00,845:INFO:Checking exceptions
2025-10-09 20:59:00,847:INFO:Preloading libraries
2025-10-09 20:59:00,847:INFO:Copying training dataset
2025-10-09 20:59:00,848:INFO:Plot type: ks
2025-10-09 20:59:00,848:INFO:Generating predictions / predict_proba on X_test
2025-10-09 20:59:01,075:INFO:Visual Rendered Successfully
2025-10-09 20:59:01,161:INFO:plot_model() successfully completed......................................
2025-10-09 20:59:13,661:INFO:Initializing plot_model()
2025-10-09 20:59:13,662:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), plot=confusion_matrix, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-09 20:59:13,662:INFO:Checking exceptions
2025-10-09 20:59:13,668:INFO:Preloading libraries
2025-10-09 20:59:13,669:INFO:Copying training dataset
2025-10-09 20:59:13,669:INFO:Plot type: confusion_matrix
2025-10-09 20:59:13,921:INFO:Fitting Model
2025-10-09 20:59:13,921:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but GaussianNB was fitted with feature names
  warnings.warn(

2025-10-09 20:59:13,922:INFO:Scoring test/hold-out set
2025-10-09 20:59:14,019:INFO:Visual Rendered Successfully
2025-10-09 20:59:14,193:INFO:plot_model() successfully completed......................................
2025-10-09 20:59:39,166:INFO:Initializing plot_model()
2025-10-09 20:59:39,166:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), plot=feature, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-09 20:59:39,166:INFO:Checking exceptions
2025-10-09 20:59:41,098:INFO:Initializing plot_model()
2025-10-09 20:59:41,099:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), plot=feature_all, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-09 20:59:41,099:INFO:Checking exceptions
2025-10-09 21:01:51,812:INFO:Initializing create_model()
2025-10-09 21:01:51,812:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=dt, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 21:01:51,812:INFO:Checking exceptions
2025-10-09 21:01:51,843:INFO:Importing libraries
2025-10-09 21:01:51,843:INFO:Copying training dataset
2025-10-09 21:01:51,854:INFO:Defining folds
2025-10-09 21:01:51,854:INFO:Declaring metric variables
2025-10-09 21:01:51,863:INFO:Importing untrained model
2025-10-09 21:01:51,870:INFO:Decision Tree Classifier Imported successfully
2025-10-09 21:01:51,884:INFO:Starting cross validation
2025-10-09 21:01:51,888:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 21:01:56,860:INFO:Calculating mean and std
2025-10-09 21:01:56,861:INFO:Creating metrics dataframe
2025-10-09 21:01:56,869:INFO:Finalizing model
2025-10-09 21:01:56,938:INFO:Uploading results into container
2025-10-09 21:01:56,939:INFO:Uploading model into container now
2025-10-09 21:01:56,951:INFO:_master_model_container: 60
2025-10-09 21:01:56,952:INFO:_display_container: 8
2025-10-09 21:01:56,953:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-10-09 21:01:56,954:INFO:create_model() successfully completed......................................
2025-10-09 21:02:10,628:INFO:Initializing tune_model()
2025-10-09 21:02:10,628:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best'), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-10-09 21:02:10,628:INFO:Checking exceptions
2025-10-09 21:02:10,660:INFO:Copying training dataset
2025-10-09 21:02:10,670:INFO:Checking base model
2025-10-09 21:02:10,671:INFO:Base model : Decision Tree Classifier
2025-10-09 21:02:10,677:INFO:Declaring metric variables
2025-10-09 21:02:10,685:INFO:Defining Hyperparameters
2025-10-09 21:02:10,895:INFO:Tuning with n_jobs=-1
2025-10-09 21:02:10,895:INFO:Initializing RandomizedSearchCV
2025-10-09 21:02:15,230:INFO:best_params: {'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 6, 'actual_estimator__min_impurity_decrease': 0.01, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 1, 'actual_estimator__criterion': 'gini'}
2025-10-09 21:02:15,231:INFO:Hyperparameter search completed
2025-10-09 21:02:15,231:INFO:SubProcess create_model() called ==================================
2025-10-09 21:02:15,232:INFO:Initializing create_model()
2025-10-09 21:02:15,232:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000205C3318150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'min_samples_split': 5, 'min_samples_leaf': 6, 'min_impurity_decrease': 0.01, 'max_features': 1.0, 'max_depth': 1, 'criterion': 'gini'})
2025-10-09 21:02:15,232:INFO:Checking exceptions
2025-10-09 21:02:15,232:INFO:Importing libraries
2025-10-09 21:02:15,232:INFO:Copying training dataset
2025-10-09 21:02:15,237:INFO:Defining folds
2025-10-09 21:02:15,237:INFO:Declaring metric variables
2025-10-09 21:02:15,242:INFO:Importing untrained model
2025-10-09 21:02:15,242:INFO:Declaring custom model
2025-10-09 21:02:15,249:INFO:Decision Tree Classifier Imported successfully
2025-10-09 21:02:15,261:INFO:Starting cross validation
2025-10-09 21:02:15,263:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 21:02:15,464:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 21:02:15,477:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 21:02:15,477:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 21:02:15,479:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 21:02:15,481:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 21:02:15,487:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 21:02:15,488:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 21:02:15,494:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 21:02:15,497:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 21:02:15,498:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 21:02:15,509:INFO:Calculating mean and std
2025-10-09 21:02:15,510:INFO:Creating metrics dataframe
2025-10-09 21:02:15,518:INFO:Finalizing model
2025-10-09 21:02:15,586:INFO:Uploading results into container
2025-10-09 21:02:15,587:INFO:Uploading model into container now
2025-10-09 21:02:15,587:INFO:_master_model_container: 61
2025-10-09 21:02:15,587:INFO:_display_container: 9
2025-10-09 21:02:15,587:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=1, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.01, min_samples_leaf=6,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-10-09 21:02:15,587:INFO:create_model() successfully completed......................................
2025-10-09 21:02:15,724:INFO:SubProcess create_model() end ==================================
2025-10-09 21:02:15,724:INFO:choose_better activated
2025-10-09 21:02:15,731:INFO:SubProcess create_model() called ==================================
2025-10-09 21:02:15,732:INFO:Initializing create_model()
2025-10-09 21:02:15,732:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 21:02:15,732:INFO:Checking exceptions
2025-10-09 21:02:15,736:INFO:Importing libraries
2025-10-09 21:02:15,736:INFO:Copying training dataset
2025-10-09 21:02:15,742:INFO:Defining folds
2025-10-09 21:02:15,742:INFO:Declaring metric variables
2025-10-09 21:02:15,742:INFO:Importing untrained model
2025-10-09 21:02:15,742:INFO:Declaring custom model
2025-10-09 21:02:15,743:INFO:Decision Tree Classifier Imported successfully
2025-10-09 21:02:15,743:INFO:Starting cross validation
2025-10-09 21:02:15,744:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 21:02:15,980:INFO:Calculating mean and std
2025-10-09 21:02:15,982:INFO:Creating metrics dataframe
2025-10-09 21:02:15,986:INFO:Finalizing model
2025-10-09 21:02:16,043:INFO:Uploading results into container
2025-10-09 21:02:16,044:INFO:Uploading model into container now
2025-10-09 21:02:16,046:INFO:_master_model_container: 62
2025-10-09 21:02:16,046:INFO:_display_container: 10
2025-10-09 21:02:16,046:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-10-09 21:02:16,046:INFO:create_model() successfully completed......................................
2025-10-09 21:02:16,176:INFO:SubProcess create_model() end ==================================
2025-10-09 21:02:16,177:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best') result for Accuracy is 0.6524
2025-10-09 21:02:16,177:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=1, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.01, min_samples_leaf=6,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best') result for Accuracy is 0.7381
2025-10-09 21:02:16,178:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=1, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.01, min_samples_leaf=6,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best') is best model
2025-10-09 21:02:16,178:INFO:choose_better completed
2025-10-09 21:02:16,191:INFO:_master_model_container: 62
2025-10-09 21:02:16,191:INFO:_display_container: 9
2025-10-09 21:02:16,191:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=1, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.01, min_samples_leaf=6,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-10-09 21:02:16,191:INFO:tune_model() successfully completed......................................
2025-10-09 21:02:24,286:INFO:Initializing evaluate_model()
2025-10-09 21:02:24,286:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best'), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-10-09 21:02:24,303:INFO:Initializing plot_model()
2025-10-09 21:02:24,304:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best'), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-09 21:02:24,304:INFO:Checking exceptions
2025-10-09 21:02:24,307:INFO:Preloading libraries
2025-10-09 21:02:24,308:INFO:Copying training dataset
2025-10-09 21:02:24,308:INFO:Plot type: pipeline
2025-10-09 21:02:24,469:INFO:Visual Rendered Successfully
2025-10-09 21:02:24,591:INFO:plot_model() successfully completed......................................
2025-10-09 21:02:28,319:INFO:Initializing tune_model()
2025-10-09 21:02:28,320:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best'), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-10-09 21:02:28,320:INFO:Checking exceptions
2025-10-09 21:02:28,350:INFO:Copying training dataset
2025-10-09 21:02:28,354:INFO:Checking base model
2025-10-09 21:02:28,354:INFO:Base model : Decision Tree Classifier
2025-10-09 21:02:28,368:INFO:Declaring metric variables
2025-10-09 21:02:28,374:INFO:Defining Hyperparameters
2025-10-09 21:02:28,568:INFO:Tuning with n_jobs=-1
2025-10-09 21:02:28,568:INFO:Initializing RandomizedSearchCV
2025-10-09 21:02:30,516:INFO:best_params: {'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 6, 'actual_estimator__min_impurity_decrease': 0.01, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 1, 'actual_estimator__criterion': 'gini'}
2025-10-09 21:02:30,516:INFO:Hyperparameter search completed
2025-10-09 21:02:30,517:INFO:SubProcess create_model() called ==================================
2025-10-09 21:02:30,518:INFO:Initializing create_model()
2025-10-09 21:02:30,518:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000205BCE08090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'min_samples_split': 5, 'min_samples_leaf': 6, 'min_impurity_decrease': 0.01, 'max_features': 1.0, 'max_depth': 1, 'criterion': 'gini'})
2025-10-09 21:02:30,519:INFO:Checking exceptions
2025-10-09 21:02:30,519:INFO:Importing libraries
2025-10-09 21:02:30,519:INFO:Copying training dataset
2025-10-09 21:02:30,524:INFO:Defining folds
2025-10-09 21:02:30,524:INFO:Declaring metric variables
2025-10-09 21:02:30,530:INFO:Importing untrained model
2025-10-09 21:02:30,530:INFO:Declaring custom model
2025-10-09 21:02:30,539:INFO:Decision Tree Classifier Imported successfully
2025-10-09 21:02:30,548:INFO:Starting cross validation
2025-10-09 21:02:30,550:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 21:02:30,806:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 21:02:30,806:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 21:02:30,808:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 21:02:30,812:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 21:02:30,820:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 21:02:30,829:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 21:02:30,832:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 21:02:30,832:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 21:02:30,838:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 21:02:30,846:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 21:02:30,857:INFO:Calculating mean and std
2025-10-09 21:02:30,859:INFO:Creating metrics dataframe
2025-10-09 21:02:30,868:INFO:Finalizing model
2025-10-09 21:02:30,941:INFO:Uploading results into container
2025-10-09 21:02:30,942:INFO:Uploading model into container now
2025-10-09 21:02:30,942:INFO:_master_model_container: 63
2025-10-09 21:02:30,942:INFO:_display_container: 10
2025-10-09 21:02:30,943:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=1, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.01, min_samples_leaf=6,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-10-09 21:02:30,943:INFO:create_model() successfully completed......................................
2025-10-09 21:02:31,086:INFO:SubProcess create_model() end ==================================
2025-10-09 21:02:31,086:INFO:choose_better activated
2025-10-09 21:02:31,093:INFO:SubProcess create_model() called ==================================
2025-10-09 21:02:31,094:INFO:Initializing create_model()
2025-10-09 21:02:31,094:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 21:02:31,094:INFO:Checking exceptions
2025-10-09 21:02:31,097:INFO:Importing libraries
2025-10-09 21:02:31,097:INFO:Copying training dataset
2025-10-09 21:02:31,101:INFO:Defining folds
2025-10-09 21:02:31,103:INFO:Declaring metric variables
2025-10-09 21:02:31,103:INFO:Importing untrained model
2025-10-09 21:02:31,103:INFO:Declaring custom model
2025-10-09 21:02:31,105:INFO:Decision Tree Classifier Imported successfully
2025-10-09 21:02:31,105:INFO:Starting cross validation
2025-10-09 21:02:31,107:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 21:02:31,354:INFO:Calculating mean and std
2025-10-09 21:02:31,354:INFO:Creating metrics dataframe
2025-10-09 21:02:31,358:INFO:Finalizing model
2025-10-09 21:02:31,408:INFO:Uploading results into container
2025-10-09 21:02:31,409:INFO:Uploading model into container now
2025-10-09 21:02:31,409:INFO:_master_model_container: 64
2025-10-09 21:02:31,409:INFO:_display_container: 11
2025-10-09 21:02:31,410:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-10-09 21:02:31,410:INFO:create_model() successfully completed......................................
2025-10-09 21:02:31,546:INFO:SubProcess create_model() end ==================================
2025-10-09 21:02:31,546:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best') result for Accuracy is 0.6524
2025-10-09 21:02:31,547:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=1, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.01, min_samples_leaf=6,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best') result for Accuracy is 0.7381
2025-10-09 21:02:31,547:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=1, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.01, min_samples_leaf=6,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best') is best model
2025-10-09 21:02:31,547:INFO:choose_better completed
2025-10-09 21:02:31,563:INFO:_master_model_container: 64
2025-10-09 21:02:31,563:INFO:_display_container: 10
2025-10-09 21:02:31,564:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=1, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.01, min_samples_leaf=6,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-10-09 21:02:31,564:INFO:tune_model() successfully completed......................................
2025-10-09 21:02:38,553:INFO:Initializing evaluate_model()
2025-10-09 21:02:38,553:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best'), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-10-09 21:02:38,570:INFO:Initializing plot_model()
2025-10-09 21:02:38,570:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best'), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-09 21:02:38,570:INFO:Checking exceptions
2025-10-09 21:02:38,575:INFO:Preloading libraries
2025-10-09 21:02:38,577:INFO:Copying training dataset
2025-10-09 21:02:38,578:INFO:Plot type: pipeline
2025-10-09 21:02:38,771:INFO:Visual Rendered Successfully
2025-10-09 21:02:38,951:INFO:plot_model() successfully completed......................................
2025-10-09 21:02:49,747:INFO:Initializing tune_model()
2025-10-09 21:02:49,747:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best'), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-10-09 21:02:49,747:INFO:Checking exceptions
2025-10-09 21:02:49,775:INFO:Copying training dataset
2025-10-09 21:02:49,783:INFO:Checking base model
2025-10-09 21:02:49,783:INFO:Base model : Decision Tree Classifier
2025-10-09 21:02:49,792:INFO:Declaring metric variables
2025-10-09 21:02:49,797:INFO:Defining Hyperparameters
2025-10-09 21:02:50,017:INFO:Tuning with n_jobs=-1
2025-10-09 21:02:50,017:INFO:Initializing RandomizedSearchCV
2025-10-09 21:02:51,993:INFO:best_params: {'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 6, 'actual_estimator__min_impurity_decrease': 0.01, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 1, 'actual_estimator__criterion': 'gini'}
2025-10-09 21:02:51,994:INFO:Hyperparameter search completed
2025-10-09 21:02:51,994:INFO:SubProcess create_model() called ==================================
2025-10-09 21:02:51,995:INFO:Initializing create_model()
2025-10-09 21:02:51,995:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000205C2D39010>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'min_samples_split': 5, 'min_samples_leaf': 6, 'min_impurity_decrease': 0.01, 'max_features': 1.0, 'max_depth': 1, 'criterion': 'gini'})
2025-10-09 21:02:51,995:INFO:Checking exceptions
2025-10-09 21:02:51,996:INFO:Importing libraries
2025-10-09 21:02:51,996:INFO:Copying training dataset
2025-10-09 21:02:52,006:INFO:Defining folds
2025-10-09 21:02:52,006:INFO:Declaring metric variables
2025-10-09 21:02:52,010:INFO:Importing untrained model
2025-10-09 21:02:52,010:INFO:Declaring custom model
2025-10-09 21:02:52,015:INFO:Decision Tree Classifier Imported successfully
2025-10-09 21:02:52,027:INFO:Starting cross validation
2025-10-09 21:02:52,029:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 21:02:52,259:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 21:02:52,262:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 21:02:52,270:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 21:02:52,270:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 21:02:52,272:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 21:02:52,277:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 21:02:52,282:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 21:02:52,285:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 21:02:52,290:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 21:02:52,307:INFO:Calculating mean and std
2025-10-09 21:02:52,309:INFO:Creating metrics dataframe
2025-10-09 21:02:52,316:INFO:Finalizing model
2025-10-09 21:02:52,398:INFO:Uploading results into container
2025-10-09 21:02:52,400:INFO:Uploading model into container now
2025-10-09 21:02:52,401:INFO:_master_model_container: 65
2025-10-09 21:02:52,401:INFO:_display_container: 11
2025-10-09 21:02:52,401:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=1, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.01, min_samples_leaf=6,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-10-09 21:02:52,401:INFO:create_model() successfully completed......................................
2025-10-09 21:02:52,549:INFO:SubProcess create_model() end ==================================
2025-10-09 21:02:52,550:INFO:choose_better activated
2025-10-09 21:02:52,555:INFO:SubProcess create_model() called ==================================
2025-10-09 21:02:52,556:INFO:Initializing create_model()
2025-10-09 21:02:52,556:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 21:02:52,556:INFO:Checking exceptions
2025-10-09 21:02:52,558:INFO:Importing libraries
2025-10-09 21:02:52,558:INFO:Copying training dataset
2025-10-09 21:02:52,564:INFO:Defining folds
2025-10-09 21:02:52,564:INFO:Declaring metric variables
2025-10-09 21:02:52,564:INFO:Importing untrained model
2025-10-09 21:02:52,565:INFO:Declaring custom model
2025-10-09 21:02:52,565:INFO:Decision Tree Classifier Imported successfully
2025-10-09 21:02:52,565:INFO:Starting cross validation
2025-10-09 21:02:52,567:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 21:02:52,850:INFO:Calculating mean and std
2025-10-09 21:02:52,851:INFO:Creating metrics dataframe
2025-10-09 21:02:52,857:INFO:Finalizing model
2025-10-09 21:02:52,924:INFO:Uploading results into container
2025-10-09 21:02:52,924:INFO:Uploading model into container now
2025-10-09 21:02:52,924:INFO:_master_model_container: 66
2025-10-09 21:02:52,924:INFO:_display_container: 12
2025-10-09 21:02:52,926:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-10-09 21:02:52,926:INFO:create_model() successfully completed......................................
2025-10-09 21:02:53,089:INFO:SubProcess create_model() end ==================================
2025-10-09 21:02:53,090:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best') result for Accuracy is 0.6524
2025-10-09 21:02:53,092:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=1, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.01, min_samples_leaf=6,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best') result for Accuracy is 0.7381
2025-10-09 21:02:53,093:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=1, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.01, min_samples_leaf=6,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best') is best model
2025-10-09 21:02:53,093:INFO:choose_better completed
2025-10-09 21:02:53,108:INFO:_master_model_container: 66
2025-10-09 21:02:53,108:INFO:_display_container: 11
2025-10-09 21:02:53,109:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=1, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.01, min_samples_leaf=6,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-10-09 21:02:53,109:INFO:tune_model() successfully completed......................................
2025-10-09 21:02:54,925:INFO:Initializing evaluate_model()
2025-10-09 21:02:54,925:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=1, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.01, min_samples_leaf=6,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best'), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-10-09 21:02:54,934:INFO:Initializing plot_model()
2025-10-09 21:02:54,934:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=1, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.01, min_samples_leaf=6,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best'), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-09 21:02:54,936:INFO:Checking exceptions
2025-10-09 21:02:54,939:INFO:Preloading libraries
2025-10-09 21:02:54,939:INFO:Copying training dataset
2025-10-09 21:02:54,939:INFO:Plot type: pipeline
2025-10-09 21:02:55,107:INFO:Visual Rendered Successfully
2025-10-09 21:02:55,231:INFO:plot_model() successfully completed......................................
2025-10-09 21:02:57,274:INFO:Initializing plot_model()
2025-10-09 21:02:57,274:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=1, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.01, min_samples_leaf=6,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best'), plot=confusion_matrix, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-09 21:02:57,274:INFO:Checking exceptions
2025-10-09 21:02:57,275:INFO:Preloading libraries
2025-10-09 21:02:57,276:INFO:Copying training dataset
2025-10-09 21:02:57,276:INFO:Plot type: confusion_matrix
2025-10-09 21:02:57,520:INFO:Fitting Model
2025-10-09 21:02:57,520:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names
  warnings.warn(

2025-10-09 21:02:57,520:INFO:Scoring test/hold-out set
2025-10-09 21:02:57,622:INFO:Visual Rendered Successfully
2025-10-09 21:02:57,791:INFO:plot_model() successfully completed......................................
2025-10-09 21:03:09,978:INFO:Initializing evaluate_model()
2025-10-09 21:03:09,979:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best'), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-10-09 21:03:09,990:INFO:Initializing plot_model()
2025-10-09 21:03:09,990:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best'), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-09 21:03:09,990:INFO:Checking exceptions
2025-10-09 21:03:09,996:INFO:Preloading libraries
2025-10-09 21:03:09,997:INFO:Copying training dataset
2025-10-09 21:03:09,998:INFO:Plot type: pipeline
2025-10-09 21:03:10,194:INFO:Visual Rendered Successfully
2025-10-09 21:03:10,311:INFO:plot_model() successfully completed......................................
2025-10-09 21:03:11,749:INFO:Initializing plot_model()
2025-10-09 21:03:11,749:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best'), plot=confusion_matrix, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-09 21:03:11,749:INFO:Checking exceptions
2025-10-09 21:03:11,751:INFO:Preloading libraries
2025-10-09 21:03:11,751:INFO:Copying training dataset
2025-10-09 21:03:11,751:INFO:Plot type: confusion_matrix
2025-10-09 21:03:11,955:INFO:Fitting Model
2025-10-09 21:03:11,955:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names
  warnings.warn(

2025-10-09 21:03:11,955:INFO:Scoring test/hold-out set
2025-10-09 21:03:12,048:INFO:Visual Rendered Successfully
2025-10-09 21:03:12,191:INFO:plot_model() successfully completed......................................
2025-10-09 21:03:30,682:INFO:Initializing plot_model()
2025-10-09 21:03:30,682:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best'), plot=pr, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-09 21:03:30,683:INFO:Checking exceptions
2025-10-09 21:03:30,687:INFO:Preloading libraries
2025-10-09 21:03:30,687:INFO:Copying training dataset
2025-10-09 21:03:30,687:INFO:Plot type: pr
2025-10-09 21:03:30,865:INFO:Fitting Model
2025-10-09 21:03:30,865:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names
  warnings.warn(

2025-10-09 21:03:30,865:INFO:Scoring test/hold-out set
2025-10-09 21:03:31,012:INFO:Visual Rendered Successfully
2025-10-09 21:03:31,161:INFO:plot_model() successfully completed......................................
2025-10-09 21:03:34,661:INFO:Initializing plot_model()
2025-10-09 21:03:34,661:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best'), plot=feature_all, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-09 21:03:34,661:INFO:Checking exceptions
2025-10-09 21:03:34,663:INFO:Preloading libraries
2025-10-09 21:03:34,664:INFO:Copying training dataset
2025-10-09 21:03:34,664:INFO:Plot type: feature_all
2025-10-09 21:03:34,712:WARNING:No coef_ found. Trying feature_importances_
2025-10-09 21:03:34,845:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\_tight_bbox.py:67: RuntimeWarning: divide by zero encountered in scalar divide
  fig.patch.set_bounds(x0 / w1, y0 / h1,

2025-10-09 21:03:34,845:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\_tight_bbox.py:68: RuntimeWarning: divide by zero encountered in scalar divide
  fig.bbox.width / w1, fig.bbox.height / h1)

2025-10-09 21:03:34,868:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\patches.py:739: RuntimeWarning: invalid value encountered in scalar add
  y1 = self.convert_yunits(self._y0 + self._height)

2025-10-09 21:03:34,886:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\transforms.py:2050: RuntimeWarning: invalid value encountered in scalar add
  self._mtx[1, 2] += ty

2025-10-09 21:03:34,920:INFO:Visual Rendered Successfully
2025-10-09 21:03:35,006:INFO:plot_model() successfully completed......................................
2025-10-09 21:03:36,696:INFO:Initializing plot_model()
2025-10-09 21:03:36,697:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205BE4D6D90>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best'), plot=feature, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-09 21:03:36,697:INFO:Checking exceptions
2025-10-09 21:03:36,700:INFO:Preloading libraries
2025-10-09 21:03:36,701:INFO:Copying training dataset
2025-10-09 21:03:36,701:INFO:Plot type: feature
2025-10-09 21:03:36,702:WARNING:No coef_ found. Trying feature_importances_
2025-10-09 21:03:36,874:INFO:Visual Rendered Successfully
2025-10-09 21:03:36,994:INFO:plot_model() successfully completed......................................
2025-10-09 21:21:48,205:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-09 21:21:48,205:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-09 21:21:48,205:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-09 21:21:48,205:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-09 21:21:49,267:INFO:PyCaret ClassificationExperiment
2025-10-09 21:21:49,267:INFO:Logging name: clf-default-name
2025-10-09 21:21:49,267:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-10-09 21:21:49,267:INFO:version 3.3.2
2025-10-09 21:21:49,267:INFO:Initializing setup()
2025-10-09 21:21:49,267:INFO:self.USI: eaff
2025-10-09 21:21:49,267:INFO:self._variable_keys: {'_available_plots', 'gpu_n_jobs_param', 'n_jobs_param', 'gpu_param', 'idx', 'html_param', 'log_plots_param', 'X', 'is_multiclass', 'seed', 'fold_generator', 'fold_groups_param', 'y_test', 'fold_shuffle_param', 'exp_id', '_ml_usecase', 'logging_param', 'y', 'pipeline', 'data', 'y_train', 'X_test', 'target_param', 'USI', 'exp_name_log', 'X_train', 'fix_imbalance', 'memory'}
2025-10-09 21:21:49,267:INFO:Checking environment
2025-10-09 21:21:49,268:INFO:python_version: 3.11.0
2025-10-09 21:21:49,268:INFO:python_build: ('main', 'Oct 24 2022 18:26:48')
2025-10-09 21:21:49,268:INFO:machine: AMD64
2025-10-09 21:21:49,268:INFO:platform: Windows-10-10.0.26100-SP0
2025-10-09 21:21:49,272:INFO:Memory: svmem(total=34211835904, available=19260055552, percent=43.7, used=14951780352, free=19260055552)
2025-10-09 21:21:49,272:INFO:Physical Core: 6
2025-10-09 21:21:49,272:INFO:Logical Core: 12
2025-10-09 21:21:49,272:INFO:Checking libraries
2025-10-09 21:21:49,273:INFO:System:
2025-10-09 21:21:49,273:INFO:    python: 3.11.0 (main, Oct 24 2022, 18:26:48) [MSC v.1933 64 bit (AMD64)]
2025-10-09 21:21:49,273:INFO:executable: c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\python.exe
2025-10-09 21:21:49,273:INFO:   machine: Windows-10-10.0.26100-SP0
2025-10-09 21:21:49,273:INFO:PyCaret required dependencies:
2025-10-09 21:21:49,305:INFO:                 pip: 22.3
2025-10-09 21:21:49,305:INFO:          setuptools: 65.5.0
2025-10-09 21:21:49,305:INFO:             pycaret: 3.3.2
2025-10-09 21:21:49,305:INFO:             IPython: 9.6.0
2025-10-09 21:21:49,305:INFO:          ipywidgets: 8.1.7
2025-10-09 21:21:49,305:INFO:                tqdm: 4.67.1
2025-10-09 21:21:49,306:INFO:               numpy: 1.26.4
2025-10-09 21:21:49,306:INFO:              pandas: 2.1.4
2025-10-09 21:21:49,306:INFO:              jinja2: 3.1.6
2025-10-09 21:21:49,306:INFO:               scipy: 1.11.4
2025-10-09 21:21:49,306:INFO:              joblib: 1.3.2
2025-10-09 21:21:49,306:INFO:             sklearn: 1.4.2
2025-10-09 21:21:49,306:INFO:                pyod: 2.0.5
2025-10-09 21:21:49,306:INFO:            imblearn: 0.14.0
2025-10-09 21:21:49,306:INFO:   category_encoders: 2.7.0
2025-10-09 21:21:49,306:INFO:            lightgbm: 4.6.0
2025-10-09 21:21:49,306:INFO:               numba: 0.62.1
2025-10-09 21:21:49,306:INFO:            requests: 2.32.5
2025-10-09 21:21:49,306:INFO:          matplotlib: 3.7.5
2025-10-09 21:21:49,306:INFO:          scikitplot: 0.3.7
2025-10-09 21:21:49,306:INFO:         yellowbrick: 1.5
2025-10-09 21:21:49,306:INFO:              plotly: 6.3.1
2025-10-09 21:21:49,306:INFO:    plotly-resampler: Not installed
2025-10-09 21:21:49,306:INFO:             kaleido: 1.1.0
2025-10-09 21:21:49,306:INFO:           schemdraw: 0.15
2025-10-09 21:21:49,306:INFO:         statsmodels: 0.14.5
2025-10-09 21:21:49,306:INFO:              sktime: 0.26.0
2025-10-09 21:21:49,306:INFO:               tbats: 1.1.3
2025-10-09 21:21:49,306:INFO:            pmdarima: 2.0.4
2025-10-09 21:21:49,307:INFO:              psutil: 7.1.0
2025-10-09 21:21:49,307:INFO:          markupsafe: 3.0.3
2025-10-09 21:21:49,307:INFO:             pickle5: Not installed
2025-10-09 21:21:49,307:INFO:         cloudpickle: 3.1.1
2025-10-09 21:21:49,307:INFO:         deprecation: 2.1.0
2025-10-09 21:21:49,307:INFO:              xxhash: 3.6.0
2025-10-09 21:21:49,307:INFO:           wurlitzer: Not installed
2025-10-09 21:21:49,307:INFO:PyCaret optional dependencies:
2025-10-09 21:21:49,326:INFO:                shap: Not installed
2025-10-09 21:21:49,326:INFO:           interpret: Not installed
2025-10-09 21:21:49,326:INFO:                umap: Not installed
2025-10-09 21:21:49,326:INFO:     ydata_profiling: Not installed
2025-10-09 21:21:49,326:INFO:  explainerdashboard: Not installed
2025-10-09 21:21:49,326:INFO:             autoviz: Not installed
2025-10-09 21:21:49,326:INFO:           fairlearn: Not installed
2025-10-09 21:21:49,326:INFO:          deepchecks: Not installed
2025-10-09 21:21:49,326:INFO:             xgboost: Not installed
2025-10-09 21:21:49,326:INFO:            catboost: Not installed
2025-10-09 21:21:49,327:INFO:              kmodes: Not installed
2025-10-09 21:21:49,327:INFO:             mlxtend: Not installed
2025-10-09 21:21:49,327:INFO:       statsforecast: Not installed
2025-10-09 21:21:49,327:INFO:        tune_sklearn: Not installed
2025-10-09 21:21:49,327:INFO:                 ray: Not installed
2025-10-09 21:21:49,327:INFO:            hyperopt: Not installed
2025-10-09 21:21:49,327:INFO:              optuna: Not installed
2025-10-09 21:21:49,327:INFO:               skopt: Not installed
2025-10-09 21:21:49,327:INFO:              mlflow: Not installed
2025-10-09 21:21:49,327:INFO:              gradio: Not installed
2025-10-09 21:21:49,327:INFO:             fastapi: Not installed
2025-10-09 21:21:49,327:INFO:             uvicorn: Not installed
2025-10-09 21:21:49,327:INFO:              m2cgen: Not installed
2025-10-09 21:21:49,327:INFO:           evidently: Not installed
2025-10-09 21:21:49,328:INFO:               fugue: Not installed
2025-10-09 21:21:49,328:INFO:           streamlit: Not installed
2025-10-09 21:21:49,328:INFO:             prophet: Not installed
2025-10-09 21:21:49,328:INFO:None
2025-10-09 21:21:49,328:INFO:Set up data.
2025-10-09 21:21:49,336:INFO:Set up folding strategy.
2025-10-09 21:21:49,336:INFO:Set up train/test split.
2025-10-09 21:21:49,346:INFO:Set up index.
2025-10-09 21:21:49,346:INFO:Assigning column types.
2025-10-09 21:21:49,351:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-09 21:21:49,399:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-09 21:21:49,403:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-09 21:21:49,435:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 21:21:49,435:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 21:21:49,475:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-09 21:21:49,475:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-09 21:21:49,502:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 21:21:49,502:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 21:21:49,502:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-09 21:21:49,542:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-09 21:21:49,567:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 21:21:49,568:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 21:21:49,609:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-09 21:21:49,632:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 21:21:49,634:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 21:21:49,634:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-10-09 21:21:49,698:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 21:21:49,698:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 21:21:49,767:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 21:21:49,767:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 21:21:49,782:INFO:Preparing preprocessing pipeline...
2025-10-09 21:21:49,784:INFO:Set up simple imputation.
2025-10-09 21:21:49,785:INFO:Set up encoding of ordinal features.
2025-10-09 21:21:49,787:INFO:Set up encoding of categorical features.
2025-10-09 21:21:49,787:INFO:Set up imbalanced handling.
2025-10-09 21:22:09,354:INFO:PyCaret ClassificationExperiment
2025-10-09 21:22:09,354:INFO:Logging name: clf-default-name
2025-10-09 21:22:09,354:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-10-09 21:22:09,354:INFO:version 3.3.2
2025-10-09 21:22:09,354:INFO:Initializing setup()
2025-10-09 21:22:09,354:INFO:self.USI: 04be
2025-10-09 21:22:09,354:INFO:self._variable_keys: {'_available_plots', 'gpu_n_jobs_param', 'n_jobs_param', 'gpu_param', 'idx', 'html_param', 'log_plots_param', 'X', 'is_multiclass', 'seed', 'fold_generator', 'fold_groups_param', 'y_test', 'fold_shuffle_param', 'exp_id', '_ml_usecase', 'logging_param', 'y', 'pipeline', 'data', 'y_train', 'X_test', 'target_param', 'USI', 'exp_name_log', 'X_train', 'fix_imbalance', 'memory'}
2025-10-09 21:22:09,354:INFO:Checking environment
2025-10-09 21:22:09,355:INFO:python_version: 3.11.0
2025-10-09 21:22:09,355:INFO:python_build: ('main', 'Oct 24 2022 18:26:48')
2025-10-09 21:22:09,355:INFO:machine: AMD64
2025-10-09 21:22:09,355:INFO:platform: Windows-10-10.0.26100-SP0
2025-10-09 21:22:09,359:INFO:Memory: svmem(total=34211835904, available=19273895936, percent=43.7, used=14937939968, free=19273895936)
2025-10-09 21:22:09,359:INFO:Physical Core: 6
2025-10-09 21:22:09,359:INFO:Logical Core: 12
2025-10-09 21:22:09,359:INFO:Checking libraries
2025-10-09 21:22:09,359:INFO:System:
2025-10-09 21:22:09,359:INFO:    python: 3.11.0 (main, Oct 24 2022, 18:26:48) [MSC v.1933 64 bit (AMD64)]
2025-10-09 21:22:09,359:INFO:executable: c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\python.exe
2025-10-09 21:22:09,361:INFO:   machine: Windows-10-10.0.26100-SP0
2025-10-09 21:22:09,361:INFO:PyCaret required dependencies:
2025-10-09 21:22:09,361:INFO:                 pip: 22.3
2025-10-09 21:22:09,361:INFO:          setuptools: 65.5.0
2025-10-09 21:22:09,361:INFO:             pycaret: 3.3.2
2025-10-09 21:22:09,361:INFO:             IPython: 9.6.0
2025-10-09 21:22:09,361:INFO:          ipywidgets: 8.1.7
2025-10-09 21:22:09,361:INFO:                tqdm: 4.67.1
2025-10-09 21:22:09,361:INFO:               numpy: 1.26.4
2025-10-09 21:22:09,361:INFO:              pandas: 2.1.4
2025-10-09 21:22:09,361:INFO:              jinja2: 3.1.6
2025-10-09 21:22:09,361:INFO:               scipy: 1.11.4
2025-10-09 21:22:09,361:INFO:              joblib: 1.3.2
2025-10-09 21:22:09,361:INFO:             sklearn: 1.4.2
2025-10-09 21:22:09,361:INFO:                pyod: 2.0.5
2025-10-09 21:22:09,361:INFO:            imblearn: 0.14.0
2025-10-09 21:22:09,361:INFO:   category_encoders: 2.7.0
2025-10-09 21:22:09,361:INFO:            lightgbm: 4.6.0
2025-10-09 21:22:09,362:INFO:               numba: 0.62.1
2025-10-09 21:22:09,362:INFO:            requests: 2.32.5
2025-10-09 21:22:09,362:INFO:          matplotlib: 3.7.5
2025-10-09 21:22:09,362:INFO:          scikitplot: 0.3.7
2025-10-09 21:22:09,362:INFO:         yellowbrick: 1.5
2025-10-09 21:22:09,362:INFO:              plotly: 6.3.1
2025-10-09 21:22:09,362:INFO:    plotly-resampler: Not installed
2025-10-09 21:22:09,362:INFO:             kaleido: 1.1.0
2025-10-09 21:22:09,362:INFO:           schemdraw: 0.15
2025-10-09 21:22:09,362:INFO:         statsmodels: 0.14.5
2025-10-09 21:22:09,362:INFO:              sktime: 0.26.0
2025-10-09 21:22:09,362:INFO:               tbats: 1.1.3
2025-10-09 21:22:09,362:INFO:            pmdarima: 2.0.4
2025-10-09 21:22:09,362:INFO:              psutil: 7.1.0
2025-10-09 21:22:09,362:INFO:          markupsafe: 3.0.3
2025-10-09 21:22:09,362:INFO:             pickle5: Not installed
2025-10-09 21:22:09,362:INFO:         cloudpickle: 3.1.1
2025-10-09 21:22:09,362:INFO:         deprecation: 2.1.0
2025-10-09 21:22:09,362:INFO:              xxhash: 3.6.0
2025-10-09 21:22:09,362:INFO:           wurlitzer: Not installed
2025-10-09 21:22:09,363:INFO:PyCaret optional dependencies:
2025-10-09 21:22:09,363:INFO:                shap: Not installed
2025-10-09 21:22:09,363:INFO:           interpret: Not installed
2025-10-09 21:22:09,363:INFO:                umap: Not installed
2025-10-09 21:22:09,363:INFO:     ydata_profiling: Not installed
2025-10-09 21:22:09,363:INFO:  explainerdashboard: Not installed
2025-10-09 21:22:09,363:INFO:             autoviz: Not installed
2025-10-09 21:22:09,363:INFO:           fairlearn: Not installed
2025-10-09 21:22:09,363:INFO:          deepchecks: Not installed
2025-10-09 21:22:09,363:INFO:             xgboost: Not installed
2025-10-09 21:22:09,363:INFO:            catboost: Not installed
2025-10-09 21:22:09,363:INFO:              kmodes: Not installed
2025-10-09 21:22:09,363:INFO:             mlxtend: Not installed
2025-10-09 21:22:09,363:INFO:       statsforecast: Not installed
2025-10-09 21:22:09,363:INFO:        tune_sklearn: Not installed
2025-10-09 21:22:09,363:INFO:                 ray: Not installed
2025-10-09 21:22:09,363:INFO:            hyperopt: Not installed
2025-10-09 21:22:09,364:INFO:              optuna: Not installed
2025-10-09 21:22:09,364:INFO:               skopt: Not installed
2025-10-09 21:22:09,364:INFO:              mlflow: Not installed
2025-10-09 21:22:09,364:INFO:              gradio: Not installed
2025-10-09 21:22:09,364:INFO:             fastapi: Not installed
2025-10-09 21:22:09,364:INFO:             uvicorn: Not installed
2025-10-09 21:22:09,364:INFO:              m2cgen: Not installed
2025-10-09 21:22:09,364:INFO:           evidently: Not installed
2025-10-09 21:22:09,364:INFO:               fugue: Not installed
2025-10-09 21:22:09,364:INFO:           streamlit: Not installed
2025-10-09 21:22:09,364:INFO:             prophet: Not installed
2025-10-09 21:22:09,364:INFO:None
2025-10-09 21:22:09,364:INFO:Set up data.
2025-10-09 21:22:09,368:INFO:Set up folding strategy.
2025-10-09 21:22:09,369:INFO:Set up train/test split.
2025-10-09 21:22:09,372:INFO:Set up index.
2025-10-09 21:22:09,372:INFO:Assigning column types.
2025-10-09 21:22:09,376:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-09 21:22:09,418:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-09 21:22:09,419:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-09 21:22:09,444:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 21:22:09,444:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 21:22:09,485:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-09 21:22:09,486:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-09 21:22:09,511:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 21:22:09,511:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 21:22:09,511:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-09 21:22:09,551:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-09 21:22:09,576:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 21:22:09,576:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 21:22:09,616:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-09 21:22:09,641:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 21:22:09,641:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 21:22:09,641:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-10-09 21:22:09,704:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 21:22:09,705:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 21:22:09,769:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 21:22:09,769:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 21:22:09,770:INFO:Preparing preprocessing pipeline...
2025-10-09 21:22:09,771:INFO:Set up simple imputation.
2025-10-09 21:22:09,773:INFO:Set up encoding of ordinal features.
2025-10-09 21:22:09,773:INFO:Set up encoding of categorical features.
2025-10-09 21:22:09,773:INFO:Set up imbalanced handling.
2025-10-09 21:22:38,962:INFO:PyCaret ClassificationExperiment
2025-10-09 21:22:38,962:INFO:Logging name: clf-default-name
2025-10-09 21:22:38,962:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-10-09 21:22:38,962:INFO:version 3.3.2
2025-10-09 21:22:38,962:INFO:Initializing setup()
2025-10-09 21:22:38,962:INFO:self.USI: 1443
2025-10-09 21:22:38,962:INFO:self._variable_keys: {'_available_plots', 'gpu_n_jobs_param', 'n_jobs_param', 'gpu_param', 'idx', 'html_param', 'log_plots_param', 'X', 'is_multiclass', 'seed', 'fold_generator', 'fold_groups_param', 'y_test', 'fold_shuffle_param', 'exp_id', '_ml_usecase', 'logging_param', 'y', 'pipeline', 'data', 'y_train', 'X_test', 'target_param', 'USI', 'exp_name_log', 'X_train', 'fix_imbalance', 'memory'}
2025-10-09 21:22:38,962:INFO:Checking environment
2025-10-09 21:22:38,962:INFO:python_version: 3.11.0
2025-10-09 21:22:38,962:INFO:python_build: ('main', 'Oct 24 2022 18:26:48')
2025-10-09 21:22:38,962:INFO:machine: AMD64
2025-10-09 21:22:38,962:INFO:platform: Windows-10-10.0.26100-SP0
2025-10-09 21:22:38,966:INFO:Memory: svmem(total=34211835904, available=19299397632, percent=43.6, used=14912438272, free=19299397632)
2025-10-09 21:22:38,966:INFO:Physical Core: 6
2025-10-09 21:22:38,966:INFO:Logical Core: 12
2025-10-09 21:22:38,966:INFO:Checking libraries
2025-10-09 21:22:38,966:INFO:System:
2025-10-09 21:22:38,966:INFO:    python: 3.11.0 (main, Oct 24 2022, 18:26:48) [MSC v.1933 64 bit (AMD64)]
2025-10-09 21:22:38,966:INFO:executable: c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\python.exe
2025-10-09 21:22:38,966:INFO:   machine: Windows-10-10.0.26100-SP0
2025-10-09 21:22:38,966:INFO:PyCaret required dependencies:
2025-10-09 21:22:38,966:INFO:                 pip: 22.3
2025-10-09 21:22:38,966:INFO:          setuptools: 65.5.0
2025-10-09 21:22:38,966:INFO:             pycaret: 3.3.2
2025-10-09 21:22:38,967:INFO:             IPython: 9.6.0
2025-10-09 21:22:38,967:INFO:          ipywidgets: 8.1.7
2025-10-09 21:22:38,967:INFO:                tqdm: 4.67.1
2025-10-09 21:22:38,967:INFO:               numpy: 1.26.4
2025-10-09 21:22:38,967:INFO:              pandas: 2.1.4
2025-10-09 21:22:38,967:INFO:              jinja2: 3.1.6
2025-10-09 21:22:38,967:INFO:               scipy: 1.11.4
2025-10-09 21:22:38,967:INFO:              joblib: 1.3.2
2025-10-09 21:22:38,967:INFO:             sklearn: 1.4.2
2025-10-09 21:22:38,967:INFO:                pyod: 2.0.5
2025-10-09 21:22:38,967:INFO:            imblearn: 0.14.0
2025-10-09 21:22:38,967:INFO:   category_encoders: 2.7.0
2025-10-09 21:22:38,967:INFO:            lightgbm: 4.6.0
2025-10-09 21:22:38,967:INFO:               numba: 0.62.1
2025-10-09 21:22:38,967:INFO:            requests: 2.32.5
2025-10-09 21:22:38,967:INFO:          matplotlib: 3.7.5
2025-10-09 21:22:38,967:INFO:          scikitplot: 0.3.7
2025-10-09 21:22:38,967:INFO:         yellowbrick: 1.5
2025-10-09 21:22:38,967:INFO:              plotly: 6.3.1
2025-10-09 21:22:38,967:INFO:    plotly-resampler: Not installed
2025-10-09 21:22:38,967:INFO:             kaleido: 1.1.0
2025-10-09 21:22:38,968:INFO:           schemdraw: 0.15
2025-10-09 21:22:38,968:INFO:         statsmodels: 0.14.5
2025-10-09 21:22:38,968:INFO:              sktime: 0.26.0
2025-10-09 21:22:38,968:INFO:               tbats: 1.1.3
2025-10-09 21:22:38,968:INFO:            pmdarima: 2.0.4
2025-10-09 21:22:38,968:INFO:              psutil: 7.1.0
2025-10-09 21:22:38,968:INFO:          markupsafe: 3.0.3
2025-10-09 21:22:38,968:INFO:             pickle5: Not installed
2025-10-09 21:22:38,968:INFO:         cloudpickle: 3.1.1
2025-10-09 21:22:38,968:INFO:         deprecation: 2.1.0
2025-10-09 21:22:38,968:INFO:              xxhash: 3.6.0
2025-10-09 21:22:38,968:INFO:           wurlitzer: Not installed
2025-10-09 21:22:38,968:INFO:PyCaret optional dependencies:
2025-10-09 21:22:38,968:INFO:                shap: Not installed
2025-10-09 21:22:38,968:INFO:           interpret: Not installed
2025-10-09 21:22:38,968:INFO:                umap: Not installed
2025-10-09 21:22:38,968:INFO:     ydata_profiling: Not installed
2025-10-09 21:22:38,968:INFO:  explainerdashboard: Not installed
2025-10-09 21:22:38,968:INFO:             autoviz: Not installed
2025-10-09 21:22:38,968:INFO:           fairlearn: Not installed
2025-10-09 21:22:38,968:INFO:          deepchecks: Not installed
2025-10-09 21:22:38,968:INFO:             xgboost: Not installed
2025-10-09 21:22:38,968:INFO:            catboost: Not installed
2025-10-09 21:22:38,969:INFO:              kmodes: Not installed
2025-10-09 21:22:38,969:INFO:             mlxtend: Not installed
2025-10-09 21:22:38,969:INFO:       statsforecast: Not installed
2025-10-09 21:22:38,969:INFO:        tune_sklearn: Not installed
2025-10-09 21:22:38,969:INFO:                 ray: Not installed
2025-10-09 21:22:38,969:INFO:            hyperopt: Not installed
2025-10-09 21:22:38,969:INFO:              optuna: Not installed
2025-10-09 21:22:38,969:INFO:               skopt: Not installed
2025-10-09 21:22:38,969:INFO:              mlflow: Not installed
2025-10-09 21:22:38,969:INFO:              gradio: Not installed
2025-10-09 21:22:38,969:INFO:             fastapi: Not installed
2025-10-09 21:22:38,969:INFO:             uvicorn: Not installed
2025-10-09 21:22:38,969:INFO:              m2cgen: Not installed
2025-10-09 21:22:38,969:INFO:           evidently: Not installed
2025-10-09 21:22:38,969:INFO:               fugue: Not installed
2025-10-09 21:22:38,969:INFO:           streamlit: Not installed
2025-10-09 21:22:38,969:INFO:             prophet: Not installed
2025-10-09 21:22:38,969:INFO:None
2025-10-09 21:22:38,969:INFO:Set up data.
2025-10-09 21:22:38,974:INFO:Set up folding strategy.
2025-10-09 21:22:38,974:INFO:Set up train/test split.
2025-10-09 21:22:38,978:INFO:Set up index.
2025-10-09 21:22:38,978:INFO:Assigning column types.
2025-10-09 21:22:38,981:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-09 21:22:39,023:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-09 21:22:39,023:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-09 21:22:39,048:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 21:22:39,048:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 21:22:39,088:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-09 21:22:39,088:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-09 21:22:39,115:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 21:22:39,115:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 21:22:39,115:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-09 21:22:39,155:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-09 21:22:39,180:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 21:22:39,180:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 21:22:39,222:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-09 21:22:39,246:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 21:22:39,246:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 21:22:39,246:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-10-09 21:22:39,311:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 21:22:39,311:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 21:22:39,377:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 21:22:39,377:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 21:22:39,378:INFO:Preparing preprocessing pipeline...
2025-10-09 21:22:39,379:INFO:Set up simple imputation.
2025-10-09 21:22:39,380:INFO:Set up encoding of ordinal features.
2025-10-09 21:22:39,382:INFO:Set up encoding of categorical features.
2025-10-09 21:22:39,382:INFO:Set up imbalanced handling.
2025-10-09 21:23:44,330:INFO:PyCaret ClassificationExperiment
2025-10-09 21:23:44,330:INFO:Logging name: clf-default-name
2025-10-09 21:23:44,330:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-10-09 21:23:44,330:INFO:version 3.3.2
2025-10-09 21:23:44,330:INFO:Initializing setup()
2025-10-09 21:23:44,330:INFO:self.USI: 04f6
2025-10-09 21:23:44,330:INFO:self._variable_keys: {'_available_plots', 'gpu_n_jobs_param', 'n_jobs_param', 'gpu_param', 'idx', 'html_param', 'log_plots_param', 'X', 'is_multiclass', 'seed', 'fold_generator', 'fold_groups_param', 'y_test', 'fold_shuffle_param', 'exp_id', '_ml_usecase', 'logging_param', 'y', 'pipeline', 'data', 'y_train', 'X_test', 'target_param', 'USI', 'exp_name_log', 'X_train', 'fix_imbalance', 'memory'}
2025-10-09 21:23:44,330:INFO:Checking environment
2025-10-09 21:23:44,330:INFO:python_version: 3.11.0
2025-10-09 21:23:44,331:INFO:python_build: ('main', 'Oct 24 2022 18:26:48')
2025-10-09 21:23:44,331:INFO:machine: AMD64
2025-10-09 21:23:44,331:INFO:platform: Windows-10-10.0.26100-SP0
2025-10-09 21:23:44,335:INFO:Memory: svmem(total=34211835904, available=19243405312, percent=43.8, used=14968430592, free=19243405312)
2025-10-09 21:23:44,335:INFO:Physical Core: 6
2025-10-09 21:23:44,336:INFO:Logical Core: 12
2025-10-09 21:23:44,336:INFO:Checking libraries
2025-10-09 21:23:44,336:INFO:System:
2025-10-09 21:23:44,336:INFO:    python: 3.11.0 (main, Oct 24 2022, 18:26:48) [MSC v.1933 64 bit (AMD64)]
2025-10-09 21:23:44,336:INFO:executable: c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\python.exe
2025-10-09 21:23:44,336:INFO:   machine: Windows-10-10.0.26100-SP0
2025-10-09 21:23:44,336:INFO:PyCaret required dependencies:
2025-10-09 21:23:44,336:INFO:                 pip: 22.3
2025-10-09 21:23:44,336:INFO:          setuptools: 65.5.0
2025-10-09 21:23:44,336:INFO:             pycaret: 3.3.2
2025-10-09 21:23:44,336:INFO:             IPython: 9.6.0
2025-10-09 21:23:44,336:INFO:          ipywidgets: 8.1.7
2025-10-09 21:23:44,336:INFO:                tqdm: 4.67.1
2025-10-09 21:23:44,336:INFO:               numpy: 1.26.4
2025-10-09 21:23:44,336:INFO:              pandas: 2.1.4
2025-10-09 21:23:44,336:INFO:              jinja2: 3.1.6
2025-10-09 21:23:44,336:INFO:               scipy: 1.11.4
2025-10-09 21:23:44,336:INFO:              joblib: 1.3.2
2025-10-09 21:23:44,336:INFO:             sklearn: 1.4.2
2025-10-09 21:23:44,336:INFO:                pyod: 2.0.5
2025-10-09 21:23:44,336:INFO:            imblearn: 0.14.0
2025-10-09 21:23:44,336:INFO:   category_encoders: 2.7.0
2025-10-09 21:23:44,336:INFO:            lightgbm: 4.6.0
2025-10-09 21:23:44,337:INFO:               numba: 0.62.1
2025-10-09 21:23:44,337:INFO:            requests: 2.32.5
2025-10-09 21:23:44,337:INFO:          matplotlib: 3.7.5
2025-10-09 21:23:44,337:INFO:          scikitplot: 0.3.7
2025-10-09 21:23:44,337:INFO:         yellowbrick: 1.5
2025-10-09 21:23:44,337:INFO:              plotly: 6.3.1
2025-10-09 21:23:44,337:INFO:    plotly-resampler: Not installed
2025-10-09 21:23:44,337:INFO:             kaleido: 1.1.0
2025-10-09 21:23:44,337:INFO:           schemdraw: 0.15
2025-10-09 21:23:44,337:INFO:         statsmodels: 0.14.5
2025-10-09 21:23:44,337:INFO:              sktime: 0.26.0
2025-10-09 21:23:44,337:INFO:               tbats: 1.1.3
2025-10-09 21:23:44,337:INFO:            pmdarima: 2.0.4
2025-10-09 21:23:44,337:INFO:              psutil: 7.1.0
2025-10-09 21:23:44,337:INFO:          markupsafe: 3.0.3
2025-10-09 21:23:44,337:INFO:             pickle5: Not installed
2025-10-09 21:23:44,337:INFO:         cloudpickle: 3.1.1
2025-10-09 21:23:44,337:INFO:         deprecation: 2.1.0
2025-10-09 21:23:44,337:INFO:              xxhash: 3.6.0
2025-10-09 21:23:44,337:INFO:           wurlitzer: Not installed
2025-10-09 21:23:44,337:INFO:PyCaret optional dependencies:
2025-10-09 21:23:44,338:INFO:                shap: Not installed
2025-10-09 21:23:44,338:INFO:           interpret: Not installed
2025-10-09 21:23:44,338:INFO:                umap: Not installed
2025-10-09 21:23:44,338:INFO:     ydata_profiling: Not installed
2025-10-09 21:23:44,338:INFO:  explainerdashboard: Not installed
2025-10-09 21:23:44,338:INFO:             autoviz: Not installed
2025-10-09 21:23:44,338:INFO:           fairlearn: Not installed
2025-10-09 21:23:44,338:INFO:          deepchecks: Not installed
2025-10-09 21:23:44,338:INFO:             xgboost: Not installed
2025-10-09 21:23:44,338:INFO:            catboost: Not installed
2025-10-09 21:23:44,338:INFO:              kmodes: Not installed
2025-10-09 21:23:44,338:INFO:             mlxtend: Not installed
2025-10-09 21:23:44,338:INFO:       statsforecast: Not installed
2025-10-09 21:23:44,338:INFO:        tune_sklearn: Not installed
2025-10-09 21:23:44,338:INFO:                 ray: Not installed
2025-10-09 21:23:44,338:INFO:            hyperopt: Not installed
2025-10-09 21:23:44,338:INFO:              optuna: Not installed
2025-10-09 21:23:44,338:INFO:               skopt: Not installed
2025-10-09 21:23:44,338:INFO:              mlflow: Not installed
2025-10-09 21:23:44,339:INFO:              gradio: Not installed
2025-10-09 21:23:44,339:INFO:             fastapi: Not installed
2025-10-09 21:23:44,339:INFO:             uvicorn: Not installed
2025-10-09 21:23:44,339:INFO:              m2cgen: Not installed
2025-10-09 21:23:44,339:INFO:           evidently: Not installed
2025-10-09 21:23:44,339:INFO:               fugue: Not installed
2025-10-09 21:23:44,339:INFO:           streamlit: Not installed
2025-10-09 21:23:44,339:INFO:             prophet: Not installed
2025-10-09 21:23:44,339:INFO:None
2025-10-09 21:23:44,339:INFO:Set up data.
2025-10-09 21:23:44,344:INFO:Set up folding strategy.
2025-10-09 21:23:44,344:INFO:Set up train/test split.
2025-10-09 21:23:44,347:INFO:Set up index.
2025-10-09 21:23:44,348:INFO:Assigning column types.
2025-10-09 21:23:44,352:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-09 21:23:44,396:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-09 21:23:44,397:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-09 21:23:44,421:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 21:23:44,422:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 21:23:44,462:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-09 21:23:44,462:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-09 21:23:44,486:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 21:23:44,487:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 21:23:44,487:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-09 21:23:44,528:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-09 21:23:44,553:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 21:23:44,553:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 21:23:44,593:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-09 21:23:44,617:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 21:23:44,618:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 21:23:44,618:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-10-09 21:23:44,682:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 21:23:44,682:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 21:23:44,746:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 21:23:44,746:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 21:23:44,747:INFO:Preparing preprocessing pipeline...
2025-10-09 21:23:44,748:INFO:Set up simple imputation.
2025-10-09 21:23:44,750:INFO:Set up encoding of ordinal features.
2025-10-09 21:23:44,750:INFO:Set up encoding of categorical features.
2025-10-09 21:23:44,750:INFO:Set up imbalanced handling.
2025-10-09 21:23:44,750:INFO:Set up feature normalization.
2025-10-09 21:23:44,836:INFO:Finished creating preprocessing pipeline.
2025-10-09 21:23:44,860:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\ARNALDO\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'meses_como_cliente',
                                             'frecuencia_uso',
                                             'soporte_llamadas'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),...
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=123,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2025-10-09 21:23:44,860:INFO:Creating final display dataframe.
2025-10-09 21:23:45,060:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target             churn
2                   Target type            Binary
3           Original data shape          (300, 7)
4        Transformed data shape          (400, 9)
5   Transformed train set shape          (310, 9)
6    Transformed test set shape           (90, 9)
7              Numeric features                 4
8          Categorical features                 2
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                Fix imbalance              True
16         Fix imbalance method             SMOTE
17                    Normalize              True
18             Normalize method            zscore
19               Fold Generator   StratifiedKFold
20                  Fold Number                10
21                     CPU Jobs                -1
22                      Use GPU             False
23               Log Experiment             False
24              Experiment Name  clf-default-name
25                          USI              04f6
2025-10-09 21:23:45,132:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 21:23:45,132:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 21:23:45,198:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 21:23:45,198:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 21:23:45,199:INFO:setup() successfully completed in 0.87s...............
2025-10-09 21:23:51,953:INFO:Initializing compare_models()
2025-10-09 21:23:51,953:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EBBCE1EBD0>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001EBBCE1EBD0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-10-09 21:23:51,953:INFO:Checking exceptions
2025-10-09 21:23:51,957:INFO:Preparing display monitor
2025-10-09 21:23:51,985:INFO:Initializing Logistic Regression
2025-10-09 21:23:51,986:INFO:Total runtime is 1.6673405965169272e-05 minutes
2025-10-09 21:23:51,993:INFO:SubProcess create_model() called ==================================
2025-10-09 21:23:51,993:INFO:Initializing create_model()
2025-10-09 21:23:51,994:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EBBCE1EBD0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EBBCDE1ED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 21:23:51,994:INFO:Checking exceptions
2025-10-09 21:23:51,994:INFO:Importing libraries
2025-10-09 21:23:51,994:INFO:Copying training dataset
2025-10-09 21:23:52,001:INFO:Defining folds
2025-10-09 21:23:52,001:INFO:Declaring metric variables
2025-10-09 21:23:52,005:INFO:Importing untrained model
2025-10-09 21:23:52,009:INFO:Logistic Regression Imported successfully
2025-10-09 21:23:52,015:INFO:Starting cross validation
2025-10-09 21:23:52,018:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 21:23:58,377:INFO:Calculating mean and std
2025-10-09 21:23:58,381:INFO:Creating metrics dataframe
2025-10-09 21:23:58,387:INFO:Uploading results into container
2025-10-09 21:23:58,389:INFO:Uploading model into container now
2025-10-09 21:23:58,390:INFO:_master_model_container: 1
2025-10-09 21:23:58,390:INFO:_display_container: 2
2025-10-09 21:23:58,392:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-09 21:23:58,392:INFO:create_model() successfully completed......................................
2025-10-09 21:23:58,542:INFO:SubProcess create_model() end ==================================
2025-10-09 21:23:58,542:INFO:Creating metrics dataframe
2025-10-09 21:23:58,550:INFO:Initializing K Neighbors Classifier
2025-10-09 21:23:58,550:INFO:Total runtime is 0.10940159956614177 minutes
2025-10-09 21:23:58,553:INFO:SubProcess create_model() called ==================================
2025-10-09 21:23:58,553:INFO:Initializing create_model()
2025-10-09 21:23:58,553:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EBBCE1EBD0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EBBCDE1ED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 21:23:58,553:INFO:Checking exceptions
2025-10-09 21:23:58,553:INFO:Importing libraries
2025-10-09 21:23:58,553:INFO:Copying training dataset
2025-10-09 21:23:58,557:INFO:Defining folds
2025-10-09 21:23:58,558:INFO:Declaring metric variables
2025-10-09 21:23:58,561:INFO:Importing untrained model
2025-10-09 21:23:58,565:INFO:K Neighbors Classifier Imported successfully
2025-10-09 21:23:58,573:INFO:Starting cross validation
2025-10-09 21:23:58,574:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 21:24:01,590:INFO:Calculating mean and std
2025-10-09 21:24:01,590:INFO:Creating metrics dataframe
2025-10-09 21:24:01,593:INFO:Uploading results into container
2025-10-09 21:24:01,594:INFO:Uploading model into container now
2025-10-09 21:24:01,594:INFO:_master_model_container: 2
2025-10-09 21:24:01,595:INFO:_display_container: 2
2025-10-09 21:24:01,595:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-10-09 21:24:01,595:INFO:create_model() successfully completed......................................
2025-10-09 21:24:01,696:INFO:SubProcess create_model() end ==================================
2025-10-09 21:24:01,696:INFO:Creating metrics dataframe
2025-10-09 21:24:01,705:INFO:Initializing Naive Bayes
2025-10-09 21:24:01,705:INFO:Total runtime is 0.16199934085210166 minutes
2025-10-09 21:24:01,709:INFO:SubProcess create_model() called ==================================
2025-10-09 21:24:01,710:INFO:Initializing create_model()
2025-10-09 21:24:01,710:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EBBCE1EBD0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EBBCDE1ED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 21:24:01,710:INFO:Checking exceptions
2025-10-09 21:24:01,710:INFO:Importing libraries
2025-10-09 21:24:01,710:INFO:Copying training dataset
2025-10-09 21:24:01,715:INFO:Defining folds
2025-10-09 21:24:01,715:INFO:Declaring metric variables
2025-10-09 21:24:01,719:INFO:Importing untrained model
2025-10-09 21:24:01,724:INFO:Naive Bayes Imported successfully
2025-10-09 21:24:01,730:INFO:Starting cross validation
2025-10-09 21:24:01,731:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 21:24:01,905:INFO:Calculating mean and std
2025-10-09 21:24:01,906:INFO:Creating metrics dataframe
2025-10-09 21:24:01,908:INFO:Uploading results into container
2025-10-09 21:24:01,909:INFO:Uploading model into container now
2025-10-09 21:24:01,909:INFO:_master_model_container: 3
2025-10-09 21:24:01,909:INFO:_display_container: 2
2025-10-09 21:24:01,909:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-10-09 21:24:01,910:INFO:create_model() successfully completed......................................
2025-10-09 21:24:01,993:INFO:SubProcess create_model() end ==================================
2025-10-09 21:24:01,993:INFO:Creating metrics dataframe
2025-10-09 21:24:02,002:INFO:Initializing Decision Tree Classifier
2025-10-09 21:24:02,002:INFO:Total runtime is 0.1669462521870931 minutes
2025-10-09 21:24:02,005:INFO:SubProcess create_model() called ==================================
2025-10-09 21:24:02,006:INFO:Initializing create_model()
2025-10-09 21:24:02,006:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EBBCE1EBD0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EBBCDE1ED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 21:24:02,006:INFO:Checking exceptions
2025-10-09 21:24:02,006:INFO:Importing libraries
2025-10-09 21:24:02,006:INFO:Copying training dataset
2025-10-09 21:24:02,011:INFO:Defining folds
2025-10-09 21:24:02,011:INFO:Declaring metric variables
2025-10-09 21:24:02,014:INFO:Importing untrained model
2025-10-09 21:24:02,019:INFO:Decision Tree Classifier Imported successfully
2025-10-09 21:24:02,027:INFO:Starting cross validation
2025-10-09 21:24:02,028:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 21:24:02,201:INFO:Calculating mean and std
2025-10-09 21:24:02,202:INFO:Creating metrics dataframe
2025-10-09 21:24:02,204:INFO:Uploading results into container
2025-10-09 21:24:02,204:INFO:Uploading model into container now
2025-10-09 21:24:02,205:INFO:_master_model_container: 4
2025-10-09 21:24:02,205:INFO:_display_container: 2
2025-10-09 21:24:02,206:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-10-09 21:24:02,206:INFO:create_model() successfully completed......................................
2025-10-09 21:24:02,291:INFO:SubProcess create_model() end ==================================
2025-10-09 21:24:02,291:INFO:Creating metrics dataframe
2025-10-09 21:24:02,299:INFO:Initializing SVM - Linear Kernel
2025-10-09 21:24:02,300:INFO:Total runtime is 0.1719048539797465 minutes
2025-10-09 21:24:02,302:INFO:SubProcess create_model() called ==================================
2025-10-09 21:24:02,303:INFO:Initializing create_model()
2025-10-09 21:24:02,303:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EBBCE1EBD0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EBBCDE1ED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 21:24:02,303:INFO:Checking exceptions
2025-10-09 21:24:02,303:INFO:Importing libraries
2025-10-09 21:24:02,303:INFO:Copying training dataset
2025-10-09 21:24:02,307:INFO:Defining folds
2025-10-09 21:24:02,308:INFO:Declaring metric variables
2025-10-09 21:24:02,310:INFO:Importing untrained model
2025-10-09 21:24:02,315:INFO:SVM - Linear Kernel Imported successfully
2025-10-09 21:24:02,321:INFO:Starting cross validation
2025-10-09 21:24:02,323:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 21:24:02,496:INFO:Calculating mean and std
2025-10-09 21:24:02,497:INFO:Creating metrics dataframe
2025-10-09 21:24:02,499:INFO:Uploading results into container
2025-10-09 21:24:02,500:INFO:Uploading model into container now
2025-10-09 21:24:02,500:INFO:_master_model_container: 5
2025-10-09 21:24:02,500:INFO:_display_container: 2
2025-10-09 21:24:02,501:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-10-09 21:24:02,501:INFO:create_model() successfully completed......................................
2025-10-09 21:24:02,587:INFO:SubProcess create_model() end ==================================
2025-10-09 21:24:02,587:INFO:Creating metrics dataframe
2025-10-09 21:24:02,595:INFO:Initializing Ridge Classifier
2025-10-09 21:24:02,596:INFO:Total runtime is 0.17683692375818888 minutes
2025-10-09 21:24:02,600:INFO:SubProcess create_model() called ==================================
2025-10-09 21:24:02,600:INFO:Initializing create_model()
2025-10-09 21:24:02,600:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EBBCE1EBD0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EBBCDE1ED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 21:24:02,600:INFO:Checking exceptions
2025-10-09 21:24:02,600:INFO:Importing libraries
2025-10-09 21:24:02,600:INFO:Copying training dataset
2025-10-09 21:24:02,605:INFO:Defining folds
2025-10-09 21:24:02,605:INFO:Declaring metric variables
2025-10-09 21:24:02,609:INFO:Importing untrained model
2025-10-09 21:24:02,612:INFO:Ridge Classifier Imported successfully
2025-10-09 21:24:02,620:INFO:Starting cross validation
2025-10-09 21:24:02,624:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 21:24:02,819:INFO:Calculating mean and std
2025-10-09 21:24:02,820:INFO:Creating metrics dataframe
2025-10-09 21:24:02,823:INFO:Uploading results into container
2025-10-09 21:24:02,824:INFO:Uploading model into container now
2025-10-09 21:24:02,824:INFO:_master_model_container: 6
2025-10-09 21:24:02,824:INFO:_display_container: 2
2025-10-09 21:24:02,825:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-10-09 21:24:02,825:INFO:create_model() successfully completed......................................
2025-10-09 21:24:02,910:INFO:SubProcess create_model() end ==================================
2025-10-09 21:24:02,910:INFO:Creating metrics dataframe
2025-10-09 21:24:02,918:INFO:Initializing Random Forest Classifier
2025-10-09 21:24:02,918:INFO:Total runtime is 0.1822039842605591 minutes
2025-10-09 21:24:02,921:INFO:SubProcess create_model() called ==================================
2025-10-09 21:24:02,922:INFO:Initializing create_model()
2025-10-09 21:24:02,922:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EBBCE1EBD0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EBBCDE1ED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 21:24:02,922:INFO:Checking exceptions
2025-10-09 21:24:02,922:INFO:Importing libraries
2025-10-09 21:24:02,922:INFO:Copying training dataset
2025-10-09 21:24:02,927:INFO:Defining folds
2025-10-09 21:24:02,927:INFO:Declaring metric variables
2025-10-09 21:24:02,930:INFO:Importing untrained model
2025-10-09 21:24:02,937:INFO:Random Forest Classifier Imported successfully
2025-10-09 21:24:02,943:INFO:Starting cross validation
2025-10-09 21:24:02,946:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 21:24:03,592:INFO:Calculating mean and std
2025-10-09 21:24:03,593:INFO:Creating metrics dataframe
2025-10-09 21:24:03,595:INFO:Uploading results into container
2025-10-09 21:24:03,596:INFO:Uploading model into container now
2025-10-09 21:24:03,597:INFO:_master_model_container: 7
2025-10-09 21:24:03,597:INFO:_display_container: 2
2025-10-09 21:24:03,598:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-10-09 21:24:03,598:INFO:create_model() successfully completed......................................
2025-10-09 21:24:03,688:INFO:SubProcess create_model() end ==================================
2025-10-09 21:24:03,688:INFO:Creating metrics dataframe
2025-10-09 21:24:03,695:INFO:Initializing Quadratic Discriminant Analysis
2025-10-09 21:24:03,695:INFO:Total runtime is 0.19516279697418212 minutes
2025-10-09 21:24:03,700:INFO:SubProcess create_model() called ==================================
2025-10-09 21:24:03,701:INFO:Initializing create_model()
2025-10-09 21:24:03,701:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EBBCE1EBD0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EBBCDE1ED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 21:24:03,701:INFO:Checking exceptions
2025-10-09 21:24:03,701:INFO:Importing libraries
2025-10-09 21:24:03,701:INFO:Copying training dataset
2025-10-09 21:24:03,705:INFO:Defining folds
2025-10-09 21:24:03,705:INFO:Declaring metric variables
2025-10-09 21:24:03,709:INFO:Importing untrained model
2025-10-09 21:24:03,713:INFO:Quadratic Discriminant Analysis Imported successfully
2025-10-09 21:24:03,728:INFO:Starting cross validation
2025-10-09 21:24:03,733:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 21:24:03,886:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 21:24:03,886:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 21:24:03,886:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 21:24:03,886:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 21:24:03,886:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 21:24:03,886:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 21:24:03,886:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 21:24:03,886:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 21:24:03,959:INFO:Calculating mean and std
2025-10-09 21:24:03,961:INFO:Creating metrics dataframe
2025-10-09 21:24:03,965:INFO:Uploading results into container
2025-10-09 21:24:03,965:INFO:Uploading model into container now
2025-10-09 21:24:03,966:INFO:_master_model_container: 8
2025-10-09 21:24:03,966:INFO:_display_container: 2
2025-10-09 21:24:03,966:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-10-09 21:24:03,967:INFO:create_model() successfully completed......................................
2025-10-09 21:24:04,053:INFO:SubProcess create_model() end ==================================
2025-10-09 21:24:04,053:INFO:Creating metrics dataframe
2025-10-09 21:24:04,062:INFO:Initializing Ada Boost Classifier
2025-10-09 21:24:04,062:INFO:Total runtime is 0.2012781858444214 minutes
2025-10-09 21:24:04,066:INFO:SubProcess create_model() called ==================================
2025-10-09 21:24:04,067:INFO:Initializing create_model()
2025-10-09 21:24:04,067:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EBBCE1EBD0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EBBCDE1ED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 21:24:04,067:INFO:Checking exceptions
2025-10-09 21:24:04,067:INFO:Importing libraries
2025-10-09 21:24:04,067:INFO:Copying training dataset
2025-10-09 21:24:04,071:INFO:Defining folds
2025-10-09 21:24:04,071:INFO:Declaring metric variables
2025-10-09 21:24:04,076:INFO:Importing untrained model
2025-10-09 21:24:04,081:INFO:Ada Boost Classifier Imported successfully
2025-10-09 21:24:04,089:INFO:Starting cross validation
2025-10-09 21:24:04,090:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 21:24:04,223:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 21:24:04,223:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 21:24:04,223:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 21:24:04,223:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 21:24:04,223:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 21:24:04,223:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 21:24:04,223:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 21:24:04,483:INFO:Calculating mean and std
2025-10-09 21:24:04,484:INFO:Creating metrics dataframe
2025-10-09 21:24:04,486:INFO:Uploading results into container
2025-10-09 21:24:04,486:INFO:Uploading model into container now
2025-10-09 21:24:04,487:INFO:_master_model_container: 9
2025-10-09 21:24:04,487:INFO:_display_container: 2
2025-10-09 21:24:04,488:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-10-09 21:24:04,488:INFO:create_model() successfully completed......................................
2025-10-09 21:24:04,575:INFO:SubProcess create_model() end ==================================
2025-10-09 21:24:04,575:INFO:Creating metrics dataframe
2025-10-09 21:24:04,586:INFO:Initializing Gradient Boosting Classifier
2025-10-09 21:24:04,586:INFO:Total runtime is 0.21000198523203534 minutes
2025-10-09 21:24:04,590:INFO:SubProcess create_model() called ==================================
2025-10-09 21:24:04,590:INFO:Initializing create_model()
2025-10-09 21:24:04,590:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EBBCE1EBD0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EBBCDE1ED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 21:24:04,590:INFO:Checking exceptions
2025-10-09 21:24:04,590:INFO:Importing libraries
2025-10-09 21:24:04,590:INFO:Copying training dataset
2025-10-09 21:24:04,596:INFO:Defining folds
2025-10-09 21:24:04,596:INFO:Declaring metric variables
2025-10-09 21:24:04,601:INFO:Importing untrained model
2025-10-09 21:24:04,605:INFO:Gradient Boosting Classifier Imported successfully
2025-10-09 21:24:04,613:INFO:Starting cross validation
2025-10-09 21:24:04,616:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 21:24:05,063:INFO:Calculating mean and std
2025-10-09 21:24:05,065:INFO:Creating metrics dataframe
2025-10-09 21:24:05,067:INFO:Uploading results into container
2025-10-09 21:24:05,068:INFO:Uploading model into container now
2025-10-09 21:24:05,068:INFO:_master_model_container: 10
2025-10-09 21:24:05,068:INFO:_display_container: 2
2025-10-09 21:24:05,069:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-09 21:24:05,069:INFO:create_model() successfully completed......................................
2025-10-09 21:24:05,152:INFO:SubProcess create_model() end ==================================
2025-10-09 21:24:05,152:INFO:Creating metrics dataframe
2025-10-09 21:24:05,161:INFO:Initializing Linear Discriminant Analysis
2025-10-09 21:24:05,161:INFO:Total runtime is 0.21959842840830487 minutes
2025-10-09 21:24:05,165:INFO:SubProcess create_model() called ==================================
2025-10-09 21:24:05,165:INFO:Initializing create_model()
2025-10-09 21:24:05,166:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EBBCE1EBD0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EBBCDE1ED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 21:24:05,166:INFO:Checking exceptions
2025-10-09 21:24:05,166:INFO:Importing libraries
2025-10-09 21:24:05,166:INFO:Copying training dataset
2025-10-09 21:24:05,170:INFO:Defining folds
2025-10-09 21:24:05,170:INFO:Declaring metric variables
2025-10-09 21:24:05,174:INFO:Importing untrained model
2025-10-09 21:24:05,178:INFO:Linear Discriminant Analysis Imported successfully
2025-10-09 21:24:05,187:INFO:Starting cross validation
2025-10-09 21:24:05,188:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 21:24:05,382:INFO:Calculating mean and std
2025-10-09 21:24:05,383:INFO:Creating metrics dataframe
2025-10-09 21:24:05,387:INFO:Uploading results into container
2025-10-09 21:24:05,388:INFO:Uploading model into container now
2025-10-09 21:24:05,389:INFO:_master_model_container: 11
2025-10-09 21:24:05,389:INFO:_display_container: 2
2025-10-09 21:24:05,389:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-09 21:24:05,389:INFO:create_model() successfully completed......................................
2025-10-09 21:24:05,473:INFO:SubProcess create_model() end ==================================
2025-10-09 21:24:05,473:INFO:Creating metrics dataframe
2025-10-09 21:24:05,483:INFO:Initializing Extra Trees Classifier
2025-10-09 21:24:05,483:INFO:Total runtime is 0.22495861450831098 minutes
2025-10-09 21:24:05,486:INFO:SubProcess create_model() called ==================================
2025-10-09 21:24:05,488:INFO:Initializing create_model()
2025-10-09 21:24:05,488:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EBBCE1EBD0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EBBCDE1ED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 21:24:05,488:INFO:Checking exceptions
2025-10-09 21:24:05,488:INFO:Importing libraries
2025-10-09 21:24:05,488:INFO:Copying training dataset
2025-10-09 21:24:05,492:INFO:Defining folds
2025-10-09 21:24:05,492:INFO:Declaring metric variables
2025-10-09 21:24:05,497:INFO:Importing untrained model
2025-10-09 21:24:05,501:INFO:Extra Trees Classifier Imported successfully
2025-10-09 21:24:05,508:INFO:Starting cross validation
2025-10-09 21:24:05,509:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 21:24:06,071:INFO:Calculating mean and std
2025-10-09 21:24:06,073:INFO:Creating metrics dataframe
2025-10-09 21:24:06,075:INFO:Uploading results into container
2025-10-09 21:24:06,075:INFO:Uploading model into container now
2025-10-09 21:24:06,076:INFO:_master_model_container: 12
2025-10-09 21:24:06,076:INFO:_display_container: 2
2025-10-09 21:24:06,076:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-10-09 21:24:06,076:INFO:create_model() successfully completed......................................
2025-10-09 21:24:06,161:INFO:SubProcess create_model() end ==================================
2025-10-09 21:24:06,161:INFO:Creating metrics dataframe
2025-10-09 21:24:06,171:INFO:Initializing Light Gradient Boosting Machine
2025-10-09 21:24:06,171:INFO:Total runtime is 0.23642903963724773 minutes
2025-10-09 21:24:06,174:INFO:SubProcess create_model() called ==================================
2025-10-09 21:24:06,175:INFO:Initializing create_model()
2025-10-09 21:24:06,175:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EBBCE1EBD0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EBBCDE1ED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 21:24:06,175:INFO:Checking exceptions
2025-10-09 21:24:06,175:INFO:Importing libraries
2025-10-09 21:24:06,175:INFO:Copying training dataset
2025-10-09 21:24:06,179:INFO:Defining folds
2025-10-09 21:24:06,180:INFO:Declaring metric variables
2025-10-09 21:24:06,186:INFO:Importing untrained model
2025-10-09 21:24:06,189:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-09 21:24:06,196:INFO:Starting cross validation
2025-10-09 21:24:06,198:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 21:24:07,127:INFO:Calculating mean and std
2025-10-09 21:24:07,129:INFO:Creating metrics dataframe
2025-10-09 21:24:07,132:INFO:Uploading results into container
2025-10-09 21:24:07,133:INFO:Uploading model into container now
2025-10-09 21:24:07,135:INFO:_master_model_container: 13
2025-10-09 21:24:07,135:INFO:_display_container: 2
2025-10-09 21:24:07,138:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-09 21:24:07,138:INFO:create_model() successfully completed......................................
2025-10-09 21:24:07,250:INFO:SubProcess create_model() end ==================================
2025-10-09 21:24:07,250:INFO:Creating metrics dataframe
2025-10-09 21:24:07,260:INFO:Initializing Dummy Classifier
2025-10-09 21:24:07,260:INFO:Total runtime is 0.25457953214645385 minutes
2025-10-09 21:24:07,263:INFO:SubProcess create_model() called ==================================
2025-10-09 21:24:07,264:INFO:Initializing create_model()
2025-10-09 21:24:07,264:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EBBCE1EBD0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EBBCDE1ED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 21:24:07,264:INFO:Checking exceptions
2025-10-09 21:24:07,264:INFO:Importing libraries
2025-10-09 21:24:07,264:INFO:Copying training dataset
2025-10-09 21:24:07,269:INFO:Defining folds
2025-10-09 21:24:07,269:INFO:Declaring metric variables
2025-10-09 21:24:07,274:INFO:Importing untrained model
2025-10-09 21:24:07,279:INFO:Dummy Classifier Imported successfully
2025-10-09 21:24:07,287:INFO:Starting cross validation
2025-10-09 21:24:07,289:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 21:24:07,460:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 21:24:07,463:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 21:24:07,463:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 21:24:07,465:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 21:24:07,470:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 21:24:07,473:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 21:24:07,473:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 21:24:07,473:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 21:24:07,478:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 21:24:07,497:INFO:Calculating mean and std
2025-10-09 21:24:07,500:INFO:Creating metrics dataframe
2025-10-09 21:24:07,507:INFO:Uploading results into container
2025-10-09 21:24:07,508:INFO:Uploading model into container now
2025-10-09 21:24:07,509:INFO:_master_model_container: 14
2025-10-09 21:24:07,510:INFO:_display_container: 2
2025-10-09 21:24:07,510:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-10-09 21:24:07,511:INFO:create_model() successfully completed......................................
2025-10-09 21:24:07,609:INFO:SubProcess create_model() end ==================================
2025-10-09 21:24:07,609:INFO:Creating metrics dataframe
2025-10-09 21:24:07,648:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-10-09 21:24:07,657:INFO:Initializing create_model()
2025-10-09 21:24:07,657:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EBBCE1EBD0>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 21:24:07,657:INFO:Checking exceptions
2025-10-09 21:24:07,660:INFO:Importing libraries
2025-10-09 21:24:07,660:INFO:Copying training dataset
2025-10-09 21:24:07,666:INFO:Defining folds
2025-10-09 21:24:07,666:INFO:Declaring metric variables
2025-10-09 21:24:07,666:INFO:Importing untrained model
2025-10-09 21:24:07,666:INFO:Declaring custom model
2025-10-09 21:24:07,667:INFO:Ridge Classifier Imported successfully
2025-10-09 21:24:07,668:INFO:Cross validation set to False
2025-10-09 21:24:07,668:INFO:Fitting Model
2025-10-09 21:24:07,717:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-10-09 21:24:07,717:INFO:create_model() successfully completed......................................
2025-10-09 21:24:07,849:INFO:_master_model_container: 14
2025-10-09 21:24:07,849:INFO:_display_container: 2
2025-10-09 21:24:07,850:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-10-09 21:24:07,850:INFO:compare_models() successfully completed......................................
2025-10-09 21:24:17,565:INFO:Initializing compare_models()
2025-10-09 21:24:17,566:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EBBCE1EBD0>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001EBBCE1EBD0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-10-09 21:24:17,566:INFO:Checking exceptions
2025-10-09 21:24:17,568:INFO:Preparing display monitor
2025-10-09 21:24:17,595:INFO:Initializing Logistic Regression
2025-10-09 21:24:17,595:INFO:Total runtime is 0.0 minutes
2025-10-09 21:24:17,599:INFO:SubProcess create_model() called ==================================
2025-10-09 21:24:17,599:INFO:Initializing create_model()
2025-10-09 21:24:17,599:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EBBCE1EBD0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EBBCBD9210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 21:24:17,599:INFO:Checking exceptions
2025-10-09 21:24:17,600:INFO:Importing libraries
2025-10-09 21:24:17,600:INFO:Copying training dataset
2025-10-09 21:24:17,603:INFO:Defining folds
2025-10-09 21:24:17,603:INFO:Declaring metric variables
2025-10-09 21:24:17,607:INFO:Importing untrained model
2025-10-09 21:24:17,612:INFO:Logistic Regression Imported successfully
2025-10-09 21:24:17,620:INFO:Starting cross validation
2025-10-09 21:24:17,623:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 21:24:17,867:INFO:Calculating mean and std
2025-10-09 21:24:17,869:INFO:Creating metrics dataframe
2025-10-09 21:24:17,874:INFO:Uploading results into container
2025-10-09 21:24:17,875:INFO:Uploading model into container now
2025-10-09 21:24:17,876:INFO:_master_model_container: 15
2025-10-09 21:24:17,876:INFO:_display_container: 3
2025-10-09 21:24:17,877:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-09 21:24:17,877:INFO:create_model() successfully completed......................................
2025-10-09 21:24:17,967:INFO:SubProcess create_model() end ==================================
2025-10-09 21:24:17,967:INFO:Creating metrics dataframe
2025-10-09 21:24:17,973:INFO:Initializing K Neighbors Classifier
2025-10-09 21:24:17,974:INFO:Total runtime is 0.006332854429880778 minutes
2025-10-09 21:24:17,977:INFO:SubProcess create_model() called ==================================
2025-10-09 21:24:17,978:INFO:Initializing create_model()
2025-10-09 21:24:17,978:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EBBCE1EBD0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EBBCBD9210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 21:24:17,978:INFO:Checking exceptions
2025-10-09 21:24:17,978:INFO:Importing libraries
2025-10-09 21:24:17,978:INFO:Copying training dataset
2025-10-09 21:24:17,983:INFO:Defining folds
2025-10-09 21:24:17,983:INFO:Declaring metric variables
2025-10-09 21:24:17,985:INFO:Importing untrained model
2025-10-09 21:24:17,989:INFO:K Neighbors Classifier Imported successfully
2025-10-09 21:24:17,998:INFO:Starting cross validation
2025-10-09 21:24:18,000:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 21:24:18,235:INFO:Calculating mean and std
2025-10-09 21:24:18,235:INFO:Creating metrics dataframe
2025-10-09 21:24:18,237:INFO:Uploading results into container
2025-10-09 21:24:18,237:INFO:Uploading model into container now
2025-10-09 21:24:18,237:INFO:_master_model_container: 16
2025-10-09 21:24:18,238:INFO:_display_container: 3
2025-10-09 21:24:18,238:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-10-09 21:24:18,238:INFO:create_model() successfully completed......................................
2025-10-09 21:24:18,321:INFO:SubProcess create_model() end ==================================
2025-10-09 21:24:18,321:INFO:Creating metrics dataframe
2025-10-09 21:24:18,329:INFO:Initializing Naive Bayes
2025-10-09 21:24:18,330:INFO:Total runtime is 0.012254631519317627 minutes
2025-10-09 21:24:18,333:INFO:SubProcess create_model() called ==================================
2025-10-09 21:24:18,333:INFO:Initializing create_model()
2025-10-09 21:24:18,333:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EBBCE1EBD0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EBBCBD9210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 21:24:18,333:INFO:Checking exceptions
2025-10-09 21:24:18,333:INFO:Importing libraries
2025-10-09 21:24:18,333:INFO:Copying training dataset
2025-10-09 21:24:18,338:INFO:Defining folds
2025-10-09 21:24:18,338:INFO:Declaring metric variables
2025-10-09 21:24:18,341:INFO:Importing untrained model
2025-10-09 21:24:18,345:INFO:Naive Bayes Imported successfully
2025-10-09 21:24:18,353:INFO:Starting cross validation
2025-10-09 21:24:18,355:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 21:24:18,538:INFO:Calculating mean and std
2025-10-09 21:24:18,540:INFO:Creating metrics dataframe
2025-10-09 21:24:18,544:INFO:Uploading results into container
2025-10-09 21:24:18,545:INFO:Uploading model into container now
2025-10-09 21:24:18,546:INFO:_master_model_container: 17
2025-10-09 21:24:18,546:INFO:_display_container: 3
2025-10-09 21:24:18,546:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-10-09 21:24:18,547:INFO:create_model() successfully completed......................................
2025-10-09 21:24:18,638:INFO:SubProcess create_model() end ==================================
2025-10-09 21:24:18,638:INFO:Creating metrics dataframe
2025-10-09 21:24:18,647:INFO:Initializing Decision Tree Classifier
2025-10-09 21:24:18,647:INFO:Total runtime is 0.017536842823028566 minutes
2025-10-09 21:24:18,650:INFO:SubProcess create_model() called ==================================
2025-10-09 21:24:18,650:INFO:Initializing create_model()
2025-10-09 21:24:18,650:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EBBCE1EBD0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EBBCBD9210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 21:24:18,650:INFO:Checking exceptions
2025-10-09 21:24:18,650:INFO:Importing libraries
2025-10-09 21:24:18,650:INFO:Copying training dataset
2025-10-09 21:24:18,655:INFO:Defining folds
2025-10-09 21:24:18,655:INFO:Declaring metric variables
2025-10-09 21:24:18,660:INFO:Importing untrained model
2025-10-09 21:24:18,665:INFO:Decision Tree Classifier Imported successfully
2025-10-09 21:24:18,671:INFO:Starting cross validation
2025-10-09 21:24:18,674:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 21:24:18,872:INFO:Calculating mean and std
2025-10-09 21:24:18,873:INFO:Creating metrics dataframe
2025-10-09 21:24:18,875:INFO:Uploading results into container
2025-10-09 21:24:18,875:INFO:Uploading model into container now
2025-10-09 21:24:18,876:INFO:_master_model_container: 18
2025-10-09 21:24:18,876:INFO:_display_container: 3
2025-10-09 21:24:18,876:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-10-09 21:24:18,876:INFO:create_model() successfully completed......................................
2025-10-09 21:24:18,963:INFO:SubProcess create_model() end ==================================
2025-10-09 21:24:18,963:INFO:Creating metrics dataframe
2025-10-09 21:24:18,970:INFO:Initializing SVM - Linear Kernel
2025-10-09 21:24:18,970:INFO:Total runtime is 0.02292153835296631 minutes
2025-10-09 21:24:18,973:INFO:SubProcess create_model() called ==================================
2025-10-09 21:24:18,973:INFO:Initializing create_model()
2025-10-09 21:24:18,973:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EBBCE1EBD0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EBBCBD9210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 21:24:18,973:INFO:Checking exceptions
2025-10-09 21:24:18,973:INFO:Importing libraries
2025-10-09 21:24:18,974:INFO:Copying training dataset
2025-10-09 21:24:18,978:INFO:Defining folds
2025-10-09 21:24:18,978:INFO:Declaring metric variables
2025-10-09 21:24:18,982:INFO:Importing untrained model
2025-10-09 21:24:18,986:INFO:SVM - Linear Kernel Imported successfully
2025-10-09 21:24:18,993:INFO:Starting cross validation
2025-10-09 21:24:18,995:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 21:24:19,177:INFO:Calculating mean and std
2025-10-09 21:24:19,178:INFO:Creating metrics dataframe
2025-10-09 21:24:19,180:INFO:Uploading results into container
2025-10-09 21:24:19,181:INFO:Uploading model into container now
2025-10-09 21:24:19,181:INFO:_master_model_container: 19
2025-10-09 21:24:19,181:INFO:_display_container: 3
2025-10-09 21:24:19,183:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-10-09 21:24:19,183:INFO:create_model() successfully completed......................................
2025-10-09 21:24:19,270:INFO:SubProcess create_model() end ==================================
2025-10-09 21:24:19,271:INFO:Creating metrics dataframe
2025-10-09 21:24:19,280:INFO:Initializing Ridge Classifier
2025-10-09 21:24:19,280:INFO:Total runtime is 0.028086523214975994 minutes
2025-10-09 21:24:19,283:INFO:SubProcess create_model() called ==================================
2025-10-09 21:24:19,283:INFO:Initializing create_model()
2025-10-09 21:24:19,283:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EBBCE1EBD0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EBBCBD9210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 21:24:19,283:INFO:Checking exceptions
2025-10-09 21:24:19,285:INFO:Importing libraries
2025-10-09 21:24:19,285:INFO:Copying training dataset
2025-10-09 21:24:19,289:INFO:Defining folds
2025-10-09 21:24:19,290:INFO:Declaring metric variables
2025-10-09 21:24:19,295:INFO:Importing untrained model
2025-10-09 21:24:19,299:INFO:Ridge Classifier Imported successfully
2025-10-09 21:24:19,307:INFO:Starting cross validation
2025-10-09 21:24:19,309:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 21:24:19,500:INFO:Calculating mean and std
2025-10-09 21:24:19,501:INFO:Creating metrics dataframe
2025-10-09 21:24:19,503:INFO:Uploading results into container
2025-10-09 21:24:19,503:INFO:Uploading model into container now
2025-10-09 21:24:19,504:INFO:_master_model_container: 20
2025-10-09 21:24:19,504:INFO:_display_container: 3
2025-10-09 21:24:19,504:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-10-09 21:24:19,504:INFO:create_model() successfully completed......................................
2025-10-09 21:24:19,593:INFO:SubProcess create_model() end ==================================
2025-10-09 21:24:19,593:INFO:Creating metrics dataframe
2025-10-09 21:24:19,601:INFO:Initializing Random Forest Classifier
2025-10-09 21:24:19,601:INFO:Total runtime is 0.033443323771158856 minutes
2025-10-09 21:24:19,605:INFO:SubProcess create_model() called ==================================
2025-10-09 21:24:19,606:INFO:Initializing create_model()
2025-10-09 21:24:19,606:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EBBCE1EBD0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EBBCBD9210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 21:24:19,606:INFO:Checking exceptions
2025-10-09 21:24:19,606:INFO:Importing libraries
2025-10-09 21:24:19,606:INFO:Copying training dataset
2025-10-09 21:24:19,612:INFO:Defining folds
2025-10-09 21:24:19,612:INFO:Declaring metric variables
2025-10-09 21:24:19,617:INFO:Importing untrained model
2025-10-09 21:24:19,621:INFO:Random Forest Classifier Imported successfully
2025-10-09 21:24:19,629:INFO:Starting cross validation
2025-10-09 21:24:19,631:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 21:24:20,236:INFO:Calculating mean and std
2025-10-09 21:24:20,237:INFO:Creating metrics dataframe
2025-10-09 21:24:20,239:INFO:Uploading results into container
2025-10-09 21:24:20,239:INFO:Uploading model into container now
2025-10-09 21:24:20,240:INFO:_master_model_container: 21
2025-10-09 21:24:20,240:INFO:_display_container: 3
2025-10-09 21:24:20,240:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-10-09 21:24:20,240:INFO:create_model() successfully completed......................................
2025-10-09 21:24:20,326:INFO:SubProcess create_model() end ==================================
2025-10-09 21:24:20,327:INFO:Creating metrics dataframe
2025-10-09 21:24:20,335:INFO:Initializing Quadratic Discriminant Analysis
2025-10-09 21:24:20,336:INFO:Total runtime is 0.04568479458491008 minutes
2025-10-09 21:24:20,339:INFO:SubProcess create_model() called ==================================
2025-10-09 21:24:20,339:INFO:Initializing create_model()
2025-10-09 21:24:20,339:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EBBCE1EBD0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EBBCBD9210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 21:24:20,340:INFO:Checking exceptions
2025-10-09 21:24:20,340:INFO:Importing libraries
2025-10-09 21:24:20,340:INFO:Copying training dataset
2025-10-09 21:24:20,343:INFO:Defining folds
2025-10-09 21:24:20,345:INFO:Declaring metric variables
2025-10-09 21:24:20,349:INFO:Importing untrained model
2025-10-09 21:24:20,352:INFO:Quadratic Discriminant Analysis Imported successfully
2025-10-09 21:24:20,358:INFO:Starting cross validation
2025-10-09 21:24:20,360:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 21:24:20,459:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 21:24:20,460:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 21:24:20,462:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 21:24:20,462:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 21:24:20,463:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 21:24:20,471:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 21:24:20,473:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 21:24:20,474:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 21:24:20,474:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 21:24:20,479:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 21:24:20,535:INFO:Calculating mean and std
2025-10-09 21:24:20,536:INFO:Creating metrics dataframe
2025-10-09 21:24:20,538:INFO:Uploading results into container
2025-10-09 21:24:20,539:INFO:Uploading model into container now
2025-10-09 21:24:20,539:INFO:_master_model_container: 22
2025-10-09 21:24:20,540:INFO:_display_container: 3
2025-10-09 21:24:20,540:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-10-09 21:24:20,540:INFO:create_model() successfully completed......................................
2025-10-09 21:24:20,623:INFO:SubProcess create_model() end ==================================
2025-10-09 21:24:20,624:INFO:Creating metrics dataframe
2025-10-09 21:24:20,633:INFO:Initializing Ada Boost Classifier
2025-10-09 21:24:20,634:INFO:Total runtime is 0.05066444079081218 minutes
2025-10-09 21:24:20,637:INFO:SubProcess create_model() called ==================================
2025-10-09 21:24:20,637:INFO:Initializing create_model()
2025-10-09 21:24:20,637:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EBBCE1EBD0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EBBCBD9210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 21:24:20,638:INFO:Checking exceptions
2025-10-09 21:24:20,638:INFO:Importing libraries
2025-10-09 21:24:20,638:INFO:Copying training dataset
2025-10-09 21:24:20,642:INFO:Defining folds
2025-10-09 21:24:20,642:INFO:Declaring metric variables
2025-10-09 21:24:20,646:INFO:Importing untrained model
2025-10-09 21:24:20,649:INFO:Ada Boost Classifier Imported successfully
2025-10-09 21:24:20,657:INFO:Starting cross validation
2025-10-09 21:24:20,658:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 21:24:20,759:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 21:24:20,760:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 21:24:20,762:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 21:24:20,762:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 21:24:20,766:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 21:24:20,766:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 21:24:20,769:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 21:24:20,772:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 21:24:20,772:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 21:24:20,776:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 21:24:21,065:INFO:Calculating mean and std
2025-10-09 21:24:21,066:INFO:Creating metrics dataframe
2025-10-09 21:24:21,068:INFO:Uploading results into container
2025-10-09 21:24:21,069:INFO:Uploading model into container now
2025-10-09 21:24:21,069:INFO:_master_model_container: 23
2025-10-09 21:24:21,069:INFO:_display_container: 3
2025-10-09 21:24:21,070:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-10-09 21:24:21,070:INFO:create_model() successfully completed......................................
2025-10-09 21:24:21,153:INFO:SubProcess create_model() end ==================================
2025-10-09 21:24:21,153:INFO:Creating metrics dataframe
2025-10-09 21:24:21,163:INFO:Initializing Gradient Boosting Classifier
2025-10-09 21:24:21,163:INFO:Total runtime is 0.05947624444961548 minutes
2025-10-09 21:24:21,168:INFO:SubProcess create_model() called ==================================
2025-10-09 21:24:21,168:INFO:Initializing create_model()
2025-10-09 21:24:21,168:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EBBCE1EBD0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EBBCBD9210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 21:24:21,168:INFO:Checking exceptions
2025-10-09 21:24:21,168:INFO:Importing libraries
2025-10-09 21:24:21,169:INFO:Copying training dataset
2025-10-09 21:24:21,173:INFO:Defining folds
2025-10-09 21:24:21,173:INFO:Declaring metric variables
2025-10-09 21:24:21,179:INFO:Importing untrained model
2025-10-09 21:24:21,183:INFO:Gradient Boosting Classifier Imported successfully
2025-10-09 21:24:21,190:INFO:Starting cross validation
2025-10-09 21:24:21,192:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 21:24:21,604:INFO:Calculating mean and std
2025-10-09 21:24:21,607:INFO:Creating metrics dataframe
2025-10-09 21:24:21,612:INFO:Uploading results into container
2025-10-09 21:24:21,613:INFO:Uploading model into container now
2025-10-09 21:24:21,614:INFO:_master_model_container: 24
2025-10-09 21:24:21,615:INFO:_display_container: 3
2025-10-09 21:24:21,616:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-09 21:24:21,616:INFO:create_model() successfully completed......................................
2025-10-09 21:24:21,707:INFO:SubProcess create_model() end ==================================
2025-10-09 21:24:21,707:INFO:Creating metrics dataframe
2025-10-09 21:24:21,718:INFO:Initializing Linear Discriminant Analysis
2025-10-09 21:24:21,718:INFO:Total runtime is 0.06871812343597412 minutes
2025-10-09 21:24:21,722:INFO:SubProcess create_model() called ==================================
2025-10-09 21:24:21,722:INFO:Initializing create_model()
2025-10-09 21:24:21,722:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EBBCE1EBD0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EBBCBD9210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 21:24:21,722:INFO:Checking exceptions
2025-10-09 21:24:21,722:INFO:Importing libraries
2025-10-09 21:24:21,722:INFO:Copying training dataset
2025-10-09 21:24:21,729:INFO:Defining folds
2025-10-09 21:24:21,729:INFO:Declaring metric variables
2025-10-09 21:24:21,733:INFO:Importing untrained model
2025-10-09 21:24:21,736:INFO:Linear Discriminant Analysis Imported successfully
2025-10-09 21:24:21,743:INFO:Starting cross validation
2025-10-09 21:24:21,745:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 21:24:21,926:INFO:Calculating mean and std
2025-10-09 21:24:21,929:INFO:Creating metrics dataframe
2025-10-09 21:24:21,934:INFO:Uploading results into container
2025-10-09 21:24:21,935:INFO:Uploading model into container now
2025-10-09 21:24:21,936:INFO:_master_model_container: 25
2025-10-09 21:24:21,936:INFO:_display_container: 3
2025-10-09 21:24:21,937:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-09 21:24:21,937:INFO:create_model() successfully completed......................................
2025-10-09 21:24:22,026:INFO:SubProcess create_model() end ==================================
2025-10-09 21:24:22,026:INFO:Creating metrics dataframe
2025-10-09 21:24:22,036:INFO:Initializing Extra Trees Classifier
2025-10-09 21:24:22,036:INFO:Total runtime is 0.07401751279830933 minutes
2025-10-09 21:24:22,039:INFO:SubProcess create_model() called ==================================
2025-10-09 21:24:22,040:INFO:Initializing create_model()
2025-10-09 21:24:22,040:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EBBCE1EBD0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EBBCBD9210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 21:24:22,040:INFO:Checking exceptions
2025-10-09 21:24:22,040:INFO:Importing libraries
2025-10-09 21:24:22,040:INFO:Copying training dataset
2025-10-09 21:24:22,043:INFO:Defining folds
2025-10-09 21:24:22,044:INFO:Declaring metric variables
2025-10-09 21:24:22,047:INFO:Importing untrained model
2025-10-09 21:24:22,051:INFO:Extra Trees Classifier Imported successfully
2025-10-09 21:24:22,057:INFO:Starting cross validation
2025-10-09 21:24:22,059:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 21:24:22,612:INFO:Calculating mean and std
2025-10-09 21:24:22,616:INFO:Creating metrics dataframe
2025-10-09 21:24:22,623:INFO:Uploading results into container
2025-10-09 21:24:22,626:INFO:Uploading model into container now
2025-10-09 21:24:22,628:INFO:_master_model_container: 26
2025-10-09 21:24:22,629:INFO:_display_container: 3
2025-10-09 21:24:22,631:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-10-09 21:24:22,631:INFO:create_model() successfully completed......................................
2025-10-09 21:24:22,729:INFO:SubProcess create_model() end ==================================
2025-10-09 21:24:22,729:INFO:Creating metrics dataframe
2025-10-09 21:24:22,739:INFO:Initializing Light Gradient Boosting Machine
2025-10-09 21:24:22,739:INFO:Total runtime is 0.08573538462320963 minutes
2025-10-09 21:24:22,742:INFO:SubProcess create_model() called ==================================
2025-10-09 21:24:22,742:INFO:Initializing create_model()
2025-10-09 21:24:22,742:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EBBCE1EBD0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EBBCBD9210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 21:24:22,742:INFO:Checking exceptions
2025-10-09 21:24:22,742:INFO:Importing libraries
2025-10-09 21:24:22,742:INFO:Copying training dataset
2025-10-09 21:24:22,747:INFO:Defining folds
2025-10-09 21:24:22,747:INFO:Declaring metric variables
2025-10-09 21:24:22,750:INFO:Importing untrained model
2025-10-09 21:24:22,754:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-09 21:24:22,761:INFO:Starting cross validation
2025-10-09 21:24:22,763:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 21:24:23,517:INFO:Calculating mean and std
2025-10-09 21:24:23,519:INFO:Creating metrics dataframe
2025-10-09 21:24:23,523:INFO:Uploading results into container
2025-10-09 21:24:23,524:INFO:Uploading model into container now
2025-10-09 21:24:23,525:INFO:_master_model_container: 27
2025-10-09 21:24:23,526:INFO:_display_container: 3
2025-10-09 21:24:23,527:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-09 21:24:23,527:INFO:create_model() successfully completed......................................
2025-10-09 21:24:23,641:INFO:SubProcess create_model() end ==================================
2025-10-09 21:24:23,642:INFO:Creating metrics dataframe
2025-10-09 21:24:23,652:INFO:Initializing Dummy Classifier
2025-10-09 21:24:23,652:INFO:Total runtime is 0.10095855792363484 minutes
2025-10-09 21:24:23,657:INFO:SubProcess create_model() called ==================================
2025-10-09 21:24:23,657:INFO:Initializing create_model()
2025-10-09 21:24:23,657:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EBBCE1EBD0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EBBCBD9210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 21:24:23,657:INFO:Checking exceptions
2025-10-09 21:24:23,657:INFO:Importing libraries
2025-10-09 21:24:23,657:INFO:Copying training dataset
2025-10-09 21:24:23,662:INFO:Defining folds
2025-10-09 21:24:23,662:INFO:Declaring metric variables
2025-10-09 21:24:23,665:INFO:Importing untrained model
2025-10-09 21:24:23,669:INFO:Dummy Classifier Imported successfully
2025-10-09 21:24:23,677:INFO:Starting cross validation
2025-10-09 21:24:23,679:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 21:24:23,832:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 21:24:23,834:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 21:24:23,835:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 21:24:23,838:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 21:24:23,840:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 21:24:23,845:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 21:24:23,846:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 21:24:23,847:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 21:24:23,848:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 21:24:23,865:INFO:Calculating mean and std
2025-10-09 21:24:23,866:INFO:Creating metrics dataframe
2025-10-09 21:24:23,868:INFO:Uploading results into container
2025-10-09 21:24:23,868:INFO:Uploading model into container now
2025-10-09 21:24:23,869:INFO:_master_model_container: 28
2025-10-09 21:24:23,869:INFO:_display_container: 3
2025-10-09 21:24:23,869:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-10-09 21:24:23,869:INFO:create_model() successfully completed......................................
2025-10-09 21:24:23,953:INFO:SubProcess create_model() end ==================================
2025-10-09 21:24:23,953:INFO:Creating metrics dataframe
2025-10-09 21:24:23,967:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-10-09 21:24:23,977:INFO:Initializing create_model()
2025-10-09 21:24:23,977:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EBBCE1EBD0>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 21:24:23,977:INFO:Checking exceptions
2025-10-09 21:24:23,979:INFO:Importing libraries
2025-10-09 21:24:23,979:INFO:Copying training dataset
2025-10-09 21:24:23,983:INFO:Defining folds
2025-10-09 21:24:23,983:INFO:Declaring metric variables
2025-10-09 21:24:23,983:INFO:Importing untrained model
2025-10-09 21:24:23,983:INFO:Declaring custom model
2025-10-09 21:24:23,984:INFO:Ridge Classifier Imported successfully
2025-10-09 21:24:23,986:INFO:Cross validation set to False
2025-10-09 21:24:23,986:INFO:Fitting Model
2025-10-09 21:24:24,029:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-10-09 21:24:24,029:INFO:create_model() successfully completed......................................
2025-10-09 21:24:24,144:INFO:_master_model_container: 28
2025-10-09 21:24:24,144:INFO:_display_container: 3
2025-10-09 21:24:24,144:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-10-09 21:24:24,145:INFO:compare_models() successfully completed......................................
2025-10-09 21:24:39,611:INFO:Initializing create_model()
2025-10-09 21:24:39,611:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EBBCE1EBD0>, estimator=ridge, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 21:24:39,611:INFO:Checking exceptions
2025-10-09 21:24:39,627:INFO:Importing libraries
2025-10-09 21:24:39,627:INFO:Copying training dataset
2025-10-09 21:24:39,630:INFO:Defining folds
2025-10-09 21:24:39,632:INFO:Declaring metric variables
2025-10-09 21:24:39,637:INFO:Importing untrained model
2025-10-09 21:24:39,643:INFO:Ridge Classifier Imported successfully
2025-10-09 21:24:39,655:INFO:Starting cross validation
2025-10-09 21:24:39,658:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 21:24:39,855:INFO:Calculating mean and std
2025-10-09 21:24:39,856:INFO:Creating metrics dataframe
2025-10-09 21:24:39,860:INFO:Finalizing model
2025-10-09 21:24:39,907:INFO:Uploading results into container
2025-10-09 21:24:39,908:INFO:Uploading model into container now
2025-10-09 21:24:39,918:INFO:_master_model_container: 29
2025-10-09 21:24:39,919:INFO:_display_container: 4
2025-10-09 21:24:39,919:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-10-09 21:24:39,919:INFO:create_model() successfully completed......................................
2025-10-09 21:24:54,779:INFO:Initializing tune_model()
2025-10-09 21:24:54,779:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EBBCE1EBD0>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-10-09 21:24:54,779:INFO:Checking exceptions
2025-10-09 21:24:54,796:INFO:Copying training dataset
2025-10-09 21:24:54,799:INFO:Checking base model
2025-10-09 21:24:54,799:INFO:Base model : Ridge Classifier
2025-10-09 21:24:54,803:INFO:Declaring metric variables
2025-10-09 21:24:54,809:INFO:Defining Hyperparameters
2025-10-09 21:24:54,920:INFO:Tuning with n_jobs=-1
2025-10-09 21:24:54,920:INFO:Initializing RandomizedSearchCV
2025-10-09 21:24:56,270:INFO:best_params: {'actual_estimator__fit_intercept': True, 'actual_estimator__alpha': 5.62}
2025-10-09 21:24:56,272:INFO:Hyperparameter search completed
2025-10-09 21:24:56,272:INFO:SubProcess create_model() called ==================================
2025-10-09 21:24:56,273:INFO:Initializing create_model()
2025-10-09 21:24:56,273:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EBBCE1EBD0>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EBBC84EE10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'fit_intercept': True, 'alpha': 5.62})
2025-10-09 21:24:56,273:INFO:Checking exceptions
2025-10-09 21:24:56,273:INFO:Importing libraries
2025-10-09 21:24:56,273:INFO:Copying training dataset
2025-10-09 21:24:56,277:INFO:Defining folds
2025-10-09 21:24:56,277:INFO:Declaring metric variables
2025-10-09 21:24:56,280:INFO:Importing untrained model
2025-10-09 21:24:56,280:INFO:Declaring custom model
2025-10-09 21:24:56,283:INFO:Ridge Classifier Imported successfully
2025-10-09 21:24:56,291:INFO:Starting cross validation
2025-10-09 21:24:56,293:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 21:24:56,476:INFO:Calculating mean and std
2025-10-09 21:24:56,477:INFO:Creating metrics dataframe
2025-10-09 21:24:56,482:INFO:Finalizing model
2025-10-09 21:24:56,529:INFO:Uploading results into container
2025-10-09 21:24:56,530:INFO:Uploading model into container now
2025-10-09 21:24:56,531:INFO:_master_model_container: 30
2025-10-09 21:24:56,531:INFO:_display_container: 5
2025-10-09 21:24:56,531:INFO:RidgeClassifier(alpha=5.62, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-10-09 21:24:56,531:INFO:create_model() successfully completed......................................
2025-10-09 21:24:56,619:INFO:SubProcess create_model() end ==================================
2025-10-09 21:24:56,619:INFO:choose_better activated
2025-10-09 21:24:56,622:INFO:SubProcess create_model() called ==================================
2025-10-09 21:24:56,623:INFO:Initializing create_model()
2025-10-09 21:24:56,623:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EBBCE1EBD0>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 21:24:56,623:INFO:Checking exceptions
2025-10-09 21:24:56,625:INFO:Importing libraries
2025-10-09 21:24:56,625:INFO:Copying training dataset
2025-10-09 21:24:56,630:INFO:Defining folds
2025-10-09 21:24:56,630:INFO:Declaring metric variables
2025-10-09 21:24:56,630:INFO:Importing untrained model
2025-10-09 21:24:56,630:INFO:Declaring custom model
2025-10-09 21:24:56,630:INFO:Ridge Classifier Imported successfully
2025-10-09 21:24:56,630:INFO:Starting cross validation
2025-10-09 21:24:56,632:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 21:24:56,817:INFO:Calculating mean and std
2025-10-09 21:24:56,819:INFO:Creating metrics dataframe
2025-10-09 21:24:56,824:INFO:Finalizing model
2025-10-09 21:24:56,877:INFO:Uploading results into container
2025-10-09 21:24:56,878:INFO:Uploading model into container now
2025-10-09 21:24:56,878:INFO:_master_model_container: 31
2025-10-09 21:24:56,878:INFO:_display_container: 6
2025-10-09 21:24:56,878:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-10-09 21:24:56,878:INFO:create_model() successfully completed......................................
2025-10-09 21:24:56,962:INFO:SubProcess create_model() end ==================================
2025-10-09 21:24:56,963:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001) result for Accuracy is 0.6429
2025-10-09 21:24:56,963:INFO:RidgeClassifier(alpha=5.62, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001) result for Accuracy is 0.6429
2025-10-09 21:24:56,963:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001) is best model
2025-10-09 21:24:56,963:INFO:choose_better completed
2025-10-09 21:24:56,964:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-10-09 21:24:56,976:INFO:_master_model_container: 31
2025-10-09 21:24:56,976:INFO:_display_container: 5
2025-10-09 21:24:56,976:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-10-09 21:24:56,976:INFO:tune_model() successfully completed......................................
2025-10-09 21:25:08,233:INFO:Initializing evaluate_model()
2025-10-09 21:25:08,233:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EBBCE1EBD0>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-10-09 21:25:08,248:INFO:Initializing plot_model()
2025-10-09 21:25:08,248:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EBBCE1EBD0>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-09 21:25:08,248:INFO:Checking exceptions
2025-10-09 21:25:08,251:INFO:Preloading libraries
2025-10-09 21:25:08,251:INFO:Copying training dataset
2025-10-09 21:25:08,251:INFO:Plot type: pipeline
2025-10-09 21:25:08,467:INFO:Visual Rendered Successfully
2025-10-09 21:25:08,551:INFO:plot_model() successfully completed......................................
2025-10-09 21:25:10,193:INFO:Initializing plot_model()
2025-10-09 21:25:10,193:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EBBCE1EBD0>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), plot=auc, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-09 21:25:10,193:INFO:Checking exceptions
2025-10-09 21:25:12,394:INFO:Initializing plot_model()
2025-10-09 21:25:12,394:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EBBCE1EBD0>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), plot=feature_all, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-09 21:25:12,394:INFO:Checking exceptions
2025-10-09 21:25:12,398:INFO:Preloading libraries
2025-10-09 21:25:12,398:INFO:Copying training dataset
2025-10-09 21:25:12,398:INFO:Plot type: feature_all
2025-10-09 21:25:12,637:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\_tight_bbox.py:67: RuntimeWarning: divide by zero encountered in scalar divide
  fig.patch.set_bounds(x0 / w1, y0 / h1,

2025-10-09 21:25:12,637:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\_tight_bbox.py:68: RuntimeWarning: divide by zero encountered in scalar divide
  fig.bbox.width / w1, fig.bbox.height / h1)

2025-10-09 21:25:12,638:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\patches.py:739: RuntimeWarning: invalid value encountered in scalar add
  y1 = self.convert_yunits(self._y0 + self._height)

2025-10-09 21:25:12,639:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\transforms.py:2050: RuntimeWarning: invalid value encountered in scalar add
  self._mtx[1, 2] += ty

2025-10-09 21:25:12,673:INFO:Visual Rendered Successfully
2025-10-09 21:25:12,764:INFO:plot_model() successfully completed......................................
2025-10-09 21:25:13,981:INFO:Initializing plot_model()
2025-10-09 21:25:13,982:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EBBCE1EBD0>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), plot=feature, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-09 21:25:13,982:INFO:Checking exceptions
2025-10-09 21:25:13,983:INFO:Preloading libraries
2025-10-09 21:25:13,983:INFO:Copying training dataset
2025-10-09 21:25:13,985:INFO:Plot type: feature
2025-10-09 21:25:14,203:INFO:Visual Rendered Successfully
2025-10-09 21:25:14,293:INFO:plot_model() successfully completed......................................
2025-10-09 21:28:32,003:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-09 21:28:32,003:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-09 21:28:32,003:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-09 21:28:32,004:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-09 21:28:33,285:INFO:PyCaret ClassificationExperiment
2025-10-09 21:28:33,285:INFO:Logging name: clf-default-name
2025-10-09 21:28:33,285:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-10-09 21:28:33,285:INFO:version 3.3.2
2025-10-09 21:28:33,285:INFO:Initializing setup()
2025-10-09 21:28:33,285:INFO:self.USI: 7446
2025-10-09 21:28:33,286:INFO:self._variable_keys: {'memory', 'gpu_param', 'gpu_n_jobs_param', 'fix_imbalance', '_ml_usecase', 'log_plots_param', 'html_param', 'data', 'y_train', 'target_param', 'exp_name_log', 'USI', 'seed', 'X_test', 'fold_groups_param', 'y', 'logging_param', 'idx', 'X', 'fold_generator', 'n_jobs_param', '_available_plots', 'fold_shuffle_param', 'pipeline', 'y_test', 'X_train', 'exp_id', 'is_multiclass'}
2025-10-09 21:28:33,286:INFO:Checking environment
2025-10-09 21:28:33,286:INFO:python_version: 3.11.0
2025-10-09 21:28:33,286:INFO:python_build: ('main', 'Oct 24 2022 18:26:48')
2025-10-09 21:28:33,286:INFO:machine: AMD64
2025-10-09 21:28:33,286:INFO:platform: Windows-10-10.0.26100-SP0
2025-10-09 21:28:33,291:INFO:Memory: svmem(total=34211835904, available=18484432896, percent=46.0, used=15727403008, free=18484432896)
2025-10-09 21:28:33,293:INFO:Physical Core: 6
2025-10-09 21:28:33,293:INFO:Logical Core: 12
2025-10-09 21:28:33,293:INFO:Checking libraries
2025-10-09 21:28:33,293:INFO:System:
2025-10-09 21:28:33,293:INFO:    python: 3.11.0 (main, Oct 24 2022, 18:26:48) [MSC v.1933 64 bit (AMD64)]
2025-10-09 21:28:33,293:INFO:executable: c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\python.exe
2025-10-09 21:28:33,293:INFO:   machine: Windows-10-10.0.26100-SP0
2025-10-09 21:28:33,293:INFO:PyCaret required dependencies:
2025-10-09 21:28:33,351:INFO:                 pip: 22.3
2025-10-09 21:28:33,351:INFO:          setuptools: 65.5.0
2025-10-09 21:28:33,351:INFO:             pycaret: 3.3.2
2025-10-09 21:28:33,351:INFO:             IPython: 9.6.0
2025-10-09 21:28:33,351:INFO:          ipywidgets: 8.1.7
2025-10-09 21:28:33,351:INFO:                tqdm: 4.67.1
2025-10-09 21:28:33,351:INFO:               numpy: 1.26.4
2025-10-09 21:28:33,351:INFO:              pandas: 2.1.4
2025-10-09 21:28:33,351:INFO:              jinja2: 3.1.6
2025-10-09 21:28:33,351:INFO:               scipy: 1.11.4
2025-10-09 21:28:33,351:INFO:              joblib: 1.3.2
2025-10-09 21:28:33,353:INFO:             sklearn: 1.4.2
2025-10-09 21:28:33,353:INFO:                pyod: 2.0.5
2025-10-09 21:28:33,353:INFO:            imblearn: 0.14.0
2025-10-09 21:28:33,353:INFO:   category_encoders: 2.7.0
2025-10-09 21:28:33,353:INFO:            lightgbm: 4.6.0
2025-10-09 21:28:33,353:INFO:               numba: 0.62.1
2025-10-09 21:28:33,353:INFO:            requests: 2.32.5
2025-10-09 21:28:33,353:INFO:          matplotlib: 3.7.5
2025-10-09 21:28:33,353:INFO:          scikitplot: 0.3.7
2025-10-09 21:28:33,353:INFO:         yellowbrick: 1.5
2025-10-09 21:28:33,353:INFO:              plotly: 6.3.1
2025-10-09 21:28:33,353:INFO:    plotly-resampler: Not installed
2025-10-09 21:28:33,353:INFO:             kaleido: 1.1.0
2025-10-09 21:28:33,353:INFO:           schemdraw: 0.15
2025-10-09 21:28:33,353:INFO:         statsmodels: 0.14.5
2025-10-09 21:28:33,353:INFO:              sktime: 0.26.0
2025-10-09 21:28:33,353:INFO:               tbats: 1.1.3
2025-10-09 21:28:33,353:INFO:            pmdarima: 2.0.4
2025-10-09 21:28:33,353:INFO:              psutil: 7.1.0
2025-10-09 21:28:33,354:INFO:          markupsafe: 3.0.3
2025-10-09 21:28:33,354:INFO:             pickle5: Not installed
2025-10-09 21:28:33,354:INFO:         cloudpickle: 3.1.1
2025-10-09 21:28:33,354:INFO:         deprecation: 2.1.0
2025-10-09 21:28:33,354:INFO:              xxhash: 3.6.0
2025-10-09 21:28:33,354:INFO:           wurlitzer: Not installed
2025-10-09 21:28:33,354:INFO:PyCaret optional dependencies:
2025-10-09 21:28:33,395:INFO:                shap: Not installed
2025-10-09 21:28:33,396:INFO:           interpret: Not installed
2025-10-09 21:28:33,396:INFO:                umap: Not installed
2025-10-09 21:28:33,396:INFO:     ydata_profiling: Not installed
2025-10-09 21:28:33,396:INFO:  explainerdashboard: Not installed
2025-10-09 21:28:33,396:INFO:             autoviz: Not installed
2025-10-09 21:28:33,396:INFO:           fairlearn: Not installed
2025-10-09 21:28:33,396:INFO:          deepchecks: Not installed
2025-10-09 21:28:33,396:INFO:             xgboost: Not installed
2025-10-09 21:28:33,396:INFO:            catboost: Not installed
2025-10-09 21:28:33,397:INFO:              kmodes: Not installed
2025-10-09 21:28:33,397:INFO:             mlxtend: Not installed
2025-10-09 21:28:33,397:INFO:       statsforecast: Not installed
2025-10-09 21:28:33,397:INFO:        tune_sklearn: Not installed
2025-10-09 21:28:33,397:INFO:                 ray: Not installed
2025-10-09 21:28:33,397:INFO:            hyperopt: Not installed
2025-10-09 21:28:33,397:INFO:              optuna: Not installed
2025-10-09 21:28:33,397:INFO:               skopt: Not installed
2025-10-09 21:28:33,398:INFO:              mlflow: Not installed
2025-10-09 21:28:33,398:INFO:              gradio: Not installed
2025-10-09 21:28:33,398:INFO:             fastapi: Not installed
2025-10-09 21:28:33,398:INFO:             uvicorn: Not installed
2025-10-09 21:28:33,398:INFO:              m2cgen: Not installed
2025-10-09 21:28:33,398:INFO:           evidently: Not installed
2025-10-09 21:28:33,398:INFO:               fugue: Not installed
2025-10-09 21:28:33,398:INFO:           streamlit: Not installed
2025-10-09 21:28:33,398:INFO:             prophet: Not installed
2025-10-09 21:28:33,398:INFO:None
2025-10-09 21:28:33,398:INFO:Set up data.
2025-10-09 21:28:33,410:INFO:Set up folding strategy.
2025-10-09 21:28:33,411:INFO:Set up train/test split.
2025-10-09 21:28:33,422:INFO:Set up index.
2025-10-09 21:28:33,423:INFO:Assigning column types.
2025-10-09 21:28:33,427:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-09 21:28:33,508:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-09 21:28:33,514:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-09 21:28:33,592:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 21:28:33,592:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 21:28:33,697:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-09 21:28:33,698:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-09 21:28:33,730:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 21:28:33,730:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 21:28:33,731:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-09 21:28:33,781:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-09 21:28:33,815:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 21:28:33,815:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 21:28:33,869:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-09 21:28:33,903:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 21:28:33,904:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 21:28:33,904:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-10-09 21:28:33,988:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 21:28:33,988:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 21:28:34,070:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 21:28:34,071:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 21:28:34,072:INFO:Preparing preprocessing pipeline...
2025-10-09 21:28:34,073:INFO:Set up simple imputation.
2025-10-09 21:28:34,074:INFO:Set up encoding of ordinal features.
2025-10-09 21:28:34,077:INFO:Set up encoding of categorical features.
2025-10-09 21:28:34,077:INFO:Set up imbalanced handling.
2025-10-09 21:28:34,077:INFO:Set up feature normalization.
2025-10-09 21:28:34,188:INFO:Finished creating preprocessing pipeline.
2025-10-09 21:28:34,216:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\ARNALDO\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'meses_como_cliente',
                                             'frecuencia_uso',
                                             'soporte_llamadas'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),...
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=123,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2025-10-09 21:28:34,216:INFO:Creating final display dataframe.
2025-10-09 21:28:34,688:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target             churn
2                   Target type            Binary
3           Original data shape          (300, 7)
4        Transformed data shape          (400, 9)
5   Transformed train set shape          (310, 9)
6    Transformed test set shape           (90, 9)
7              Numeric features                 4
8          Categorical features                 2
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                Fix imbalance              True
16         Fix imbalance method             SMOTE
17                    Normalize              True
18             Normalize method            zscore
19               Fold Generator   StratifiedKFold
20                  Fold Number                10
21                     CPU Jobs                -1
22                      Use GPU             False
23               Log Experiment             False
24              Experiment Name  clf-default-name
25                          USI              7446
2025-10-09 21:28:34,814:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 21:28:34,815:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 21:28:34,900:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 21:28:34,900:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 21:28:34,901:INFO:setup() successfully completed in 1.62s...............
2025-10-09 21:28:34,912:INFO:Initializing compare_models()
2025-10-09 21:28:34,913:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000216631CFBD0>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000216631CFBD0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-10-09 21:28:34,913:INFO:Checking exceptions
2025-10-09 21:28:34,919:INFO:Preparing display monitor
2025-10-09 21:28:34,961:INFO:Initializing Logistic Regression
2025-10-09 21:28:34,962:INFO:Total runtime is 0.0 minutes
2025-10-09 21:28:34,969:INFO:SubProcess create_model() called ==================================
2025-10-09 21:28:34,969:INFO:Initializing create_model()
2025-10-09 21:28:34,969:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000216631CFBD0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021663962CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 21:28:34,969:INFO:Checking exceptions
2025-10-09 21:28:34,969:INFO:Importing libraries
2025-10-09 21:28:34,969:INFO:Copying training dataset
2025-10-09 21:28:34,981:INFO:Defining folds
2025-10-09 21:28:34,982:INFO:Declaring metric variables
2025-10-09 21:28:34,990:INFO:Importing untrained model
2025-10-09 21:28:34,999:INFO:Logistic Regression Imported successfully
2025-10-09 21:28:35,014:INFO:Starting cross validation
2025-10-09 21:28:35,129:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 21:28:45,885:INFO:Calculating mean and std
2025-10-09 21:28:45,887:INFO:Creating metrics dataframe
2025-10-09 21:28:45,891:INFO:Uploading results into container
2025-10-09 21:28:45,891:INFO:Uploading model into container now
2025-10-09 21:28:45,893:INFO:_master_model_container: 1
2025-10-09 21:28:45,893:INFO:_display_container: 2
2025-10-09 21:28:45,894:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-09 21:28:45,894:INFO:create_model() successfully completed......................................
2025-10-09 21:28:46,037:INFO:SubProcess create_model() end ==================================
2025-10-09 21:28:46,037:INFO:Creating metrics dataframe
2025-10-09 21:28:46,046:INFO:Initializing K Neighbors Classifier
2025-10-09 21:28:46,046:INFO:Total runtime is 0.18475120067596434 minutes
2025-10-09 21:28:46,050:INFO:SubProcess create_model() called ==================================
2025-10-09 21:28:46,051:INFO:Initializing create_model()
2025-10-09 21:28:46,051:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000216631CFBD0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021663962CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 21:28:46,051:INFO:Checking exceptions
2025-10-09 21:28:46,051:INFO:Importing libraries
2025-10-09 21:28:46,051:INFO:Copying training dataset
2025-10-09 21:28:46,061:INFO:Defining folds
2025-10-09 21:28:46,062:INFO:Declaring metric variables
2025-10-09 21:28:46,068:INFO:Importing untrained model
2025-10-09 21:28:46,073:INFO:K Neighbors Classifier Imported successfully
2025-10-09 21:28:46,084:INFO:Starting cross validation
2025-10-09 21:28:46,087:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 21:28:51,113:INFO:Calculating mean and std
2025-10-09 21:28:51,118:INFO:Creating metrics dataframe
2025-10-09 21:28:51,121:INFO:Uploading results into container
2025-10-09 21:28:51,122:INFO:Uploading model into container now
2025-10-09 21:28:51,123:INFO:_master_model_container: 2
2025-10-09 21:28:51,123:INFO:_display_container: 2
2025-10-09 21:28:51,124:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-10-09 21:28:51,124:INFO:create_model() successfully completed......................................
2025-10-09 21:28:51,257:INFO:SubProcess create_model() end ==================================
2025-10-09 21:28:51,257:INFO:Creating metrics dataframe
2025-10-09 21:28:51,266:INFO:Initializing Naive Bayes
2025-10-09 21:28:51,266:INFO:Total runtime is 0.2717532237370809 minutes
2025-10-09 21:28:51,271:INFO:SubProcess create_model() called ==================================
2025-10-09 21:28:51,273:INFO:Initializing create_model()
2025-10-09 21:28:51,273:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000216631CFBD0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021663962CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 21:28:51,273:INFO:Checking exceptions
2025-10-09 21:28:51,273:INFO:Importing libraries
2025-10-09 21:28:51,273:INFO:Copying training dataset
2025-10-09 21:28:51,280:INFO:Defining folds
2025-10-09 21:28:51,280:INFO:Declaring metric variables
2025-10-09 21:28:51,283:INFO:Importing untrained model
2025-10-09 21:28:51,293:INFO:Naive Bayes Imported successfully
2025-10-09 21:28:51,302:INFO:Starting cross validation
2025-10-09 21:28:51,304:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 21:28:51,641:INFO:Calculating mean and std
2025-10-09 21:28:51,643:INFO:Creating metrics dataframe
2025-10-09 21:28:51,645:INFO:Uploading results into container
2025-10-09 21:28:51,646:INFO:Uploading model into container now
2025-10-09 21:28:51,646:INFO:_master_model_container: 3
2025-10-09 21:28:51,646:INFO:_display_container: 2
2025-10-09 21:28:51,647:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-10-09 21:28:51,647:INFO:create_model() successfully completed......................................
2025-10-09 21:28:51,762:INFO:SubProcess create_model() end ==================================
2025-10-09 21:28:51,762:INFO:Creating metrics dataframe
2025-10-09 21:28:51,773:INFO:Initializing Decision Tree Classifier
2025-10-09 21:28:51,774:INFO:Total runtime is 0.28021050691604615 minutes
2025-10-09 21:28:51,778:INFO:SubProcess create_model() called ==================================
2025-10-09 21:28:51,778:INFO:Initializing create_model()
2025-10-09 21:28:51,778:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000216631CFBD0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021663962CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 21:28:51,779:INFO:Checking exceptions
2025-10-09 21:28:51,779:INFO:Importing libraries
2025-10-09 21:28:51,779:INFO:Copying training dataset
2025-10-09 21:28:51,786:INFO:Defining folds
2025-10-09 21:28:51,786:INFO:Declaring metric variables
2025-10-09 21:28:51,791:INFO:Importing untrained model
2025-10-09 21:28:51,798:INFO:Decision Tree Classifier Imported successfully
2025-10-09 21:28:51,808:INFO:Starting cross validation
2025-10-09 21:28:51,814:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 21:28:52,084:INFO:Calculating mean and std
2025-10-09 21:28:52,085:INFO:Creating metrics dataframe
2025-10-09 21:28:52,088:INFO:Uploading results into container
2025-10-09 21:28:52,089:INFO:Uploading model into container now
2025-10-09 21:28:52,089:INFO:_master_model_container: 4
2025-10-09 21:28:52,089:INFO:_display_container: 2
2025-10-09 21:28:52,090:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-10-09 21:28:52,090:INFO:create_model() successfully completed......................................
2025-10-09 21:28:52,203:INFO:SubProcess create_model() end ==================================
2025-10-09 21:28:52,203:INFO:Creating metrics dataframe
2025-10-09 21:28:52,214:INFO:Initializing SVM - Linear Kernel
2025-10-09 21:28:52,216:INFO:Total runtime is 0.2875822146733602 minutes
2025-10-09 21:28:52,221:INFO:SubProcess create_model() called ==================================
2025-10-09 21:28:52,221:INFO:Initializing create_model()
2025-10-09 21:28:52,221:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000216631CFBD0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021663962CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 21:28:52,221:INFO:Checking exceptions
2025-10-09 21:28:52,221:INFO:Importing libraries
2025-10-09 21:28:52,221:INFO:Copying training dataset
2025-10-09 21:28:52,231:INFO:Defining folds
2025-10-09 21:28:52,231:INFO:Declaring metric variables
2025-10-09 21:28:52,239:INFO:Importing untrained model
2025-10-09 21:28:52,244:INFO:SVM - Linear Kernel Imported successfully
2025-10-09 21:28:52,256:INFO:Starting cross validation
2025-10-09 21:28:52,259:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 21:28:52,527:INFO:Calculating mean and std
2025-10-09 21:28:52,528:INFO:Creating metrics dataframe
2025-10-09 21:28:52,531:INFO:Uploading results into container
2025-10-09 21:28:52,531:INFO:Uploading model into container now
2025-10-09 21:28:52,534:INFO:_master_model_container: 5
2025-10-09 21:28:52,534:INFO:_display_container: 2
2025-10-09 21:28:52,535:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-10-09 21:28:52,535:INFO:create_model() successfully completed......................................
2025-10-09 21:28:52,651:INFO:SubProcess create_model() end ==================================
2025-10-09 21:28:52,651:INFO:Creating metrics dataframe
2025-10-09 21:28:52,661:INFO:Initializing Ridge Classifier
2025-10-09 21:28:52,663:INFO:Total runtime is 0.2950312693913778 minutes
2025-10-09 21:28:52,668:INFO:SubProcess create_model() called ==================================
2025-10-09 21:28:52,669:INFO:Initializing create_model()
2025-10-09 21:28:52,669:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000216631CFBD0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021663962CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 21:28:52,669:INFO:Checking exceptions
2025-10-09 21:28:52,669:INFO:Importing libraries
2025-10-09 21:28:52,669:INFO:Copying training dataset
2025-10-09 21:28:52,681:INFO:Defining folds
2025-10-09 21:28:52,681:INFO:Declaring metric variables
2025-10-09 21:28:52,684:INFO:Importing untrained model
2025-10-09 21:28:52,691:INFO:Ridge Classifier Imported successfully
2025-10-09 21:28:52,701:INFO:Starting cross validation
2025-10-09 21:28:52,706:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 21:28:52,987:INFO:Calculating mean and std
2025-10-09 21:28:52,988:INFO:Creating metrics dataframe
2025-10-09 21:28:52,991:INFO:Uploading results into container
2025-10-09 21:28:52,991:INFO:Uploading model into container now
2025-10-09 21:28:52,992:INFO:_master_model_container: 6
2025-10-09 21:28:52,992:INFO:_display_container: 2
2025-10-09 21:28:52,993:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-10-09 21:28:52,993:INFO:create_model() successfully completed......................................
2025-10-09 21:28:53,109:INFO:SubProcess create_model() end ==================================
2025-10-09 21:28:53,109:INFO:Creating metrics dataframe
2025-10-09 21:28:53,120:INFO:Initializing Random Forest Classifier
2025-10-09 21:28:53,120:INFO:Total runtime is 0.3026464899381002 minutes
2025-10-09 21:28:53,129:INFO:SubProcess create_model() called ==================================
2025-10-09 21:28:53,129:INFO:Initializing create_model()
2025-10-09 21:28:53,129:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000216631CFBD0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021663962CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 21:28:53,129:INFO:Checking exceptions
2025-10-09 21:28:53,130:INFO:Importing libraries
2025-10-09 21:28:53,130:INFO:Copying training dataset
2025-10-09 21:28:53,137:INFO:Defining folds
2025-10-09 21:28:53,137:INFO:Declaring metric variables
2025-10-09 21:28:53,141:INFO:Importing untrained model
2025-10-09 21:28:53,147:INFO:Random Forest Classifier Imported successfully
2025-10-09 21:28:53,156:INFO:Starting cross validation
2025-10-09 21:28:53,158:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 21:28:53,999:INFO:Calculating mean and std
2025-10-09 21:28:53,999:INFO:Creating metrics dataframe
2025-10-09 21:28:54,001:INFO:Uploading results into container
2025-10-09 21:28:54,003:INFO:Uploading model into container now
2025-10-09 21:28:54,004:INFO:_master_model_container: 7
2025-10-09 21:28:54,004:INFO:_display_container: 2
2025-10-09 21:28:54,004:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-10-09 21:28:54,005:INFO:create_model() successfully completed......................................
2025-10-09 21:28:54,120:INFO:SubProcess create_model() end ==================================
2025-10-09 21:28:54,120:INFO:Creating metrics dataframe
2025-10-09 21:28:54,132:INFO:Initializing Quadratic Discriminant Analysis
2025-10-09 21:28:54,132:INFO:Total runtime is 0.31951412757237757 minutes
2025-10-09 21:28:54,136:INFO:SubProcess create_model() called ==================================
2025-10-09 21:28:54,137:INFO:Initializing create_model()
2025-10-09 21:28:54,138:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000216631CFBD0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021663962CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 21:28:54,138:INFO:Checking exceptions
2025-10-09 21:28:54,138:INFO:Importing libraries
2025-10-09 21:28:54,138:INFO:Copying training dataset
2025-10-09 21:28:54,144:INFO:Defining folds
2025-10-09 21:28:54,146:INFO:Declaring metric variables
2025-10-09 21:28:54,151:INFO:Importing untrained model
2025-10-09 21:28:54,156:INFO:Quadratic Discriminant Analysis Imported successfully
2025-10-09 21:28:54,171:INFO:Starting cross validation
2025-10-09 21:28:54,177:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 21:28:54,336:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 21:28:54,339:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 21:28:54,343:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 21:28:54,344:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 21:28:54,344:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 21:28:54,347:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 21:28:54,349:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 21:28:54,363:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 21:28:54,368:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 21:28:54,373:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 21:28:54,464:INFO:Calculating mean and std
2025-10-09 21:28:54,467:INFO:Creating metrics dataframe
2025-10-09 21:28:54,469:INFO:Uploading results into container
2025-10-09 21:28:54,471:INFO:Uploading model into container now
2025-10-09 21:28:54,471:INFO:_master_model_container: 8
2025-10-09 21:28:54,472:INFO:_display_container: 2
2025-10-09 21:28:54,472:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-10-09 21:28:54,472:INFO:create_model() successfully completed......................................
2025-10-09 21:28:54,588:INFO:SubProcess create_model() end ==================================
2025-10-09 21:28:54,588:INFO:Creating metrics dataframe
2025-10-09 21:28:54,598:INFO:Initializing Ada Boost Classifier
2025-10-09 21:28:54,598:INFO:Total runtime is 0.3272874315579733 minutes
2025-10-09 21:28:54,603:INFO:SubProcess create_model() called ==================================
2025-10-09 21:28:54,603:INFO:Initializing create_model()
2025-10-09 21:28:54,603:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000216631CFBD0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021663962CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 21:28:54,603:INFO:Checking exceptions
2025-10-09 21:28:54,603:INFO:Importing libraries
2025-10-09 21:28:54,604:INFO:Copying training dataset
2025-10-09 21:28:54,611:INFO:Defining folds
2025-10-09 21:28:54,612:INFO:Declaring metric variables
2025-10-09 21:28:54,618:INFO:Importing untrained model
2025-10-09 21:28:54,623:INFO:Ada Boost Classifier Imported successfully
2025-10-09 21:28:54,634:INFO:Starting cross validation
2025-10-09 21:28:54,638:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 21:28:54,809:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 21:28:54,811:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 21:28:54,812:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 21:28:54,816:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 21:28:54,821:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 21:28:54,823:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 21:28:54,829:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 21:28:54,835:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 21:28:54,841:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 21:28:55,181:INFO:Calculating mean and std
2025-10-09 21:28:55,181:INFO:Creating metrics dataframe
2025-10-09 21:28:55,186:INFO:Uploading results into container
2025-10-09 21:28:55,187:INFO:Uploading model into container now
2025-10-09 21:28:55,187:INFO:_master_model_container: 9
2025-10-09 21:28:55,187:INFO:_display_container: 2
2025-10-09 21:28:55,188:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-10-09 21:28:55,188:INFO:create_model() successfully completed......................................
2025-10-09 21:28:55,310:INFO:SubProcess create_model() end ==================================
2025-10-09 21:28:55,310:INFO:Creating metrics dataframe
2025-10-09 21:28:55,329:INFO:Initializing Gradient Boosting Classifier
2025-10-09 21:28:55,330:INFO:Total runtime is 0.33947948614756274 minutes
2025-10-09 21:28:55,334:INFO:SubProcess create_model() called ==================================
2025-10-09 21:28:55,334:INFO:Initializing create_model()
2025-10-09 21:28:55,334:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000216631CFBD0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021663962CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 21:28:55,334:INFO:Checking exceptions
2025-10-09 21:28:55,334:INFO:Importing libraries
2025-10-09 21:28:55,334:INFO:Copying training dataset
2025-10-09 21:28:55,342:INFO:Defining folds
2025-10-09 21:28:55,342:INFO:Declaring metric variables
2025-10-09 21:28:55,353:INFO:Importing untrained model
2025-10-09 21:28:55,362:INFO:Gradient Boosting Classifier Imported successfully
2025-10-09 21:28:55,379:INFO:Starting cross validation
2025-10-09 21:28:55,381:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 21:28:56,043:INFO:Calculating mean and std
2025-10-09 21:28:56,044:INFO:Creating metrics dataframe
2025-10-09 21:28:56,047:INFO:Uploading results into container
2025-10-09 21:28:56,048:INFO:Uploading model into container now
2025-10-09 21:28:56,049:INFO:_master_model_container: 10
2025-10-09 21:28:56,049:INFO:_display_container: 2
2025-10-09 21:28:56,050:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-09 21:28:56,050:INFO:create_model() successfully completed......................................
2025-10-09 21:28:56,172:INFO:SubProcess create_model() end ==================================
2025-10-09 21:28:56,172:INFO:Creating metrics dataframe
2025-10-09 21:28:56,186:INFO:Initializing Linear Discriminant Analysis
2025-10-09 21:28:56,186:INFO:Total runtime is 0.35375213225682584 minutes
2025-10-09 21:28:56,190:INFO:SubProcess create_model() called ==================================
2025-10-09 21:28:56,191:INFO:Initializing create_model()
2025-10-09 21:28:56,193:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000216631CFBD0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021663962CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 21:28:56,193:INFO:Checking exceptions
2025-10-09 21:28:56,193:INFO:Importing libraries
2025-10-09 21:28:56,193:INFO:Copying training dataset
2025-10-09 21:28:56,199:INFO:Defining folds
2025-10-09 21:28:56,200:INFO:Declaring metric variables
2025-10-09 21:28:56,209:INFO:Importing untrained model
2025-10-09 21:28:56,213:INFO:Linear Discriminant Analysis Imported successfully
2025-10-09 21:28:56,229:INFO:Starting cross validation
2025-10-09 21:28:56,233:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 21:28:56,524:INFO:Calculating mean and std
2025-10-09 21:28:56,530:INFO:Creating metrics dataframe
2025-10-09 21:28:56,537:INFO:Uploading results into container
2025-10-09 21:28:56,538:INFO:Uploading model into container now
2025-10-09 21:28:56,539:INFO:_master_model_container: 11
2025-10-09 21:28:56,539:INFO:_display_container: 2
2025-10-09 21:28:56,539:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-09 21:28:56,539:INFO:create_model() successfully completed......................................
2025-10-09 21:28:56,675:INFO:SubProcess create_model() end ==================================
2025-10-09 21:28:56,676:INFO:Creating metrics dataframe
2025-10-09 21:28:56,689:INFO:Initializing Extra Trees Classifier
2025-10-09 21:28:56,689:INFO:Total runtime is 0.36213541030883795 minutes
2025-10-09 21:28:56,696:INFO:SubProcess create_model() called ==================================
2025-10-09 21:28:56,697:INFO:Initializing create_model()
2025-10-09 21:28:56,697:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000216631CFBD0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021663962CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 21:28:56,698:INFO:Checking exceptions
2025-10-09 21:28:56,698:INFO:Importing libraries
2025-10-09 21:28:56,698:INFO:Copying training dataset
2025-10-09 21:28:56,705:INFO:Defining folds
2025-10-09 21:28:56,706:INFO:Declaring metric variables
2025-10-09 21:28:56,711:INFO:Importing untrained model
2025-10-09 21:28:56,716:INFO:Extra Trees Classifier Imported successfully
2025-10-09 21:28:56,729:INFO:Starting cross validation
2025-10-09 21:28:56,733:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 21:28:57,630:INFO:Calculating mean and std
2025-10-09 21:28:57,631:INFO:Creating metrics dataframe
2025-10-09 21:28:57,634:INFO:Uploading results into container
2025-10-09 21:28:57,634:INFO:Uploading model into container now
2025-10-09 21:28:57,634:INFO:_master_model_container: 12
2025-10-09 21:28:57,634:INFO:_display_container: 2
2025-10-09 21:28:57,637:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-10-09 21:28:57,638:INFO:create_model() successfully completed......................................
2025-10-09 21:28:57,756:INFO:SubProcess create_model() end ==================================
2025-10-09 21:28:57,756:INFO:Creating metrics dataframe
2025-10-09 21:28:57,774:INFO:Initializing Light Gradient Boosting Machine
2025-10-09 21:28:57,775:INFO:Total runtime is 0.3802271723747254 minutes
2025-10-09 21:28:57,781:INFO:SubProcess create_model() called ==================================
2025-10-09 21:28:57,783:INFO:Initializing create_model()
2025-10-09 21:28:57,783:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000216631CFBD0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021663962CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 21:28:57,783:INFO:Checking exceptions
2025-10-09 21:28:57,784:INFO:Importing libraries
2025-10-09 21:28:57,784:INFO:Copying training dataset
2025-10-09 21:28:57,793:INFO:Defining folds
2025-10-09 21:28:57,793:INFO:Declaring metric variables
2025-10-09 21:28:57,798:INFO:Importing untrained model
2025-10-09 21:28:57,805:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-09 21:28:57,819:INFO:Starting cross validation
2025-10-09 21:28:57,823:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 21:28:59,038:INFO:Calculating mean and std
2025-10-09 21:28:59,041:INFO:Creating metrics dataframe
2025-10-09 21:28:59,046:INFO:Uploading results into container
2025-10-09 21:28:59,047:INFO:Uploading model into container now
2025-10-09 21:28:59,048:INFO:_master_model_container: 13
2025-10-09 21:28:59,048:INFO:_display_container: 2
2025-10-09 21:28:59,051:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-09 21:28:59,051:INFO:create_model() successfully completed......................................
2025-10-09 21:28:59,187:INFO:SubProcess create_model() end ==================================
2025-10-09 21:28:59,187:INFO:Creating metrics dataframe
2025-10-09 21:28:59,201:INFO:Initializing Dummy Classifier
2025-10-09 21:28:59,202:INFO:Total runtime is 0.40401487350463877 minutes
2025-10-09 21:28:59,206:INFO:SubProcess create_model() called ==================================
2025-10-09 21:28:59,206:INFO:Initializing create_model()
2025-10-09 21:28:59,206:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000216631CFBD0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021663962CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 21:28:59,207:INFO:Checking exceptions
2025-10-09 21:28:59,207:INFO:Importing libraries
2025-10-09 21:28:59,207:INFO:Copying training dataset
2025-10-09 21:28:59,214:INFO:Defining folds
2025-10-09 21:28:59,214:INFO:Declaring metric variables
2025-10-09 21:28:59,218:INFO:Importing untrained model
2025-10-09 21:28:59,233:INFO:Dummy Classifier Imported successfully
2025-10-09 21:28:59,244:INFO:Starting cross validation
2025-10-09 21:28:59,248:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 21:28:59,487:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 21:28:59,511:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 21:28:59,513:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 21:28:59,514:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 21:28:59,517:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 21:28:59,523:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 21:28:59,524:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 21:28:59,528:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 21:28:59,530:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 21:28:59,535:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 21:28:59,549:INFO:Calculating mean and std
2025-10-09 21:28:59,550:INFO:Creating metrics dataframe
2025-10-09 21:28:59,554:INFO:Uploading results into container
2025-10-09 21:28:59,556:INFO:Uploading model into container now
2025-10-09 21:28:59,557:INFO:_master_model_container: 14
2025-10-09 21:28:59,557:INFO:_display_container: 2
2025-10-09 21:28:59,557:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-10-09 21:28:59,558:INFO:create_model() successfully completed......................................
2025-10-09 21:28:59,673:INFO:SubProcess create_model() end ==================================
2025-10-09 21:28:59,673:INFO:Creating metrics dataframe
2025-10-09 21:28:59,693:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-10-09 21:28:59,708:INFO:Initializing create_model()
2025-10-09 21:28:59,708:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000216631CFBD0>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 21:28:59,708:INFO:Checking exceptions
2025-10-09 21:28:59,710:INFO:Importing libraries
2025-10-09 21:28:59,710:INFO:Copying training dataset
2025-10-09 21:28:59,714:INFO:Defining folds
2025-10-09 21:28:59,714:INFO:Declaring metric variables
2025-10-09 21:28:59,715:INFO:Importing untrained model
2025-10-09 21:28:59,715:INFO:Declaring custom model
2025-10-09 21:28:59,715:INFO:Ridge Classifier Imported successfully
2025-10-09 21:28:59,718:INFO:Cross validation set to False
2025-10-09 21:28:59,718:INFO:Fitting Model
2025-10-09 21:28:59,862:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-10-09 21:28:59,862:INFO:create_model() successfully completed......................................
2025-10-09 21:29:00,052:INFO:_master_model_container: 14
2025-10-09 21:29:00,053:INFO:_display_container: 2
2025-10-09 21:29:00,053:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-10-09 21:29:00,053:INFO:compare_models() successfully completed......................................
2025-10-09 21:29:00,098:INFO:Initializing create_model()
2025-10-09 21:29:00,098:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000216631CFBD0>, estimator=ridge, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 21:29:00,098:INFO:Checking exceptions
2025-10-09 21:29:00,131:INFO:Importing libraries
2025-10-09 21:29:00,131:INFO:Copying training dataset
2025-10-09 21:29:00,144:INFO:Defining folds
2025-10-09 21:29:00,144:INFO:Declaring metric variables
2025-10-09 21:29:00,150:INFO:Importing untrained model
2025-10-09 21:29:00,158:INFO:Ridge Classifier Imported successfully
2025-10-09 21:29:00,174:INFO:Starting cross validation
2025-10-09 21:29:00,177:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 21:29:00,528:INFO:Calculating mean and std
2025-10-09 21:29:00,529:INFO:Creating metrics dataframe
2025-10-09 21:29:00,539:INFO:Finalizing model
2025-10-09 21:29:00,641:INFO:Uploading results into container
2025-10-09 21:29:00,644:INFO:Uploading model into container now
2025-10-09 21:29:00,663:INFO:_master_model_container: 15
2025-10-09 21:29:00,663:INFO:_display_container: 3
2025-10-09 21:29:00,664:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-10-09 21:29:00,664:INFO:create_model() successfully completed......................................
2025-10-09 21:29:00,828:INFO:Initializing tune_model()
2025-10-09 21:29:00,829:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000216631CFBD0>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-10-09 21:29:00,829:INFO:Checking exceptions
2025-10-09 21:29:00,875:INFO:Copying training dataset
2025-10-09 21:29:00,884:INFO:Checking base model
2025-10-09 21:29:00,887:INFO:Base model : Ridge Classifier
2025-10-09 21:29:00,903:INFO:Declaring metric variables
2025-10-09 21:29:00,915:INFO:Defining Hyperparameters
2025-10-09 21:29:01,088:INFO:Tuning with n_jobs=-1
2025-10-09 21:29:01,088:INFO:Initializing RandomizedSearchCV
2025-10-09 21:29:03,351:INFO:best_params: {'actual_estimator__fit_intercept': True, 'actual_estimator__alpha': 5.62}
2025-10-09 21:29:03,353:INFO:Hyperparameter search completed
2025-10-09 21:29:03,353:INFO:SubProcess create_model() called ==================================
2025-10-09 21:29:03,354:INFO:Initializing create_model()
2025-10-09 21:29:03,354:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000216631CFBD0>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002162EF92310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'fit_intercept': True, 'alpha': 5.62})
2025-10-09 21:29:03,354:INFO:Checking exceptions
2025-10-09 21:29:03,354:INFO:Importing libraries
2025-10-09 21:29:03,354:INFO:Copying training dataset
2025-10-09 21:29:03,359:INFO:Defining folds
2025-10-09 21:29:03,359:INFO:Declaring metric variables
2025-10-09 21:29:03,365:INFO:Importing untrained model
2025-10-09 21:29:03,366:INFO:Declaring custom model
2025-10-09 21:29:03,370:INFO:Ridge Classifier Imported successfully
2025-10-09 21:29:03,384:INFO:Starting cross validation
2025-10-09 21:29:03,387:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 21:29:03,673:INFO:Calculating mean and std
2025-10-09 21:29:03,674:INFO:Creating metrics dataframe
2025-10-09 21:29:03,681:INFO:Finalizing model
2025-10-09 21:29:03,748:INFO:Uploading results into container
2025-10-09 21:29:03,749:INFO:Uploading model into container now
2025-10-09 21:29:03,750:INFO:_master_model_container: 16
2025-10-09 21:29:03,750:INFO:_display_container: 4
2025-10-09 21:29:03,750:INFO:RidgeClassifier(alpha=5.62, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-10-09 21:29:03,750:INFO:create_model() successfully completed......................................
2025-10-09 21:29:03,864:INFO:SubProcess create_model() end ==================================
2025-10-09 21:29:03,864:INFO:choose_better activated
2025-10-09 21:29:03,869:INFO:SubProcess create_model() called ==================================
2025-10-09 21:29:03,870:INFO:Initializing create_model()
2025-10-09 21:29:03,870:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000216631CFBD0>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 21:29:03,870:INFO:Checking exceptions
2025-10-09 21:29:03,873:INFO:Importing libraries
2025-10-09 21:29:03,875:INFO:Copying training dataset
2025-10-09 21:29:03,884:INFO:Defining folds
2025-10-09 21:29:03,884:INFO:Declaring metric variables
2025-10-09 21:29:03,884:INFO:Importing untrained model
2025-10-09 21:29:03,884:INFO:Declaring custom model
2025-10-09 21:29:03,885:INFO:Ridge Classifier Imported successfully
2025-10-09 21:29:03,885:INFO:Starting cross validation
2025-10-09 21:29:03,887:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 21:29:04,153:INFO:Calculating mean and std
2025-10-09 21:29:04,154:INFO:Creating metrics dataframe
2025-10-09 21:29:04,155:INFO:Finalizing model
2025-10-09 21:29:04,218:INFO:Uploading results into container
2025-10-09 21:29:04,219:INFO:Uploading model into container now
2025-10-09 21:29:04,219:INFO:_master_model_container: 17
2025-10-09 21:29:04,219:INFO:_display_container: 5
2025-10-09 21:29:04,220:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-10-09 21:29:04,220:INFO:create_model() successfully completed......................................
2025-10-09 21:29:04,336:INFO:SubProcess create_model() end ==================================
2025-10-09 21:29:04,336:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001) result for Accuracy is 0.6429
2025-10-09 21:29:04,337:INFO:RidgeClassifier(alpha=5.62, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001) result for Accuracy is 0.6429
2025-10-09 21:29:04,337:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001) is best model
2025-10-09 21:29:04,338:INFO:choose_better completed
2025-10-09 21:29:04,338:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-10-09 21:29:04,354:INFO:_master_model_container: 17
2025-10-09 21:29:04,354:INFO:_display_container: 4
2025-10-09 21:29:04,356:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-10-09 21:29:04,356:INFO:tune_model() successfully completed......................................
2025-10-09 21:29:04,505:INFO:Initializing evaluate_model()
2025-10-09 21:29:04,506:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000216631CFBD0>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-10-09 21:29:04,523:INFO:Initializing plot_model()
2025-10-09 21:29:04,524:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000216631CFBD0>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-09 21:29:04,524:INFO:Checking exceptions
2025-10-09 21:29:04,529:INFO:Preloading libraries
2025-10-09 21:29:04,529:INFO:Copying training dataset
2025-10-09 21:29:04,529:INFO:Plot type: pipeline
2025-10-09 21:29:04,787:INFO:Visual Rendered Successfully
2025-10-09 21:29:04,905:INFO:plot_model() successfully completed......................................
2025-10-09 21:29:13,306:INFO:Initializing plot_model()
2025-10-09 21:29:13,306:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000216631CFBD0>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), plot=feature, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-09 21:29:13,306:INFO:Checking exceptions
2025-10-09 21:29:13,308:INFO:Preloading libraries
2025-10-09 21:29:13,308:INFO:Copying training dataset
2025-10-09 21:29:13,309:INFO:Plot type: feature
2025-10-09 21:29:13,509:INFO:Visual Rendered Successfully
2025-10-09 21:29:13,626:INFO:plot_model() successfully completed......................................
2025-10-09 21:30:32,105:INFO:Initializing plot_model()
2025-10-09 21:30:32,106:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000216631CFBD0>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), plot=feature_all, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-09 21:30:32,106:INFO:Checking exceptions
2025-10-09 21:30:32,111:INFO:Preloading libraries
2025-10-09 21:30:32,112:INFO:Copying training dataset
2025-10-09 21:30:32,112:INFO:Plot type: feature_all
2025-10-09 21:30:32,291:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\_tight_bbox.py:67: RuntimeWarning: divide by zero encountered in scalar divide
  fig.patch.set_bounds(x0 / w1, y0 / h1,

2025-10-09 21:30:32,291:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\_tight_bbox.py:68: RuntimeWarning: divide by zero encountered in scalar divide
  fig.bbox.width / w1, fig.bbox.height / h1)

2025-10-09 21:30:32,293:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\patches.py:739: RuntimeWarning: invalid value encountered in scalar add
  y1 = self.convert_yunits(self._y0 + self._height)

2025-10-09 21:30:32,293:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\transforms.py:2050: RuntimeWarning: invalid value encountered in scalar add
  self._mtx[1, 2] += ty

2025-10-09 21:30:32,339:INFO:Visual Rendered Successfully
2025-10-09 21:30:32,465:INFO:plot_model() successfully completed......................................
2025-10-09 21:30:35,088:INFO:Initializing plot_model()
2025-10-09 21:30:35,089:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000216631CFBD0>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), plot=feature, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-09 21:30:35,089:INFO:Checking exceptions
2025-10-09 21:30:35,093:INFO:Preloading libraries
2025-10-09 21:30:35,093:INFO:Copying training dataset
2025-10-09 21:30:35,093:INFO:Plot type: feature
2025-10-09 21:30:35,259:INFO:Visual Rendered Successfully
2025-10-09 21:30:35,469:INFO:plot_model() successfully completed......................................
2025-10-09 21:30:36,906:INFO:Initializing plot_model()
2025-10-09 21:30:36,906:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000216631CFBD0>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), plot=boundary, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-09 21:30:36,906:INFO:Checking exceptions
2025-10-09 21:30:36,910:INFO:Preloading libraries
2025-10-09 21:30:36,911:INFO:Copying training dataset
2025-10-09 21:30:36,911:INFO:Plot type: boundary
2025-10-09 21:30:37,001:INFO:Fitting StandardScaler()
2025-10-09 21:30:37,007:INFO:Fitting PCA()
2025-10-09 21:30:37,097:INFO:Fitting Model
2025-10-09 21:30:37,968:INFO:Visual Rendered Successfully
2025-10-09 21:30:38,168:INFO:plot_model() successfully completed......................................
2025-10-09 21:30:41,718:INFO:Initializing plot_model()
2025-10-09 21:30:41,719:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000216631CFBD0>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), plot=gain, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-09 21:30:41,719:INFO:Checking exceptions
2025-10-09 21:30:41,722:INFO:Preloading libraries
2025-10-09 21:30:41,722:INFO:Copying training dataset
2025-10-09 21:30:41,722:INFO:Plot type: gain
2025-10-09 21:30:41,723:INFO:Generating predictions / predict_proba on X_test
2025-10-09 21:30:43,373:INFO:Initializing plot_model()
2025-10-09 21:30:43,373:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000216631CFBD0>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), plot=tree, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-09 21:30:43,373:INFO:Checking exceptions
2025-10-09 21:30:44,649:INFO:Initializing plot_model()
2025-10-09 21:30:44,650:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000216631CFBD0>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), plot=ks, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-09 21:30:44,650:INFO:Checking exceptions
2025-10-09 21:30:44,653:INFO:Preloading libraries
2025-10-09 21:30:44,653:INFO:Copying training dataset
2025-10-09 21:30:44,654:INFO:Plot type: ks
2025-10-09 21:30:44,654:INFO:Generating predictions / predict_proba on X_test
2025-10-09 21:30:45,568:INFO:Initializing plot_model()
2025-10-09 21:30:45,568:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000216631CFBD0>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), plot=dimension, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-09 21:30:45,568:INFO:Checking exceptions
2025-10-09 21:30:45,570:INFO:Preloading libraries
2025-10-09 21:30:45,571:INFO:Copying training dataset
2025-10-09 21:30:45,571:INFO:Plot type: dimension
2025-10-09 21:30:45,618:INFO:Fitting StandardScaler()
2025-10-09 21:30:45,632:INFO:Fitting PCA()
2025-10-09 21:30:45,736:INFO:Fitting & Transforming Model
2025-10-09 21:30:45,839:INFO:Visual Rendered Successfully
2025-10-09 21:30:45,987:INFO:plot_model() successfully completed......................................
2025-10-09 21:30:47,018:INFO:Initializing plot_model()
2025-10-09 21:30:47,019:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000216631CFBD0>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), plot=vc, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-09 21:30:47,019:INFO:Checking exceptions
2025-10-09 21:30:47,022:INFO:Preloading libraries
2025-10-09 21:30:47,023:INFO:Copying training dataset
2025-10-09 21:30:47,024:INFO:Plot type: vc
2025-10-09 21:30:47,024:INFO:Determining param_name
2025-10-09 21:30:47,024:INFO:param_name: alpha
2025-10-09 21:30:47,144:INFO:Fitting Model
2025-10-09 21:30:47,228:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=7.52765e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-10-09 21:30:47,588:INFO:Visual Rendered Successfully
2025-10-09 21:30:47,715:INFO:plot_model() successfully completed......................................
2025-10-09 21:30:48,568:INFO:Initializing plot_model()
2025-10-09 21:30:48,568:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000216631CFBD0>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), plot=calibration, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-09 21:30:48,569:INFO:Checking exceptions
2025-10-09 21:30:49,391:INFO:Initializing plot_model()
2025-10-09 21:30:49,391:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000216631CFBD0>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), plot=manifold, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-09 21:30:49,391:INFO:Checking exceptions
2025-10-09 21:30:49,395:INFO:Preloading libraries
2025-10-09 21:30:49,395:INFO:Copying training dataset
2025-10-09 21:30:49,395:INFO:Plot type: manifold
2025-10-09 21:30:49,520:INFO:Fitting & Transforming Model
2025-10-09 21:30:50,987:INFO:Visual Rendered Successfully
2025-10-09 21:30:51,069:INFO:plot_model() successfully completed......................................
2025-10-09 21:30:51,151:INFO:Initializing plot_model()
2025-10-09 21:30:51,152:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000216631CFBD0>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), plot=learning, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-09 21:30:51,153:INFO:Checking exceptions
2025-10-09 21:30:51,155:INFO:Preloading libraries
2025-10-09 21:30:51,155:INFO:Copying training dataset
2025-10-09 21:30:51,155:INFO:Plot type: learning
2025-10-09 21:30:51,303:INFO:Fitting Model
2025-10-09 21:30:51,751:INFO:Visual Rendered Successfully
2025-10-09 21:30:51,876:INFO:plot_model() successfully completed......................................
2025-10-09 21:30:51,891:INFO:Initializing plot_model()
2025-10-09 21:30:51,891:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000216631CFBD0>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), plot=rfe, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-09 21:30:51,891:INFO:Checking exceptions
2025-10-09 21:30:51,893:INFO:Preloading libraries
2025-10-09 21:30:51,894:INFO:Copying training dataset
2025-10-09 21:30:51,894:INFO:Plot type: rfe
2025-10-09 21:30:52,025:INFO:Fitting Model
2025-10-09 21:30:52,864:INFO:Visual Rendered Successfully
2025-10-09 21:30:53,003:INFO:plot_model() successfully completed......................................
2025-10-09 21:30:54,699:INFO:Initializing plot_model()
2025-10-09 21:30:54,699:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000216631CFBD0>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), plot=class_report, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-09 21:30:54,699:INFO:Checking exceptions
2025-10-09 21:30:54,702:INFO:Preloading libraries
2025-10-09 21:30:54,702:INFO:Copying training dataset
2025-10-09 21:30:54,702:INFO:Plot type: class_report
2025-10-09 21:30:54,814:INFO:Fitting Model
2025-10-09 21:30:54,815:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RidgeClassifier was fitted with feature names
  warnings.warn(

2025-10-09 21:30:54,815:INFO:Scoring test/hold-out set
2025-10-09 21:30:55,009:INFO:Visual Rendered Successfully
2025-10-09 21:30:55,129:INFO:plot_model() successfully completed......................................
2025-10-09 21:30:57,950:INFO:Initializing plot_model()
2025-10-09 21:30:57,950:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000216631CFBD0>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), plot=feature, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-09 21:30:57,950:INFO:Checking exceptions
2025-10-09 21:30:57,953:INFO:Preloading libraries
2025-10-09 21:30:57,953:INFO:Copying training dataset
2025-10-09 21:30:57,953:INFO:Plot type: feature
2025-10-09 21:30:58,101:INFO:Visual Rendered Successfully
2025-10-09 21:30:58,204:INFO:plot_model() successfully completed......................................
2025-10-09 21:31:01,724:INFO:Initializing plot_model()
2025-10-09 21:31:01,724:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000216631CFBD0>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), plot=confusion_matrix, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-09 21:31:01,724:INFO:Checking exceptions
2025-10-09 21:31:01,727:INFO:Preloading libraries
2025-10-09 21:31:01,727:INFO:Copying training dataset
2025-10-09 21:31:01,727:INFO:Plot type: confusion_matrix
2025-10-09 21:31:01,839:INFO:Fitting Model
2025-10-09 21:31:01,839:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RidgeClassifier was fitted with feature names
  warnings.warn(

2025-10-09 21:31:01,839:INFO:Scoring test/hold-out set
2025-10-09 21:31:01,933:INFO:Visual Rendered Successfully
2025-10-09 21:31:02,078:INFO:plot_model() successfully completed......................................
2025-10-09 21:31:13,910:INFO:Initializing plot_model()
2025-10-09 21:31:13,911:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000216631CFBD0>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), plot=feature, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-09 21:31:13,911:INFO:Checking exceptions
2025-10-09 21:31:13,912:INFO:Preloading libraries
2025-10-09 21:31:13,912:INFO:Copying training dataset
2025-10-09 21:31:13,913:INFO:Plot type: feature
2025-10-09 21:31:14,060:INFO:Visual Rendered Successfully
2025-10-09 21:31:14,142:INFO:plot_model() successfully completed......................................
2025-10-09 21:46:37,941:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-09 21:46:37,941:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-09 21:46:37,941:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-09 21:46:37,942:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-09 22:11:00,763:INFO:PyCaret ClassificationExperiment
2025-10-09 22:11:00,764:INFO:Logging name: clf-default-name
2025-10-09 22:11:00,764:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-10-09 22:11:00,764:INFO:version 3.3.2
2025-10-09 22:11:00,764:INFO:Initializing setup()
2025-10-09 22:11:00,764:INFO:self.USI: 8a8f
2025-10-09 22:11:00,764:INFO:self._variable_keys: {'_ml_usecase', 'memory', 'exp_name_log', 'logging_param', 'gpu_param', 'fix_imbalance', 'X_train', 'y_train', 'y_test', 'idx', 'html_param', 'fold_generator', 'pipeline', 'seed', '_available_plots', 'y', 'target_param', 'X_test', 'USI', 'gpu_n_jobs_param', 'log_plots_param', 'fold_groups_param', 'exp_id', 'is_multiclass', 'fold_shuffle_param', 'X', 'n_jobs_param', 'data'}
2025-10-09 22:11:00,764:INFO:Checking environment
2025-10-09 22:11:00,764:INFO:python_version: 3.11.0
2025-10-09 22:11:00,764:INFO:python_build: ('main', 'Oct 24 2022 18:26:48')
2025-10-09 22:11:00,764:INFO:machine: AMD64
2025-10-09 22:11:00,764:INFO:platform: Windows-10-10.0.26100-SP0
2025-10-09 22:11:00,768:INFO:Memory: svmem(total=34211835904, available=17470828544, percent=48.9, used=16741007360, free=17470828544)
2025-10-09 22:11:00,768:INFO:Physical Core: 6
2025-10-09 22:11:00,768:INFO:Logical Core: 12
2025-10-09 22:11:00,768:INFO:Checking libraries
2025-10-09 22:11:00,768:INFO:System:
2025-10-09 22:11:00,768:INFO:    python: 3.11.0 (main, Oct 24 2022, 18:26:48) [MSC v.1933 64 bit (AMD64)]
2025-10-09 22:11:00,768:INFO:executable: c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\python.exe
2025-10-09 22:11:00,768:INFO:   machine: Windows-10-10.0.26100-SP0
2025-10-09 22:11:00,769:INFO:PyCaret required dependencies:
2025-10-09 22:11:00,808:INFO:                 pip: 22.3
2025-10-09 22:11:00,808:INFO:          setuptools: 65.5.0
2025-10-09 22:11:00,808:INFO:             pycaret: 3.3.2
2025-10-09 22:11:00,808:INFO:             IPython: 9.6.0
2025-10-09 22:11:00,808:INFO:          ipywidgets: 8.1.7
2025-10-09 22:11:00,808:INFO:                tqdm: 4.67.1
2025-10-09 22:11:00,808:INFO:               numpy: 1.26.4
2025-10-09 22:11:00,808:INFO:              pandas: 2.1.4
2025-10-09 22:11:00,808:INFO:              jinja2: 3.1.6
2025-10-09 22:11:00,808:INFO:               scipy: 1.11.4
2025-10-09 22:11:00,808:INFO:              joblib: 1.3.2
2025-10-09 22:11:00,808:INFO:             sklearn: 1.4.2
2025-10-09 22:11:00,808:INFO:                pyod: 2.0.5
2025-10-09 22:11:00,808:INFO:            imblearn: 0.14.0
2025-10-09 22:11:00,808:INFO:   category_encoders: 2.7.0
2025-10-09 22:11:00,808:INFO:            lightgbm: 4.6.0
2025-10-09 22:11:00,808:INFO:               numba: 0.62.1
2025-10-09 22:11:00,808:INFO:            requests: 2.32.5
2025-10-09 22:11:00,808:INFO:          matplotlib: 3.7.5
2025-10-09 22:11:00,808:INFO:          scikitplot: 0.3.7
2025-10-09 22:11:00,808:INFO:         yellowbrick: 1.5
2025-10-09 22:11:00,808:INFO:              plotly: 6.3.1
2025-10-09 22:11:00,808:INFO:    plotly-resampler: Not installed
2025-10-09 22:11:00,808:INFO:             kaleido: 1.1.0
2025-10-09 22:11:00,808:INFO:           schemdraw: 0.15
2025-10-09 22:11:00,808:INFO:         statsmodels: 0.14.5
2025-10-09 22:11:00,808:INFO:              sktime: 0.26.0
2025-10-09 22:11:00,808:INFO:               tbats: 1.1.3
2025-10-09 22:11:00,808:INFO:            pmdarima: 2.0.4
2025-10-09 22:11:00,808:INFO:              psutil: 7.1.0
2025-10-09 22:11:00,810:INFO:          markupsafe: 3.0.3
2025-10-09 22:11:00,810:INFO:             pickle5: Not installed
2025-10-09 22:11:00,810:INFO:         cloudpickle: 3.1.1
2025-10-09 22:11:00,810:INFO:         deprecation: 2.1.0
2025-10-09 22:11:00,810:INFO:              xxhash: 3.6.0
2025-10-09 22:11:00,810:INFO:           wurlitzer: Not installed
2025-10-09 22:11:00,810:INFO:PyCaret optional dependencies:
2025-10-09 22:11:00,827:INFO:                shap: Not installed
2025-10-09 22:11:00,827:INFO:           interpret: Not installed
2025-10-09 22:11:00,827:INFO:                umap: Not installed
2025-10-09 22:11:00,827:INFO:     ydata_profiling: Not installed
2025-10-09 22:11:00,827:INFO:  explainerdashboard: Not installed
2025-10-09 22:11:00,827:INFO:             autoviz: Not installed
2025-10-09 22:11:00,827:INFO:           fairlearn: Not installed
2025-10-09 22:11:00,827:INFO:          deepchecks: Not installed
2025-10-09 22:11:00,827:INFO:             xgboost: Not installed
2025-10-09 22:11:00,827:INFO:            catboost: Not installed
2025-10-09 22:11:00,828:INFO:              kmodes: Not installed
2025-10-09 22:11:00,828:INFO:             mlxtend: Not installed
2025-10-09 22:11:00,828:INFO:       statsforecast: Not installed
2025-10-09 22:11:00,828:INFO:        tune_sklearn: Not installed
2025-10-09 22:11:00,828:INFO:                 ray: Not installed
2025-10-09 22:11:00,828:INFO:            hyperopt: Not installed
2025-10-09 22:11:00,828:INFO:              optuna: Not installed
2025-10-09 22:11:00,828:INFO:               skopt: Not installed
2025-10-09 22:11:00,828:INFO:              mlflow: Not installed
2025-10-09 22:11:00,828:INFO:              gradio: Not installed
2025-10-09 22:11:00,828:INFO:             fastapi: Not installed
2025-10-09 22:11:00,828:INFO:             uvicorn: Not installed
2025-10-09 22:11:00,828:INFO:              m2cgen: Not installed
2025-10-09 22:11:00,828:INFO:           evidently: Not installed
2025-10-09 22:11:00,828:INFO:               fugue: Not installed
2025-10-09 22:11:00,828:INFO:           streamlit: Not installed
2025-10-09 22:11:00,828:INFO:             prophet: Not installed
2025-10-09 22:11:00,828:INFO:None
2025-10-09 22:11:00,828:INFO:Set up data.
2025-10-09 22:11:00,838:INFO:Set up folding strategy.
2025-10-09 22:11:00,838:INFO:Set up train/test split.
2025-10-09 22:11:00,847:INFO:Set up index.
2025-10-09 22:11:00,847:INFO:Assigning column types.
2025-10-09 22:11:00,851:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-09 22:11:00,894:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-09 22:11:00,897:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-09 22:11:00,937:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 22:11:00,937:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 22:11:00,980:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-09 22:11:00,981:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-09 22:11:01,013:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 22:11:01,013:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 22:11:01,013:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-09 22:11:01,059:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-09 22:11:01,084:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 22:11:01,085:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 22:11:01,131:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-09 22:11:01,158:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 22:11:01,158:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 22:11:01,159:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-10-09 22:11:01,228:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 22:11:01,228:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 22:11:01,302:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 22:11:01,303:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 22:11:01,305:INFO:Preparing preprocessing pipeline...
2025-10-09 22:11:01,307:INFO:Set up simple imputation.
2025-10-09 22:11:01,310:INFO:Set up encoding of categorical features.
2025-10-09 22:11:01,310:INFO:Set up removing multicollinearity.
2025-10-09 22:11:01,310:INFO:Set up column transformation.
2025-10-09 22:11:01,310:INFO:Set up feature normalization.
2025-10-09 22:11:01,310:INFO:Set up feature selection.
2025-10-09 22:11:01,393:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 22:11:01,393:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 22:11:01,827:INFO:Finished creating preprocessing pipeline.
2025-10-09 22:11:01,866:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\ARNALDO\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['likes', 'comentarios',
                                             'engagement'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Transf...
                                                                                         learning_rate=0.1,
                                                                                         max_depth=-1,
                                                                                         min_child_samples=20,
                                                                                         min_child_weight=0.001,
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=None,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=1,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf)))],
         verbose=False)
2025-10-09 22:11:01,866:INFO:Creating final display dataframe.
2025-10-09 22:11:02,522:INFO:Setup _display_container:                     Description             Value
0                    Session id              2025
1                        Target        conversion
2                   Target type            Binary
3           Original data shape         (220, 10)
4        Transformed data shape          (220, 2)
5   Transformed train set shape          (154, 2)
6    Transformed test set shape           (66, 2)
7               Ignore features                 2
8              Numeric features                 3
9          Categorical features                 4
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16     Remove multicollinearity              True
17  Multicollinearity threshold               0.9
18               Transformation              True
19        Transformation method       yeo-johnson
20                    Normalize              True
21             Normalize method            zscore
22            Feature selection              True
23     Feature selection method           classic
24  Feature selection estimator          lightgbm
25  Number of features selected               0.2
26               Fold Generator   StratifiedKFold
27                  Fold Number                10
28                     CPU Jobs                -1
29                      Use GPU             False
30               Log Experiment             False
31              Experiment Name  clf-default-name
32                          USI              8a8f
2025-10-09 22:11:02,713:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 22:11:02,714:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 22:11:02,818:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 22:11:02,819:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 22:11:02,821:INFO:setup() successfully completed in 2.06s...............
2025-10-09 22:12:25,928:INFO:Initializing compare_models()
2025-10-09 22:12:25,930:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EF27BAE490>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=F1, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001EF27BAE490>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'F1', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-10-09 22:12:25,930:INFO:Checking exceptions
2025-10-09 22:12:25,936:INFO:Preparing display monitor
2025-10-09 22:12:25,972:INFO:Initializing Logistic Regression
2025-10-09 22:12:25,972:INFO:Total runtime is 1.657406489054362e-05 minutes
2025-10-09 22:12:25,977:INFO:SubProcess create_model() called ==================================
2025-10-09 22:12:25,977:INFO:Initializing create_model()
2025-10-09 22:12:25,977:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EF27BAE490>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EF27BAD890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 22:12:25,978:INFO:Checking exceptions
2025-10-09 22:12:25,978:INFO:Importing libraries
2025-10-09 22:12:25,978:INFO:Copying training dataset
2025-10-09 22:12:25,986:INFO:Defining folds
2025-10-09 22:12:25,986:INFO:Declaring metric variables
2025-10-09 22:12:25,993:INFO:Importing untrained model
2025-10-09 22:12:26,001:INFO:Logistic Regression Imported successfully
2025-10-09 22:12:26,016:INFO:Starting cross validation
2025-10-09 22:12:26,027:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 22:12:35,632:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:12:35,710:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:12:35,762:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:12:35,784:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:12:35,861:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:12:36,000:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:12:36,035:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:12:36,073:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:12:36,155:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:12:36,173:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:12:36,193:INFO:Calculating mean and std
2025-10-09 22:12:36,195:INFO:Creating metrics dataframe
2025-10-09 22:12:36,201:INFO:Uploading results into container
2025-10-09 22:12:36,203:INFO:Uploading model into container now
2025-10-09 22:12:36,204:INFO:_master_model_container: 1
2025-10-09 22:12:36,204:INFO:_display_container: 2
2025-10-09 22:12:36,205:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2025, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-09 22:12:36,205:INFO:create_model() successfully completed......................................
2025-10-09 22:12:36,351:INFO:SubProcess create_model() end ==================================
2025-10-09 22:12:36,351:INFO:Creating metrics dataframe
2025-10-09 22:12:36,363:INFO:Initializing K Neighbors Classifier
2025-10-09 22:12:36,363:INFO:Total runtime is 0.17320144971211754 minutes
2025-10-09 22:12:36,367:INFO:SubProcess create_model() called ==================================
2025-10-09 22:12:36,367:INFO:Initializing create_model()
2025-10-09 22:12:36,367:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EF27BAE490>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EF27BAD890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 22:12:36,367:INFO:Checking exceptions
2025-10-09 22:12:36,367:INFO:Importing libraries
2025-10-09 22:12:36,367:INFO:Copying training dataset
2025-10-09 22:12:36,376:INFO:Defining folds
2025-10-09 22:12:36,376:INFO:Declaring metric variables
2025-10-09 22:12:36,384:INFO:Importing untrained model
2025-10-09 22:12:36,388:INFO:K Neighbors Classifier Imported successfully
2025-10-09 22:12:36,398:INFO:Starting cross validation
2025-10-09 22:12:36,407:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 22:12:37,513:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:12:41,377:INFO:Calculating mean and std
2025-10-09 22:12:41,378:INFO:Creating metrics dataframe
2025-10-09 22:12:41,381:INFO:Uploading results into container
2025-10-09 22:12:41,382:INFO:Uploading model into container now
2025-10-09 22:12:41,382:INFO:_master_model_container: 2
2025-10-09 22:12:41,383:INFO:_display_container: 2
2025-10-09 22:12:41,383:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-10-09 22:12:41,383:INFO:create_model() successfully completed......................................
2025-10-09 22:12:41,544:INFO:SubProcess create_model() end ==================================
2025-10-09 22:12:41,545:INFO:Creating metrics dataframe
2025-10-09 22:12:41,555:INFO:Initializing Naive Bayes
2025-10-09 22:12:41,556:INFO:Total runtime is 0.2597628196080526 minutes
2025-10-09 22:12:41,566:INFO:SubProcess create_model() called ==================================
2025-10-09 22:12:41,566:INFO:Initializing create_model()
2025-10-09 22:12:41,567:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EF27BAE490>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EF27BAD890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 22:12:41,567:INFO:Checking exceptions
2025-10-09 22:12:41,567:INFO:Importing libraries
2025-10-09 22:12:41,567:INFO:Copying training dataset
2025-10-09 22:12:41,575:INFO:Defining folds
2025-10-09 22:12:41,575:INFO:Declaring metric variables
2025-10-09 22:12:41,580:INFO:Importing untrained model
2025-10-09 22:12:41,586:INFO:Naive Bayes Imported successfully
2025-10-09 22:12:41,597:INFO:Starting cross validation
2025-10-09 22:12:41,608:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 22:12:42,278:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:12:42,292:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:12:42,302:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:12:42,330:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:12:42,410:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:12:42,418:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:12:42,457:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:12:42,492:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:12:42,542:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:12:42,555:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:12:42,572:INFO:Calculating mean and std
2025-10-09 22:12:42,574:INFO:Creating metrics dataframe
2025-10-09 22:12:42,576:INFO:Uploading results into container
2025-10-09 22:12:42,577:INFO:Uploading model into container now
2025-10-09 22:12:42,577:INFO:_master_model_container: 3
2025-10-09 22:12:42,578:INFO:_display_container: 2
2025-10-09 22:12:42,578:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-10-09 22:12:42,578:INFO:create_model() successfully completed......................................
2025-10-09 22:12:42,698:INFO:SubProcess create_model() end ==================================
2025-10-09 22:12:42,698:INFO:Creating metrics dataframe
2025-10-09 22:12:42,707:INFO:Initializing Decision Tree Classifier
2025-10-09 22:12:42,708:INFO:Total runtime is 0.2789535442988078 minutes
2025-10-09 22:12:42,713:INFO:SubProcess create_model() called ==================================
2025-10-09 22:12:42,713:INFO:Initializing create_model()
2025-10-09 22:12:42,713:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EF27BAE490>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EF27BAD890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 22:12:42,713:INFO:Checking exceptions
2025-10-09 22:12:42,714:INFO:Importing libraries
2025-10-09 22:12:42,714:INFO:Copying training dataset
2025-10-09 22:12:42,722:INFO:Defining folds
2025-10-09 22:12:42,722:INFO:Declaring metric variables
2025-10-09 22:12:42,726:INFO:Importing untrained model
2025-10-09 22:12:42,733:INFO:Decision Tree Classifier Imported successfully
2025-10-09 22:12:42,746:INFO:Starting cross validation
2025-10-09 22:12:42,755:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 22:12:43,720:INFO:Calculating mean and std
2025-10-09 22:12:43,721:INFO:Creating metrics dataframe
2025-10-09 22:12:43,723:INFO:Uploading results into container
2025-10-09 22:12:43,724:INFO:Uploading model into container now
2025-10-09 22:12:43,725:INFO:_master_model_container: 4
2025-10-09 22:12:43,725:INFO:_display_container: 2
2025-10-09 22:12:43,726:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best')
2025-10-09 22:12:43,726:INFO:create_model() successfully completed......................................
2025-10-09 22:12:43,840:INFO:SubProcess create_model() end ==================================
2025-10-09 22:12:43,840:INFO:Creating metrics dataframe
2025-10-09 22:12:43,850:INFO:Initializing SVM - Linear Kernel
2025-10-09 22:12:43,850:INFO:Total runtime is 0.29798350334167484 minutes
2025-10-09 22:12:43,857:INFO:SubProcess create_model() called ==================================
2025-10-09 22:12:43,858:INFO:Initializing create_model()
2025-10-09 22:12:43,858:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EF27BAE490>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EF27BAD890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 22:12:43,858:INFO:Checking exceptions
2025-10-09 22:12:43,858:INFO:Importing libraries
2025-10-09 22:12:43,858:INFO:Copying training dataset
2025-10-09 22:12:43,865:INFO:Defining folds
2025-10-09 22:12:43,865:INFO:Declaring metric variables
2025-10-09 22:12:43,872:INFO:Importing untrained model
2025-10-09 22:12:43,878:INFO:SVM - Linear Kernel Imported successfully
2025-10-09 22:12:43,890:INFO:Starting cross validation
2025-10-09 22:12:43,901:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 22:12:44,660:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:12:44,704:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:12:44,741:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:12:44,765:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:12:44,805:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:12:44,837:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:12:44,844:INFO:Calculating mean and std
2025-10-09 22:12:44,845:INFO:Creating metrics dataframe
2025-10-09 22:12:44,849:INFO:Uploading results into container
2025-10-09 22:12:44,851:INFO:Uploading model into container now
2025-10-09 22:12:44,851:INFO:_master_model_container: 5
2025-10-09 22:12:44,852:INFO:_display_container: 2
2025-10-09 22:12:44,853:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=2025, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-10-09 22:12:44,853:INFO:create_model() successfully completed......................................
2025-10-09 22:12:44,980:INFO:SubProcess create_model() end ==================================
2025-10-09 22:12:44,980:INFO:Creating metrics dataframe
2025-10-09 22:12:44,991:INFO:Initializing Ridge Classifier
2025-10-09 22:12:44,991:INFO:Total runtime is 0.31701085964838666 minutes
2025-10-09 22:12:44,995:INFO:SubProcess create_model() called ==================================
2025-10-09 22:12:44,996:INFO:Initializing create_model()
2025-10-09 22:12:44,996:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EF27BAE490>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EF27BAD890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 22:12:44,996:INFO:Checking exceptions
2025-10-09 22:12:44,996:INFO:Importing libraries
2025-10-09 22:12:44,996:INFO:Copying training dataset
2025-10-09 22:12:45,001:INFO:Defining folds
2025-10-09 22:12:45,001:INFO:Declaring metric variables
2025-10-09 22:12:45,009:INFO:Importing untrained model
2025-10-09 22:12:45,015:INFO:Ridge Classifier Imported successfully
2025-10-09 22:12:45,027:INFO:Starting cross validation
2025-10-09 22:12:45,037:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 22:12:45,766:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:12:45,768:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:12:45,784:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:12:45,785:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:12:45,909:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:12:45,928:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:12:45,937:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:12:45,948:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:12:46,035:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:12:46,051:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:12:46,064:INFO:Calculating mean and std
2025-10-09 22:12:46,066:INFO:Creating metrics dataframe
2025-10-09 22:12:46,069:INFO:Uploading results into container
2025-10-09 22:12:46,070:INFO:Uploading model into container now
2025-10-09 22:12:46,071:INFO:_master_model_container: 6
2025-10-09 22:12:46,071:INFO:_display_container: 2
2025-10-09 22:12:46,071:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=2025, solver='auto',
                tol=0.0001)
2025-10-09 22:12:46,072:INFO:create_model() successfully completed......................................
2025-10-09 22:12:46,194:INFO:SubProcess create_model() end ==================================
2025-10-09 22:12:46,194:INFO:Creating metrics dataframe
2025-10-09 22:12:46,206:INFO:Initializing Random Forest Classifier
2025-10-09 22:12:46,206:INFO:Total runtime is 0.33726490338643395 minutes
2025-10-09 22:12:46,214:INFO:SubProcess create_model() called ==================================
2025-10-09 22:12:46,215:INFO:Initializing create_model()
2025-10-09 22:12:46,215:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EF27BAE490>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EF27BAD890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 22:12:46,215:INFO:Checking exceptions
2025-10-09 22:12:46,215:INFO:Importing libraries
2025-10-09 22:12:46,215:INFO:Copying training dataset
2025-10-09 22:12:46,221:INFO:Defining folds
2025-10-09 22:12:46,221:INFO:Declaring metric variables
2025-10-09 22:12:46,226:INFO:Importing untrained model
2025-10-09 22:12:46,232:INFO:Random Forest Classifier Imported successfully
2025-10-09 22:12:46,245:INFO:Starting cross validation
2025-10-09 22:12:46,254:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 22:12:47,842:INFO:Calculating mean and std
2025-10-09 22:12:47,844:INFO:Creating metrics dataframe
2025-10-09 22:12:47,846:INFO:Uploading results into container
2025-10-09 22:12:47,847:INFO:Uploading model into container now
2025-10-09 22:12:47,848:INFO:_master_model_container: 7
2025-10-09 22:12:47,849:INFO:_display_container: 2
2025-10-09 22:12:47,850:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=2025, verbose=0,
                       warm_start=False)
2025-10-09 22:12:47,851:INFO:create_model() successfully completed......................................
2025-10-09 22:12:47,979:INFO:SubProcess create_model() end ==================================
2025-10-09 22:12:47,980:INFO:Creating metrics dataframe
2025-10-09 22:12:47,994:INFO:Initializing Quadratic Discriminant Analysis
2025-10-09 22:12:47,994:INFO:Total runtime is 0.3670495470364889 minutes
2025-10-09 22:12:47,997:INFO:SubProcess create_model() called ==================================
2025-10-09 22:12:47,997:INFO:Initializing create_model()
2025-10-09 22:12:47,997:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EF27BAE490>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EF27BAD890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 22:12:47,997:INFO:Checking exceptions
2025-10-09 22:12:47,998:INFO:Importing libraries
2025-10-09 22:12:47,998:INFO:Copying training dataset
2025-10-09 22:12:48,003:INFO:Defining folds
2025-10-09 22:12:48,003:INFO:Declaring metric variables
2025-10-09 22:12:48,011:INFO:Importing untrained model
2025-10-09 22:12:48,020:INFO:Quadratic Discriminant Analysis Imported successfully
2025-10-09 22:12:48,031:INFO:Starting cross validation
2025-10-09 22:12:48,038:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 22:12:48,752:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:12:48,760:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:12:48,785:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:12:48,795:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:12:48,850:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:12:48,888:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:12:48,921:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:12:48,965:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:12:49,009:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:12:49,022:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:12:49,044:INFO:Calculating mean and std
2025-10-09 22:12:49,045:INFO:Creating metrics dataframe
2025-10-09 22:12:49,047:INFO:Uploading results into container
2025-10-09 22:12:49,048:INFO:Uploading model into container now
2025-10-09 22:12:49,050:INFO:_master_model_container: 8
2025-10-09 22:12:49,050:INFO:_display_container: 2
2025-10-09 22:12:49,051:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-10-09 22:12:49,051:INFO:create_model() successfully completed......................................
2025-10-09 22:12:49,172:INFO:SubProcess create_model() end ==================================
2025-10-09 22:12:49,172:INFO:Creating metrics dataframe
2025-10-09 22:12:49,182:INFO:Initializing Ada Boost Classifier
2025-10-09 22:12:49,183:INFO:Total runtime is 0.3868820985158285 minutes
2025-10-09 22:12:49,188:INFO:SubProcess create_model() called ==================================
2025-10-09 22:12:49,188:INFO:Initializing create_model()
2025-10-09 22:12:49,190:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EF27BAE490>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EF27BAD890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 22:12:49,190:INFO:Checking exceptions
2025-10-09 22:12:49,190:INFO:Importing libraries
2025-10-09 22:12:49,190:INFO:Copying training dataset
2025-10-09 22:12:49,195:INFO:Defining folds
2025-10-09 22:12:49,195:INFO:Declaring metric variables
2025-10-09 22:12:49,198:INFO:Importing untrained model
2025-10-09 22:12:49,206:INFO:Ada Boost Classifier Imported successfully
2025-10-09 22:12:49,220:INFO:Starting cross validation
2025-10-09 22:12:49,230:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 22:12:49,793:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 22:12:49,795:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 22:12:49,803:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 22:12:49,812:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 22:12:50,119:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 22:12:50,130:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 22:12:50,180:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 22:12:50,183:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 22:12:50,427:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 22:12:50,480:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 22:12:50,670:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:12:50,681:INFO:Calculating mean and std
2025-10-09 22:12:50,683:INFO:Creating metrics dataframe
2025-10-09 22:12:50,684:INFO:Uploading results into container
2025-10-09 22:12:50,685:INFO:Uploading model into container now
2025-10-09 22:12:50,685:INFO:_master_model_container: 9
2025-10-09 22:12:50,685:INFO:_display_container: 2
2025-10-09 22:12:50,685:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2025)
2025-10-09 22:12:50,685:INFO:create_model() successfully completed......................................
2025-10-09 22:12:50,799:INFO:SubProcess create_model() end ==================================
2025-10-09 22:12:50,799:INFO:Creating metrics dataframe
2025-10-09 22:12:50,811:INFO:Initializing Gradient Boosting Classifier
2025-10-09 22:12:50,811:INFO:Total runtime is 0.41400001446406054 minutes
2025-10-09 22:12:50,815:INFO:SubProcess create_model() called ==================================
2025-10-09 22:12:50,815:INFO:Initializing create_model()
2025-10-09 22:12:50,815:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EF27BAE490>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EF27BAD890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 22:12:50,817:INFO:Checking exceptions
2025-10-09 22:12:50,817:INFO:Importing libraries
2025-10-09 22:12:50,817:INFO:Copying training dataset
2025-10-09 22:12:50,825:INFO:Defining folds
2025-10-09 22:12:50,825:INFO:Declaring metric variables
2025-10-09 22:12:50,828:INFO:Importing untrained model
2025-10-09 22:12:50,838:INFO:Gradient Boosting Classifier Imported successfully
2025-10-09 22:12:50,852:INFO:Starting cross validation
2025-10-09 22:12:50,861:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 22:12:52,105:INFO:Calculating mean and std
2025-10-09 22:12:52,108:INFO:Creating metrics dataframe
2025-10-09 22:12:52,118:INFO:Uploading results into container
2025-10-09 22:12:52,119:INFO:Uploading model into container now
2025-10-09 22:12:52,120:INFO:_master_model_container: 10
2025-10-09 22:12:52,120:INFO:_display_container: 2
2025-10-09 22:12:52,121:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2025, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-09 22:12:52,121:INFO:create_model() successfully completed......................................
2025-10-09 22:12:52,238:INFO:SubProcess create_model() end ==================================
2025-10-09 22:12:52,238:INFO:Creating metrics dataframe
2025-10-09 22:12:52,248:INFO:Initializing Linear Discriminant Analysis
2025-10-09 22:12:52,248:INFO:Total runtime is 0.43795626560846973 minutes
2025-10-09 22:12:52,253:INFO:SubProcess create_model() called ==================================
2025-10-09 22:12:52,254:INFO:Initializing create_model()
2025-10-09 22:12:52,254:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EF27BAE490>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EF27BAD890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 22:12:52,254:INFO:Checking exceptions
2025-10-09 22:12:52,254:INFO:Importing libraries
2025-10-09 22:12:52,254:INFO:Copying training dataset
2025-10-09 22:12:52,261:INFO:Defining folds
2025-10-09 22:12:52,261:INFO:Declaring metric variables
2025-10-09 22:12:52,267:INFO:Importing untrained model
2025-10-09 22:12:52,271:INFO:Linear Discriminant Analysis Imported successfully
2025-10-09 22:12:52,282:INFO:Starting cross validation
2025-10-09 22:12:52,290:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 22:12:52,883:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:12:52,906:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:12:52,909:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:12:52,931:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:12:53,005:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:12:53,037:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:12:53,053:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:12:53,064:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:12:53,146:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:12:53,177:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:12:53,192:INFO:Calculating mean and std
2025-10-09 22:12:53,193:INFO:Creating metrics dataframe
2025-10-09 22:12:53,195:INFO:Uploading results into container
2025-10-09 22:12:53,195:INFO:Uploading model into container now
2025-10-09 22:12:53,196:INFO:_master_model_container: 11
2025-10-09 22:12:53,197:INFO:_display_container: 2
2025-10-09 22:12:53,197:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-09 22:12:53,197:INFO:create_model() successfully completed......................................
2025-10-09 22:12:53,319:INFO:SubProcess create_model() end ==================================
2025-10-09 22:12:53,320:INFO:Creating metrics dataframe
2025-10-09 22:12:53,333:INFO:Initializing Extra Trees Classifier
2025-10-09 22:12:53,333:INFO:Total runtime is 0.4560334086418153 minutes
2025-10-09 22:12:53,337:INFO:SubProcess create_model() called ==================================
2025-10-09 22:12:53,338:INFO:Initializing create_model()
2025-10-09 22:12:53,338:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EF27BAE490>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EF27BAD890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 22:12:53,339:INFO:Checking exceptions
2025-10-09 22:12:53,339:INFO:Importing libraries
2025-10-09 22:12:53,339:INFO:Copying training dataset
2025-10-09 22:12:53,346:INFO:Defining folds
2025-10-09 22:12:53,346:INFO:Declaring metric variables
2025-10-09 22:12:53,364:INFO:Importing untrained model
2025-10-09 22:12:53,375:INFO:Extra Trees Classifier Imported successfully
2025-10-09 22:12:53,410:INFO:Starting cross validation
2025-10-09 22:12:53,427:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 22:12:54,958:INFO:Calculating mean and std
2025-10-09 22:12:54,959:INFO:Creating metrics dataframe
2025-10-09 22:12:54,962:INFO:Uploading results into container
2025-10-09 22:12:54,964:INFO:Uploading model into container now
2025-10-09 22:12:54,964:INFO:_master_model_container: 12
2025-10-09 22:12:54,965:INFO:_display_container: 2
2025-10-09 22:12:54,965:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=2025, verbose=0,
                     warm_start=False)
2025-10-09 22:12:54,965:INFO:create_model() successfully completed......................................
2025-10-09 22:12:55,084:INFO:SubProcess create_model() end ==================================
2025-10-09 22:12:55,085:INFO:Creating metrics dataframe
2025-10-09 22:12:55,097:INFO:Initializing Light Gradient Boosting Machine
2025-10-09 22:12:55,097:INFO:Total runtime is 0.4854334394137066 minutes
2025-10-09 22:12:55,101:INFO:SubProcess create_model() called ==================================
2025-10-09 22:12:55,102:INFO:Initializing create_model()
2025-10-09 22:12:55,102:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EF27BAE490>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EF27BAD890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 22:12:55,102:INFO:Checking exceptions
2025-10-09 22:12:55,102:INFO:Importing libraries
2025-10-09 22:12:55,102:INFO:Copying training dataset
2025-10-09 22:12:55,110:INFO:Defining folds
2025-10-09 22:12:55,111:INFO:Declaring metric variables
2025-10-09 22:12:55,115:INFO:Importing untrained model
2025-10-09 22:12:55,121:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-09 22:12:55,134:INFO:Starting cross validation
2025-10-09 22:12:55,146:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 22:12:56,085:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:12:56,087:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:12:56,118:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:12:56,332:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:12:56,357:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:12:56,468:INFO:Calculating mean and std
2025-10-09 22:12:56,472:INFO:Creating metrics dataframe
2025-10-09 22:12:56,477:INFO:Uploading results into container
2025-10-09 22:12:56,478:INFO:Uploading model into container now
2025-10-09 22:12:56,479:INFO:_master_model_container: 13
2025-10-09 22:12:56,479:INFO:_display_container: 2
2025-10-09 22:12:56,481:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2025, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-09 22:12:56,481:INFO:create_model() successfully completed......................................
2025-10-09 22:12:56,618:INFO:SubProcess create_model() end ==================================
2025-10-09 22:12:56,619:INFO:Creating metrics dataframe
2025-10-09 22:12:56,631:INFO:Initializing Dummy Classifier
2025-10-09 22:12:56,631:INFO:Total runtime is 0.510999902089437 minutes
2025-10-09 22:12:56,635:INFO:SubProcess create_model() called ==================================
2025-10-09 22:12:56,635:INFO:Initializing create_model()
2025-10-09 22:12:56,635:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EF27BAE490>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EF27BAD890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 22:12:56,635:INFO:Checking exceptions
2025-10-09 22:12:56,635:INFO:Importing libraries
2025-10-09 22:12:56,635:INFO:Copying training dataset
2025-10-09 22:12:56,642:INFO:Defining folds
2025-10-09 22:12:56,642:INFO:Declaring metric variables
2025-10-09 22:12:56,646:INFO:Importing untrained model
2025-10-09 22:12:56,652:INFO:Dummy Classifier Imported successfully
2025-10-09 22:12:56,665:INFO:Starting cross validation
2025-10-09 22:12:56,674:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 22:12:57,339:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:12:57,347:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:12:57,372:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:12:57,372:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:12:57,432:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:12:57,473:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:12:57,501:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:12:57,516:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:12:57,561:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:12:57,603:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:12:57,624:INFO:Calculating mean and std
2025-10-09 22:12:57,626:INFO:Creating metrics dataframe
2025-10-09 22:12:57,628:INFO:Uploading results into container
2025-10-09 22:12:57,628:INFO:Uploading model into container now
2025-10-09 22:12:57,630:INFO:_master_model_container: 14
2025-10-09 22:12:57,630:INFO:_display_container: 2
2025-10-09 22:12:57,631:INFO:DummyClassifier(constant=None, random_state=2025, strategy='prior')
2025-10-09 22:12:57,631:INFO:create_model() successfully completed......................................
2025-10-09 22:12:57,754:INFO:SubProcess create_model() end ==================================
2025-10-09 22:12:57,754:INFO:Creating metrics dataframe
2025-10-09 22:12:57,772:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-10-09 22:12:57,785:INFO:Initializing create_model()
2025-10-09 22:12:57,785:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EF27BAE490>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 22:12:57,785:INFO:Checking exceptions
2025-10-09 22:12:57,788:INFO:Importing libraries
2025-10-09 22:12:57,788:INFO:Copying training dataset
2025-10-09 22:12:57,796:INFO:Defining folds
2025-10-09 22:12:57,797:INFO:Declaring metric variables
2025-10-09 22:12:57,797:INFO:Importing untrained model
2025-10-09 22:12:57,797:INFO:Declaring custom model
2025-10-09 22:12:57,797:INFO:Decision Tree Classifier Imported successfully
2025-10-09 22:12:57,806:INFO:Cross validation set to False
2025-10-09 22:12:57,806:INFO:Fitting Model
2025-10-09 22:12:57,964:INFO:[LightGBM] [Info] Number of positive: 32, number of negative: 122
2025-10-09 22:12:57,964:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000047 seconds.
2025-10-09 22:12:57,964:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-10-09 22:12:57,964:INFO:[LightGBM] [Info] Total Bins 186
2025-10-09 22:12:57,964:INFO:[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 14
2025-10-09 22:12:57,964:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.207792 -> initscore=-1.338285
2025-10-09 22:12:57,964:INFO:[LightGBM] [Info] Start training from score -1.338285
2025-10-09 22:12:57,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:12:57,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:12:57,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:12:57,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:12:57,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:12:57,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:12:57,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:12:57,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:12:57,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:12:57,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:12:57,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:12:57,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:12:57,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:12:57,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:12:57,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:12:57,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:12:57,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:12:57,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:12:57,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:12:57,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:12:57,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:12:57,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:12:57,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:12:57,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:12:57,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:12:57,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:12:57,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:12:57,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:12:57,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:12:57,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:12:57,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:12:57,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:12:57,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:12:57,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:12:57,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:12:57,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:12:57,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:12:57,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:12:57,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:12:57,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:12:57,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:12:57,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:12:57,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:12:57,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:12:57,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:12:57,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:12:57,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:12:57,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:12:57,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:12:57,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:12:57,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:12:57,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:12:57,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:12:57,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:12:57,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:12:57,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:12:57,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:12:57,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:12:57,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:12:57,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:12:57,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:12:57,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:12:57,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:12:57,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:12:57,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:12:57,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:12:57,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:12:57,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:12:57,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:12:57,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:12:57,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:12:57,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:12:57,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:12:57,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:12:57,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:12:57,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:12:57,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:12:57,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:12:57,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:12:57,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:12:57,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:12:57,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:12:57,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:12:57,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:12:57,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:12:57,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:12:57,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:12:57,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:12:57,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:12:57,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:12:57,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:12:57,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:12:57,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:12:57,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:12:57,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:12:57,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:12:57,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:12:57,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:12:57,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:12:57,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:12:58,000:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best')
2025-10-09 22:12:58,001:INFO:create_model() successfully completed......................................
2025-10-09 22:12:58,200:INFO:_master_model_container: 14
2025-10-09 22:12:58,200:INFO:_display_container: 2
2025-10-09 22:12:58,201:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best')
2025-10-09 22:12:58,201:INFO:compare_models() successfully completed......................................
2025-10-09 22:15:30,851:INFO:Initializing tune_model()
2025-10-09 22:15:30,851:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EF27BAE490>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best'), fold=None, round=4, n_iter=10, custom_grid=None, optimize=F1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-10-09 22:15:30,851:INFO:Checking exceptions
2025-10-09 22:15:30,876:INFO:Copying training dataset
2025-10-09 22:15:30,883:INFO:Checking base model
2025-10-09 22:15:30,883:INFO:Base model : Decision Tree Classifier
2025-10-09 22:15:30,890:INFO:Declaring metric variables
2025-10-09 22:15:30,900:INFO:Defining Hyperparameters
2025-10-09 22:15:31,134:INFO:Tuning with n_jobs=-1
2025-10-09 22:15:31,134:INFO:Initializing RandomizedSearchCV
2025-10-09 22:16:01,305:INFO:Initializing tune_model()
2025-10-09 22:16:01,305:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EF27BAE490>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best'), fold=None, round=4, n_iter=10, custom_grid=None, optimize=F1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-10-09 22:16:01,305:INFO:Checking exceptions
2025-10-09 22:16:01,333:INFO:Copying training dataset
2025-10-09 22:16:01,340:INFO:Checking base model
2025-10-09 22:16:01,340:INFO:Base model : Decision Tree Classifier
2025-10-09 22:16:01,347:INFO:Declaring metric variables
2025-10-09 22:16:01,354:INFO:Defining Hyperparameters
2025-10-09 22:16:01,538:INFO:Tuning with n_jobs=-1
2025-10-09 22:16:01,538:INFO:Initializing RandomizedSearchCV
2025-10-09 22:16:25,730:INFO:best_params: {'actual_estimator__min_samples_split': 9, 'actual_estimator__min_samples_leaf': 5, 'actual_estimator__min_impurity_decrease': 0.002, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 11, 'actual_estimator__criterion': 'gini'}
2025-10-09 22:16:25,732:INFO:Hyperparameter search completed
2025-10-09 22:16:25,733:INFO:SubProcess create_model() called ==================================
2025-10-09 22:16:25,734:INFO:Initializing create_model()
2025-10-09 22:16:25,734:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EF27BAE490>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EF2933EE10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'min_samples_split': 9, 'min_samples_leaf': 5, 'min_impurity_decrease': 0.002, 'max_features': 'sqrt', 'max_depth': 11, 'criterion': 'gini'})
2025-10-09 22:16:25,734:INFO:Checking exceptions
2025-10-09 22:16:25,735:INFO:Importing libraries
2025-10-09 22:16:25,735:INFO:Copying training dataset
2025-10-09 22:16:25,749:INFO:Defining folds
2025-10-09 22:16:25,750:INFO:Declaring metric variables
2025-10-09 22:16:25,763:INFO:Importing untrained model
2025-10-09 22:16:25,763:INFO:Declaring custom model
2025-10-09 22:16:25,774:INFO:Decision Tree Classifier Imported successfully
2025-10-09 22:16:25,785:INFO:Starting cross validation
2025-10-09 22:16:25,797:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 22:16:26,479:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:16:26,766:INFO:Calculating mean and std
2025-10-09 22:16:26,770:INFO:Creating metrics dataframe
2025-10-09 22:16:26,784:INFO:Finalizing model
2025-10-09 22:16:26,916:INFO:[LightGBM] [Info] Number of positive: 32, number of negative: 122
2025-10-09 22:16:26,916:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000052 seconds.
2025-10-09 22:16:26,917:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-09 22:16:26,917:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-09 22:16:26,917:INFO:[LightGBM] [Info] Total Bins 186
2025-10-09 22:16:26,917:INFO:[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 14
2025-10-09 22:16:26,917:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.207792 -> initscore=-1.338285
2025-10-09 22:16:26,917:INFO:[LightGBM] [Info] Start training from score -1.338285
2025-10-09 22:16:26,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:26,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:26,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:26,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:26,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:26,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:26,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:26,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:26,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:26,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:26,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:26,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:26,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:26,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:26,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:26,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:26,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:26,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:26,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:26,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:26,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:26,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:26,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:26,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:26,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:26,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:26,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:26,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:26,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:26,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:26,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:26,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:26,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:26,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:26,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:26,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:26,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:26,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:26,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:26,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:26,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:26,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:26,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:26,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:26,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:26,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:26,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:26,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:26,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:26,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:26,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:26,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:26,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:26,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:26,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:26,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:26,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:26,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:26,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:26,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:26,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:26,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:26,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:26,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:26,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:26,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:26,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:26,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:26,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:26,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:26,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:26,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:26,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:26,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:26,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:26,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:26,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:26,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:26,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:26,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:26,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:26,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:26,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:26,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:26,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:26,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:26,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:26,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:26,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:26,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:26,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:26,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:26,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:26,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:26,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:26,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:26,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:26,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:26,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:26,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:26,961:INFO:Uploading results into container
2025-10-09 22:16:26,963:INFO:Uploading model into container now
2025-10-09 22:16:26,963:INFO:_master_model_container: 15
2025-10-09 22:16:26,964:INFO:_display_container: 3
2025-10-09 22:16:26,964:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=11, max_features='sqrt', max_leaf_nodes=None,
                       min_impurity_decrease=0.002, min_samples_leaf=5,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best')
2025-10-09 22:16:26,964:INFO:create_model() successfully completed......................................
2025-10-09 22:16:27,123:INFO:SubProcess create_model() end ==================================
2025-10-09 22:16:27,123:INFO:choose_better activated
2025-10-09 22:16:27,129:INFO:SubProcess create_model() called ==================================
2025-10-09 22:16:27,130:INFO:Initializing create_model()
2025-10-09 22:16:27,130:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EF27BAE490>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 22:16:27,130:INFO:Checking exceptions
2025-10-09 22:16:27,132:INFO:Importing libraries
2025-10-09 22:16:27,132:INFO:Copying training dataset
2025-10-09 22:16:27,136:INFO:Defining folds
2025-10-09 22:16:27,136:INFO:Declaring metric variables
2025-10-09 22:16:27,136:INFO:Importing untrained model
2025-10-09 22:16:27,136:INFO:Declaring custom model
2025-10-09 22:16:27,137:INFO:Decision Tree Classifier Imported successfully
2025-10-09 22:16:27,137:INFO:Starting cross validation
2025-10-09 22:16:27,146:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 22:16:28,104:INFO:Calculating mean and std
2025-10-09 22:16:28,104:INFO:Creating metrics dataframe
2025-10-09 22:16:28,106:INFO:Finalizing model
2025-10-09 22:16:28,227:INFO:[LightGBM] [Info] Number of positive: 32, number of negative: 122
2025-10-09 22:16:28,228:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000065 seconds.
2025-10-09 22:16:28,228:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-10-09 22:16:28,228:INFO:[LightGBM] [Info] Total Bins 186
2025-10-09 22:16:28,228:INFO:[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 14
2025-10-09 22:16:28,228:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.207792 -> initscore=-1.338285
2025-10-09 22:16:28,228:INFO:[LightGBM] [Info] Start training from score -1.338285
2025-10-09 22:16:28,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:28,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:28,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:28,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:28,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:28,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:28,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:28,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:28,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:28,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:28,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:28,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:28,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:28,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:28,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:28,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:28,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:28,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:28,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:28,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:28,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:28,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:28,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:28,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:28,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:28,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:28,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:28,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:28,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:28,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:28,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:28,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:28,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:28,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:28,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:28,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:28,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:28,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:28,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:28,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:28,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:28,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:28,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:28,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:28,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:28,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:28,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:28,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:28,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:28,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:28,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:28,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:28,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:28,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:28,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:28,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:28,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:28,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:28,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:28,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:28,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:28,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:28,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:28,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:28,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:28,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:28,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:28,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:28,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:28,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:28,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:28,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:28,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:28,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:28,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:28,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:28,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:28,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:28,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:28,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:28,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:28,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:28,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:28,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:28,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:28,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:28,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:28,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:28,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:28,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:28,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:28,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:28,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:28,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:28,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:28,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:28,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:28,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:28,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:28,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:16:28,265:INFO:Uploading results into container
2025-10-09 22:16:28,266:INFO:Uploading model into container now
2025-10-09 22:16:28,266:INFO:_master_model_container: 16
2025-10-09 22:16:28,266:INFO:_display_container: 4
2025-10-09 22:16:28,267:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best')
2025-10-09 22:16:28,267:INFO:create_model() successfully completed......................................
2025-10-09 22:16:28,441:INFO:SubProcess create_model() end ==================================
2025-10-09 22:16:28,441:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best') result for F1 is 0.3333
2025-10-09 22:16:28,442:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=11, max_features='sqrt', max_leaf_nodes=None,
                       min_impurity_decrease=0.002, min_samples_leaf=5,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best') result for F1 is 0.24
2025-10-09 22:16:28,442:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best') is best model
2025-10-09 22:16:28,442:INFO:choose_better completed
2025-10-09 22:16:28,443:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-10-09 22:16:28,457:INFO:_master_model_container: 16
2025-10-09 22:16:28,457:INFO:_display_container: 3
2025-10-09 22:16:28,458:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best')
2025-10-09 22:16:28,458:INFO:tune_model() successfully completed......................................
2025-10-09 22:16:28,621:INFO:Initializing plot_model()
2025-10-09 22:16:28,621:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EF27BAE490>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best'), plot=pr, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-10-09 22:16:28,621:INFO:Checking exceptions
2025-10-09 22:16:28,625:INFO:Preloading libraries
2025-10-09 22:16:28,626:INFO:Copying training dataset
2025-10-09 22:16:28,626:INFO:Plot type: pr
2025-10-09 22:16:28,782:INFO:Fitting Model
2025-10-09 22:16:28,783:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names
  warnings.warn(

2025-10-09 22:16:28,783:INFO:Scoring test/hold-out set
2025-10-09 22:16:29,031:INFO:Visual Rendered Successfully
2025-10-09 22:16:29,197:INFO:plot_model() successfully completed......................................
2025-10-09 22:16:29,198:INFO:Initializing plot_model()
2025-10-09 22:16:29,198:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EF27BAE490>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best'), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-10-09 22:16:29,198:INFO:Checking exceptions
2025-10-09 22:16:29,204:INFO:Preloading libraries
2025-10-09 22:16:29,204:INFO:Copying training dataset
2025-10-09 22:16:29,204:INFO:Plot type: confusion_matrix
2025-10-09 22:16:29,355:INFO:Fitting Model
2025-10-09 22:16:29,355:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names
  warnings.warn(

2025-10-09 22:16:29,355:INFO:Scoring test/hold-out set
2025-10-09 22:16:29,505:INFO:Visual Rendered Successfully
2025-10-09 22:16:29,665:INFO:plot_model() successfully completed......................................
2025-10-09 22:17:39,878:INFO:Initializing interpret_model()
2025-10-09 22:17:39,880:INFO:interpret_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EF27BAE490>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best'), plot=summary, feature=None, observation=None, use_train_data=False, X_new_sample=None, y_new_sample=None, save=False, kwargs={})
2025-10-09 22:17:39,880:INFO:Checking exceptions
2025-10-09 22:17:39,880:ERROR:
'shap' is a soft dependency and not included in the pycaret installation. Please run: `pip install shap` to install.
Alternately, you can install this by running `pip install pycaret[analysis]`
NoneType: None
2025-10-09 22:23:03,987:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-09 22:23:03,987:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-09 22:23:03,988:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-09 22:23:03,988:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-09 22:23:05,694:INFO:PyCaret ClassificationExperiment
2025-10-09 22:23:05,696:INFO:Logging name: clf-default-name
2025-10-09 22:23:05,696:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-10-09 22:23:05,696:INFO:version 3.3.2
2025-10-09 22:23:05,696:INFO:Initializing setup()
2025-10-09 22:23:05,696:INFO:self.USI: 7ef8
2025-10-09 22:23:05,697:INFO:self._variable_keys: {'_available_plots', 'fold_generator', 'pipeline', 'seed', 'y', 'n_jobs_param', 'memory', '_ml_usecase', 'fold_groups_param', 'log_plots_param', 'gpu_n_jobs_param', 'fold_shuffle_param', 'y_train', 'X_train', 'html_param', 'X_test', 'fix_imbalance', 'data', 'X', 'logging_param', 'USI', 'exp_id', 'exp_name_log', 'gpu_param', 'idx', 'target_param', 'is_multiclass', 'y_test'}
2025-10-09 22:23:05,697:INFO:Checking environment
2025-10-09 22:23:05,697:INFO:python_version: 3.11.0
2025-10-09 22:23:05,697:INFO:python_build: ('main', 'Oct 24 2022 18:26:48')
2025-10-09 22:23:05,697:INFO:machine: AMD64
2025-10-09 22:23:05,697:INFO:platform: Windows-10-10.0.26100-SP0
2025-10-09 22:23:05,705:INFO:Memory: svmem(total=34211835904, available=17577824256, percent=48.6, used=16634011648, free=17577824256)
2025-10-09 22:23:05,705:INFO:Physical Core: 6
2025-10-09 22:23:05,705:INFO:Logical Core: 12
2025-10-09 22:23:05,705:INFO:Checking libraries
2025-10-09 22:23:05,705:INFO:System:
2025-10-09 22:23:05,706:INFO:    python: 3.11.0 (main, Oct 24 2022, 18:26:48) [MSC v.1933 64 bit (AMD64)]
2025-10-09 22:23:05,706:INFO:executable: c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\python.exe
2025-10-09 22:23:05,706:INFO:   machine: Windows-10-10.0.26100-SP0
2025-10-09 22:23:05,706:INFO:PyCaret required dependencies:
2025-10-09 22:23:05,760:INFO:                 pip: 22.3
2025-10-09 22:23:05,760:INFO:          setuptools: 65.5.0
2025-10-09 22:23:05,760:INFO:             pycaret: 3.3.2
2025-10-09 22:23:05,760:INFO:             IPython: 9.6.0
2025-10-09 22:23:05,760:INFO:          ipywidgets: 8.1.7
2025-10-09 22:23:05,760:INFO:                tqdm: 4.67.1
2025-10-09 22:23:05,760:INFO:               numpy: 1.26.4
2025-10-09 22:23:05,760:INFO:              pandas: 2.1.4
2025-10-09 22:23:05,760:INFO:              jinja2: 3.1.6
2025-10-09 22:23:05,761:INFO:               scipy: 1.11.4
2025-10-09 22:23:05,761:INFO:              joblib: 1.3.2
2025-10-09 22:23:05,761:INFO:             sklearn: 1.4.2
2025-10-09 22:23:05,761:INFO:                pyod: 2.0.5
2025-10-09 22:23:05,761:INFO:            imblearn: 0.14.0
2025-10-09 22:23:05,761:INFO:   category_encoders: 2.7.0
2025-10-09 22:23:05,761:INFO:            lightgbm: 4.6.0
2025-10-09 22:23:05,761:INFO:               numba: 0.62.1
2025-10-09 22:23:05,762:INFO:            requests: 2.32.5
2025-10-09 22:23:05,762:INFO:          matplotlib: 3.7.5
2025-10-09 22:23:05,762:INFO:          scikitplot: 0.3.7
2025-10-09 22:23:05,762:INFO:         yellowbrick: 1.5
2025-10-09 22:23:05,762:INFO:              plotly: 6.3.1
2025-10-09 22:23:05,762:INFO:    plotly-resampler: Not installed
2025-10-09 22:23:05,762:INFO:             kaleido: 1.1.0
2025-10-09 22:23:05,762:INFO:           schemdraw: 0.15
2025-10-09 22:23:05,762:INFO:         statsmodels: 0.14.5
2025-10-09 22:23:05,762:INFO:              sktime: 0.26.0
2025-10-09 22:23:05,763:INFO:               tbats: 1.1.3
2025-10-09 22:23:05,763:INFO:            pmdarima: 2.0.4
2025-10-09 22:23:05,763:INFO:              psutil: 7.1.0
2025-10-09 22:23:05,763:INFO:          markupsafe: 3.0.3
2025-10-09 22:23:05,763:INFO:             pickle5: Not installed
2025-10-09 22:23:05,763:INFO:         cloudpickle: 3.1.1
2025-10-09 22:23:05,764:INFO:         deprecation: 2.1.0
2025-10-09 22:23:05,764:INFO:              xxhash: 3.6.0
2025-10-09 22:23:05,764:INFO:           wurlitzer: Not installed
2025-10-09 22:23:05,764:INFO:PyCaret optional dependencies:
2025-10-09 22:23:05,798:INFO:                shap: 0.48.0
2025-10-09 22:23:05,798:INFO:           interpret: Not installed
2025-10-09 22:23:05,798:INFO:                umap: Not installed
2025-10-09 22:23:05,798:INFO:     ydata_profiling: Not installed
2025-10-09 22:23:05,798:INFO:  explainerdashboard: Not installed
2025-10-09 22:23:05,798:INFO:             autoviz: Not installed
2025-10-09 22:23:05,798:INFO:           fairlearn: Not installed
2025-10-09 22:23:05,798:INFO:          deepchecks: Not installed
2025-10-09 22:23:05,798:INFO:             xgboost: Not installed
2025-10-09 22:23:05,798:INFO:            catboost: Not installed
2025-10-09 22:23:05,798:INFO:              kmodes: Not installed
2025-10-09 22:23:05,798:INFO:             mlxtend: Not installed
2025-10-09 22:23:05,798:INFO:       statsforecast: Not installed
2025-10-09 22:23:05,798:INFO:        tune_sklearn: Not installed
2025-10-09 22:23:05,798:INFO:                 ray: Not installed
2025-10-09 22:23:05,798:INFO:            hyperopt: Not installed
2025-10-09 22:23:05,799:INFO:              optuna: Not installed
2025-10-09 22:23:05,799:INFO:               skopt: Not installed
2025-10-09 22:23:05,799:INFO:              mlflow: Not installed
2025-10-09 22:23:05,799:INFO:              gradio: Not installed
2025-10-09 22:23:05,799:INFO:             fastapi: Not installed
2025-10-09 22:23:05,799:INFO:             uvicorn: Not installed
2025-10-09 22:23:05,799:INFO:              m2cgen: Not installed
2025-10-09 22:23:05,799:INFO:           evidently: Not installed
2025-10-09 22:23:05,799:INFO:               fugue: Not installed
2025-10-09 22:23:05,799:INFO:           streamlit: Not installed
2025-10-09 22:23:05,799:INFO:             prophet: Not installed
2025-10-09 22:23:05,800:INFO:None
2025-10-09 22:23:05,800:INFO:Set up data.
2025-10-09 22:23:05,809:INFO:Set up folding strategy.
2025-10-09 22:23:05,809:INFO:Set up train/test split.
2025-10-09 22:23:05,817:INFO:Set up index.
2025-10-09 22:23:05,818:INFO:Assigning column types.
2025-10-09 22:23:05,823:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-09 22:23:05,879:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-09 22:23:05,884:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-09 22:23:05,932:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 22:23:05,932:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 22:23:05,983:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-09 22:23:05,984:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-09 22:23:06,016:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 22:23:06,017:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 22:23:06,017:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-09 22:23:06,077:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-09 22:23:06,113:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 22:23:06,114:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 22:23:06,178:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-09 22:23:06,209:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 22:23:06,209:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 22:23:06,209:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-10-09 22:23:06,284:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 22:23:06,285:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 22:23:06,370:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 22:23:06,371:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 22:23:06,373:INFO:Preparing preprocessing pipeline...
2025-10-09 22:23:06,374:INFO:Set up simple imputation.
2025-10-09 22:23:06,378:INFO:Set up encoding of categorical features.
2025-10-09 22:23:06,379:INFO:Set up removing multicollinearity.
2025-10-09 22:23:06,379:INFO:Set up column transformation.
2025-10-09 22:23:06,379:INFO:Set up feature normalization.
2025-10-09 22:23:06,379:INFO:Set up feature selection.
2025-10-09 22:23:06,488:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 22:23:06,489:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 22:23:06,822:INFO:Finished creating preprocessing pipeline.
2025-10-09 22:23:06,879:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\ARNALDO\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['likes', 'comentarios',
                                             'engagement'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Transf...
                                                                                         learning_rate=0.1,
                                                                                         max_depth=-1,
                                                                                         min_child_samples=20,
                                                                                         min_child_weight=0.001,
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=None,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=1,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf)))],
         verbose=False)
2025-10-09 22:23:06,880:INFO:Creating final display dataframe.
2025-10-09 22:23:07,149:INFO:Setup _display_container:                     Description             Value
0                    Session id              2025
1                        Target        conversion
2                   Target type            Binary
3           Original data shape         (220, 10)
4        Transformed data shape          (220, 2)
5   Transformed train set shape          (154, 2)
6    Transformed test set shape           (66, 2)
7               Ignore features                 2
8              Numeric features                 3
9          Categorical features                 4
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16     Remove multicollinearity              True
17  Multicollinearity threshold               0.9
18               Transformation              True
19        Transformation method       yeo-johnson
20                    Normalize              True
21             Normalize method            zscore
22            Feature selection              True
23     Feature selection method           classic
24  Feature selection estimator          lightgbm
25  Number of features selected               0.2
26               Fold Generator   StratifiedKFold
27                  Fold Number                10
28                     CPU Jobs                -1
29                      Use GPU             False
30               Log Experiment             False
31              Experiment Name  clf-default-name
32                          USI              7ef8
2025-10-09 22:23:07,326:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 22:23:07,327:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 22:23:07,413:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 22:23:07,413:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 22:23:07,416:INFO:setup() successfully completed in 1.72s...............
2025-10-09 22:23:07,428:INFO:Initializing compare_models()
2025-10-09 22:23:07,428:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E251AE7590>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=F1, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001E251AE7590>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'F1', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-10-09 22:23:07,429:INFO:Checking exceptions
2025-10-09 22:23:07,436:INFO:Preparing display monitor
2025-10-09 22:23:07,481:INFO:Initializing Logistic Regression
2025-10-09 22:23:07,481:INFO:Total runtime is 0.0 minutes
2025-10-09 22:23:07,492:INFO:SubProcess create_model() called ==================================
2025-10-09 22:23:07,492:INFO:Initializing create_model()
2025-10-09 22:23:07,492:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E251AE7590>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E251A33590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 22:23:07,492:INFO:Checking exceptions
2025-10-09 22:23:07,493:INFO:Importing libraries
2025-10-09 22:23:07,493:INFO:Copying training dataset
2025-10-09 22:23:07,500:INFO:Defining folds
2025-10-09 22:23:07,500:INFO:Declaring metric variables
2025-10-09 22:23:07,506:INFO:Importing untrained model
2025-10-09 22:23:07,513:INFO:Logistic Regression Imported successfully
2025-10-09 22:23:07,527:INFO:Starting cross validation
2025-10-09 22:23:07,538:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 22:23:18,136:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:23:18,141:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:23:18,157:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:23:18,163:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:23:18,412:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:23:18,415:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:23:18,432:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:23:18,581:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:23:18,623:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:23:18,644:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:23:18,662:INFO:Calculating mean and std
2025-10-09 22:23:18,665:INFO:Creating metrics dataframe
2025-10-09 22:23:18,669:INFO:Uploading results into container
2025-10-09 22:23:18,671:INFO:Uploading model into container now
2025-10-09 22:23:18,672:INFO:_master_model_container: 1
2025-10-09 22:23:18,673:INFO:_display_container: 2
2025-10-09 22:23:18,674:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2025, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-09 22:23:18,674:INFO:create_model() successfully completed......................................
2025-10-09 22:23:18,808:INFO:SubProcess create_model() end ==================================
2025-10-09 22:23:18,808:INFO:Creating metrics dataframe
2025-10-09 22:23:18,816:INFO:Initializing K Neighbors Classifier
2025-10-09 22:23:18,816:INFO:Total runtime is 0.18890974521636963 minutes
2025-10-09 22:23:18,822:INFO:SubProcess create_model() called ==================================
2025-10-09 22:23:18,823:INFO:Initializing create_model()
2025-10-09 22:23:18,823:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E251AE7590>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E251A33590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 22:23:18,823:INFO:Checking exceptions
2025-10-09 22:23:18,823:INFO:Importing libraries
2025-10-09 22:23:18,823:INFO:Copying training dataset
2025-10-09 22:23:18,830:INFO:Defining folds
2025-10-09 22:23:18,830:INFO:Declaring metric variables
2025-10-09 22:23:18,834:INFO:Importing untrained model
2025-10-09 22:23:18,840:INFO:K Neighbors Classifier Imported successfully
2025-10-09 22:23:18,851:INFO:Starting cross validation
2025-10-09 22:23:18,860:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 22:23:19,974:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:23:24,125:INFO:Calculating mean and std
2025-10-09 22:23:24,128:INFO:Creating metrics dataframe
2025-10-09 22:23:24,133:INFO:Uploading results into container
2025-10-09 22:23:24,133:INFO:Uploading model into container now
2025-10-09 22:23:24,134:INFO:_master_model_container: 2
2025-10-09 22:23:24,134:INFO:_display_container: 2
2025-10-09 22:23:24,135:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-10-09 22:23:24,135:INFO:create_model() successfully completed......................................
2025-10-09 22:23:24,281:INFO:SubProcess create_model() end ==================================
2025-10-09 22:23:24,281:INFO:Creating metrics dataframe
2025-10-09 22:23:24,291:INFO:Initializing Naive Bayes
2025-10-09 22:23:24,292:INFO:Total runtime is 0.28018418947855633 minutes
2025-10-09 22:23:24,296:INFO:SubProcess create_model() called ==================================
2025-10-09 22:23:24,297:INFO:Initializing create_model()
2025-10-09 22:23:24,297:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E251AE7590>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E251A33590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 22:23:24,298:INFO:Checking exceptions
2025-10-09 22:23:24,298:INFO:Importing libraries
2025-10-09 22:23:24,298:INFO:Copying training dataset
2025-10-09 22:23:24,303:INFO:Defining folds
2025-10-09 22:23:24,304:INFO:Declaring metric variables
2025-10-09 22:23:24,314:INFO:Importing untrained model
2025-10-09 22:23:24,320:INFO:Naive Bayes Imported successfully
2025-10-09 22:23:24,329:INFO:Starting cross validation
2025-10-09 22:23:24,339:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 22:23:25,172:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:23:25,187:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:23:25,208:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:23:25,215:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:23:25,322:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:23:25,340:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:23:25,350:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:23:25,364:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:23:25,469:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:23:25,476:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:23:25,492:INFO:Calculating mean and std
2025-10-09 22:23:25,493:INFO:Creating metrics dataframe
2025-10-09 22:23:25,496:INFO:Uploading results into container
2025-10-09 22:23:25,496:INFO:Uploading model into container now
2025-10-09 22:23:25,498:INFO:_master_model_container: 3
2025-10-09 22:23:25,498:INFO:_display_container: 2
2025-10-09 22:23:25,498:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-10-09 22:23:25,498:INFO:create_model() successfully completed......................................
2025-10-09 22:23:25,624:INFO:SubProcess create_model() end ==================================
2025-10-09 22:23:25,624:INFO:Creating metrics dataframe
2025-10-09 22:23:25,634:INFO:Initializing Decision Tree Classifier
2025-10-09 22:23:25,634:INFO:Total runtime is 0.3025474905967713 minutes
2025-10-09 22:23:25,638:INFO:SubProcess create_model() called ==================================
2025-10-09 22:23:25,639:INFO:Initializing create_model()
2025-10-09 22:23:25,639:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E251AE7590>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E251A33590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 22:23:25,639:INFO:Checking exceptions
2025-10-09 22:23:25,640:INFO:Importing libraries
2025-10-09 22:23:25,640:INFO:Copying training dataset
2025-10-09 22:23:25,649:INFO:Defining folds
2025-10-09 22:23:25,649:INFO:Declaring metric variables
2025-10-09 22:23:25,653:INFO:Importing untrained model
2025-10-09 22:23:25,661:INFO:Decision Tree Classifier Imported successfully
2025-10-09 22:23:25,670:INFO:Starting cross validation
2025-10-09 22:23:25,681:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 22:23:26,710:INFO:Calculating mean and std
2025-10-09 22:23:26,712:INFO:Creating metrics dataframe
2025-10-09 22:23:26,716:INFO:Uploading results into container
2025-10-09 22:23:26,717:INFO:Uploading model into container now
2025-10-09 22:23:26,718:INFO:_master_model_container: 4
2025-10-09 22:23:26,719:INFO:_display_container: 2
2025-10-09 22:23:26,719:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best')
2025-10-09 22:23:26,719:INFO:create_model() successfully completed......................................
2025-10-09 22:23:26,852:INFO:SubProcess create_model() end ==================================
2025-10-09 22:23:26,852:INFO:Creating metrics dataframe
2025-10-09 22:23:26,863:INFO:Initializing SVM - Linear Kernel
2025-10-09 22:23:26,863:INFO:Total runtime is 0.3230291565259298 minutes
2025-10-09 22:23:26,869:INFO:SubProcess create_model() called ==================================
2025-10-09 22:23:26,870:INFO:Initializing create_model()
2025-10-09 22:23:26,871:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E251AE7590>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E251A33590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 22:23:26,871:INFO:Checking exceptions
2025-10-09 22:23:26,871:INFO:Importing libraries
2025-10-09 22:23:26,871:INFO:Copying training dataset
2025-10-09 22:23:26,877:INFO:Defining folds
2025-10-09 22:23:26,878:INFO:Declaring metric variables
2025-10-09 22:23:26,882:INFO:Importing untrained model
2025-10-09 22:23:26,887:INFO:SVM - Linear Kernel Imported successfully
2025-10-09 22:23:26,898:INFO:Starting cross validation
2025-10-09 22:23:26,908:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 22:23:27,671:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:23:27,694:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:23:27,795:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:23:27,838:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:23:27,927:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:23:27,930:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:23:27,949:INFO:Calculating mean and std
2025-10-09 22:23:27,950:INFO:Creating metrics dataframe
2025-10-09 22:23:27,954:INFO:Uploading results into container
2025-10-09 22:23:27,955:INFO:Uploading model into container now
2025-10-09 22:23:27,956:INFO:_master_model_container: 5
2025-10-09 22:23:27,956:INFO:_display_container: 2
2025-10-09 22:23:27,956:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=2025, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-10-09 22:23:27,957:INFO:create_model() successfully completed......................................
2025-10-09 22:23:28,082:INFO:SubProcess create_model() end ==================================
2025-10-09 22:23:28,083:INFO:Creating metrics dataframe
2025-10-09 22:23:28,092:INFO:Initializing Ridge Classifier
2025-10-09 22:23:28,092:INFO:Total runtime is 0.3435183882713318 minutes
2025-10-09 22:23:28,098:INFO:SubProcess create_model() called ==================================
2025-10-09 22:23:28,098:INFO:Initializing create_model()
2025-10-09 22:23:28,099:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E251AE7590>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E251A33590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 22:23:28,099:INFO:Checking exceptions
2025-10-09 22:23:28,099:INFO:Importing libraries
2025-10-09 22:23:28,099:INFO:Copying training dataset
2025-10-09 22:23:28,104:INFO:Defining folds
2025-10-09 22:23:28,106:INFO:Declaring metric variables
2025-10-09 22:23:28,113:INFO:Importing untrained model
2025-10-09 22:23:28,120:INFO:Ridge Classifier Imported successfully
2025-10-09 22:23:28,130:INFO:Starting cross validation
2025-10-09 22:23:28,140:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 22:23:28,851:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:23:28,862:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:23:28,894:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:23:28,926:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:23:29,000:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:23:29,014:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:23:29,023:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:23:29,057:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:23:29,136:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:23:29,138:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:23:29,155:INFO:Calculating mean and std
2025-10-09 22:23:29,156:INFO:Creating metrics dataframe
2025-10-09 22:23:29,158:INFO:Uploading results into container
2025-10-09 22:23:29,159:INFO:Uploading model into container now
2025-10-09 22:23:29,159:INFO:_master_model_container: 6
2025-10-09 22:23:29,159:INFO:_display_container: 2
2025-10-09 22:23:29,160:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=2025, solver='auto',
                tol=0.0001)
2025-10-09 22:23:29,160:INFO:create_model() successfully completed......................................
2025-10-09 22:23:29,274:INFO:SubProcess create_model() end ==================================
2025-10-09 22:23:29,274:INFO:Creating metrics dataframe
2025-10-09 22:23:29,285:INFO:Initializing Random Forest Classifier
2025-10-09 22:23:29,285:INFO:Total runtime is 0.36339897314707437 minutes
2025-10-09 22:23:29,289:INFO:SubProcess create_model() called ==================================
2025-10-09 22:23:29,289:INFO:Initializing create_model()
2025-10-09 22:23:29,290:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E251AE7590>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E251A33590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 22:23:29,290:INFO:Checking exceptions
2025-10-09 22:23:29,290:INFO:Importing libraries
2025-10-09 22:23:29,290:INFO:Copying training dataset
2025-10-09 22:23:29,296:INFO:Defining folds
2025-10-09 22:23:29,297:INFO:Declaring metric variables
2025-10-09 22:23:29,305:INFO:Importing untrained model
2025-10-09 22:23:29,310:INFO:Random Forest Classifier Imported successfully
2025-10-09 22:23:29,322:INFO:Starting cross validation
2025-10-09 22:23:29,330:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 22:23:31,074:INFO:Calculating mean and std
2025-10-09 22:23:31,075:INFO:Creating metrics dataframe
2025-10-09 22:23:31,081:INFO:Uploading results into container
2025-10-09 22:23:31,083:INFO:Uploading model into container now
2025-10-09 22:23:31,084:INFO:_master_model_container: 7
2025-10-09 22:23:31,085:INFO:_display_container: 2
2025-10-09 22:23:31,086:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=2025, verbose=0,
                       warm_start=False)
2025-10-09 22:23:31,086:INFO:create_model() successfully completed......................................
2025-10-09 22:23:31,222:INFO:SubProcess create_model() end ==================================
2025-10-09 22:23:31,223:INFO:Creating metrics dataframe
2025-10-09 22:23:31,234:INFO:Initializing Quadratic Discriminant Analysis
2025-10-09 22:23:31,234:INFO:Total runtime is 0.39587975740432735 minutes
2025-10-09 22:23:31,241:INFO:SubProcess create_model() called ==================================
2025-10-09 22:23:31,242:INFO:Initializing create_model()
2025-10-09 22:23:31,242:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E251AE7590>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E251A33590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 22:23:31,242:INFO:Checking exceptions
2025-10-09 22:23:31,242:INFO:Importing libraries
2025-10-09 22:23:31,242:INFO:Copying training dataset
2025-10-09 22:23:31,248:INFO:Defining folds
2025-10-09 22:23:31,248:INFO:Declaring metric variables
2025-10-09 22:23:31,255:INFO:Importing untrained model
2025-10-09 22:23:31,262:INFO:Quadratic Discriminant Analysis Imported successfully
2025-10-09 22:23:31,271:INFO:Starting cross validation
2025-10-09 22:23:31,279:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 22:23:32,056:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:23:32,062:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:23:32,101:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:23:32,225:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:23:32,334:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:23:32,358:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:23:32,437:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:23:32,507:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:23:32,524:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:23:32,535:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:23:32,544:INFO:Calculating mean and std
2025-10-09 22:23:32,548:INFO:Creating metrics dataframe
2025-10-09 22:23:32,551:INFO:Uploading results into container
2025-10-09 22:23:32,552:INFO:Uploading model into container now
2025-10-09 22:23:32,553:INFO:_master_model_container: 8
2025-10-09 22:23:32,553:INFO:_display_container: 2
2025-10-09 22:23:32,553:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-10-09 22:23:32,553:INFO:create_model() successfully completed......................................
2025-10-09 22:23:32,685:INFO:SubProcess create_model() end ==================================
2025-10-09 22:23:32,685:INFO:Creating metrics dataframe
2025-10-09 22:23:32,698:INFO:Initializing Ada Boost Classifier
2025-10-09 22:23:32,698:INFO:Total runtime is 0.420271348953247 minutes
2025-10-09 22:23:32,703:INFO:SubProcess create_model() called ==================================
2025-10-09 22:23:32,703:INFO:Initializing create_model()
2025-10-09 22:23:32,703:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E251AE7590>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E251A33590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 22:23:32,704:INFO:Checking exceptions
2025-10-09 22:23:32,704:INFO:Importing libraries
2025-10-09 22:23:32,704:INFO:Copying training dataset
2025-10-09 22:23:32,714:INFO:Defining folds
2025-10-09 22:23:32,714:INFO:Declaring metric variables
2025-10-09 22:23:32,719:INFO:Importing untrained model
2025-10-09 22:23:32,723:INFO:Ada Boost Classifier Imported successfully
2025-10-09 22:23:32,733:INFO:Starting cross validation
2025-10-09 22:23:32,744:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 22:23:33,363:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 22:23:33,371:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 22:23:33,393:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 22:23:33,398:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 22:23:33,875:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 22:23:33,891:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 22:23:33,893:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 22:23:33,929:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 22:23:34,040:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 22:23:34,044:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 22:23:34,240:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:23:34,342:INFO:Calculating mean and std
2025-10-09 22:23:34,343:INFO:Creating metrics dataframe
2025-10-09 22:23:34,349:INFO:Uploading results into container
2025-10-09 22:23:34,352:INFO:Uploading model into container now
2025-10-09 22:23:34,353:INFO:_master_model_container: 9
2025-10-09 22:23:34,353:INFO:_display_container: 2
2025-10-09 22:23:34,353:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2025)
2025-10-09 22:23:34,353:INFO:create_model() successfully completed......................................
2025-10-09 22:23:34,515:INFO:SubProcess create_model() end ==================================
2025-10-09 22:23:34,515:INFO:Creating metrics dataframe
2025-10-09 22:23:34,531:INFO:Initializing Gradient Boosting Classifier
2025-10-09 22:23:34,532:INFO:Total runtime is 0.45084998210271193 minutes
2025-10-09 22:23:34,537:INFO:SubProcess create_model() called ==================================
2025-10-09 22:23:34,538:INFO:Initializing create_model()
2025-10-09 22:23:34,538:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E251AE7590>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E251A33590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 22:23:34,538:INFO:Checking exceptions
2025-10-09 22:23:34,538:INFO:Importing libraries
2025-10-09 22:23:34,538:INFO:Copying training dataset
2025-10-09 22:23:34,544:INFO:Defining folds
2025-10-09 22:23:34,546:INFO:Declaring metric variables
2025-10-09 22:23:34,554:INFO:Importing untrained model
2025-10-09 22:23:34,562:INFO:Gradient Boosting Classifier Imported successfully
2025-10-09 22:23:34,576:INFO:Starting cross validation
2025-10-09 22:23:34,589:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 22:23:36,151:INFO:Calculating mean and std
2025-10-09 22:23:36,152:INFO:Creating metrics dataframe
2025-10-09 22:23:36,155:INFO:Uploading results into container
2025-10-09 22:23:36,155:INFO:Uploading model into container now
2025-10-09 22:23:36,156:INFO:_master_model_container: 10
2025-10-09 22:23:36,156:INFO:_display_container: 2
2025-10-09 22:23:36,156:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2025, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-09 22:23:36,156:INFO:create_model() successfully completed......................................
2025-10-09 22:23:36,295:INFO:SubProcess create_model() end ==================================
2025-10-09 22:23:36,295:INFO:Creating metrics dataframe
2025-10-09 22:23:36,308:INFO:Initializing Linear Discriminant Analysis
2025-10-09 22:23:36,308:INFO:Total runtime is 0.4804394086201985 minutes
2025-10-09 22:23:36,315:INFO:SubProcess create_model() called ==================================
2025-10-09 22:23:36,316:INFO:Initializing create_model()
2025-10-09 22:23:36,316:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E251AE7590>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E251A33590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 22:23:36,318:INFO:Checking exceptions
2025-10-09 22:23:36,318:INFO:Importing libraries
2025-10-09 22:23:36,318:INFO:Copying training dataset
2025-10-09 22:23:36,324:INFO:Defining folds
2025-10-09 22:23:36,325:INFO:Declaring metric variables
2025-10-09 22:23:36,334:INFO:Importing untrained model
2025-10-09 22:23:36,339:INFO:Linear Discriminant Analysis Imported successfully
2025-10-09 22:23:36,349:INFO:Starting cross validation
2025-10-09 22:23:36,360:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 22:23:37,288:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:23:37,291:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:23:37,317:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:23:37,383:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:23:37,443:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:23:37,463:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:23:37,473:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:23:37,557:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:23:37,565:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:23:37,598:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:23:37,616:INFO:Calculating mean and std
2025-10-09 22:23:37,617:INFO:Creating metrics dataframe
2025-10-09 22:23:37,620:INFO:Uploading results into container
2025-10-09 22:23:37,621:INFO:Uploading model into container now
2025-10-09 22:23:37,622:INFO:_master_model_container: 11
2025-10-09 22:23:37,622:INFO:_display_container: 2
2025-10-09 22:23:37,623:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-09 22:23:37,623:INFO:create_model() successfully completed......................................
2025-10-09 22:23:37,744:INFO:SubProcess create_model() end ==================================
2025-10-09 22:23:37,744:INFO:Creating metrics dataframe
2025-10-09 22:23:37,756:INFO:Initializing Extra Trees Classifier
2025-10-09 22:23:37,756:INFO:Total runtime is 0.5045772751172383 minutes
2025-10-09 22:23:37,764:INFO:SubProcess create_model() called ==================================
2025-10-09 22:23:37,765:INFO:Initializing create_model()
2025-10-09 22:23:37,765:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E251AE7590>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E251A33590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 22:23:37,765:INFO:Checking exceptions
2025-10-09 22:23:37,765:INFO:Importing libraries
2025-10-09 22:23:37,765:INFO:Copying training dataset
2025-10-09 22:23:37,769:INFO:Defining folds
2025-10-09 22:23:37,770:INFO:Declaring metric variables
2025-10-09 22:23:37,777:INFO:Importing untrained model
2025-10-09 22:23:37,783:INFO:Extra Trees Classifier Imported successfully
2025-10-09 22:23:37,794:INFO:Starting cross validation
2025-10-09 22:23:37,802:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 22:23:39,784:INFO:Calculating mean and std
2025-10-09 22:23:39,786:INFO:Creating metrics dataframe
2025-10-09 22:23:39,788:INFO:Uploading results into container
2025-10-09 22:23:39,789:INFO:Uploading model into container now
2025-10-09 22:23:39,791:INFO:_master_model_container: 12
2025-10-09 22:23:39,791:INFO:_display_container: 2
2025-10-09 22:23:39,791:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=2025, verbose=0,
                     warm_start=False)
2025-10-09 22:23:39,791:INFO:create_model() successfully completed......................................
2025-10-09 22:23:39,919:INFO:SubProcess create_model() end ==================================
2025-10-09 22:23:39,919:INFO:Creating metrics dataframe
2025-10-09 22:23:39,931:INFO:Initializing Light Gradient Boosting Machine
2025-10-09 22:23:39,932:INFO:Total runtime is 0.5408454259236652 minutes
2025-10-09 22:23:39,938:INFO:SubProcess create_model() called ==================================
2025-10-09 22:23:39,938:INFO:Initializing create_model()
2025-10-09 22:23:39,939:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E251AE7590>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E251A33590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 22:23:39,939:INFO:Checking exceptions
2025-10-09 22:23:39,939:INFO:Importing libraries
2025-10-09 22:23:39,939:INFO:Copying training dataset
2025-10-09 22:23:39,945:INFO:Defining folds
2025-10-09 22:23:39,945:INFO:Declaring metric variables
2025-10-09 22:23:39,952:INFO:Importing untrained model
2025-10-09 22:23:39,958:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-09 22:23:39,969:INFO:Starting cross validation
2025-10-09 22:23:39,977:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 22:23:41,185:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:23:41,204:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:23:41,303:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:23:41,374:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:23:41,509:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:23:41,570:INFO:Calculating mean and std
2025-10-09 22:23:41,572:INFO:Creating metrics dataframe
2025-10-09 22:23:41,577:INFO:Uploading results into container
2025-10-09 22:23:41,579:INFO:Uploading model into container now
2025-10-09 22:23:41,580:INFO:_master_model_container: 13
2025-10-09 22:23:41,581:INFO:_display_container: 2
2025-10-09 22:23:41,582:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2025, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-09 22:23:41,583:INFO:create_model() successfully completed......................................
2025-10-09 22:23:41,731:INFO:SubProcess create_model() end ==================================
2025-10-09 22:23:41,732:INFO:Creating metrics dataframe
2025-10-09 22:23:41,749:INFO:Initializing Dummy Classifier
2025-10-09 22:23:41,749:INFO:Total runtime is 0.5711275299390156 minutes
2025-10-09 22:23:41,754:INFO:SubProcess create_model() called ==================================
2025-10-09 22:23:41,754:INFO:Initializing create_model()
2025-10-09 22:23:41,755:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E251AE7590>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E251A33590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 22:23:41,755:INFO:Checking exceptions
2025-10-09 22:23:41,755:INFO:Importing libraries
2025-10-09 22:23:41,755:INFO:Copying training dataset
2025-10-09 22:23:41,761:INFO:Defining folds
2025-10-09 22:23:41,762:INFO:Declaring metric variables
2025-10-09 22:23:41,769:INFO:Importing untrained model
2025-10-09 22:23:41,774:INFO:Dummy Classifier Imported successfully
2025-10-09 22:23:41,782:INFO:Starting cross validation
2025-10-09 22:23:41,791:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 22:23:42,492:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:23:42,503:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:23:42,505:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:23:42,550:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:23:42,614:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:23:42,629:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:23:42,648:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:23:42,688:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:23:42,746:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:23:42,775:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:23:42,786:INFO:Calculating mean and std
2025-10-09 22:23:42,787:INFO:Creating metrics dataframe
2025-10-09 22:23:42,789:INFO:Uploading results into container
2025-10-09 22:23:42,789:INFO:Uploading model into container now
2025-10-09 22:23:42,790:INFO:_master_model_container: 14
2025-10-09 22:23:42,790:INFO:_display_container: 2
2025-10-09 22:23:42,790:INFO:DummyClassifier(constant=None, random_state=2025, strategy='prior')
2025-10-09 22:23:42,791:INFO:create_model() successfully completed......................................
2025-10-09 22:23:42,920:INFO:SubProcess create_model() end ==================================
2025-10-09 22:23:42,920:INFO:Creating metrics dataframe
2025-10-09 22:23:42,938:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-10-09 22:23:42,969:INFO:Initializing create_model()
2025-10-09 22:23:42,970:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E251AE7590>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 22:23:42,970:INFO:Checking exceptions
2025-10-09 22:23:42,973:INFO:Importing libraries
2025-10-09 22:23:42,973:INFO:Copying training dataset
2025-10-09 22:23:42,983:INFO:Defining folds
2025-10-09 22:23:42,983:INFO:Declaring metric variables
2025-10-09 22:23:42,983:INFO:Importing untrained model
2025-10-09 22:23:42,984:INFO:Declaring custom model
2025-10-09 22:23:42,985:INFO:Decision Tree Classifier Imported successfully
2025-10-09 22:23:43,012:INFO:Cross validation set to False
2025-10-09 22:23:43,012:INFO:Fitting Model
2025-10-09 22:23:43,288:INFO:[LightGBM] [Info] Number of positive: 32, number of negative: 122
2025-10-09 22:23:43,289:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000094 seconds.
2025-10-09 22:23:43,289:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-09 22:23:43,289:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-09 22:23:43,290:INFO:[LightGBM] [Info] Total Bins 186
2025-10-09 22:23:43,290:INFO:[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 14
2025-10-09 22:23:43,290:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.207792 -> initscore=-1.338285
2025-10-09 22:23:43,291:INFO:[LightGBM] [Info] Start training from score -1.338285
2025-10-09 22:23:43,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:43,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:43,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:43,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:43,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:43,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:43,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:43,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:43,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:43,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:43,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:43,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:43,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:43,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:43,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:43,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:43,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:43,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:43,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:43,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:43,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:43,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:43,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:43,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:43,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:43,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:43,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:43,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:43,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:43,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:43,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:43,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:43,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:43,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:43,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:43,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:43,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:43,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:43,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:43,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:43,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:43,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:43,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:43,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:43,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:43,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:43,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:43,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:43,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:43,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:43,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:43,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:43,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:43,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:43,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:43,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:43,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:43,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:43,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:43,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:43,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:43,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:43,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:43,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:43,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:43,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:43,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:43,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:43,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:43,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:43,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:43,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:43,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:43,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:43,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:43,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:43,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:43,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:43,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:43,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:43,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:43,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:43,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:43,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:43,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:43,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:43,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:43,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:43,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:43,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:43,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:43,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:43,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:43,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:43,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:43,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:43,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:43,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:43,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:43,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:43,340:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best')
2025-10-09 22:23:43,340:INFO:create_model() successfully completed......................................
2025-10-09 22:23:43,508:INFO:_master_model_container: 14
2025-10-09 22:23:43,508:INFO:_display_container: 2
2025-10-09 22:23:43,508:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best')
2025-10-09 22:23:43,508:INFO:compare_models() successfully completed......................................
2025-10-09 22:23:43,531:INFO:Initializing tune_model()
2025-10-09 22:23:43,531:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E251AE7590>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best'), fold=None, round=4, n_iter=10, custom_grid=None, optimize=F1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-10-09 22:23:43,531:INFO:Checking exceptions
2025-10-09 22:23:43,558:INFO:Copying training dataset
2025-10-09 22:23:43,564:INFO:Checking base model
2025-10-09 22:23:43,566:INFO:Base model : Decision Tree Classifier
2025-10-09 22:23:43,572:INFO:Declaring metric variables
2025-10-09 22:23:43,579:INFO:Defining Hyperparameters
2025-10-09 22:23:43,748:INFO:Tuning with n_jobs=-1
2025-10-09 22:23:43,748:INFO:Initializing RandomizedSearchCV
2025-10-09 22:23:55,161:INFO:best_params: {'actual_estimator__min_samples_split': 9, 'actual_estimator__min_samples_leaf': 5, 'actual_estimator__min_impurity_decrease': 0.002, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 11, 'actual_estimator__criterion': 'gini'}
2025-10-09 22:23:55,165:INFO:Hyperparameter search completed
2025-10-09 22:23:55,166:INFO:SubProcess create_model() called ==================================
2025-10-09 22:23:55,168:INFO:Initializing create_model()
2025-10-09 22:23:55,168:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E251AE7590>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E251A0C390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'min_samples_split': 9, 'min_samples_leaf': 5, 'min_impurity_decrease': 0.002, 'max_features': 'sqrt', 'max_depth': 11, 'criterion': 'gini'})
2025-10-09 22:23:55,169:INFO:Checking exceptions
2025-10-09 22:23:55,169:INFO:Importing libraries
2025-10-09 22:23:55,169:INFO:Copying training dataset
2025-10-09 22:23:55,177:INFO:Defining folds
2025-10-09 22:23:55,177:INFO:Declaring metric variables
2025-10-09 22:23:55,183:INFO:Importing untrained model
2025-10-09 22:23:55,183:INFO:Declaring custom model
2025-10-09 22:23:55,187:INFO:Decision Tree Classifier Imported successfully
2025-10-09 22:23:55,197:INFO:Starting cross validation
2025-10-09 22:23:55,244:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 22:23:55,951:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 22:23:56,222:INFO:Calculating mean and std
2025-10-09 22:23:56,223:INFO:Creating metrics dataframe
2025-10-09 22:23:56,231:INFO:Finalizing model
2025-10-09 22:23:56,374:INFO:[LightGBM] [Info] Number of positive: 32, number of negative: 122
2025-10-09 22:23:56,376:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000176 seconds.
2025-10-09 22:23:56,376:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-10-09 22:23:56,376:INFO:[LightGBM] [Info] Total Bins 186
2025-10-09 22:23:56,376:INFO:[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 14
2025-10-09 22:23:56,376:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.207792 -> initscore=-1.338285
2025-10-09 22:23:56,378:INFO:[LightGBM] [Info] Start training from score -1.338285
2025-10-09 22:23:56,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:56,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:56,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:56,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:56,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:56,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:56,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:56,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:56,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:56,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:56,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:56,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:56,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:56,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:56,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:56,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:56,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:56,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:56,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:56,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:56,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:56,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:56,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:56,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:56,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:56,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:56,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:56,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:56,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:56,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:56,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:56,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:56,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:56,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:56,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:56,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:56,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:56,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:56,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:56,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:56,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:56,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:56,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:56,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:56,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:56,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:56,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:56,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:56,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:56,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:56,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:56,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:56,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:56,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:56,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:56,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:56,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:56,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:56,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:56,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:56,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:56,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:56,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:56,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:56,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:56,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:56,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:56,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:56,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:56,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:56,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:56,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:56,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:56,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:56,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:56,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:56,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:56,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:56,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:56,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:56,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:56,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:56,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:56,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:56,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:56,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:56,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:56,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:56,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:56,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:56,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:56,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:56,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:56,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:56,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:56,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:56,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:56,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:56,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:56,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:56,439:INFO:Uploading results into container
2025-10-09 22:23:56,440:INFO:Uploading model into container now
2025-10-09 22:23:56,442:INFO:_master_model_container: 15
2025-10-09 22:23:56,442:INFO:_display_container: 3
2025-10-09 22:23:56,443:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=11, max_features='sqrt', max_leaf_nodes=None,
                       min_impurity_decrease=0.002, min_samples_leaf=5,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best')
2025-10-09 22:23:56,443:INFO:create_model() successfully completed......................................
2025-10-09 22:23:56,582:INFO:SubProcess create_model() end ==================================
2025-10-09 22:23:56,582:INFO:choose_better activated
2025-10-09 22:23:56,586:INFO:SubProcess create_model() called ==================================
2025-10-09 22:23:56,586:INFO:Initializing create_model()
2025-10-09 22:23:56,586:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E251AE7590>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 22:23:56,587:INFO:Checking exceptions
2025-10-09 22:23:56,588:INFO:Importing libraries
2025-10-09 22:23:56,589:INFO:Copying training dataset
2025-10-09 22:23:56,592:INFO:Defining folds
2025-10-09 22:23:56,593:INFO:Declaring metric variables
2025-10-09 22:23:56,593:INFO:Importing untrained model
2025-10-09 22:23:56,593:INFO:Declaring custom model
2025-10-09 22:23:56,593:INFO:Decision Tree Classifier Imported successfully
2025-10-09 22:23:56,594:INFO:Starting cross validation
2025-10-09 22:23:56,599:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 22:23:57,521:INFO:Calculating mean and std
2025-10-09 22:23:57,523:INFO:Creating metrics dataframe
2025-10-09 22:23:57,526:INFO:Finalizing model
2025-10-09 22:23:57,651:INFO:[LightGBM] [Info] Number of positive: 32, number of negative: 122
2025-10-09 22:23:57,651:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000077 seconds.
2025-10-09 22:23:57,651:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-09 22:23:57,652:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-09 22:23:57,652:INFO:[LightGBM] [Info] Total Bins 186
2025-10-09 22:23:57,652:INFO:[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 14
2025-10-09 22:23:57,652:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.207792 -> initscore=-1.338285
2025-10-09 22:23:57,652:INFO:[LightGBM] [Info] Start training from score -1.338285
2025-10-09 22:23:57,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:57,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:57,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:57,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:57,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:57,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:57,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:57,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:57,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:57,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:57,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:57,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:57,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:57,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:57,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:57,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:57,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:57,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:57,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:57,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:57,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:57,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:57,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:57,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:57,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:57,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:57,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:57,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:57,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:57,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:57,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:57,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:57,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:57,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:57,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:57,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:57,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:57,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:57,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:57,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:57,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:57,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:57,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:57,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:57,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:57,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:57,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:57,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:57,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:57,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:57,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:57,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:57,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:57,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:57,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:57,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:57,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:57,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:57,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:57,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:57,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:57,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:57,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:57,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:57,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:57,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:57,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:57,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:57,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:57,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:57,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:57,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:57,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:57,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:57,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:57,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:57,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:57,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:57,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:57,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:57,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:57,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:57,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:57,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:57,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:57,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:57,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:57,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:57,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:57,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:57,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:57,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:57,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:57,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:57,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:57,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:57,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:57,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:57,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:57,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:23:57,692:INFO:Uploading results into container
2025-10-09 22:23:57,694:INFO:Uploading model into container now
2025-10-09 22:23:57,695:INFO:_master_model_container: 16
2025-10-09 22:23:57,695:INFO:_display_container: 4
2025-10-09 22:23:57,696:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best')
2025-10-09 22:23:57,696:INFO:create_model() successfully completed......................................
2025-10-09 22:23:57,829:INFO:SubProcess create_model() end ==================================
2025-10-09 22:23:57,830:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best') result for F1 is 0.3333
2025-10-09 22:23:57,830:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=11, max_features='sqrt', max_leaf_nodes=None,
                       min_impurity_decrease=0.002, min_samples_leaf=5,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best') result for F1 is 0.24
2025-10-09 22:23:57,831:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best') is best model
2025-10-09 22:23:57,831:INFO:choose_better completed
2025-10-09 22:23:57,831:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-10-09 22:23:57,844:INFO:_master_model_container: 16
2025-10-09 22:23:57,844:INFO:_display_container: 3
2025-10-09 22:23:57,845:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best')
2025-10-09 22:23:57,845:INFO:tune_model() successfully completed......................................
2025-10-09 22:23:57,962:INFO:Initializing plot_model()
2025-10-09 22:23:57,962:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E251AE7590>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best'), plot=pr, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-10-09 22:23:57,962:INFO:Checking exceptions
2025-10-09 22:23:57,966:INFO:Preloading libraries
2025-10-09 22:23:57,966:INFO:Copying training dataset
2025-10-09 22:23:57,966:INFO:Plot type: pr
2025-10-09 22:23:58,127:INFO:Fitting Model
2025-10-09 22:23:58,129:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names
  warnings.warn(

2025-10-09 22:23:58,130:INFO:Scoring test/hold-out set
2025-10-09 22:23:58,367:INFO:Visual Rendered Successfully
2025-10-09 22:23:58,472:INFO:plot_model() successfully completed......................................
2025-10-09 22:23:58,473:INFO:Initializing plot_model()
2025-10-09 22:23:58,473:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E251AE7590>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best'), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-10-09 22:23:58,473:INFO:Checking exceptions
2025-10-09 22:23:58,479:INFO:Preloading libraries
2025-10-09 22:23:58,479:INFO:Copying training dataset
2025-10-09 22:23:58,480:INFO:Plot type: confusion_matrix
2025-10-09 22:23:58,647:INFO:Fitting Model
2025-10-09 22:23:58,647:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names
  warnings.warn(

2025-10-09 22:23:58,649:INFO:Scoring test/hold-out set
2025-10-09 22:23:58,820:INFO:Visual Rendered Successfully
2025-10-09 22:23:58,940:INFO:plot_model() successfully completed......................................
2025-10-09 22:23:58,971:INFO:Initializing create_model()
2025-10-09 22:23:58,971:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E251AE7590>, estimator=rf, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 22:23:58,972:INFO:Checking exceptions
2025-10-09 22:23:58,995:INFO:Importing libraries
2025-10-09 22:23:58,995:INFO:Copying training dataset
2025-10-09 22:23:59,006:INFO:Defining folds
2025-10-09 22:23:59,007:INFO:Declaring metric variables
2025-10-09 22:23:59,012:INFO:Importing untrained model
2025-10-09 22:23:59,019:INFO:Random Forest Classifier Imported successfully
2025-10-09 22:23:59,029:INFO:Starting cross validation
2025-10-09 22:23:59,036:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 22:24:00,765:INFO:Calculating mean and std
2025-10-09 22:24:00,766:INFO:Creating metrics dataframe
2025-10-09 22:24:00,771:INFO:Finalizing model
2025-10-09 22:24:00,877:INFO:[LightGBM] [Info] Number of positive: 32, number of negative: 122
2025-10-09 22:24:00,877:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000053 seconds.
2025-10-09 22:24:00,877:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-10-09 22:24:00,877:INFO:[LightGBM] [Info] Total Bins 186
2025-10-09 22:24:00,877:INFO:[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 14
2025-10-09 22:24:00,877:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.207792 -> initscore=-1.338285
2025-10-09 22:24:00,877:INFO:[LightGBM] [Info] Start training from score -1.338285
2025-10-09 22:24:00,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:24:00,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:24:00,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:24:00,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:24:00,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:24:00,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:24:00,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:24:00,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:24:00,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:24:00,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:24:00,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:24:00,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:24:00,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:24:00,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:24:00,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:24:00,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:24:00,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:24:00,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:24:00,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:24:00,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:24:00,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:24:00,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:24:00,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:24:00,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:24:00,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:24:00,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:24:00,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:24:00,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:24:00,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:24:00,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:24:00,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:24:00,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:24:00,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:24:00,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:24:00,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:24:00,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:24:00,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:24:00,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:24:00,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:24:00,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:24:00,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:24:00,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:24:00,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:24:00,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:24:00,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:24:00,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:24:00,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:24:00,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:24:00,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:24:00,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:24:00,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:24:00,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:24:00,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:24:00,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:24:00,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:24:00,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:24:00,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:24:00,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:24:00,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:24:00,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:24:00,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:24:00,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:24:00,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:24:00,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:24:00,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:24:00,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:24:00,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:24:00,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:24:00,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:24:00,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:24:00,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:24:00,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:24:00,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:24:00,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:24:00,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:24:00,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:24:00,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:24:00,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:24:00,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:24:00,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:24:00,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:24:00,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:24:00,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:24:00,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:24:00,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:24:00,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:24:00,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:24:00,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:24:00,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:24:00,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:24:00,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:24:00,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:24:00,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:24:00,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:24:00,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:24:00,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:24:00,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:24:00,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:24:00,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:24:00,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 22:24:01,120:INFO:Uploading results into container
2025-10-09 22:24:01,121:INFO:Uploading model into container now
2025-10-09 22:24:01,136:INFO:_master_model_container: 17
2025-10-09 22:24:01,137:INFO:_display_container: 4
2025-10-09 22:24:01,137:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=2025, verbose=0,
                       warm_start=False)
2025-10-09 22:24:01,137:INFO:create_model() successfully completed......................................
2025-10-09 22:24:19,521:INFO:Initializing interpret_model()
2025-10-09 22:24:19,521:INFO:interpret_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E251AE7590>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=2025, verbose=0,
                       warm_start=False), plot=summary, feature=None, observation=None, use_train_data=False, X_new_sample=None, y_new_sample=None, save=False, kwargs={})
2025-10-09 22:24:19,521:INFO:Checking exceptions
2025-10-09 22:24:19,521:INFO:Soft dependency imported: shap: 0.48.0
2025-10-09 22:24:19,573:INFO:plot type: summary
2025-10-09 22:24:19,574:INFO:Creating TreeExplainer
2025-10-09 22:24:19,586:INFO:Compiling shap values
2025-10-09 22:24:19,622:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:4145: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.
  shap_plot = shap.summary_plot(shap_values, test_X, show=show, **kwargs)

2025-10-09 22:27:14,276:INFO:Initializing interpret_model()
2025-10-09 22:27:14,276:INFO:interpret_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E251AE7590>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=2025, verbose=0,
                       warm_start=False), plot=summary, feature=None, observation=None, use_train_data=False, X_new_sample=None, y_new_sample=None, save=False, kwargs={})
2025-10-09 22:27:14,276:INFO:Checking exceptions
2025-10-09 22:27:14,276:INFO:Soft dependency imported: shap: 0.48.0
2025-10-09 22:27:14,304:INFO:plot type: summary
2025-10-09 22:27:14,304:INFO:Creating TreeExplainer
2025-10-09 22:27:14,308:INFO:Compiling shap values
2025-10-09 22:27:14,330:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:4145: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.
  shap_plot = shap.summary_plot(shap_values, test_X, show=show, **kwargs)

2025-10-11 14:13:26,980:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-11 14:13:26,980:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-11 14:13:26,980:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-11 14:13:26,980:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-11 14:13:48,266:INFO:PyCaret ClassificationExperiment
2025-10-11 14:13:48,267:INFO:Logging name: clf-default-name
2025-10-11 14:13:48,267:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-10-11 14:13:48,267:INFO:version 3.3.2
2025-10-11 14:13:48,267:INFO:Initializing setup()
2025-10-11 14:13:48,267:INFO:self.USI: c291
2025-10-11 14:13:48,267:INFO:self._variable_keys: {'idx', 'fold_shuffle_param', 'y', 'X', 'fold_groups_param', 'fix_imbalance', 'exp_name_log', 'fold_generator', 'gpu_n_jobs_param', 'X_test', 'USI', 'memory', 'gpu_param', 'data', 'html_param', '_ml_usecase', 'is_multiclass', 'seed', 'exp_id', 'pipeline', 'n_jobs_param', 'logging_param', 'log_plots_param', 'X_train', '_available_plots', 'y_test', 'target_param', 'y_train'}
2025-10-11 14:13:48,267:INFO:Checking environment
2025-10-11 14:13:48,267:INFO:python_version: 3.11.0
2025-10-11 14:13:48,268:INFO:python_build: ('main', 'Oct 24 2022 18:26:48')
2025-10-11 14:13:48,268:INFO:machine: AMD64
2025-10-11 14:13:48,268:INFO:platform: Windows-10-10.0.26100-SP0
2025-10-11 14:13:48,272:INFO:Memory: svmem(total=34211835904, available=21367148544, percent=37.5, used=12844687360, free=21367148544)
2025-10-11 14:13:48,272:INFO:Physical Core: 6
2025-10-11 14:13:48,272:INFO:Logical Core: 12
2025-10-11 14:13:48,272:INFO:Checking libraries
2025-10-11 14:13:48,272:INFO:System:
2025-10-11 14:13:48,272:INFO:    python: 3.11.0 (main, Oct 24 2022, 18:26:48) [MSC v.1933 64 bit (AMD64)]
2025-10-11 14:13:48,272:INFO:executable: c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\python.exe
2025-10-11 14:13:48,272:INFO:   machine: Windows-10-10.0.26100-SP0
2025-10-11 14:13:48,272:INFO:PyCaret required dependencies:
2025-10-11 14:13:48,344:INFO:                 pip: 22.3
2025-10-11 14:13:48,344:INFO:          setuptools: 65.5.0
2025-10-11 14:13:48,344:INFO:             pycaret: 3.3.2
2025-10-11 14:13:48,344:INFO:             IPython: 9.6.0
2025-10-11 14:13:48,344:INFO:          ipywidgets: 8.1.7
2025-10-11 14:13:48,344:INFO:                tqdm: 4.67.1
2025-10-11 14:13:48,344:INFO:               numpy: 1.26.4
2025-10-11 14:13:48,344:INFO:              pandas: 2.1.4
2025-10-11 14:13:48,344:INFO:              jinja2: 3.1.6
2025-10-11 14:13:48,344:INFO:               scipy: 1.11.4
2025-10-11 14:13:48,344:INFO:              joblib: 1.3.2
2025-10-11 14:13:48,344:INFO:             sklearn: 1.4.2
2025-10-11 14:13:48,344:INFO:                pyod: 2.0.5
2025-10-11 14:13:48,344:INFO:            imblearn: 0.14.0
2025-10-11 14:13:48,344:INFO:   category_encoders: 2.7.0
2025-10-11 14:13:48,344:INFO:            lightgbm: 4.6.0
2025-10-11 14:13:48,344:INFO:               numba: 0.62.1
2025-10-11 14:13:48,344:INFO:            requests: 2.32.5
2025-10-11 14:13:48,344:INFO:          matplotlib: 3.7.5
2025-10-11 14:13:48,344:INFO:          scikitplot: 0.3.7
2025-10-11 14:13:48,344:INFO:         yellowbrick: 1.5
2025-10-11 14:13:48,344:INFO:              plotly: 6.3.1
2025-10-11 14:13:48,344:INFO:    plotly-resampler: Not installed
2025-10-11 14:13:48,344:INFO:             kaleido: 1.1.0
2025-10-11 14:13:48,344:INFO:           schemdraw: 0.15
2025-10-11 14:13:48,344:INFO:         statsmodels: 0.14.5
2025-10-11 14:13:48,344:INFO:              sktime: 0.26.0
2025-10-11 14:13:48,344:INFO:               tbats: 1.1.3
2025-10-11 14:13:48,344:INFO:            pmdarima: 2.0.4
2025-10-11 14:13:48,344:INFO:              psutil: 7.1.0
2025-10-11 14:13:48,344:INFO:          markupsafe: 3.0.3
2025-10-11 14:13:48,344:INFO:             pickle5: Not installed
2025-10-11 14:13:48,344:INFO:         cloudpickle: 3.1.1
2025-10-11 14:13:48,344:INFO:         deprecation: 2.1.0
2025-10-11 14:13:48,344:INFO:              xxhash: 3.6.0
2025-10-11 14:13:48,344:INFO:           wurlitzer: Not installed
2025-10-11 14:13:48,344:INFO:PyCaret optional dependencies:
2025-10-11 14:13:48,360:INFO:                shap: 0.48.0
2025-10-11 14:13:48,360:INFO:           interpret: Not installed
2025-10-11 14:13:48,360:INFO:                umap: Not installed
2025-10-11 14:13:48,360:INFO:     ydata_profiling: Not installed
2025-10-11 14:13:48,360:INFO:  explainerdashboard: Not installed
2025-10-11 14:13:48,360:INFO:             autoviz: Not installed
2025-10-11 14:13:48,360:INFO:           fairlearn: Not installed
2025-10-11 14:13:48,360:INFO:          deepchecks: Not installed
2025-10-11 14:13:48,360:INFO:             xgboost: Not installed
2025-10-11 14:13:48,360:INFO:            catboost: Not installed
2025-10-11 14:13:48,360:INFO:              kmodes: Not installed
2025-10-11 14:13:48,360:INFO:             mlxtend: Not installed
2025-10-11 14:13:48,360:INFO:       statsforecast: Not installed
2025-10-11 14:13:48,360:INFO:        tune_sklearn: Not installed
2025-10-11 14:13:48,360:INFO:                 ray: Not installed
2025-10-11 14:13:48,360:INFO:            hyperopt: Not installed
2025-10-11 14:13:48,360:INFO:              optuna: Not installed
2025-10-11 14:13:48,360:INFO:               skopt: Not installed
2025-10-11 14:13:48,360:INFO:              mlflow: Not installed
2025-10-11 14:13:48,360:INFO:              gradio: Not installed
2025-10-11 14:13:48,360:INFO:             fastapi: Not installed
2025-10-11 14:13:48,360:INFO:             uvicorn: Not installed
2025-10-11 14:13:48,360:INFO:              m2cgen: Not installed
2025-10-11 14:13:48,360:INFO:           evidently: Not installed
2025-10-11 14:13:48,360:INFO:               fugue: Not installed
2025-10-11 14:13:48,360:INFO:           streamlit: Not installed
2025-10-11 14:13:48,360:INFO:             prophet: Not installed
2025-10-11 14:13:48,360:INFO:None
2025-10-11 14:13:48,360:INFO:Set up data.
2025-10-11 14:13:48,360:INFO:Set up folding strategy.
2025-10-11 14:13:48,360:INFO:Set up train/test split.
2025-10-11 14:13:48,396:INFO:Set up index.
2025-10-11 14:13:48,396:INFO:Assigning column types.
2025-10-11 14:13:48,396:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-11 14:13:48,444:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-11 14:13:48,444:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-11 14:13:48,484:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 14:13:48,484:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 14:13:48,528:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-11 14:13:48,528:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-11 14:13:48,544:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 14:13:48,544:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 14:13:48,544:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-11 14:13:48,596:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-11 14:13:48,613:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 14:13:48,613:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 14:13:48,661:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-11 14:13:48,677:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 14:13:48,677:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 14:13:48,677:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-10-11 14:13:48,745:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 14:13:48,745:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 14:13:48,814:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 14:13:48,814:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 14:13:48,814:INFO:Preparing preprocessing pipeline...
2025-10-11 14:13:48,814:INFO:Set up simple imputation.
2025-10-11 14:13:48,814:INFO:Set up encoding of categorical features.
2025-10-11 14:13:48,814:INFO:Set up removing multicollinearity.
2025-10-11 14:13:48,814:INFO:Set up column transformation.
2025-10-11 14:13:48,814:INFO:Set up feature normalization.
2025-10-11 14:13:48,814:INFO:Set up feature selection.
2025-10-11 14:13:48,883:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 14:13:48,883:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 14:13:49,067:INFO:Finished creating preprocessing pipeline.
2025-10-11 14:13:49,104:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\ARNALDO\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['likes', 'comentarios',
                                             'engagement'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Transf...
                                                                                         learning_rate=0.1,
                                                                                         max_depth=-1,
                                                                                         min_child_samples=20,
                                                                                         min_child_weight=0.001,
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=None,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=1,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf)))],
         verbose=False)
2025-10-11 14:13:49,104:INFO:Creating final display dataframe.
2025-10-11 14:13:49,360:INFO:Setup _display_container:                     Description             Value
0                    Session id              2025
1                        Target        conversion
2                   Target type            Binary
3           Original data shape         (220, 10)
4        Transformed data shape          (220, 2)
5   Transformed train set shape          (154, 2)
6    Transformed test set shape           (66, 2)
7               Ignore features                 2
8              Numeric features                 3
9          Categorical features                 4
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16     Remove multicollinearity              True
17  Multicollinearity threshold               0.9
18               Transformation              True
19        Transformation method       yeo-johnson
20                    Normalize              True
21             Normalize method            zscore
22            Feature selection              True
23     Feature selection method           classic
24  Feature selection estimator          lightgbm
25  Number of features selected               0.2
26               Fold Generator   StratifiedKFold
27                  Fold Number                10
28                     CPU Jobs                -1
29                      Use GPU             False
30               Log Experiment             False
31              Experiment Name  clf-default-name
32                          USI              c291
2025-10-11 14:13:49,483:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 14:13:49,498:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 14:13:49,565:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 14:13:49,565:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 14:13:49,565:INFO:setup() successfully completed in 1.31s...............
2025-10-11 14:13:53,528:INFO:Initializing compare_models()
2025-10-11 14:13:53,528:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012CFFE7DF90>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=F1, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000012CFFE7DF90>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'F1', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-10-11 14:13:53,528:INFO:Checking exceptions
2025-10-11 14:13:53,545:INFO:Preparing display monitor
2025-10-11 14:13:53,573:INFO:Initializing Logistic Regression
2025-10-11 14:13:53,573:INFO:Total runtime is 0.0 minutes
2025-10-11 14:13:53,578:INFO:SubProcess create_model() called ==================================
2025-10-11 14:13:53,578:INFO:Initializing create_model()
2025-10-11 14:13:53,578:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012CFFE7DF90>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012CFFE7C190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-11 14:13:53,578:INFO:Checking exceptions
2025-10-11 14:13:53,579:INFO:Importing libraries
2025-10-11 14:13:53,579:INFO:Copying training dataset
2025-10-11 14:13:53,584:INFO:Defining folds
2025-10-11 14:13:53,584:INFO:Declaring metric variables
2025-10-11 14:13:53,589:INFO:Importing untrained model
2025-10-11 14:13:53,595:INFO:Logistic Regression Imported successfully
2025-10-11 14:13:53,607:INFO:Starting cross validation
2025-10-11 14:13:53,618:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-11 14:14:00,747:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 14:14:00,748:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 14:14:00,776:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 14:14:00,776:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 14:14:00,870:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 14:14:00,899:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 14:14:00,981:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 14:14:01,027:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 14:14:01,049:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 14:14:01,063:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 14:14:01,070:INFO:Calculating mean and std
2025-10-11 14:14:01,070:INFO:Creating metrics dataframe
2025-10-11 14:14:01,070:INFO:Uploading results into container
2025-10-11 14:14:01,070:INFO:Uploading model into container now
2025-10-11 14:14:01,076:INFO:_master_model_container: 1
2025-10-11 14:14:01,076:INFO:_display_container: 2
2025-10-11 14:14:01,077:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2025, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-11 14:14:01,077:INFO:create_model() successfully completed......................................
2025-10-11 14:14:01,165:INFO:SubProcess create_model() end ==================================
2025-10-11 14:14:01,165:INFO:Creating metrics dataframe
2025-10-11 14:14:01,179:INFO:Initializing K Neighbors Classifier
2025-10-11 14:14:01,179:INFO:Total runtime is 0.12676601409912108 minutes
2025-10-11 14:14:01,182:INFO:SubProcess create_model() called ==================================
2025-10-11 14:14:01,182:INFO:Initializing create_model()
2025-10-11 14:14:01,182:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012CFFE7DF90>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012CFFE7C190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-11 14:14:01,182:INFO:Checking exceptions
2025-10-11 14:14:01,182:INFO:Importing libraries
2025-10-11 14:14:01,182:INFO:Copying training dataset
2025-10-11 14:14:01,187:INFO:Defining folds
2025-10-11 14:14:01,187:INFO:Declaring metric variables
2025-10-11 14:14:01,193:INFO:Importing untrained model
2025-10-11 14:14:01,197:INFO:K Neighbors Classifier Imported successfully
2025-10-11 14:14:01,199:INFO:Starting cross validation
2025-10-11 14:14:01,211:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-11 14:14:02,110:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 14:14:04,915:INFO:Calculating mean and std
2025-10-11 14:14:04,915:INFO:Creating metrics dataframe
2025-10-11 14:14:04,915:INFO:Uploading results into container
2025-10-11 14:14:04,915:INFO:Uploading model into container now
2025-10-11 14:14:04,915:INFO:_master_model_container: 2
2025-10-11 14:14:04,915:INFO:_display_container: 2
2025-10-11 14:14:04,921:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-10-11 14:14:04,921:INFO:create_model() successfully completed......................................
2025-10-11 14:14:04,996:INFO:SubProcess create_model() end ==================================
2025-10-11 14:14:04,996:INFO:Creating metrics dataframe
2025-10-11 14:14:05,009:INFO:Initializing Naive Bayes
2025-10-11 14:14:05,009:INFO:Total runtime is 0.1906030774116516 minutes
2025-10-11 14:14:05,009:INFO:SubProcess create_model() called ==================================
2025-10-11 14:14:05,009:INFO:Initializing create_model()
2025-10-11 14:14:05,009:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012CFFE7DF90>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012CFFE7C190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-11 14:14:05,009:INFO:Checking exceptions
2025-10-11 14:14:05,009:INFO:Importing libraries
2025-10-11 14:14:05,009:INFO:Copying training dataset
2025-10-11 14:14:05,009:INFO:Defining folds
2025-10-11 14:14:05,024:INFO:Declaring metric variables
2025-10-11 14:14:05,025:INFO:Importing untrained model
2025-10-11 14:14:05,032:INFO:Naive Bayes Imported successfully
2025-10-11 14:14:05,034:INFO:Starting cross validation
2025-10-11 14:14:05,047:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-11 14:14:05,518:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 14:14:05,537:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 14:14:05,561:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 14:14:05,580:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 14:14:05,622:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 14:14:05,682:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 14:14:05,716:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 14:14:05,726:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 14:14:05,746:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 14:14:05,786:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 14:14:05,797:INFO:Calculating mean and std
2025-10-11 14:14:05,797:INFO:Creating metrics dataframe
2025-10-11 14:14:05,799:INFO:Uploading results into container
2025-10-11 14:14:05,801:INFO:Uploading model into container now
2025-10-11 14:14:05,801:INFO:_master_model_container: 3
2025-10-11 14:14:05,801:INFO:_display_container: 2
2025-10-11 14:14:05,801:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-10-11 14:14:05,801:INFO:create_model() successfully completed......................................
2025-10-11 14:14:05,874:INFO:SubProcess create_model() end ==================================
2025-10-11 14:14:05,874:INFO:Creating metrics dataframe
2025-10-11 14:14:05,889:INFO:Initializing Decision Tree Classifier
2025-10-11 14:14:05,889:INFO:Total runtime is 0.2052823781967163 minutes
2025-10-11 14:14:05,889:INFO:SubProcess create_model() called ==================================
2025-10-11 14:14:05,889:INFO:Initializing create_model()
2025-10-11 14:14:05,889:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012CFFE7DF90>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012CFFE7C190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-11 14:14:05,889:INFO:Checking exceptions
2025-10-11 14:14:05,889:INFO:Importing libraries
2025-10-11 14:14:05,889:INFO:Copying training dataset
2025-10-11 14:14:05,889:INFO:Defining folds
2025-10-11 14:14:05,889:INFO:Declaring metric variables
2025-10-11 14:14:05,889:INFO:Importing untrained model
2025-10-11 14:14:05,908:INFO:Decision Tree Classifier Imported successfully
2025-10-11 14:14:05,917:INFO:Starting cross validation
2025-10-11 14:14:05,924:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-11 14:14:06,708:INFO:Calculating mean and std
2025-10-11 14:14:06,708:INFO:Creating metrics dataframe
2025-10-11 14:14:06,710:INFO:Uploading results into container
2025-10-11 14:14:06,712:INFO:Uploading model into container now
2025-10-11 14:14:06,712:INFO:_master_model_container: 4
2025-10-11 14:14:06,712:INFO:_display_container: 2
2025-10-11 14:14:06,712:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best')
2025-10-11 14:14:06,712:INFO:create_model() successfully completed......................................
2025-10-11 14:14:06,775:INFO:SubProcess create_model() end ==================================
2025-10-11 14:14:06,775:INFO:Creating metrics dataframe
2025-10-11 14:14:06,793:INFO:Initializing SVM - Linear Kernel
2025-10-11 14:14:06,793:INFO:Total runtime is 0.22034624417622883 minutes
2025-10-11 14:14:06,795:INFO:SubProcess create_model() called ==================================
2025-10-11 14:14:06,795:INFO:Initializing create_model()
2025-10-11 14:14:06,795:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012CFFE7DF90>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012CFFE7C190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-11 14:14:06,795:INFO:Checking exceptions
2025-10-11 14:14:06,795:INFO:Importing libraries
2025-10-11 14:14:06,795:INFO:Copying training dataset
2025-10-11 14:14:06,800:INFO:Defining folds
2025-10-11 14:14:06,800:INFO:Declaring metric variables
2025-10-11 14:14:06,802:INFO:Importing untrained model
2025-10-11 14:14:06,802:INFO:SVM - Linear Kernel Imported successfully
2025-10-11 14:14:06,813:INFO:Starting cross validation
2025-10-11 14:14:06,821:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-11 14:14:07,356:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 14:14:07,380:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 14:14:07,538:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 14:14:07,583:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 14:14:07,589:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 14:14:07,632:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 14:14:07,650:INFO:Calculating mean and std
2025-10-11 14:14:07,650:INFO:Creating metrics dataframe
2025-10-11 14:14:07,655:INFO:Uploading results into container
2025-10-11 14:14:07,655:INFO:Uploading model into container now
2025-10-11 14:14:07,655:INFO:_master_model_container: 5
2025-10-11 14:14:07,657:INFO:_display_container: 2
2025-10-11 14:14:07,658:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=2025, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-10-11 14:14:07,658:INFO:create_model() successfully completed......................................
2025-10-11 14:14:07,727:INFO:SubProcess create_model() end ==================================
2025-10-11 14:14:07,727:INFO:Creating metrics dataframe
2025-10-11 14:14:07,727:INFO:Initializing Ridge Classifier
2025-10-11 14:14:07,727:INFO:Total runtime is 0.23590269883473713 minutes
2025-10-11 14:14:07,742:INFO:SubProcess create_model() called ==================================
2025-10-11 14:14:07,742:INFO:Initializing create_model()
2025-10-11 14:14:07,742:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012CFFE7DF90>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012CFFE7C190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-11 14:14:07,742:INFO:Checking exceptions
2025-10-11 14:14:07,742:INFO:Importing libraries
2025-10-11 14:14:07,742:INFO:Copying training dataset
2025-10-11 14:14:07,742:INFO:Defining folds
2025-10-11 14:14:07,742:INFO:Declaring metric variables
2025-10-11 14:14:07,742:INFO:Importing untrained model
2025-10-11 14:14:07,742:INFO:Ridge Classifier Imported successfully
2025-10-11 14:14:07,760:INFO:Starting cross validation
2025-10-11 14:14:07,767:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-11 14:14:08,285:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 14:14:08,289:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 14:14:08,289:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 14:14:08,296:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 14:14:08,390:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 14:14:08,400:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 14:14:08,439:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 14:14:08,455:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 14:14:08,492:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 14:14:08,510:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 14:14:08,527:INFO:Calculating mean and std
2025-10-11 14:14:08,527:INFO:Creating metrics dataframe
2025-10-11 14:14:08,531:INFO:Uploading results into container
2025-10-11 14:14:08,531:INFO:Uploading model into container now
2025-10-11 14:14:08,531:INFO:_master_model_container: 6
2025-10-11 14:14:08,531:INFO:_display_container: 2
2025-10-11 14:14:08,531:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=2025, solver='auto',
                tol=0.0001)
2025-10-11 14:14:08,531:INFO:create_model() successfully completed......................................
2025-10-11 14:14:08,591:INFO:SubProcess create_model() end ==================================
2025-10-11 14:14:08,591:INFO:Creating metrics dataframe
2025-10-11 14:14:08,607:INFO:Initializing Random Forest Classifier
2025-10-11 14:14:08,607:INFO:Total runtime is 0.2505672176678975 minutes
2025-10-11 14:14:08,607:INFO:SubProcess create_model() called ==================================
2025-10-11 14:14:08,607:INFO:Initializing create_model()
2025-10-11 14:14:08,607:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012CFFE7DF90>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012CFFE7C190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-11 14:14:08,607:INFO:Checking exceptions
2025-10-11 14:14:08,607:INFO:Importing libraries
2025-10-11 14:14:08,607:INFO:Copying training dataset
2025-10-11 14:14:08,623:INFO:Defining folds
2025-10-11 14:14:08,623:INFO:Declaring metric variables
2025-10-11 14:14:08,623:INFO:Importing untrained model
2025-10-11 14:14:08,623:INFO:Random Forest Classifier Imported successfully
2025-10-11 14:14:08,637:INFO:Starting cross validation
2025-10-11 14:14:08,647:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-11 14:14:09,972:INFO:Calculating mean and std
2025-10-11 14:14:09,972:INFO:Creating metrics dataframe
2025-10-11 14:14:09,976:INFO:Uploading results into container
2025-10-11 14:14:09,976:INFO:Uploading model into container now
2025-10-11 14:14:09,977:INFO:_master_model_container: 7
2025-10-11 14:14:09,977:INFO:_display_container: 2
2025-10-11 14:14:09,978:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=2025, verbose=0,
                       warm_start=False)
2025-10-11 14:14:09,978:INFO:create_model() successfully completed......................................
2025-10-11 14:14:10,041:INFO:SubProcess create_model() end ==================================
2025-10-11 14:14:10,041:INFO:Creating metrics dataframe
2025-10-11 14:14:10,055:INFO:Initializing Quadratic Discriminant Analysis
2025-10-11 14:14:10,055:INFO:Total runtime is 0.2747147917747497 minutes
2025-10-11 14:14:10,066:INFO:SubProcess create_model() called ==================================
2025-10-11 14:14:10,066:INFO:Initializing create_model()
2025-10-11 14:14:10,066:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012CFFE7DF90>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012CFFE7C190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-11 14:14:10,066:INFO:Checking exceptions
2025-10-11 14:14:10,066:INFO:Importing libraries
2025-10-11 14:14:10,066:INFO:Copying training dataset
2025-10-11 14:14:10,071:INFO:Defining folds
2025-10-11 14:14:10,071:INFO:Declaring metric variables
2025-10-11 14:14:10,076:INFO:Importing untrained model
2025-10-11 14:14:10,080:INFO:Quadratic Discriminant Analysis Imported successfully
2025-10-11 14:14:10,084:INFO:Starting cross validation
2025-10-11 14:14:10,095:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-11 14:14:10,620:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 14:14:10,668:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 14:14:10,676:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 14:14:10,681:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 14:14:10,769:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 14:14:10,773:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 14:14:10,785:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 14:14:10,842:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 14:14:10,876:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 14:14:10,905:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 14:14:10,922:INFO:Calculating mean and std
2025-10-11 14:14:10,922:INFO:Creating metrics dataframe
2025-10-11 14:14:10,925:INFO:Uploading results into container
2025-10-11 14:14:10,925:INFO:Uploading model into container now
2025-10-11 14:14:10,926:INFO:_master_model_container: 8
2025-10-11 14:14:10,926:INFO:_display_container: 2
2025-10-11 14:14:10,926:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-10-11 14:14:10,927:INFO:create_model() successfully completed......................................
2025-10-11 14:14:10,990:INFO:SubProcess create_model() end ==================================
2025-10-11 14:14:10,990:INFO:Creating metrics dataframe
2025-10-11 14:14:11,006:INFO:Initializing Ada Boost Classifier
2025-10-11 14:14:11,006:INFO:Total runtime is 0.29055836598078405 minutes
2025-10-11 14:14:11,009:INFO:SubProcess create_model() called ==================================
2025-10-11 14:14:11,009:INFO:Initializing create_model()
2025-10-11 14:14:11,009:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012CFFE7DF90>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012CFFE7C190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-11 14:14:11,009:INFO:Checking exceptions
2025-10-11 14:14:11,009:INFO:Importing libraries
2025-10-11 14:14:11,009:INFO:Copying training dataset
2025-10-11 14:14:11,014:INFO:Defining folds
2025-10-11 14:14:11,014:INFO:Declaring metric variables
2025-10-11 14:14:11,018:INFO:Importing untrained model
2025-10-11 14:14:11,020:INFO:Ada Boost Classifier Imported successfully
2025-10-11 14:14:11,029:INFO:Starting cross validation
2025-10-11 14:14:11,036:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-11 14:14:11,502:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-11 14:14:11,502:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-11 14:14:11,504:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-11 14:14:11,506:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-11 14:14:11,794:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-11 14:14:11,799:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-11 14:14:11,825:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-11 14:14:11,825:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-11 14:14:12,006:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-11 14:14:12,055:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 14:14:12,060:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-11 14:14:12,226:INFO:Calculating mean and std
2025-10-11 14:14:12,226:INFO:Creating metrics dataframe
2025-10-11 14:14:12,226:INFO:Uploading results into container
2025-10-11 14:14:12,226:INFO:Uploading model into container now
2025-10-11 14:14:12,235:INFO:_master_model_container: 9
2025-10-11 14:14:12,235:INFO:_display_container: 2
2025-10-11 14:14:12,235:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2025)
2025-10-11 14:14:12,235:INFO:create_model() successfully completed......................................
2025-10-11 14:14:12,325:INFO:SubProcess create_model() end ==================================
2025-10-11 14:14:12,325:INFO:Creating metrics dataframe
2025-10-11 14:14:12,328:INFO:Initializing Gradient Boosting Classifier
2025-10-11 14:14:12,328:INFO:Total runtime is 0.3125986854235331 minutes
2025-10-11 14:14:12,341:INFO:SubProcess create_model() called ==================================
2025-10-11 14:14:12,341:INFO:Initializing create_model()
2025-10-11 14:14:12,342:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012CFFE7DF90>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012CFFE7C190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-11 14:14:12,342:INFO:Checking exceptions
2025-10-11 14:14:12,342:INFO:Importing libraries
2025-10-11 14:14:12,342:INFO:Copying training dataset
2025-10-11 14:14:12,342:INFO:Defining folds
2025-10-11 14:14:12,342:INFO:Declaring metric variables
2025-10-11 14:14:12,349:INFO:Importing untrained model
2025-10-11 14:14:12,349:INFO:Gradient Boosting Classifier Imported successfully
2025-10-11 14:14:12,359:INFO:Starting cross validation
2025-10-11 14:14:12,368:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-11 14:14:13,327:INFO:Calculating mean and std
2025-10-11 14:14:13,327:INFO:Creating metrics dataframe
2025-10-11 14:14:13,335:INFO:Uploading results into container
2025-10-11 14:14:13,335:INFO:Uploading model into container now
2025-10-11 14:14:13,335:INFO:_master_model_container: 10
2025-10-11 14:14:13,335:INFO:_display_container: 2
2025-10-11 14:14:13,335:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2025, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-11 14:14:13,335:INFO:create_model() successfully completed......................................
2025-10-11 14:14:13,405:INFO:SubProcess create_model() end ==================================
2025-10-11 14:14:13,405:INFO:Creating metrics dataframe
2025-10-11 14:14:13,421:INFO:Initializing Linear Discriminant Analysis
2025-10-11 14:14:13,421:INFO:Total runtime is 0.3308077216148376 minutes
2025-10-11 14:14:13,428:INFO:SubProcess create_model() called ==================================
2025-10-11 14:14:13,428:INFO:Initializing create_model()
2025-10-11 14:14:13,428:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012CFFE7DF90>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012CFFE7C190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-11 14:14:13,428:INFO:Checking exceptions
2025-10-11 14:14:13,428:INFO:Importing libraries
2025-10-11 14:14:13,428:INFO:Copying training dataset
2025-10-11 14:14:13,428:INFO:Defining folds
2025-10-11 14:14:13,437:INFO:Declaring metric variables
2025-10-11 14:14:13,441:INFO:Importing untrained model
2025-10-11 14:14:13,444:INFO:Linear Discriminant Analysis Imported successfully
2025-10-11 14:14:13,447:INFO:Starting cross validation
2025-10-11 14:14:13,459:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-11 14:14:13,923:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 14:14:13,927:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 14:14:13,927:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 14:14:13,969:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 14:14:14,026:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 14:14:14,038:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 14:14:14,081:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 14:14:14,112:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 14:14:14,124:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 14:14:14,144:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 14:14:14,163:INFO:Calculating mean and std
2025-10-11 14:14:14,163:INFO:Creating metrics dataframe
2025-10-11 14:14:14,167:INFO:Uploading results into container
2025-10-11 14:14:14,167:INFO:Uploading model into container now
2025-10-11 14:14:14,167:INFO:_master_model_container: 11
2025-10-11 14:14:14,167:INFO:_display_container: 2
2025-10-11 14:14:14,167:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-11 14:14:14,167:INFO:create_model() successfully completed......................................
2025-10-11 14:14:14,238:INFO:SubProcess create_model() end ==================================
2025-10-11 14:14:14,238:INFO:Creating metrics dataframe
2025-10-11 14:14:14,254:INFO:Initializing Extra Trees Classifier
2025-10-11 14:14:14,254:INFO:Total runtime is 0.3446953217188517 minutes
2025-10-11 14:14:14,256:INFO:SubProcess create_model() called ==================================
2025-10-11 14:14:14,256:INFO:Initializing create_model()
2025-10-11 14:14:14,256:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012CFFE7DF90>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012CFFE7C190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-11 14:14:14,256:INFO:Checking exceptions
2025-10-11 14:14:14,256:INFO:Importing libraries
2025-10-11 14:14:14,256:INFO:Copying training dataset
2025-10-11 14:14:14,256:INFO:Defining folds
2025-10-11 14:14:14,256:INFO:Declaring metric variables
2025-10-11 14:14:14,265:INFO:Importing untrained model
2025-10-11 14:14:14,268:INFO:Extra Trees Classifier Imported successfully
2025-10-11 14:14:14,278:INFO:Starting cross validation
2025-10-11 14:14:14,285:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-11 14:14:15,594:INFO:Calculating mean and std
2025-10-11 14:14:15,594:INFO:Creating metrics dataframe
2025-10-11 14:14:15,598:INFO:Uploading results into container
2025-10-11 14:14:15,598:INFO:Uploading model into container now
2025-10-11 14:14:15,598:INFO:_master_model_container: 12
2025-10-11 14:14:15,598:INFO:_display_container: 2
2025-10-11 14:14:15,598:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=2025, verbose=0,
                     warm_start=False)
2025-10-11 14:14:15,598:INFO:create_model() successfully completed......................................
2025-10-11 14:14:15,672:INFO:SubProcess create_model() end ==================================
2025-10-11 14:14:15,672:INFO:Creating metrics dataframe
2025-10-11 14:14:15,688:INFO:Initializing Light Gradient Boosting Machine
2025-10-11 14:14:15,688:INFO:Total runtime is 0.3685850103696187 minutes
2025-10-11 14:14:15,688:INFO:SubProcess create_model() called ==================================
2025-10-11 14:14:15,688:INFO:Initializing create_model()
2025-10-11 14:14:15,688:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012CFFE7DF90>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012CFFE7C190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-11 14:14:15,688:INFO:Checking exceptions
2025-10-11 14:14:15,688:INFO:Importing libraries
2025-10-11 14:14:15,688:INFO:Copying training dataset
2025-10-11 14:14:15,700:INFO:Defining folds
2025-10-11 14:14:15,702:INFO:Declaring metric variables
2025-10-11 14:14:15,704:INFO:Importing untrained model
2025-10-11 14:14:15,709:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-11 14:14:15,717:INFO:Starting cross validation
2025-10-11 14:14:15,723:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-11 14:14:16,422:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 14:14:16,446:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 14:14:16,544:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 14:14:16,597:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 14:14:16,691:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 14:14:16,736:INFO:Calculating mean and std
2025-10-11 14:14:16,736:INFO:Creating metrics dataframe
2025-10-11 14:14:16,741:INFO:Uploading results into container
2025-10-11 14:14:16,743:INFO:Uploading model into container now
2025-10-11 14:14:16,743:INFO:_master_model_container: 13
2025-10-11 14:14:16,745:INFO:_display_container: 2
2025-10-11 14:14:16,746:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2025, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-11 14:14:16,746:INFO:create_model() successfully completed......................................
2025-10-11 14:14:16,837:INFO:SubProcess create_model() end ==================================
2025-10-11 14:14:16,837:INFO:Creating metrics dataframe
2025-10-11 14:14:16,862:INFO:Initializing Dummy Classifier
2025-10-11 14:14:16,862:INFO:Total runtime is 0.388150691986084 minutes
2025-10-11 14:14:16,866:INFO:SubProcess create_model() called ==================================
2025-10-11 14:14:16,866:INFO:Initializing create_model()
2025-10-11 14:14:16,866:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012CFFE7DF90>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012CFFE7C190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-11 14:14:16,866:INFO:Checking exceptions
2025-10-11 14:14:16,867:INFO:Importing libraries
2025-10-11 14:14:16,867:INFO:Copying training dataset
2025-10-11 14:14:16,871:INFO:Defining folds
2025-10-11 14:14:16,871:INFO:Declaring metric variables
2025-10-11 14:14:16,875:INFO:Importing untrained model
2025-10-11 14:14:16,876:INFO:Dummy Classifier Imported successfully
2025-10-11 14:14:16,876:INFO:Starting cross validation
2025-10-11 14:14:16,893:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-11 14:14:17,386:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 14:14:17,397:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 14:14:17,407:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 14:14:17,416:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 14:14:17,482:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 14:14:17,490:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 14:14:17,511:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 14:14:17,572:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 14:14:17,574:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 14:14:17,584:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 14:14:17,600:INFO:Calculating mean and std
2025-10-11 14:14:17,600:INFO:Creating metrics dataframe
2025-10-11 14:14:17,602:INFO:Uploading results into container
2025-10-11 14:14:17,604:INFO:Uploading model into container now
2025-10-11 14:14:17,604:INFO:_master_model_container: 14
2025-10-11 14:14:17,606:INFO:_display_container: 2
2025-10-11 14:14:17,607:INFO:DummyClassifier(constant=None, random_state=2025, strategy='prior')
2025-10-11 14:14:17,607:INFO:create_model() successfully completed......................................
2025-10-11 14:14:17,672:INFO:SubProcess create_model() end ==================================
2025-10-11 14:14:17,672:INFO:Creating metrics dataframe
2025-10-11 14:14:17,694:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-10-11 14:14:17,704:INFO:Initializing create_model()
2025-10-11 14:14:17,704:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012CFFE7DF90>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-11 14:14:17,704:INFO:Checking exceptions
2025-10-11 14:14:17,708:INFO:Importing libraries
2025-10-11 14:14:17,708:INFO:Copying training dataset
2025-10-11 14:14:17,713:INFO:Defining folds
2025-10-11 14:14:17,713:INFO:Declaring metric variables
2025-10-11 14:14:17,713:INFO:Importing untrained model
2025-10-11 14:14:17,713:INFO:Declaring custom model
2025-10-11 14:14:17,713:INFO:Decision Tree Classifier Imported successfully
2025-10-11 14:14:17,722:INFO:Cross validation set to False
2025-10-11 14:14:17,722:INFO:Fitting Model
2025-10-11 14:14:17,951:INFO:[LightGBM] [Info] Number of positive: 32, number of negative: 122
2025-10-11 14:14:17,951:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000071 seconds.
2025-10-11 14:14:17,951:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-11 14:14:17,951:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-11 14:14:17,951:INFO:[LightGBM] [Info] Total Bins 186
2025-10-11 14:14:17,951:INFO:[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 14
2025-10-11 14:14:17,953:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.207792 -> initscore=-1.338285
2025-10-11 14:14:17,953:INFO:[LightGBM] [Info] Start training from score -1.338285
2025-10-11 14:14:17,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:17,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:17,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:17,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:17,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:17,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:17,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:17,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:17,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:17,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:17,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:17,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:17,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:17,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:17,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:17,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:17,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:17,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:17,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:17,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:17,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:17,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:17,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:17,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:17,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:17,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:17,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:17,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:17,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:17,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:17,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:17,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:17,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:17,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:17,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:17,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:17,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:17,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:17,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:17,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:17,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:17,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:17,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:17,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:17,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:17,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:17,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:17,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:17,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:17,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:17,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:17,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:17,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:17,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:17,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:17,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:17,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:17,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:17,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:17,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:17,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:17,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:17,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:17,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:17,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:17,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:17,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:17,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:17,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:17,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:17,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:17,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:17,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:17,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:17,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:17,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:17,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:17,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:17,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:17,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:17,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:17,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:17,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:17,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:17,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:17,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:17,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:17,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:17,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:17,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:17,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:17,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:17,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:17,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:17,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:17,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:17,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:17,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:17,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:17,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:17,972:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best')
2025-10-11 14:14:17,972:INFO:create_model() successfully completed......................................
2025-10-11 14:14:18,078:INFO:_master_model_container: 14
2025-10-11 14:14:18,078:INFO:_display_container: 2
2025-10-11 14:14:18,078:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best')
2025-10-11 14:14:18,078:INFO:compare_models() successfully completed......................................
2025-10-11 14:14:18,103:INFO:Initializing tune_model()
2025-10-11 14:14:18,103:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012CFFE7DF90>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best'), fold=None, round=4, n_iter=10, custom_grid=None, optimize=F1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-10-11 14:14:18,103:INFO:Checking exceptions
2025-10-11 14:14:18,125:INFO:Copying training dataset
2025-10-11 14:14:18,130:INFO:Checking base model
2025-10-11 14:14:18,130:INFO:Base model : Decision Tree Classifier
2025-10-11 14:14:18,133:INFO:Declaring metric variables
2025-10-11 14:14:18,138:INFO:Defining Hyperparameters
2025-10-11 14:14:18,243:INFO:Tuning with n_jobs=-1
2025-10-11 14:14:18,243:INFO:Initializing RandomizedSearchCV
2025-10-11 14:14:27,135:INFO:best_params: {'actual_estimator__min_samples_split': 9, 'actual_estimator__min_samples_leaf': 5, 'actual_estimator__min_impurity_decrease': 0.002, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 11, 'actual_estimator__criterion': 'gini'}
2025-10-11 14:14:27,137:INFO:Hyperparameter search completed
2025-10-11 14:14:27,137:INFO:SubProcess create_model() called ==================================
2025-10-11 14:14:27,137:INFO:Initializing create_model()
2025-10-11 14:14:27,139:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012CFFE7DF90>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012CFEFB8F50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'min_samples_split': 9, 'min_samples_leaf': 5, 'min_impurity_decrease': 0.002, 'max_features': 'sqrt', 'max_depth': 11, 'criterion': 'gini'})
2025-10-11 14:14:27,139:INFO:Checking exceptions
2025-10-11 14:14:27,139:INFO:Importing libraries
2025-10-11 14:14:27,140:INFO:Copying training dataset
2025-10-11 14:14:27,150:INFO:Defining folds
2025-10-11 14:14:27,150:INFO:Declaring metric variables
2025-10-11 14:14:27,156:INFO:Importing untrained model
2025-10-11 14:14:27,156:INFO:Declaring custom model
2025-10-11 14:14:27,163:INFO:Decision Tree Classifier Imported successfully
2025-10-11 14:14:27,172:INFO:Starting cross validation
2025-10-11 14:14:27,179:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-11 14:14:27,810:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 14:14:27,933:INFO:Calculating mean and std
2025-10-11 14:14:27,935:INFO:Creating metrics dataframe
2025-10-11 14:14:27,938:INFO:Finalizing model
2025-10-11 14:14:28,044:INFO:[LightGBM] [Info] Number of positive: 32, number of negative: 122
2025-10-11 14:14:28,044:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000042 seconds.
2025-10-11 14:14:28,044:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-11 14:14:28,045:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-11 14:14:28,045:INFO:[LightGBM] [Info] Total Bins 186
2025-10-11 14:14:28,045:INFO:[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 14
2025-10-11 14:14:28,045:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.207792 -> initscore=-1.338285
2025-10-11 14:14:28,045:INFO:[LightGBM] [Info] Start training from score -1.338285
2025-10-11 14:14:28,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:28,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:28,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:28,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:28,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:28,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:28,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:28,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:28,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:28,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:28,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:28,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:28,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:28,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:28,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:28,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:28,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:28,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:28,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:28,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:28,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:28,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:28,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:28,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:28,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:28,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:28,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:28,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:28,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:28,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:28,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:28,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:28,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:28,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:28,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:28,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:28,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:28,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:28,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:28,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:28,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:28,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:28,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:28,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:28,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:28,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:28,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:28,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:28,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:28,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:28,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:28,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:28,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:28,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:28,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:28,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:28,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:28,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:28,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:28,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:28,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:28,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:28,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:28,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:28,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:28,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:28,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:28,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:28,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:28,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:28,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:28,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:28,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:28,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:28,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:28,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:28,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:28,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:28,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:28,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:28,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:28,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:28,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:28,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:28,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:28,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:28,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:28,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:28,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:28,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:28,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:28,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:28,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:28,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:28,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:28,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:28,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:28,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:28,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:28,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:28,082:INFO:Uploading results into container
2025-10-11 14:14:28,082:INFO:Uploading model into container now
2025-10-11 14:14:28,082:INFO:_master_model_container: 15
2025-10-11 14:14:28,082:INFO:_display_container: 3
2025-10-11 14:14:28,082:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=11, max_features='sqrt', max_leaf_nodes=None,
                       min_impurity_decrease=0.002, min_samples_leaf=5,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best')
2025-10-11 14:14:28,082:INFO:create_model() successfully completed......................................
2025-10-11 14:14:28,173:INFO:SubProcess create_model() end ==================================
2025-10-11 14:14:28,173:INFO:choose_better activated
2025-10-11 14:14:28,177:INFO:SubProcess create_model() called ==================================
2025-10-11 14:14:28,177:INFO:Initializing create_model()
2025-10-11 14:14:28,177:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012CFFE7DF90>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-11 14:14:28,177:INFO:Checking exceptions
2025-10-11 14:14:28,179:INFO:Importing libraries
2025-10-11 14:14:28,179:INFO:Copying training dataset
2025-10-11 14:14:28,182:INFO:Defining folds
2025-10-11 14:14:28,182:INFO:Declaring metric variables
2025-10-11 14:14:28,182:INFO:Importing untrained model
2025-10-11 14:14:28,182:INFO:Declaring custom model
2025-10-11 14:14:28,182:INFO:Decision Tree Classifier Imported successfully
2025-10-11 14:14:28,183:INFO:Starting cross validation
2025-10-11 14:14:28,186:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-11 14:14:28,935:INFO:Calculating mean and std
2025-10-11 14:14:28,936:INFO:Creating metrics dataframe
2025-10-11 14:14:28,939:INFO:Finalizing model
2025-10-11 14:14:29,027:INFO:[LightGBM] [Info] Number of positive: 32, number of negative: 122
2025-10-11 14:14:29,027:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000040 seconds.
2025-10-11 14:14:29,027:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-11 14:14:29,027:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-11 14:14:29,027:INFO:[LightGBM] [Info] Total Bins 186
2025-10-11 14:14:29,027:INFO:[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 14
2025-10-11 14:14:29,028:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.207792 -> initscore=-1.338285
2025-10-11 14:14:29,028:INFO:[LightGBM] [Info] Start training from score -1.338285
2025-10-11 14:14:29,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:29,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:29,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:29,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:29,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:29,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:29,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:29,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:29,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:29,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:29,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:29,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:29,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:29,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:29,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:29,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:29,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:29,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:29,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:29,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:29,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:29,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:29,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:29,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:29,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:29,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:29,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:29,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:29,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:29,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:29,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:29,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:29,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:29,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:29,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:29,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:29,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:29,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:29,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:29,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:29,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:29,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:29,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:29,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:29,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:29,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:29,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:29,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:29,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:29,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:29,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:29,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:29,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:29,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:29,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:29,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:29,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:29,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:29,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:29,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:29,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:29,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:29,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:29,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:29,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:29,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:29,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:29,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:29,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:29,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:29,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:29,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:29,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:29,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:29,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:29,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:29,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:29,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:29,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:29,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:29,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:29,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:29,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:29,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:29,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:29,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:29,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:29,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:29,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:29,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:29,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:29,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:29,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:29,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:29,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:29,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:29,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:29,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:29,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:29,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:29,049:INFO:Uploading results into container
2025-10-11 14:14:29,050:INFO:Uploading model into container now
2025-10-11 14:14:29,050:INFO:_master_model_container: 16
2025-10-11 14:14:29,050:INFO:_display_container: 4
2025-10-11 14:14:29,051:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best')
2025-10-11 14:14:29,051:INFO:create_model() successfully completed......................................
2025-10-11 14:14:29,126:INFO:SubProcess create_model() end ==================================
2025-10-11 14:14:29,127:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best') result for F1 is 0.3333
2025-10-11 14:14:29,127:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=11, max_features='sqrt', max_leaf_nodes=None,
                       min_impurity_decrease=0.002, min_samples_leaf=5,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best') result for F1 is 0.24
2025-10-11 14:14:29,128:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best') is best model
2025-10-11 14:14:29,128:INFO:choose_better completed
2025-10-11 14:14:29,128:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-10-11 14:14:29,139:INFO:_master_model_container: 16
2025-10-11 14:14:29,140:INFO:_display_container: 3
2025-10-11 14:14:29,140:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best')
2025-10-11 14:14:29,140:INFO:tune_model() successfully completed......................................
2025-10-11 14:14:29,203:INFO:Initializing plot_model()
2025-10-11 14:14:29,203:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012CFFE7DF90>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best'), plot=pr, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-10-11 14:14:29,203:INFO:Checking exceptions
2025-10-11 14:14:29,203:INFO:Preloading libraries
2025-10-11 14:14:29,203:INFO:Copying training dataset
2025-10-11 14:14:29,203:INFO:Plot type: pr
2025-10-11 14:14:29,319:INFO:Fitting Model
2025-10-11 14:14:29,354:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names
  warnings.warn(

2025-10-11 14:14:29,354:INFO:Scoring test/hold-out set
2025-10-11 14:14:29,514:INFO:Visual Rendered Successfully
2025-10-11 14:14:29,585:INFO:plot_model() successfully completed......................................
2025-10-11 14:14:29,585:INFO:Initializing plot_model()
2025-10-11 14:14:29,585:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012CFFE7DF90>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best'), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-10-11 14:14:29,585:INFO:Checking exceptions
2025-10-11 14:14:29,585:INFO:Preloading libraries
2025-10-11 14:14:29,585:INFO:Copying training dataset
2025-10-11 14:14:29,585:INFO:Plot type: confusion_matrix
2025-10-11 14:14:29,716:INFO:Fitting Model
2025-10-11 14:14:29,717:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names
  warnings.warn(

2025-10-11 14:14:29,717:INFO:Scoring test/hold-out set
2025-10-11 14:14:29,839:INFO:Visual Rendered Successfully
2025-10-11 14:14:29,901:INFO:plot_model() successfully completed......................................
2025-10-11 14:14:39,136:INFO:Initializing tune_model()
2025-10-11 14:14:39,136:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012CFFE7DF90>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best'), fold=None, round=4, n_iter=10, custom_grid=None, optimize=F1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-10-11 14:14:39,136:INFO:Checking exceptions
2025-10-11 14:14:39,154:INFO:Copying training dataset
2025-10-11 14:14:39,157:INFO:Checking base model
2025-10-11 14:14:39,157:INFO:Base model : Decision Tree Classifier
2025-10-11 14:14:39,161:INFO:Declaring metric variables
2025-10-11 14:14:39,164:INFO:Defining Hyperparameters
2025-10-11 14:14:39,248:INFO:Tuning with n_jobs=-1
2025-10-11 14:14:39,248:INFO:Initializing RandomizedSearchCV
2025-10-11 14:14:48,233:INFO:best_params: {'actual_estimator__min_samples_split': 9, 'actual_estimator__min_samples_leaf': 5, 'actual_estimator__min_impurity_decrease': 0.002, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 11, 'actual_estimator__criterion': 'gini'}
2025-10-11 14:14:48,234:INFO:Hyperparameter search completed
2025-10-11 14:14:48,235:INFO:SubProcess create_model() called ==================================
2025-10-11 14:14:48,236:INFO:Initializing create_model()
2025-10-11 14:14:48,236:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012CFFE7DF90>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012CFFAEEBD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'min_samples_split': 9, 'min_samples_leaf': 5, 'min_impurity_decrease': 0.002, 'max_features': 'sqrt', 'max_depth': 11, 'criterion': 'gini'})
2025-10-11 14:14:48,236:INFO:Checking exceptions
2025-10-11 14:14:48,237:INFO:Importing libraries
2025-10-11 14:14:48,237:INFO:Copying training dataset
2025-10-11 14:14:48,244:INFO:Defining folds
2025-10-11 14:14:48,244:INFO:Declaring metric variables
2025-10-11 14:14:48,250:INFO:Importing untrained model
2025-10-11 14:14:48,251:INFO:Declaring custom model
2025-10-11 14:14:48,254:INFO:Decision Tree Classifier Imported successfully
2025-10-11 14:14:48,265:INFO:Starting cross validation
2025-10-11 14:14:48,274:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-11 14:14:48,862:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 14:14:49,122:INFO:Calculating mean and std
2025-10-11 14:14:49,123:INFO:Creating metrics dataframe
2025-10-11 14:14:49,128:INFO:Finalizing model
2025-10-11 14:14:49,221:INFO:[LightGBM] [Info] Number of positive: 32, number of negative: 122
2025-10-11 14:14:49,221:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000047 seconds.
2025-10-11 14:14:49,221:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-11 14:14:49,221:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-11 14:14:49,221:INFO:[LightGBM] [Info] Total Bins 186
2025-10-11 14:14:49,221:INFO:[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 14
2025-10-11 14:14:49,221:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.207792 -> initscore=-1.338285
2025-10-11 14:14:49,221:INFO:[LightGBM] [Info] Start training from score -1.338285
2025-10-11 14:14:49,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:49,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:49,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:49,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:49,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:49,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:49,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:49,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:49,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:49,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:49,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:49,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:49,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:49,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:49,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:49,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:49,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:49,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:49,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:49,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:49,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:49,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:49,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:49,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:49,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:49,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:49,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:49,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:49,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:49,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:49,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:49,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:49,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:49,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:49,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:49,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:49,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:49,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:49,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:49,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:49,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:49,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:49,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:49,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:49,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:49,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:49,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:49,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:49,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:49,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:49,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:49,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:49,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:49,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:49,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:49,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:49,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:49,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:49,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:49,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:49,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:49,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:49,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:49,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:49,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:49,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:49,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:49,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:49,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:49,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:49,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:49,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:49,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:49,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:49,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:49,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:49,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:49,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:49,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:49,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:49,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:49,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:49,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:49,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:49,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:49,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:49,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:49,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:49,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:49,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:49,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:49,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:49,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:49,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:49,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:49,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:49,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:49,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:49,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:49,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:49,265:INFO:Uploading results into container
2025-10-11 14:14:49,266:INFO:Uploading model into container now
2025-10-11 14:14:49,267:INFO:_master_model_container: 17
2025-10-11 14:14:49,267:INFO:_display_container: 4
2025-10-11 14:14:49,267:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=11, max_features='sqrt', max_leaf_nodes=None,
                       min_impurity_decrease=0.002, min_samples_leaf=5,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best')
2025-10-11 14:14:49,267:INFO:create_model() successfully completed......................................
2025-10-11 14:14:49,370:INFO:SubProcess create_model() end ==================================
2025-10-11 14:14:49,370:INFO:choose_better activated
2025-10-11 14:14:49,374:INFO:SubProcess create_model() called ==================================
2025-10-11 14:14:49,375:INFO:Initializing create_model()
2025-10-11 14:14:49,375:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012CFFE7DF90>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-11 14:14:49,375:INFO:Checking exceptions
2025-10-11 14:14:49,377:INFO:Importing libraries
2025-10-11 14:14:49,377:INFO:Copying training dataset
2025-10-11 14:14:49,381:INFO:Defining folds
2025-10-11 14:14:49,381:INFO:Declaring metric variables
2025-10-11 14:14:49,381:INFO:Importing untrained model
2025-10-11 14:14:49,382:INFO:Declaring custom model
2025-10-11 14:14:49,382:INFO:Decision Tree Classifier Imported successfully
2025-10-11 14:14:49,383:INFO:Starting cross validation
2025-10-11 14:14:49,388:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-11 14:14:50,172:INFO:Calculating mean and std
2025-10-11 14:14:50,172:INFO:Creating metrics dataframe
2025-10-11 14:14:50,172:INFO:Finalizing model
2025-10-11 14:14:50,264:INFO:[LightGBM] [Info] Number of positive: 32, number of negative: 122
2025-10-11 14:14:50,265:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000111 seconds.
2025-10-11 14:14:50,265:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-11 14:14:50,265:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-11 14:14:50,265:INFO:[LightGBM] [Info] Total Bins 186
2025-10-11 14:14:50,265:INFO:[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 14
2025-10-11 14:14:50,265:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.207792 -> initscore=-1.338285
2025-10-11 14:14:50,265:INFO:[LightGBM] [Info] Start training from score -1.338285
2025-10-11 14:14:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:14:50,281:INFO:Uploading results into container
2025-10-11 14:14:50,281:INFO:Uploading model into container now
2025-10-11 14:14:50,281:INFO:_master_model_container: 18
2025-10-11 14:14:50,281:INFO:_display_container: 5
2025-10-11 14:14:50,281:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best')
2025-10-11 14:14:50,281:INFO:create_model() successfully completed......................................
2025-10-11 14:14:50,365:INFO:SubProcess create_model() end ==================================
2025-10-11 14:14:50,365:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best') result for F1 is 0.3333
2025-10-11 14:14:50,365:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=11, max_features='sqrt', max_leaf_nodes=None,
                       min_impurity_decrease=0.002, min_samples_leaf=5,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best') result for F1 is 0.24
2025-10-11 14:14:50,365:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best') is best model
2025-10-11 14:14:50,365:INFO:choose_better completed
2025-10-11 14:14:50,365:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-10-11 14:14:50,382:INFO:_master_model_container: 18
2025-10-11 14:14:50,382:INFO:_display_container: 4
2025-10-11 14:14:50,382:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best')
2025-10-11 14:14:50,382:INFO:tune_model() successfully completed......................................
2025-10-11 14:14:50,478:INFO:Initializing plot_model()
2025-10-11 14:14:50,478:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012CFFE7DF90>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best'), plot=pr, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-10-11 14:14:50,478:INFO:Checking exceptions
2025-10-11 14:14:50,481:INFO:Preloading libraries
2025-10-11 14:14:50,481:INFO:Copying training dataset
2025-10-11 14:14:50,481:INFO:Plot type: pr
2025-10-11 14:14:50,581:INFO:Fitting Model
2025-10-11 14:14:50,581:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names
  warnings.warn(

2025-10-11 14:14:50,581:INFO:Scoring test/hold-out set
2025-10-11 14:14:50,765:INFO:Visual Rendered Successfully
2025-10-11 14:14:50,847:INFO:plot_model() successfully completed......................................
2025-10-11 14:14:50,848:INFO:Initializing plot_model()
2025-10-11 14:14:50,848:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012CFFE7DF90>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best'), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-10-11 14:14:50,848:INFO:Checking exceptions
2025-10-11 14:14:50,852:INFO:Preloading libraries
2025-10-11 14:14:50,852:INFO:Copying training dataset
2025-10-11 14:14:50,852:INFO:Plot type: confusion_matrix
2025-10-11 14:14:50,965:INFO:Fitting Model
2025-10-11 14:14:50,965:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names
  warnings.warn(

2025-10-11 14:14:50,965:INFO:Scoring test/hold-out set
2025-10-11 14:14:51,098:INFO:Visual Rendered Successfully
2025-10-11 14:14:51,166:INFO:plot_model() successfully completed......................................
2025-10-11 14:15:01,348:INFO:Initializing create_model()
2025-10-11 14:15:01,348:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012CFFE7DF90>, estimator=rf, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-11 14:15:01,348:INFO:Checking exceptions
2025-10-11 14:15:01,373:INFO:Importing libraries
2025-10-11 14:15:01,373:INFO:Copying training dataset
2025-10-11 14:15:01,378:INFO:Defining folds
2025-10-11 14:15:01,378:INFO:Declaring metric variables
2025-10-11 14:15:01,383:INFO:Importing untrained model
2025-10-11 14:15:01,388:INFO:Random Forest Classifier Imported successfully
2025-10-11 14:15:01,396:INFO:Starting cross validation
2025-10-11 14:15:01,403:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-11 14:15:02,600:INFO:Calculating mean and std
2025-10-11 14:15:02,600:INFO:Creating metrics dataframe
2025-10-11 14:15:02,608:INFO:Finalizing model
2025-10-11 14:15:02,696:INFO:[LightGBM] [Info] Number of positive: 32, number of negative: 122
2025-10-11 14:15:02,697:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000066 seconds.
2025-10-11 14:15:02,697:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-11 14:15:02,697:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-11 14:15:02,697:INFO:[LightGBM] [Info] Total Bins 186
2025-10-11 14:15:02,697:INFO:[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 14
2025-10-11 14:15:02,698:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.207792 -> initscore=-1.338285
2025-10-11 14:15:02,698:INFO:[LightGBM] [Info] Start training from score -1.338285
2025-10-11 14:15:02,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:15:02,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:15:02,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:15:02,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:15:02,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:15:02,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:15:02,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:15:02,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:15:02,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:15:02,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:15:02,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:15:02,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:15:02,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:15:02,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:15:02,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:15:02,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:15:02,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:15:02,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:15:02,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:15:02,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:15:02,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:15:02,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:15:02,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:15:02,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:15:02,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:15:02,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:15:02,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:15:02,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:15:02,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:15:02,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:15:02,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:15:02,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:15:02,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:15:02,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:15:02,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:15:02,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:15:02,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:15:02,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:15:02,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:15:02,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:15:02,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:15:02,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:15:02,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:15:02,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:15:02,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:15:02,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:15:02,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:15:02,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:15:02,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:15:02,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:15:02,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:15:02,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:15:02,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:15:02,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:15:02,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:15:02,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:15:02,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:15:02,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:15:02,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:15:02,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:15:02,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:15:02,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:15:02,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:15:02,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:15:02,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:15:02,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:15:02,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:15:02,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:15:02,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:15:02,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:15:02,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:15:02,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:15:02,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:15:02,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:15:02,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:15:02,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:15:02,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:15:02,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:15:02,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:15:02,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:15:02,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:15:02,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:15:02,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:15:02,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:15:02,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:15:02,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:15:02,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:15:02,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:15:02,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:15:02,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:15:02,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:15:02,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:15:02,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:15:02,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:15:02,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:15:02,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:15:02,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:15:02,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:15:02,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:15:02,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 14:15:02,900:INFO:Uploading results into container
2025-10-11 14:15:02,901:INFO:Uploading model into container now
2025-10-11 14:15:02,910:INFO:_master_model_container: 19
2025-10-11 14:15:02,911:INFO:_display_container: 5
2025-10-11 14:15:02,911:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=2025, verbose=0,
                       warm_start=False)
2025-10-11 14:15:02,911:INFO:create_model() successfully completed......................................
2025-10-11 14:15:22,424:INFO:Initializing interpret_model()
2025-10-11 14:15:22,424:INFO:interpret_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012CFFE7DF90>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=2025, verbose=0,
                       warm_start=False), plot=summary, feature=None, observation=None, use_train_data=False, X_new_sample=None, y_new_sample=None, save=False, kwargs={})
2025-10-11 14:15:22,424:INFO:Checking exceptions
2025-10-11 14:15:22,424:INFO:Soft dependency imported: shap: 0.48.0
2025-10-11 14:15:22,443:INFO:plot type: summary
2025-10-11 14:15:22,443:INFO:Creating TreeExplainer
2025-10-11 14:15:22,443:INFO:Compiling shap values
2025-10-11 14:15:22,458:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:4145: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.
  shap_plot = shap.summary_plot(shap_values, test_X, show=show, **kwargs)

2025-10-11 14:16:53,046:INFO:Initializing get_config()
2025-10-11 14:16:53,046:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012CFFE7DF90>, variable=y_test)
2025-10-11 14:16:53,046:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-10-11 14:16:53,047:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
  warnings.warn(msg)  # print on screen

2025-10-11 14:16:53,050:INFO:Variable:  returned as 10     0
219    0
119    1
24     0
52     0
      ..
120    0
202    0
82     1
3      0
123    0
Name: conversion, Length: 66, dtype: int8
2025-10-11 14:16:53,050:INFO:get_config() successfully completed......................................
2025-10-11 14:19:44,958:INFO:Initializing interpret_model()
2025-10-11 14:19:44,958:INFO:interpret_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012CFFE7DF90>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=2025, verbose=0,
                       warm_start=False), plot=summary, feature=None, observation=None, use_train_data=True, X_new_sample=None, y_new_sample=None, save=False, kwargs={})
2025-10-11 14:19:44,958:INFO:Checking exceptions
2025-10-11 14:19:44,958:INFO:Soft dependency imported: shap: 0.48.0
2025-10-11 14:19:44,983:INFO:plot type: summary
2025-10-11 14:19:44,984:INFO:Creating TreeExplainer
2025-10-11 14:19:44,989:INFO:Compiling shap values
2025-10-11 14:19:45,014:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:4145: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.
  shap_plot = shap.summary_plot(shap_values, test_X, show=show, **kwargs)

2025-10-11 17:01:56,300:INFO:PyCaret ClassificationExperiment
2025-10-11 17:01:56,300:INFO:Logging name: clf-default-name
2025-10-11 17:01:56,300:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-10-11 17:01:56,300:INFO:version 3.3.2
2025-10-11 17:01:56,300:INFO:Initializing setup()
2025-10-11 17:01:56,300:INFO:self.USI: 2a02
2025-10-11 17:01:56,300:INFO:self._variable_keys: {'idx', 'fold_shuffle_param', 'y', 'X', 'fold_groups_param', 'fix_imbalance', 'exp_name_log', 'fold_generator', 'gpu_n_jobs_param', 'X_test', 'USI', 'memory', 'gpu_param', 'data', 'html_param', '_ml_usecase', 'is_multiclass', 'seed', 'exp_id', 'pipeline', 'n_jobs_param', 'logging_param', 'log_plots_param', 'X_train', '_available_plots', 'y_test', 'target_param', 'y_train'}
2025-10-11 17:01:56,300:INFO:Checking environment
2025-10-11 17:01:56,300:INFO:python_version: 3.11.0
2025-10-11 17:01:56,300:INFO:python_build: ('main', 'Oct 24 2022 18:26:48')
2025-10-11 17:01:56,300:INFO:machine: AMD64
2025-10-11 17:01:56,300:INFO:platform: Windows-10-10.0.26100-SP0
2025-10-11 17:01:56,308:INFO:Memory: svmem(total=34211835904, available=20735029248, percent=39.4, used=13476806656, free=20735029248)
2025-10-11 17:01:56,308:INFO:Physical Core: 6
2025-10-11 17:01:56,308:INFO:Logical Core: 12
2025-10-11 17:01:56,308:INFO:Checking libraries
2025-10-11 17:01:56,308:INFO:System:
2025-10-11 17:01:56,308:INFO:    python: 3.11.0 (main, Oct 24 2022, 18:26:48) [MSC v.1933 64 bit (AMD64)]
2025-10-11 17:01:56,308:INFO:executable: c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\python.exe
2025-10-11 17:01:56,308:INFO:   machine: Windows-10-10.0.26100-SP0
2025-10-11 17:01:56,308:INFO:PyCaret required dependencies:
2025-10-11 17:01:56,310:INFO:                 pip: 22.3
2025-10-11 17:01:56,310:INFO:          setuptools: 65.5.0
2025-10-11 17:01:56,310:INFO:             pycaret: 3.3.2
2025-10-11 17:01:56,310:INFO:             IPython: 9.6.0
2025-10-11 17:01:56,310:INFO:          ipywidgets: 8.1.7
2025-10-11 17:01:56,310:INFO:                tqdm: 4.67.1
2025-10-11 17:01:56,310:INFO:               numpy: 1.26.4
2025-10-11 17:01:56,310:INFO:              pandas: 2.1.4
2025-10-11 17:01:56,310:INFO:              jinja2: 3.1.6
2025-10-11 17:01:56,310:INFO:               scipy: 1.11.4
2025-10-11 17:01:56,310:INFO:              joblib: 1.3.2
2025-10-11 17:01:56,310:INFO:             sklearn: 1.4.2
2025-10-11 17:01:56,310:INFO:                pyod: 2.0.5
2025-10-11 17:01:56,310:INFO:            imblearn: 0.14.0
2025-10-11 17:01:56,310:INFO:   category_encoders: 2.7.0
2025-10-11 17:01:56,310:INFO:            lightgbm: 4.6.0
2025-10-11 17:01:56,312:INFO:               numba: 0.62.1
2025-10-11 17:01:56,312:INFO:            requests: 2.32.5
2025-10-11 17:01:56,312:INFO:          matplotlib: 3.7.5
2025-10-11 17:01:56,312:INFO:          scikitplot: 0.3.7
2025-10-11 17:01:56,312:INFO:         yellowbrick: 1.5
2025-10-11 17:01:56,312:INFO:              plotly: 6.3.1
2025-10-11 17:01:56,312:INFO:    plotly-resampler: Not installed
2025-10-11 17:01:56,312:INFO:             kaleido: 1.1.0
2025-10-11 17:01:56,312:INFO:           schemdraw: 0.15
2025-10-11 17:01:56,312:INFO:         statsmodels: 0.14.5
2025-10-11 17:01:56,312:INFO:              sktime: 0.26.0
2025-10-11 17:01:56,312:INFO:               tbats: 1.1.3
2025-10-11 17:01:56,312:INFO:            pmdarima: 2.0.4
2025-10-11 17:01:56,312:INFO:              psutil: 7.1.0
2025-10-11 17:01:56,312:INFO:          markupsafe: 3.0.3
2025-10-11 17:01:56,312:INFO:             pickle5: Not installed
2025-10-11 17:01:56,312:INFO:         cloudpickle: 3.1.1
2025-10-11 17:01:56,312:INFO:         deprecation: 2.1.0
2025-10-11 17:01:56,312:INFO:              xxhash: 3.6.0
2025-10-11 17:01:56,312:INFO:           wurlitzer: Not installed
2025-10-11 17:01:56,312:INFO:PyCaret optional dependencies:
2025-10-11 17:01:56,314:INFO:                shap: 0.48.0
2025-10-11 17:01:56,314:INFO:           interpret: Not installed
2025-10-11 17:01:56,314:INFO:                umap: Not installed
2025-10-11 17:01:56,314:INFO:     ydata_profiling: Not installed
2025-10-11 17:01:56,314:INFO:  explainerdashboard: Not installed
2025-10-11 17:01:56,314:INFO:             autoviz: Not installed
2025-10-11 17:01:56,314:INFO:           fairlearn: Not installed
2025-10-11 17:01:56,314:INFO:          deepchecks: Not installed
2025-10-11 17:01:56,314:INFO:             xgboost: Not installed
2025-10-11 17:01:56,314:INFO:            catboost: Not installed
2025-10-11 17:01:56,314:INFO:              kmodes: Not installed
2025-10-11 17:01:56,314:INFO:             mlxtend: Not installed
2025-10-11 17:01:56,314:INFO:       statsforecast: Not installed
2025-10-11 17:01:56,314:INFO:        tune_sklearn: Not installed
2025-10-11 17:01:56,315:INFO:                 ray: Not installed
2025-10-11 17:01:56,315:INFO:            hyperopt: Not installed
2025-10-11 17:01:56,315:INFO:              optuna: Not installed
2025-10-11 17:01:56,315:INFO:               skopt: Not installed
2025-10-11 17:01:56,315:INFO:              mlflow: Not installed
2025-10-11 17:01:56,315:INFO:              gradio: Not installed
2025-10-11 17:01:56,315:INFO:             fastapi: Not installed
2025-10-11 17:01:56,315:INFO:             uvicorn: Not installed
2025-10-11 17:01:56,315:INFO:              m2cgen: Not installed
2025-10-11 17:01:56,315:INFO:           evidently: Not installed
2025-10-11 17:01:56,315:INFO:               fugue: Not installed
2025-10-11 17:01:56,315:INFO:           streamlit: Not installed
2025-10-11 17:01:56,315:INFO:             prophet: Not installed
2025-10-11 17:01:56,315:INFO:None
2025-10-11 17:01:56,315:INFO:Set up data.
2025-10-11 17:01:56,326:INFO:Set up folding strategy.
2025-10-11 17:01:56,326:INFO:Set up train/test split.
2025-10-11 17:01:56,336:INFO:Set up index.
2025-10-11 17:01:56,336:INFO:Assigning column types.
2025-10-11 17:01:56,342:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-11 17:01:56,391:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-11 17:01:56,391:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-11 17:01:56,425:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 17:01:56,425:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 17:01:56,494:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-11 17:01:56,494:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-11 17:01:56,524:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 17:01:56,524:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 17:01:56,524:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-11 17:01:56,610:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-11 17:01:56,642:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 17:01:56,642:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 17:01:56,708:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-11 17:01:56,739:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 17:01:56,739:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 17:01:56,739:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-10-11 17:01:56,957:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 17:01:56,957:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 17:01:57,041:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 17:01:57,041:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 17:01:57,041:INFO:Preparing preprocessing pipeline...
2025-10-11 17:01:57,041:INFO:Set up simple imputation.
2025-10-11 17:01:57,041:INFO:Set up encoding of categorical features.
2025-10-11 17:01:57,041:INFO:Set up removing multicollinearity.
2025-10-11 17:01:57,041:INFO:Set up column transformation.
2025-10-11 17:01:57,041:INFO:Set up feature normalization.
2025-10-11 17:01:57,041:INFO:Set up feature selection.
2025-10-11 17:01:57,141:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 17:01:57,141:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 17:01:57,389:INFO:Finished creating preprocessing pipeline.
2025-10-11 17:01:57,418:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\ARNALDO\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['likes', 'comentarios',
                                             'engagement'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Transf...
                                                                                         learning_rate=0.1,
                                                                                         max_depth=-1,
                                                                                         min_child_samples=20,
                                                                                         min_child_weight=0.001,
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=None,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=1,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf)))],
         verbose=False)
2025-10-11 17:01:57,418:INFO:Creating final display dataframe.
2025-10-11 17:01:57,591:INFO:Setup _display_container:                     Description             Value
0                    Session id              2025
1                        Target        conversion
2                   Target type            Binary
3           Original data shape         (220, 10)
4        Transformed data shape          (220, 2)
5   Transformed train set shape          (154, 2)
6    Transformed test set shape           (66, 2)
7               Ignore features                 2
8              Numeric features                 3
9          Categorical features                 4
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16     Remove multicollinearity              True
17  Multicollinearity threshold               0.9
18               Transformation              True
19        Transformation method       yeo-johnson
20                    Normalize              True
21             Normalize method            zscore
22            Feature selection              True
23     Feature selection method           classic
24  Feature selection estimator          lightgbm
25  Number of features selected               0.2
26               Fold Generator   StratifiedKFold
27                  Fold Number                10
28                     CPU Jobs                -1
29                      Use GPU             False
30               Log Experiment             False
31              Experiment Name  clf-default-name
32                          USI              2a02
2025-10-11 17:01:57,705:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 17:01:57,705:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 17:01:57,773:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 17:01:57,773:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 17:01:57,773:INFO:setup() successfully completed in 1.48s...............
2025-10-11 17:01:57,790:INFO:Initializing compare_models()
2025-10-11 17:01:57,790:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012C8861A9D0>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=F1, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000012C8861A9D0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'F1', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-10-11 17:01:57,790:INFO:Checking exceptions
2025-10-11 17:01:57,790:INFO:Preparing display monitor
2025-10-11 17:01:57,828:INFO:Initializing Logistic Regression
2025-10-11 17:01:57,828:INFO:Total runtime is 0.0 minutes
2025-10-11 17:01:57,833:INFO:SubProcess create_model() called ==================================
2025-10-11 17:01:57,834:INFO:Initializing create_model()
2025-10-11 17:01:57,834:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012C8861A9D0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012C8873D1D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-11 17:01:57,834:INFO:Checking exceptions
2025-10-11 17:01:57,834:INFO:Importing libraries
2025-10-11 17:01:57,834:INFO:Copying training dataset
2025-10-11 17:01:57,839:INFO:Defining folds
2025-10-11 17:01:57,839:INFO:Declaring metric variables
2025-10-11 17:01:57,843:INFO:Importing untrained model
2025-10-11 17:01:57,848:INFO:Logistic Regression Imported successfully
2025-10-11 17:01:57,856:INFO:Starting cross validation
2025-10-11 17:01:57,864:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-11 17:02:17,754:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:02:17,761:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:02:17,765:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:02:17,778:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:02:17,868:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:02:17,899:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:02:17,965:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:02:18,052:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:02:18,069:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:02:18,074:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:02:18,092:INFO:Calculating mean and std
2025-10-11 17:02:18,094:INFO:Creating metrics dataframe
2025-10-11 17:02:18,097:INFO:Uploading results into container
2025-10-11 17:02:18,099:INFO:Uploading model into container now
2025-10-11 17:02:18,101:INFO:_master_model_container: 1
2025-10-11 17:02:18,101:INFO:_display_container: 2
2025-10-11 17:02:18,102:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2025, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-11 17:02:18,102:INFO:create_model() successfully completed......................................
2025-10-11 17:02:18,240:INFO:SubProcess create_model() end ==================================
2025-10-11 17:02:18,240:INFO:Creating metrics dataframe
2025-10-11 17:02:18,257:INFO:Initializing K Neighbors Classifier
2025-10-11 17:02:18,257:INFO:Total runtime is 0.3404848297437032 minutes
2025-10-11 17:02:18,268:INFO:SubProcess create_model() called ==================================
2025-10-11 17:02:18,269:INFO:Initializing create_model()
2025-10-11 17:02:18,269:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012C8861A9D0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012C8873D1D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-11 17:02:18,269:INFO:Checking exceptions
2025-10-11 17:02:18,269:INFO:Importing libraries
2025-10-11 17:02:18,269:INFO:Copying training dataset
2025-10-11 17:02:18,274:INFO:Defining folds
2025-10-11 17:02:18,274:INFO:Declaring metric variables
2025-10-11 17:02:18,286:INFO:Importing untrained model
2025-10-11 17:02:18,291:INFO:K Neighbors Classifier Imported successfully
2025-10-11 17:02:18,304:INFO:Starting cross validation
2025-10-11 17:02:18,307:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-11 17:02:19,020:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:02:22,412:INFO:Calculating mean and std
2025-10-11 17:02:22,412:INFO:Creating metrics dataframe
2025-10-11 17:02:22,415:INFO:Uploading results into container
2025-10-11 17:02:22,417:INFO:Uploading model into container now
2025-10-11 17:02:22,417:INFO:_master_model_container: 2
2025-10-11 17:02:22,417:INFO:_display_container: 2
2025-10-11 17:02:22,417:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-10-11 17:02:22,417:INFO:create_model() successfully completed......................................
2025-10-11 17:02:22,559:INFO:SubProcess create_model() end ==================================
2025-10-11 17:02:22,559:INFO:Creating metrics dataframe
2025-10-11 17:02:22,566:INFO:Initializing Naive Bayes
2025-10-11 17:02:22,566:INFO:Total runtime is 0.4123071948687235 minutes
2025-10-11 17:02:22,573:INFO:SubProcess create_model() called ==================================
2025-10-11 17:02:22,573:INFO:Initializing create_model()
2025-10-11 17:02:22,573:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012C8861A9D0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012C8873D1D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-11 17:02:22,573:INFO:Checking exceptions
2025-10-11 17:02:22,573:INFO:Importing libraries
2025-10-11 17:02:22,573:INFO:Copying training dataset
2025-10-11 17:02:22,573:INFO:Defining folds
2025-10-11 17:02:22,583:INFO:Declaring metric variables
2025-10-11 17:02:22,589:INFO:Importing untrained model
2025-10-11 17:02:22,593:INFO:Naive Bayes Imported successfully
2025-10-11 17:02:22,604:INFO:Starting cross validation
2025-10-11 17:02:22,611:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-11 17:02:23,025:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:02:23,059:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:02:23,078:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:02:23,085:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:02:23,117:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:02:23,154:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:02:23,187:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:02:23,202:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:02:23,238:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:02:23,269:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:02:23,285:INFO:Calculating mean and std
2025-10-11 17:02:23,285:INFO:Creating metrics dataframe
2025-10-11 17:02:23,293:INFO:Uploading results into container
2025-10-11 17:02:23,293:INFO:Uploading model into container now
2025-10-11 17:02:23,293:INFO:_master_model_container: 3
2025-10-11 17:02:23,293:INFO:_display_container: 2
2025-10-11 17:02:23,293:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-10-11 17:02:23,293:INFO:create_model() successfully completed......................................
2025-10-11 17:02:23,447:INFO:SubProcess create_model() end ==================================
2025-10-11 17:02:23,447:INFO:Creating metrics dataframe
2025-10-11 17:02:23,455:INFO:Initializing Decision Tree Classifier
2025-10-11 17:02:23,455:INFO:Total runtime is 0.42711044947306315 minutes
2025-10-11 17:02:23,455:INFO:SubProcess create_model() called ==================================
2025-10-11 17:02:23,455:INFO:Initializing create_model()
2025-10-11 17:02:23,455:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012C8861A9D0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012C8873D1D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-11 17:02:23,455:INFO:Checking exceptions
2025-10-11 17:02:23,455:INFO:Importing libraries
2025-10-11 17:02:23,455:INFO:Copying training dataset
2025-10-11 17:02:23,473:INFO:Defining folds
2025-10-11 17:02:23,473:INFO:Declaring metric variables
2025-10-11 17:02:23,473:INFO:Importing untrained model
2025-10-11 17:02:23,486:INFO:Decision Tree Classifier Imported successfully
2025-10-11 17:02:23,500:INFO:Starting cross validation
2025-10-11 17:02:23,509:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-11 17:02:24,622:INFO:Calculating mean and std
2025-10-11 17:02:24,623:INFO:Creating metrics dataframe
2025-10-11 17:02:24,626:INFO:Uploading results into container
2025-10-11 17:02:24,627:INFO:Uploading model into container now
2025-10-11 17:02:24,628:INFO:_master_model_container: 4
2025-10-11 17:02:24,628:INFO:_display_container: 2
2025-10-11 17:02:24,628:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best')
2025-10-11 17:02:24,628:INFO:create_model() successfully completed......................................
2025-10-11 17:02:24,757:INFO:SubProcess create_model() end ==================================
2025-10-11 17:02:24,758:INFO:Creating metrics dataframe
2025-10-11 17:02:24,769:INFO:Initializing SVM - Linear Kernel
2025-10-11 17:02:24,769:INFO:Total runtime is 0.4490140954653422 minutes
2025-10-11 17:02:24,774:INFO:SubProcess create_model() called ==================================
2025-10-11 17:02:24,774:INFO:Initializing create_model()
2025-10-11 17:02:24,774:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012C8861A9D0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012C8873D1D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-11 17:02:24,774:INFO:Checking exceptions
2025-10-11 17:02:24,775:INFO:Importing libraries
2025-10-11 17:02:24,775:INFO:Copying training dataset
2025-10-11 17:02:24,782:INFO:Defining folds
2025-10-11 17:02:24,783:INFO:Declaring metric variables
2025-10-11 17:02:24,786:INFO:Importing untrained model
2025-10-11 17:02:24,786:INFO:SVM - Linear Kernel Imported successfully
2025-10-11 17:02:24,803:INFO:Starting cross validation
2025-10-11 17:02:24,810:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-11 17:02:25,328:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:02:25,399:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:02:25,409:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:02:25,427:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:02:25,453:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:02:25,492:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:02:25,505:INFO:Calculating mean and std
2025-10-11 17:02:25,506:INFO:Creating metrics dataframe
2025-10-11 17:02:25,510:INFO:Uploading results into container
2025-10-11 17:02:25,511:INFO:Uploading model into container now
2025-10-11 17:02:25,511:INFO:_master_model_container: 5
2025-10-11 17:02:25,511:INFO:_display_container: 2
2025-10-11 17:02:25,512:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=2025, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-10-11 17:02:25,512:INFO:create_model() successfully completed......................................
2025-10-11 17:02:25,614:INFO:SubProcess create_model() end ==================================
2025-10-11 17:02:25,614:INFO:Creating metrics dataframe
2025-10-11 17:02:25,630:INFO:Initializing Ridge Classifier
2025-10-11 17:02:25,630:INFO:Total runtime is 0.4633752425511678 minutes
2025-10-11 17:02:25,630:INFO:SubProcess create_model() called ==================================
2025-10-11 17:02:25,630:INFO:Initializing create_model()
2025-10-11 17:02:25,630:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012C8861A9D0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012C8873D1D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-11 17:02:25,630:INFO:Checking exceptions
2025-10-11 17:02:25,630:INFO:Importing libraries
2025-10-11 17:02:25,630:INFO:Copying training dataset
2025-10-11 17:02:25,656:INFO:Defining folds
2025-10-11 17:02:25,656:INFO:Declaring metric variables
2025-10-11 17:02:25,661:INFO:Importing untrained model
2025-10-11 17:02:25,668:INFO:Ridge Classifier Imported successfully
2025-10-11 17:02:25,677:INFO:Starting cross validation
2025-10-11 17:02:25,684:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-11 17:02:26,401:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:02:26,404:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:02:26,408:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:02:26,537:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:02:26,537:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:02:26,551:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:02:26,551:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:02:26,636:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:02:26,641:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:02:26,661:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:02:26,674:INFO:Calculating mean and std
2025-10-11 17:02:26,675:INFO:Creating metrics dataframe
2025-10-11 17:02:26,678:INFO:Uploading results into container
2025-10-11 17:02:26,680:INFO:Uploading model into container now
2025-10-11 17:02:26,681:INFO:_master_model_container: 6
2025-10-11 17:02:26,681:INFO:_display_container: 2
2025-10-11 17:02:26,682:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=2025, solver='auto',
                tol=0.0001)
2025-10-11 17:02:26,682:INFO:create_model() successfully completed......................................
2025-10-11 17:02:26,804:INFO:SubProcess create_model() end ==================================
2025-10-11 17:02:26,804:INFO:Creating metrics dataframe
2025-10-11 17:02:26,814:INFO:Initializing Random Forest Classifier
2025-10-11 17:02:26,814:INFO:Total runtime is 0.48310394287109376 minutes
2025-10-11 17:02:26,818:INFO:SubProcess create_model() called ==================================
2025-10-11 17:02:26,818:INFO:Initializing create_model()
2025-10-11 17:02:26,819:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012C8861A9D0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012C8873D1D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-11 17:02:26,819:INFO:Checking exceptions
2025-10-11 17:02:26,819:INFO:Importing libraries
2025-10-11 17:02:26,819:INFO:Copying training dataset
2025-10-11 17:02:26,824:INFO:Defining folds
2025-10-11 17:02:26,824:INFO:Declaring metric variables
2025-10-11 17:02:26,829:INFO:Importing untrained model
2025-10-11 17:02:26,834:INFO:Random Forest Classifier Imported successfully
2025-10-11 17:02:26,843:INFO:Starting cross validation
2025-10-11 17:02:26,862:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-11 17:02:29,217:INFO:Calculating mean and std
2025-10-11 17:02:29,219:INFO:Creating metrics dataframe
2025-10-11 17:02:29,223:INFO:Uploading results into container
2025-10-11 17:02:29,224:INFO:Uploading model into container now
2025-10-11 17:02:29,225:INFO:_master_model_container: 7
2025-10-11 17:02:29,225:INFO:_display_container: 2
2025-10-11 17:02:29,225:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=2025, verbose=0,
                       warm_start=False)
2025-10-11 17:02:29,226:INFO:create_model() successfully completed......................................
2025-10-11 17:02:29,391:INFO:SubProcess create_model() end ==================================
2025-10-11 17:02:29,391:INFO:Creating metrics dataframe
2025-10-11 17:02:29,403:INFO:Initializing Quadratic Discriminant Analysis
2025-10-11 17:02:29,403:INFO:Total runtime is 0.52625066836675 minutes
2025-10-11 17:02:29,409:INFO:SubProcess create_model() called ==================================
2025-10-11 17:02:29,409:INFO:Initializing create_model()
2025-10-11 17:02:29,410:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012C8861A9D0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012C8873D1D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-11 17:02:29,410:INFO:Checking exceptions
2025-10-11 17:02:29,410:INFO:Importing libraries
2025-10-11 17:02:29,410:INFO:Copying training dataset
2025-10-11 17:02:29,422:INFO:Defining folds
2025-10-11 17:02:29,422:INFO:Declaring metric variables
2025-10-11 17:02:29,432:INFO:Importing untrained model
2025-10-11 17:02:29,441:INFO:Quadratic Discriminant Analysis Imported successfully
2025-10-11 17:02:29,453:INFO:Starting cross validation
2025-10-11 17:02:29,464:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-11 17:02:30,063:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:02:30,069:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:02:30,072:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:02:30,072:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:02:30,143:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:02:30,161:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:02:30,171:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:02:30,177:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:02:30,231:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:02:30,254:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:02:30,275:INFO:Calculating mean and std
2025-10-11 17:02:30,277:INFO:Creating metrics dataframe
2025-10-11 17:02:30,282:INFO:Uploading results into container
2025-10-11 17:02:30,282:INFO:Uploading model into container now
2025-10-11 17:02:30,282:INFO:_master_model_container: 8
2025-10-11 17:02:30,282:INFO:_display_container: 2
2025-10-11 17:02:30,282:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-10-11 17:02:30,282:INFO:create_model() successfully completed......................................
2025-10-11 17:02:30,402:INFO:SubProcess create_model() end ==================================
2025-10-11 17:02:30,402:INFO:Creating metrics dataframe
2025-10-11 17:02:30,414:INFO:Initializing Ada Boost Classifier
2025-10-11 17:02:30,414:INFO:Total runtime is 0.5431069135665894 minutes
2025-10-11 17:02:30,419:INFO:SubProcess create_model() called ==================================
2025-10-11 17:02:30,420:INFO:Initializing create_model()
2025-10-11 17:02:30,420:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012C8861A9D0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012C8873D1D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-11 17:02:30,420:INFO:Checking exceptions
2025-10-11 17:02:30,420:INFO:Importing libraries
2025-10-11 17:02:30,420:INFO:Copying training dataset
2025-10-11 17:02:30,425:INFO:Defining folds
2025-10-11 17:02:30,426:INFO:Declaring metric variables
2025-10-11 17:02:30,432:INFO:Importing untrained model
2025-10-11 17:02:30,438:INFO:Ada Boost Classifier Imported successfully
2025-10-11 17:02:30,447:INFO:Starting cross validation
2025-10-11 17:02:30,456:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-11 17:02:30,877:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-11 17:02:30,878:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-11 17:02:30,879:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-11 17:02:30,883:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-11 17:02:30,887:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-11 17:02:31,237:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-11 17:02:31,242:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-11 17:02:31,250:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-11 17:02:31,256:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-11 17:02:31,354:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-11 17:02:31,527:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:02:31,535:INFO:Calculating mean and std
2025-10-11 17:02:31,535:INFO:Creating metrics dataframe
2025-10-11 17:02:31,535:INFO:Uploading results into container
2025-10-11 17:02:31,535:INFO:Uploading model into container now
2025-10-11 17:02:31,535:INFO:_master_model_container: 9
2025-10-11 17:02:31,535:INFO:_display_container: 2
2025-10-11 17:02:31,644:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2025)
2025-10-11 17:02:31,644:INFO:create_model() successfully completed......................................
2025-10-11 17:02:31,810:INFO:SubProcess create_model() end ==================================
2025-10-11 17:02:31,810:INFO:Creating metrics dataframe
2025-10-11 17:02:31,832:INFO:Initializing Gradient Boosting Classifier
2025-10-11 17:02:31,832:INFO:Total runtime is 0.5667290091514587 minutes
2025-10-11 17:02:31,833:INFO:SubProcess create_model() called ==================================
2025-10-11 17:02:31,833:INFO:Initializing create_model()
2025-10-11 17:02:31,833:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012C8861A9D0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012C8873D1D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-11 17:02:31,833:INFO:Checking exceptions
2025-10-11 17:02:31,833:INFO:Importing libraries
2025-10-11 17:02:31,833:INFO:Copying training dataset
2025-10-11 17:02:31,849:INFO:Defining folds
2025-10-11 17:02:31,849:INFO:Declaring metric variables
2025-10-11 17:02:31,855:INFO:Importing untrained model
2025-10-11 17:02:31,861:INFO:Gradient Boosting Classifier Imported successfully
2025-10-11 17:02:31,872:INFO:Starting cross validation
2025-10-11 17:02:31,883:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-11 17:02:32,804:INFO:Calculating mean and std
2025-10-11 17:02:32,804:INFO:Creating metrics dataframe
2025-10-11 17:02:32,817:INFO:Uploading results into container
2025-10-11 17:02:32,817:INFO:Uploading model into container now
2025-10-11 17:02:32,817:INFO:_master_model_container: 10
2025-10-11 17:02:32,817:INFO:_display_container: 2
2025-10-11 17:02:32,817:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2025, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-11 17:02:32,817:INFO:create_model() successfully completed......................................
2025-10-11 17:02:32,979:INFO:SubProcess create_model() end ==================================
2025-10-11 17:02:32,979:INFO:Creating metrics dataframe
2025-10-11 17:02:32,981:INFO:Initializing Linear Discriminant Analysis
2025-10-11 17:02:32,981:INFO:Total runtime is 0.5858878135681153 minutes
2025-10-11 17:02:32,998:INFO:SubProcess create_model() called ==================================
2025-10-11 17:02:32,998:INFO:Initializing create_model()
2025-10-11 17:02:32,998:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012C8861A9D0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012C8873D1D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-11 17:02:32,998:INFO:Checking exceptions
2025-10-11 17:02:32,998:INFO:Importing libraries
2025-10-11 17:02:32,998:INFO:Copying training dataset
2025-10-11 17:02:33,004:INFO:Defining folds
2025-10-11 17:02:33,004:INFO:Declaring metric variables
2025-10-11 17:02:33,009:INFO:Importing untrained model
2025-10-11 17:02:33,018:INFO:Linear Discriminant Analysis Imported successfully
2025-10-11 17:02:33,026:INFO:Starting cross validation
2025-10-11 17:02:33,035:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-11 17:02:33,477:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:02:33,485:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:02:33,493:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:02:33,493:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:02:33,564:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:02:33,581:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:02:33,583:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:02:33,616:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:02:33,657:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:02:33,679:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:02:33,698:INFO:Calculating mean and std
2025-10-11 17:02:33,698:INFO:Creating metrics dataframe
2025-10-11 17:02:33,703:INFO:Uploading results into container
2025-10-11 17:02:33,703:INFO:Uploading model into container now
2025-10-11 17:02:33,703:INFO:_master_model_container: 11
2025-10-11 17:02:33,703:INFO:_display_container: 2
2025-10-11 17:02:33,703:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-11 17:02:33,703:INFO:create_model() successfully completed......................................
2025-10-11 17:02:33,826:INFO:SubProcess create_model() end ==================================
2025-10-11 17:02:33,826:INFO:Creating metrics dataframe
2025-10-11 17:02:33,831:INFO:Initializing Extra Trees Classifier
2025-10-11 17:02:33,831:INFO:Total runtime is 0.6000538070996603 minutes
2025-10-11 17:02:33,848:INFO:SubProcess create_model() called ==================================
2025-10-11 17:02:33,848:INFO:Initializing create_model()
2025-10-11 17:02:33,848:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012C8861A9D0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012C8873D1D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-11 17:02:33,848:INFO:Checking exceptions
2025-10-11 17:02:33,848:INFO:Importing libraries
2025-10-11 17:02:33,848:INFO:Copying training dataset
2025-10-11 17:02:33,848:INFO:Defining folds
2025-10-11 17:02:33,848:INFO:Declaring metric variables
2025-10-11 17:02:33,864:INFO:Importing untrained model
2025-10-11 17:02:33,864:INFO:Extra Trees Classifier Imported successfully
2025-10-11 17:02:33,882:INFO:Starting cross validation
2025-10-11 17:02:33,899:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-11 17:02:35,186:INFO:Calculating mean and std
2025-10-11 17:02:35,188:INFO:Creating metrics dataframe
2025-10-11 17:02:35,191:INFO:Uploading results into container
2025-10-11 17:02:35,192:INFO:Uploading model into container now
2025-10-11 17:02:35,193:INFO:_master_model_container: 12
2025-10-11 17:02:35,194:INFO:_display_container: 2
2025-10-11 17:02:35,195:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=2025, verbose=0,
                     warm_start=False)
2025-10-11 17:02:35,195:INFO:create_model() successfully completed......................................
2025-10-11 17:02:35,380:INFO:SubProcess create_model() end ==================================
2025-10-11 17:02:35,380:INFO:Creating metrics dataframe
2025-10-11 17:02:35,403:INFO:Initializing Light Gradient Boosting Machine
2025-10-11 17:02:35,403:INFO:Total runtime is 0.6262468496958415 minutes
2025-10-11 17:02:35,407:INFO:SubProcess create_model() called ==================================
2025-10-11 17:02:35,408:INFO:Initializing create_model()
2025-10-11 17:02:35,408:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012C8861A9D0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012C8873D1D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-11 17:02:35,408:INFO:Checking exceptions
2025-10-11 17:02:35,408:INFO:Importing libraries
2025-10-11 17:02:35,409:INFO:Copying training dataset
2025-10-11 17:02:35,414:INFO:Defining folds
2025-10-11 17:02:35,415:INFO:Declaring metric variables
2025-10-11 17:02:35,421:INFO:Importing untrained model
2025-10-11 17:02:35,426:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-11 17:02:35,436:INFO:Starting cross validation
2025-10-11 17:02:35,446:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-11 17:02:36,099:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:02:36,124:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:02:36,149:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:02:36,286:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:02:36,299:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:02:36,361:INFO:Calculating mean and std
2025-10-11 17:02:36,363:INFO:Creating metrics dataframe
2025-10-11 17:02:36,365:INFO:Uploading results into container
2025-10-11 17:02:36,367:INFO:Uploading model into container now
2025-10-11 17:02:36,369:INFO:_master_model_container: 13
2025-10-11 17:02:36,369:INFO:_display_container: 2
2025-10-11 17:02:36,370:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2025, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-11 17:02:36,370:INFO:create_model() successfully completed......................................
2025-10-11 17:02:36,522:INFO:SubProcess create_model() end ==================================
2025-10-11 17:02:36,522:INFO:Creating metrics dataframe
2025-10-11 17:02:36,530:INFO:Initializing Dummy Classifier
2025-10-11 17:02:36,530:INFO:Total runtime is 0.6450348099072775 minutes
2025-10-11 17:02:36,530:INFO:SubProcess create_model() called ==================================
2025-10-11 17:02:36,530:INFO:Initializing create_model()
2025-10-11 17:02:36,530:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012C8861A9D0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012C8873D1D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-11 17:02:36,530:INFO:Checking exceptions
2025-10-11 17:02:36,530:INFO:Importing libraries
2025-10-11 17:02:36,530:INFO:Copying training dataset
2025-10-11 17:02:36,547:INFO:Defining folds
2025-10-11 17:02:36,547:INFO:Declaring metric variables
2025-10-11 17:02:36,551:INFO:Importing untrained model
2025-10-11 17:02:36,551:INFO:Dummy Classifier Imported successfully
2025-10-11 17:02:36,564:INFO:Starting cross validation
2025-10-11 17:02:36,564:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-11 17:02:37,024:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:02:37,032:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:02:37,034:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:02:37,060:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:02:37,111:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:02:37,122:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:02:37,157:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:02:37,195:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:02:37,209:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:02:37,213:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:02:37,224:INFO:Calculating mean and std
2025-10-11 17:02:37,226:INFO:Creating metrics dataframe
2025-10-11 17:02:37,230:INFO:Uploading results into container
2025-10-11 17:02:37,231:INFO:Uploading model into container now
2025-10-11 17:02:37,233:INFO:_master_model_container: 14
2025-10-11 17:02:37,233:INFO:_display_container: 2
2025-10-11 17:02:37,234:INFO:DummyClassifier(constant=None, random_state=2025, strategy='prior')
2025-10-11 17:02:37,234:INFO:create_model() successfully completed......................................
2025-10-11 17:02:37,380:INFO:SubProcess create_model() end ==================================
2025-10-11 17:02:37,380:INFO:Creating metrics dataframe
2025-10-11 17:02:37,404:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-10-11 17:02:37,419:INFO:Initializing create_model()
2025-10-11 17:02:37,419:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012C8861A9D0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-11 17:02:37,419:INFO:Checking exceptions
2025-10-11 17:02:37,422:INFO:Importing libraries
2025-10-11 17:02:37,423:INFO:Copying training dataset
2025-10-11 17:02:37,429:INFO:Defining folds
2025-10-11 17:02:37,429:INFO:Declaring metric variables
2025-10-11 17:02:37,430:INFO:Importing untrained model
2025-10-11 17:02:37,430:INFO:Declaring custom model
2025-10-11 17:02:37,432:INFO:Decision Tree Classifier Imported successfully
2025-10-11 17:02:37,447:INFO:Cross validation set to False
2025-10-11 17:02:37,448:INFO:Fitting Model
2025-10-11 17:02:37,627:INFO:[LightGBM] [Info] Number of positive: 32, number of negative: 122
2025-10-11 17:02:37,627:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000103 seconds.
2025-10-11 17:02:37,627:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-11 17:02:37,627:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-11 17:02:37,628:INFO:[LightGBM] [Info] Total Bins 186
2025-10-11 17:02:37,628:INFO:[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 14
2025-10-11 17:02:37,628:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.207792 -> initscore=-1.338285
2025-10-11 17:02:37,629:INFO:[LightGBM] [Info] Start training from score -1.338285
2025-10-11 17:02:37,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:37,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:37,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:37,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:37,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:37,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:37,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:37,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:37,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:37,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:37,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:37,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:37,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:37,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:37,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:37,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:37,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:37,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:37,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:37,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:37,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:37,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:37,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:37,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:37,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:37,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:37,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:37,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:37,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:37,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:37,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:37,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:37,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:37,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:37,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:37,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:37,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:37,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:37,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:37,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:37,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:37,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:37,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:37,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:37,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:37,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:37,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:37,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:37,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:37,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:37,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:37,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:37,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:37,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:37,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:37,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:37,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:37,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:37,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:37,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:37,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:37,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:37,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:37,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:37,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:37,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:37,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:37,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:37,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:37,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:37,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:37,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:37,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:37,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:37,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:37,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:37,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:37,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:37,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:37,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:37,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:37,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:37,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:37,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:37,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:37,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:37,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:37,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:37,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:37,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:37,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:37,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:37,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:37,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:37,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:37,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:37,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:37,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:37,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:37,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:37,664:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best')
2025-10-11 17:02:37,664:INFO:create_model() successfully completed......................................
2025-10-11 17:02:37,857:INFO:_master_model_container: 14
2025-10-11 17:02:37,857:INFO:_display_container: 2
2025-10-11 17:02:37,858:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best')
2025-10-11 17:02:37,858:INFO:compare_models() successfully completed......................................
2025-10-11 17:02:37,886:INFO:Initializing tune_model()
2025-10-11 17:02:37,886:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012C8861A9D0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best'), fold=None, round=4, n_iter=10, custom_grid=None, optimize=F1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-10-11 17:02:37,886:INFO:Checking exceptions
2025-10-11 17:02:37,918:INFO:Copying training dataset
2025-10-11 17:02:37,924:INFO:Checking base model
2025-10-11 17:02:37,925:INFO:Base model : Decision Tree Classifier
2025-10-11 17:02:37,933:INFO:Declaring metric variables
2025-10-11 17:02:37,944:INFO:Defining Hyperparameters
2025-10-11 17:02:38,121:INFO:Tuning with n_jobs=-1
2025-10-11 17:02:38,121:INFO:Initializing RandomizedSearchCV
2025-10-11 17:02:47,458:INFO:best_params: {'actual_estimator__min_samples_split': 9, 'actual_estimator__min_samples_leaf': 5, 'actual_estimator__min_impurity_decrease': 0.002, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 11, 'actual_estimator__criterion': 'gini'}
2025-10-11 17:02:47,460:INFO:Hyperparameter search completed
2025-10-11 17:02:47,460:INFO:SubProcess create_model() called ==================================
2025-10-11 17:02:47,462:INFO:Initializing create_model()
2025-10-11 17:02:47,462:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012C8861A9D0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012C88453C10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'min_samples_split': 9, 'min_samples_leaf': 5, 'min_impurity_decrease': 0.002, 'max_features': 'sqrt', 'max_depth': 11, 'criterion': 'gini'})
2025-10-11 17:02:47,462:INFO:Checking exceptions
2025-10-11 17:02:47,462:INFO:Importing libraries
2025-10-11 17:02:47,462:INFO:Copying training dataset
2025-10-11 17:02:47,471:INFO:Defining folds
2025-10-11 17:02:47,471:INFO:Declaring metric variables
2025-10-11 17:02:47,479:INFO:Importing untrained model
2025-10-11 17:02:47,479:INFO:Declaring custom model
2025-10-11 17:02:47,487:INFO:Decision Tree Classifier Imported successfully
2025-10-11 17:02:47,508:INFO:Starting cross validation
2025-10-11 17:02:47,520:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-11 17:02:48,074:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:02:48,283:INFO:Calculating mean and std
2025-10-11 17:02:48,285:INFO:Creating metrics dataframe
2025-10-11 17:02:48,295:INFO:Finalizing model
2025-10-11 17:02:48,456:INFO:[LightGBM] [Info] Number of positive: 32, number of negative: 122
2025-10-11 17:02:48,456:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000112 seconds.
2025-10-11 17:02:48,456:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-10-11 17:02:48,456:INFO:[LightGBM] [Info] Total Bins 186
2025-10-11 17:02:48,456:INFO:[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 14
2025-10-11 17:02:48,456:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.207792 -> initscore=-1.338285
2025-10-11 17:02:48,456:INFO:[LightGBM] [Info] Start training from score -1.338285
2025-10-11 17:02:48,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:48,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:48,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:48,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:48,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:48,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:48,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:48,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:48,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:48,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:48,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:48,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:48,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:48,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:48,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:48,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:48,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:48,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:48,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:48,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:48,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:48,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:48,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:48,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:48,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:48,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:48,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:48,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:48,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:48,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:48,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:48,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:48,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:48,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:48,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:48,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:48,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:48,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:48,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:48,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:48,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:48,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:48,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:48,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:48,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:48,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:48,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:48,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:48,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:48,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:48,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:48,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:48,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:48,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:48,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:48,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:48,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:48,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:48,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:48,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:48,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:48,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:48,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:48,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:48,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:48,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:48,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:48,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:48,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:48,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:48,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:48,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:48,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:48,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:48,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:48,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:48,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:48,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:48,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:48,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:48,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:48,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:48,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:48,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:48,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:48,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:48,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:48,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:48,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:48,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:48,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:48,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:48,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:48,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:48,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:48,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:48,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:48,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:48,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:48,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:48,499:INFO:Uploading results into container
2025-10-11 17:02:48,500:INFO:Uploading model into container now
2025-10-11 17:02:48,501:INFO:_master_model_container: 15
2025-10-11 17:02:48,501:INFO:_display_container: 3
2025-10-11 17:02:48,502:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=11, max_features='sqrt', max_leaf_nodes=None,
                       min_impurity_decrease=0.002, min_samples_leaf=5,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best')
2025-10-11 17:02:48,503:INFO:create_model() successfully completed......................................
2025-10-11 17:02:48,643:INFO:SubProcess create_model() end ==================================
2025-10-11 17:02:48,643:INFO:choose_better activated
2025-10-11 17:02:48,643:INFO:SubProcess create_model() called ==================================
2025-10-11 17:02:48,643:INFO:Initializing create_model()
2025-10-11 17:02:48,643:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012C8861A9D0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-11 17:02:48,643:INFO:Checking exceptions
2025-10-11 17:02:48,643:INFO:Importing libraries
2025-10-11 17:02:48,643:INFO:Copying training dataset
2025-10-11 17:02:48,659:INFO:Defining folds
2025-10-11 17:02:48,659:INFO:Declaring metric variables
2025-10-11 17:02:48,659:INFO:Importing untrained model
2025-10-11 17:02:48,659:INFO:Declaring custom model
2025-10-11 17:02:48,659:INFO:Decision Tree Classifier Imported successfully
2025-10-11 17:02:48,659:INFO:Starting cross validation
2025-10-11 17:02:48,659:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-11 17:02:49,485:INFO:Calculating mean and std
2025-10-11 17:02:49,485:INFO:Creating metrics dataframe
2025-10-11 17:02:49,489:INFO:Finalizing model
2025-10-11 17:02:49,610:INFO:[LightGBM] [Info] Number of positive: 32, number of negative: 122
2025-10-11 17:02:49,610:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000081 seconds.
2025-10-11 17:02:49,610:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-11 17:02:49,610:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-11 17:02:49,610:INFO:[LightGBM] [Info] Total Bins 186
2025-10-11 17:02:49,610:INFO:[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 14
2025-10-11 17:02:49,610:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.207792 -> initscore=-1.338285
2025-10-11 17:02:49,610:INFO:[LightGBM] [Info] Start training from score -1.338285
2025-10-11 17:02:49,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:49,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:49,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:49,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:49,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:49,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:49,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:49,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:49,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:49,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:49,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:49,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:49,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:49,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:49,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:49,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:49,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:49,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:49,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:49,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:49,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:49,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:49,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:49,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:49,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:49,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:49,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:49,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:49,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:49,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:49,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:49,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:49,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:49,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:49,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:49,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:49,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:49,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:49,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:49,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:49,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:49,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:49,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:49,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:49,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:49,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:49,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:49,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:49,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:49,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:49,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:49,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:49,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:49,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:49,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:49,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:49,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:49,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:49,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:49,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:49,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:49,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:49,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:49,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:49,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:49,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:49,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:49,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:49,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:49,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:49,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:49,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:49,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:49,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:49,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:49,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:49,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:49,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:49,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:49,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:49,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:49,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:49,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:49,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:49,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:49,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:49,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:49,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:49,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:49,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:49,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:49,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:49,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:49,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:49,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:49,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:49,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:49,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:49,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:49,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:49,646:INFO:Uploading results into container
2025-10-11 17:02:49,646:INFO:Uploading model into container now
2025-10-11 17:02:49,646:INFO:_master_model_container: 16
2025-10-11 17:02:49,646:INFO:_display_container: 4
2025-10-11 17:02:49,646:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best')
2025-10-11 17:02:49,646:INFO:create_model() successfully completed......................................
2025-10-11 17:02:49,775:INFO:SubProcess create_model() end ==================================
2025-10-11 17:02:49,775:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best') result for F1 is 0.3333
2025-10-11 17:02:49,775:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=11, max_features='sqrt', max_leaf_nodes=None,
                       min_impurity_decrease=0.002, min_samples_leaf=5,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best') result for F1 is 0.24
2025-10-11 17:02:49,775:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best') is best model
2025-10-11 17:02:49,775:INFO:choose_better completed
2025-10-11 17:02:49,775:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-10-11 17:02:49,791:INFO:_master_model_container: 16
2025-10-11 17:02:49,791:INFO:_display_container: 3
2025-10-11 17:02:49,791:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best')
2025-10-11 17:02:49,807:INFO:tune_model() successfully completed......................................
2025-10-11 17:02:49,943:INFO:Initializing plot_model()
2025-10-11 17:02:49,943:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012C8861A9D0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best'), plot=pr, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-10-11 17:02:49,943:INFO:Checking exceptions
2025-10-11 17:02:49,943:INFO:Preloading libraries
2025-10-11 17:02:49,943:INFO:Copying training dataset
2025-10-11 17:02:49,943:INFO:Plot type: pr
2025-10-11 17:02:50,107:INFO:Fitting Model
2025-10-11 17:02:50,107:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names
  warnings.warn(

2025-10-11 17:02:50,107:INFO:Scoring test/hold-out set
2025-10-11 17:02:50,334:INFO:Visual Rendered Successfully
2025-10-11 17:02:50,459:INFO:plot_model() successfully completed......................................
2025-10-11 17:02:50,459:INFO:Initializing plot_model()
2025-10-11 17:02:50,459:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012C8861A9D0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best'), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-10-11 17:02:50,459:INFO:Checking exceptions
2025-10-11 17:02:50,459:INFO:Preloading libraries
2025-10-11 17:02:50,459:INFO:Copying training dataset
2025-10-11 17:02:50,459:INFO:Plot type: confusion_matrix
2025-10-11 17:02:50,604:INFO:Fitting Model
2025-10-11 17:02:50,604:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names
  warnings.warn(

2025-10-11 17:02:50,604:INFO:Scoring test/hold-out set
2025-10-11 17:02:50,740:INFO:Visual Rendered Successfully
2025-10-11 17:02:50,859:INFO:plot_model() successfully completed......................................
2025-10-11 17:02:50,886:INFO:Initializing create_model()
2025-10-11 17:02:50,886:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012C8861A9D0>, estimator=rf, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-11 17:02:50,886:INFO:Checking exceptions
2025-10-11 17:02:50,912:INFO:Importing libraries
2025-10-11 17:02:50,913:INFO:Copying training dataset
2025-10-11 17:02:50,919:INFO:Defining folds
2025-10-11 17:02:50,919:INFO:Declaring metric variables
2025-10-11 17:02:50,926:INFO:Importing untrained model
2025-10-11 17:02:50,935:INFO:Random Forest Classifier Imported successfully
2025-10-11 17:02:50,949:INFO:Starting cross validation
2025-10-11 17:02:50,957:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-11 17:02:52,370:INFO:Calculating mean and std
2025-10-11 17:02:52,370:INFO:Creating metrics dataframe
2025-10-11 17:02:52,397:INFO:Finalizing model
2025-10-11 17:02:52,573:INFO:[LightGBM] [Info] Number of positive: 32, number of negative: 122
2025-10-11 17:02:52,573:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000082 seconds.
2025-10-11 17:02:52,579:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-11 17:02:52,579:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-11 17:02:52,579:INFO:[LightGBM] [Info] Total Bins 186
2025-10-11 17:02:52,579:INFO:[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 14
2025-10-11 17:02:52,579:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.207792 -> initscore=-1.338285
2025-10-11 17:02:52,579:INFO:[LightGBM] [Info] Start training from score -1.338285
2025-10-11 17:02:52,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:52,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:52,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:52,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:52,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:52,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:52,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:52,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:52,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:52,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:52,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:52,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:52,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:52,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:52,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:52,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:52,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:52,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:52,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:52,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:52,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:52,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:52,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:52,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:52,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:52,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:52,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:52,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:52,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:52,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:52,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:52,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:52,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:52,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:52,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:52,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:52,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:52,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:52,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:52,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:52,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:52,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:52,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:52,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:52,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:52,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:52,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:52,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:52,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:52,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:52,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:52,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:52,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:52,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:52,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:52,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:52,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:52,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:52,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:52,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:52,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:52,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:52,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:52,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:52,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:52,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:52,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:52,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:52,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:52,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:52,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:52,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:52,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:52,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:52,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:52,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:52,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:52,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:52,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:52,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:52,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:52,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:52,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:52,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:52,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:52,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:52,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:52,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:52,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:52,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:52,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:52,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:52,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:52,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:52,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:52,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:52,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:52,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:52,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:52,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:02:52,885:INFO:Uploading results into container
2025-10-11 17:02:52,892:INFO:Uploading model into container now
2025-10-11 17:02:52,914:INFO:_master_model_container: 17
2025-10-11 17:02:52,914:INFO:_display_container: 4
2025-10-11 17:02:52,915:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=2025, verbose=0,
                       warm_start=False)
2025-10-11 17:02:52,915:INFO:create_model() successfully completed......................................
2025-10-11 17:02:53,077:INFO:Initializing get_config()
2025-10-11 17:02:53,077:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012C8861A9D0>, variable=y_test)
2025-10-11 17:02:53,077:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-10-11 17:02:53,077:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
  warnings.warn(msg)  # print on screen

2025-10-11 17:02:53,077:INFO:Variable:  returned as 10     0
219    0
119    1
24     0
52     0
      ..
120    0
202    0
82     1
3      0
123    0
Name: conversion, Length: 66, dtype: int8
2025-10-11 17:02:53,077:INFO:get_config() successfully completed......................................
2025-10-11 17:02:53,133:INFO:Initializing interpret_model()
2025-10-11 17:02:53,133:INFO:interpret_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012C8861A9D0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=2025, verbose=0,
                       warm_start=False), plot=summary, feature=None, observation=None, use_train_data=True, X_new_sample=None, y_new_sample=None, save=False, kwargs={})
2025-10-11 17:02:53,134:INFO:Checking exceptions
2025-10-11 17:02:53,134:INFO:Soft dependency imported: shap: 0.48.0
2025-10-11 17:02:53,176:INFO:plot type: summary
2025-10-11 17:02:53,177:INFO:Creating TreeExplainer
2025-10-11 17:02:53,180:INFO:Compiling shap values
2025-10-11 17:02:53,239:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:4145: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.
  shap_plot = shap.summary_plot(shap_values, test_X, show=show, **kwargs)

2025-10-11 17:04:09,790:INFO:Initializing interpret_model()
2025-10-11 17:04:09,790:INFO:interpret_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012C8861A9D0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=2025, verbose=0,
                       warm_start=False), plot=summary, feature=None, observation=None, use_train_data=True, X_new_sample=None, y_new_sample=None, save=False, kwargs={})
2025-10-11 17:04:09,790:INFO:Checking exceptions
2025-10-11 17:04:09,790:INFO:Soft dependency imported: shap: 0.48.0
2025-10-11 17:04:09,836:INFO:plot type: summary
2025-10-11 17:04:09,838:INFO:Creating TreeExplainer
2025-10-11 17:04:09,843:INFO:Compiling shap values
2025-10-11 17:04:09,874:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:4145: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.
  shap_plot = shap.summary_plot(shap_values, test_X, show=show, **kwargs)

2025-10-11 17:04:58,162:INFO:Initializing get_config()
2025-10-11 17:04:58,162:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012C8861A9D0>, variable=y_test)
2025-10-11 17:04:58,163:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-10-11 17:04:58,163:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
  warnings.warn(msg)  # print on screen

2025-10-11 17:04:58,166:INFO:Variable:  returned as 10     0
219    0
119    1
24     0
52     0
      ..
120    0
202    0
82     1
3      0
123    0
Name: conversion, Length: 66, dtype: int8
2025-10-11 17:04:58,166:INFO:get_config() successfully completed......................................
2025-10-11 17:06:41,864:INFO:Initializing get_config()
2025-10-11 17:06:41,864:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012C8861A9D0>, variable=X_train)
2025-10-11 17:06:41,865:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2025-10-11 17:06:41,865:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
  warnings.warn(msg)  # print on screen

2025-10-11 17:06:41,869:INFO:Variable:  returned as     plataforma segmento  likes  comentarios  engagement duracion_categoria  \
35     YouTube   Adulto    547           49   21.363520              Largo   
36    Facebook    Joven    329           61   17.938786              Medio   
85    Facebook   Senior    718            2   22.485552              Largo   
201  Instagram   Senior    187           32   13.375350              Medio   
163    YouTube   Adulto    345          195   23.108440              Medio   
..         ...      ...    ...          ...         ...                ...   
55    Facebook   Senior     90          135   16.294170              Corto   
191    YouTube   Senior     99          185   18.622566              Corto   
160  Instagram    Joven    732            1   22.669363              Largo   
183  Instagram   Senior    399           41   18.460770              Medio   
1     Facebook   Senior     36           21    7.529940              Largo   

       canal_segmento  
35     YouTube_Adulto  
36     Facebook_Joven  
85    Facebook_Senior  
201  Instagram_Senior  
163    YouTube_Adulto  
..                ...  
55    Facebook_Senior  
191    YouTube_Senior  
160   Instagram_Joven  
183  Instagram_Senior  
1     Facebook_Senior  

[154 rows x 7 columns]
2025-10-11 17:06:41,869:INFO:get_config() successfully completed......................................
2025-10-11 17:09:45,549:INFO:Initializing get_config()
2025-10-11 17:09:45,549:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012C8861A9D0>, variable=X_train)
2025-10-11 17:09:45,549:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2025-10-11 17:09:45,549:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
  warnings.warn(msg)  # print on screen

2025-10-11 17:09:45,564:INFO:Variable:  returned as     plataforma segmento  likes  comentarios  engagement duracion_categoria  \
35     YouTube   Adulto    547           49   21.363520              Largo   
36    Facebook    Joven    329           61   17.938786              Medio   
85    Facebook   Senior    718            2   22.485552              Largo   
201  Instagram   Senior    187           32   13.375350              Medio   
163    YouTube   Adulto    345          195   23.108440              Medio   
..         ...      ...    ...          ...         ...                ...   
55    Facebook   Senior     90          135   16.294170              Corto   
191    YouTube   Senior     99          185   18.622566              Corto   
160  Instagram    Joven    732            1   22.669363              Largo   
183  Instagram   Senior    399           41   18.460770              Medio   
1     Facebook   Senior     36           21    7.529940              Largo   

       canal_segmento  
35     YouTube_Adulto  
36     Facebook_Joven  
85    Facebook_Senior  
201  Instagram_Senior  
163    YouTube_Adulto  
..                ...  
55    Facebook_Senior  
191    YouTube_Senior  
160   Instagram_Joven  
183  Instagram_Senior  
1     Facebook_Senior  

[154 rows x 7 columns]
2025-10-11 17:09:45,564:INFO:get_config() successfully completed......................................
2025-10-11 17:13:48,447:INFO:Initializing compare_models()
2025-10-11 17:13:48,447:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012C8861A9D0>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=F1, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000012C8861A9D0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'F1', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-10-11 17:13:48,448:INFO:Checking exceptions
2025-10-11 17:13:48,449:INFO:Preparing display monitor
2025-10-11 17:13:48,473:INFO:Initializing Logistic Regression
2025-10-11 17:13:48,473:INFO:Total runtime is 0.0 minutes
2025-10-11 17:13:48,476:INFO:SubProcess create_model() called ==================================
2025-10-11 17:13:48,476:INFO:Initializing create_model()
2025-10-11 17:13:48,476:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012C8861A9D0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012C88DE3550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-11 17:13:48,476:INFO:Checking exceptions
2025-10-11 17:13:48,476:INFO:Importing libraries
2025-10-11 17:13:48,478:INFO:Copying training dataset
2025-10-11 17:13:48,482:INFO:Defining folds
2025-10-11 17:13:48,482:INFO:Declaring metric variables
2025-10-11 17:13:48,485:INFO:Importing untrained model
2025-10-11 17:13:48,490:INFO:Logistic Regression Imported successfully
2025-10-11 17:13:48,499:INFO:Starting cross validation
2025-10-11 17:13:48,507:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-11 17:13:55,269:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:13:55,269:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:13:55,278:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:13:55,301:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:13:55,452:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:13:55,452:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:13:55,477:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:13:55,498:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:13:55,518:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:13:55,544:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:13:55,560:INFO:Calculating mean and std
2025-10-11 17:13:55,561:INFO:Creating metrics dataframe
2025-10-11 17:13:55,566:INFO:Uploading results into container
2025-10-11 17:13:55,567:INFO:Uploading model into container now
2025-10-11 17:13:55,567:INFO:_master_model_container: 18
2025-10-11 17:13:55,567:INFO:_display_container: 5
2025-10-11 17:13:55,567:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2025, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-11 17:13:55,567:INFO:create_model() successfully completed......................................
2025-10-11 17:13:55,694:INFO:SubProcess create_model() end ==================================
2025-10-11 17:13:55,694:INFO:Creating metrics dataframe
2025-10-11 17:13:55,711:INFO:Initializing K Neighbors Classifier
2025-10-11 17:13:55,711:INFO:Total runtime is 0.12063472668329875 minutes
2025-10-11 17:13:55,711:INFO:SubProcess create_model() called ==================================
2025-10-11 17:13:55,711:INFO:Initializing create_model()
2025-10-11 17:13:55,711:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012C8861A9D0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012C88DE3550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-11 17:13:55,711:INFO:Checking exceptions
2025-10-11 17:13:55,711:INFO:Importing libraries
2025-10-11 17:13:55,711:INFO:Copying training dataset
2025-10-11 17:13:55,711:INFO:Defining folds
2025-10-11 17:13:55,711:INFO:Declaring metric variables
2025-10-11 17:13:55,728:INFO:Importing untrained model
2025-10-11 17:13:55,728:INFO:K Neighbors Classifier Imported successfully
2025-10-11 17:13:55,728:INFO:Starting cross validation
2025-10-11 17:13:55,747:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-11 17:13:56,424:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:13:59,181:INFO:Calculating mean and std
2025-10-11 17:13:59,181:INFO:Creating metrics dataframe
2025-10-11 17:13:59,185:INFO:Uploading results into container
2025-10-11 17:13:59,186:INFO:Uploading model into container now
2025-10-11 17:13:59,187:INFO:_master_model_container: 19
2025-10-11 17:13:59,187:INFO:_display_container: 5
2025-10-11 17:13:59,187:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-10-11 17:13:59,187:INFO:create_model() successfully completed......................................
2025-10-11 17:13:59,294:INFO:SubProcess create_model() end ==================================
2025-10-11 17:13:59,294:INFO:Creating metrics dataframe
2025-10-11 17:13:59,310:INFO:Initializing Naive Bayes
2025-10-11 17:13:59,310:INFO:Total runtime is 0.18061746756235758 minutes
2025-10-11 17:13:59,310:INFO:SubProcess create_model() called ==================================
2025-10-11 17:13:59,310:INFO:Initializing create_model()
2025-10-11 17:13:59,310:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012C8861A9D0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012C88DE3550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-11 17:13:59,310:INFO:Checking exceptions
2025-10-11 17:13:59,310:INFO:Importing libraries
2025-10-11 17:13:59,310:INFO:Copying training dataset
2025-10-11 17:13:59,310:INFO:Defining folds
2025-10-11 17:13:59,310:INFO:Declaring metric variables
2025-10-11 17:13:59,329:INFO:Importing untrained model
2025-10-11 17:13:59,329:INFO:Naive Bayes Imported successfully
2025-10-11 17:13:59,329:INFO:Starting cross validation
2025-10-11 17:13:59,346:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-11 17:13:59,773:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:13:59,785:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:13:59,836:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:13:59,850:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:13:59,903:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:13:59,951:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:14:00,027:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:14:00,062:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:14:00,109:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:14:00,116:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:14:00,137:INFO:Calculating mean and std
2025-10-11 17:14:00,137:INFO:Creating metrics dataframe
2025-10-11 17:14:00,140:INFO:Uploading results into container
2025-10-11 17:14:00,141:INFO:Uploading model into container now
2025-10-11 17:14:00,142:INFO:_master_model_container: 20
2025-10-11 17:14:00,143:INFO:_display_container: 5
2025-10-11 17:14:00,143:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-10-11 17:14:00,144:INFO:create_model() successfully completed......................................
2025-10-11 17:14:00,246:INFO:SubProcess create_model() end ==================================
2025-10-11 17:14:00,246:INFO:Creating metrics dataframe
2025-10-11 17:14:00,260:INFO:Initializing Decision Tree Classifier
2025-10-11 17:14:00,260:INFO:Total runtime is 0.19644893407821656 minutes
2025-10-11 17:14:00,260:INFO:SubProcess create_model() called ==================================
2025-10-11 17:14:00,260:INFO:Initializing create_model()
2025-10-11 17:14:00,260:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012C8861A9D0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012C88DE3550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-11 17:14:00,260:INFO:Checking exceptions
2025-10-11 17:14:00,260:INFO:Importing libraries
2025-10-11 17:14:00,260:INFO:Copying training dataset
2025-10-11 17:14:00,260:INFO:Defining folds
2025-10-11 17:14:00,275:INFO:Declaring metric variables
2025-10-11 17:14:00,276:INFO:Importing untrained model
2025-10-11 17:14:00,281:INFO:Decision Tree Classifier Imported successfully
2025-10-11 17:14:00,281:INFO:Starting cross validation
2025-10-11 17:14:00,295:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-11 17:14:01,214:INFO:Calculating mean and std
2025-10-11 17:14:01,214:INFO:Creating metrics dataframe
2025-10-11 17:14:01,214:INFO:Uploading results into container
2025-10-11 17:14:01,214:INFO:Uploading model into container now
2025-10-11 17:14:01,214:INFO:_master_model_container: 21
2025-10-11 17:14:01,214:INFO:_display_container: 5
2025-10-11 17:14:01,220:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best')
2025-10-11 17:14:01,220:INFO:create_model() successfully completed......................................
2025-10-11 17:14:01,343:INFO:SubProcess create_model() end ==================================
2025-10-11 17:14:01,343:INFO:Creating metrics dataframe
2025-10-11 17:14:01,343:INFO:Initializing SVM - Linear Kernel
2025-10-11 17:14:01,343:INFO:Total runtime is 0.21449868679046633 minutes
2025-10-11 17:14:01,343:INFO:SubProcess create_model() called ==================================
2025-10-11 17:14:01,343:INFO:Initializing create_model()
2025-10-11 17:14:01,343:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012C8861A9D0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012C88DE3550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-11 17:14:01,343:INFO:Checking exceptions
2025-10-11 17:14:01,343:INFO:Importing libraries
2025-10-11 17:14:01,343:INFO:Copying training dataset
2025-10-11 17:14:01,359:INFO:Defining folds
2025-10-11 17:14:01,359:INFO:Declaring metric variables
2025-10-11 17:14:01,359:INFO:Importing untrained model
2025-10-11 17:14:01,365:INFO:SVM - Linear Kernel Imported successfully
2025-10-11 17:14:01,365:INFO:Starting cross validation
2025-10-11 17:14:01,380:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-11 17:14:01,864:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:14:01,946:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:14:01,971:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:14:01,980:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:14:02,013:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:14:02,045:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:14:02,060:INFO:Calculating mean and std
2025-10-11 17:14:02,060:INFO:Creating metrics dataframe
2025-10-11 17:14:02,060:INFO:Uploading results into container
2025-10-11 17:14:02,060:INFO:Uploading model into container now
2025-10-11 17:14:02,065:INFO:_master_model_container: 22
2025-10-11 17:14:02,065:INFO:_display_container: 5
2025-10-11 17:14:02,065:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=2025, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-10-11 17:14:02,066:INFO:create_model() successfully completed......................................
2025-10-11 17:14:02,176:INFO:SubProcess create_model() end ==================================
2025-10-11 17:14:02,176:INFO:Creating metrics dataframe
2025-10-11 17:14:02,176:INFO:Initializing Ridge Classifier
2025-10-11 17:14:02,176:INFO:Total runtime is 0.22838297684987388 minutes
2025-10-11 17:14:02,176:INFO:SubProcess create_model() called ==================================
2025-10-11 17:14:02,176:INFO:Initializing create_model()
2025-10-11 17:14:02,176:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012C8861A9D0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012C88DE3550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-11 17:14:02,176:INFO:Checking exceptions
2025-10-11 17:14:02,176:INFO:Importing libraries
2025-10-11 17:14:02,176:INFO:Copying training dataset
2025-10-11 17:14:02,193:INFO:Defining folds
2025-10-11 17:14:02,193:INFO:Declaring metric variables
2025-10-11 17:14:02,193:INFO:Importing untrained model
2025-10-11 17:14:02,202:INFO:Ridge Classifier Imported successfully
2025-10-11 17:14:02,212:INFO:Starting cross validation
2025-10-11 17:14:02,219:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-11 17:14:02,669:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:14:02,678:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:14:02,687:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:14:02,722:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:14:02,775:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:14:02,797:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:14:02,817:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:14:02,832:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:14:02,879:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:14:02,900:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:14:02,910:INFO:Calculating mean and std
2025-10-11 17:14:02,913:INFO:Creating metrics dataframe
2025-10-11 17:14:02,916:INFO:Uploading results into container
2025-10-11 17:14:02,916:INFO:Uploading model into container now
2025-10-11 17:14:02,916:INFO:_master_model_container: 23
2025-10-11 17:14:02,916:INFO:_display_container: 5
2025-10-11 17:14:02,916:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=2025, solver='auto',
                tol=0.0001)
2025-10-11 17:14:02,916:INFO:create_model() successfully completed......................................
2025-10-11 17:14:03,026:INFO:SubProcess create_model() end ==================================
2025-10-11 17:14:03,026:INFO:Creating metrics dataframe
2025-10-11 17:14:03,026:INFO:Initializing Random Forest Classifier
2025-10-11 17:14:03,026:INFO:Total runtime is 0.2425473729769389 minutes
2025-10-11 17:14:03,043:INFO:SubProcess create_model() called ==================================
2025-10-11 17:14:03,043:INFO:Initializing create_model()
2025-10-11 17:14:03,043:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012C8861A9D0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012C88DE3550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-11 17:14:03,043:INFO:Checking exceptions
2025-10-11 17:14:03,043:INFO:Importing libraries
2025-10-11 17:14:03,043:INFO:Copying training dataset
2025-10-11 17:14:03,043:INFO:Defining folds
2025-10-11 17:14:03,043:INFO:Declaring metric variables
2025-10-11 17:14:03,055:INFO:Importing untrained model
2025-10-11 17:14:03,061:INFO:Random Forest Classifier Imported successfully
2025-10-11 17:14:03,064:INFO:Starting cross validation
2025-10-11 17:14:03,077:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-11 17:14:04,343:INFO:Calculating mean and std
2025-10-11 17:14:04,344:INFO:Creating metrics dataframe
2025-10-11 17:14:04,344:INFO:Uploading results into container
2025-10-11 17:14:04,344:INFO:Uploading model into container now
2025-10-11 17:14:04,344:INFO:_master_model_container: 24
2025-10-11 17:14:04,344:INFO:_display_container: 5
2025-10-11 17:14:04,344:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=2025, verbose=0,
                       warm_start=False)
2025-10-11 17:14:04,344:INFO:create_model() successfully completed......................................
2025-10-11 17:14:04,459:INFO:SubProcess create_model() end ==================================
2025-10-11 17:14:04,459:INFO:Creating metrics dataframe
2025-10-11 17:14:04,476:INFO:Initializing Quadratic Discriminant Analysis
2025-10-11 17:14:04,476:INFO:Total runtime is 0.26670918067296345 minutes
2025-10-11 17:14:04,476:INFO:SubProcess create_model() called ==================================
2025-10-11 17:14:04,476:INFO:Initializing create_model()
2025-10-11 17:14:04,476:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012C8861A9D0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012C88DE3550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-11 17:14:04,476:INFO:Checking exceptions
2025-10-11 17:14:04,476:INFO:Importing libraries
2025-10-11 17:14:04,476:INFO:Copying training dataset
2025-10-11 17:14:04,476:INFO:Defining folds
2025-10-11 17:14:04,476:INFO:Declaring metric variables
2025-10-11 17:14:04,476:INFO:Importing untrained model
2025-10-11 17:14:04,493:INFO:Quadratic Discriminant Analysis Imported successfully
2025-10-11 17:14:04,493:INFO:Starting cross validation
2025-10-11 17:14:04,506:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-11 17:14:05,085:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:14:05,102:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:14:05,103:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:14:05,125:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:14:05,204:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:14:05,204:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:14:05,217:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:14:05,279:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:14:05,314:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:14:05,316:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:14:05,334:INFO:Calculating mean and std
2025-10-11 17:14:05,334:INFO:Creating metrics dataframe
2025-10-11 17:14:05,339:INFO:Uploading results into container
2025-10-11 17:14:05,339:INFO:Uploading model into container now
2025-10-11 17:14:05,339:INFO:_master_model_container: 25
2025-10-11 17:14:05,339:INFO:_display_container: 5
2025-10-11 17:14:05,339:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-10-11 17:14:05,341:INFO:create_model() successfully completed......................................
2025-10-11 17:14:05,489:INFO:SubProcess create_model() end ==================================
2025-10-11 17:14:05,489:INFO:Creating metrics dataframe
2025-10-11 17:14:05,500:INFO:Initializing Ada Boost Classifier
2025-10-11 17:14:05,500:INFO:Total runtime is 0.2837792873382568 minutes
2025-10-11 17:14:05,500:INFO:SubProcess create_model() called ==================================
2025-10-11 17:14:05,500:INFO:Initializing create_model()
2025-10-11 17:14:05,500:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012C8861A9D0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012C88DE3550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-11 17:14:05,500:INFO:Checking exceptions
2025-10-11 17:14:05,500:INFO:Importing libraries
2025-10-11 17:14:05,508:INFO:Copying training dataset
2025-10-11 17:14:05,514:INFO:Defining folds
2025-10-11 17:14:05,514:INFO:Declaring metric variables
2025-10-11 17:14:05,514:INFO:Importing untrained model
2025-10-11 17:14:05,525:INFO:Ada Boost Classifier Imported successfully
2025-10-11 17:14:05,533:INFO:Starting cross validation
2025-10-11 17:14:05,544:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-11 17:14:06,208:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-11 17:14:06,214:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-11 17:14:06,216:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-11 17:14:06,241:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-11 17:14:06,466:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-11 17:14:06,614:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-11 17:14:06,633:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-11 17:14:06,759:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-11 17:14:06,791:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-11 17:14:06,899:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-11 17:14:07,118:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:14:07,131:INFO:Calculating mean and std
2025-10-11 17:14:07,132:INFO:Creating metrics dataframe
2025-10-11 17:14:07,134:INFO:Uploading results into container
2025-10-11 17:14:07,135:INFO:Uploading model into container now
2025-10-11 17:14:07,135:INFO:_master_model_container: 26
2025-10-11 17:14:07,136:INFO:_display_container: 5
2025-10-11 17:14:07,136:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2025)
2025-10-11 17:14:07,136:INFO:create_model() successfully completed......................................
2025-10-11 17:14:07,258:INFO:SubProcess create_model() end ==================================
2025-10-11 17:14:07,258:INFO:Creating metrics dataframe
2025-10-11 17:14:07,267:INFO:Initializing Gradient Boosting Classifier
2025-10-11 17:14:07,267:INFO:Total runtime is 0.31323269605636594 minutes
2025-10-11 17:14:07,271:INFO:SubProcess create_model() called ==================================
2025-10-11 17:14:07,271:INFO:Initializing create_model()
2025-10-11 17:14:07,271:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012C8861A9D0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012C88DE3550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-11 17:14:07,271:INFO:Checking exceptions
2025-10-11 17:14:07,272:INFO:Importing libraries
2025-10-11 17:14:07,272:INFO:Copying training dataset
2025-10-11 17:14:07,277:INFO:Defining folds
2025-10-11 17:14:07,277:INFO:Declaring metric variables
2025-10-11 17:14:07,280:INFO:Importing untrained model
2025-10-11 17:14:07,288:INFO:Gradient Boosting Classifier Imported successfully
2025-10-11 17:14:07,299:INFO:Starting cross validation
2025-10-11 17:14:07,308:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-11 17:14:08,747:INFO:Calculating mean and std
2025-10-11 17:14:08,748:INFO:Creating metrics dataframe
2025-10-11 17:14:08,750:INFO:Uploading results into container
2025-10-11 17:14:08,751:INFO:Uploading model into container now
2025-10-11 17:14:08,751:INFO:_master_model_container: 27
2025-10-11 17:14:08,752:INFO:_display_container: 5
2025-10-11 17:14:08,752:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2025, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-11 17:14:08,752:INFO:create_model() successfully completed......................................
2025-10-11 17:14:08,885:INFO:SubProcess create_model() end ==================================
2025-10-11 17:14:08,885:INFO:Creating metrics dataframe
2025-10-11 17:14:08,895:INFO:Initializing Linear Discriminant Analysis
2025-10-11 17:14:08,896:INFO:Total runtime is 0.3403829137484232 minutes
2025-10-11 17:14:08,899:INFO:SubProcess create_model() called ==================================
2025-10-11 17:14:08,899:INFO:Initializing create_model()
2025-10-11 17:14:08,899:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012C8861A9D0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012C88DE3550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-11 17:14:08,900:INFO:Checking exceptions
2025-10-11 17:14:08,900:INFO:Importing libraries
2025-10-11 17:14:08,900:INFO:Copying training dataset
2025-10-11 17:14:08,904:INFO:Defining folds
2025-10-11 17:14:08,904:INFO:Declaring metric variables
2025-10-11 17:14:08,910:INFO:Importing untrained model
2025-10-11 17:14:08,915:INFO:Linear Discriminant Analysis Imported successfully
2025-10-11 17:14:08,923:INFO:Starting cross validation
2025-10-11 17:14:08,930:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-11 17:14:09,581:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:14:09,587:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:14:09,613:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:14:09,620:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:14:09,737:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:14:09,747:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:14:09,782:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:14:09,814:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:14:09,860:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:14:09,874:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:14:09,893:INFO:Calculating mean and std
2025-10-11 17:14:09,894:INFO:Creating metrics dataframe
2025-10-11 17:14:09,898:INFO:Uploading results into container
2025-10-11 17:14:09,898:INFO:Uploading model into container now
2025-10-11 17:14:09,899:INFO:_master_model_container: 28
2025-10-11 17:14:09,899:INFO:_display_container: 5
2025-10-11 17:14:09,900:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-11 17:14:09,900:INFO:create_model() successfully completed......................................
2025-10-11 17:14:10,031:INFO:SubProcess create_model() end ==================================
2025-10-11 17:14:10,031:INFO:Creating metrics dataframe
2025-10-11 17:14:10,040:INFO:Initializing Extra Trees Classifier
2025-10-11 17:14:10,041:INFO:Total runtime is 0.3594680309295654 minutes
2025-10-11 17:14:10,044:INFO:SubProcess create_model() called ==================================
2025-10-11 17:14:10,045:INFO:Initializing create_model()
2025-10-11 17:14:10,045:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012C8861A9D0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012C88DE3550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-11 17:14:10,045:INFO:Checking exceptions
2025-10-11 17:14:10,045:INFO:Importing libraries
2025-10-11 17:14:10,045:INFO:Copying training dataset
2025-10-11 17:14:10,051:INFO:Defining folds
2025-10-11 17:14:10,051:INFO:Declaring metric variables
2025-10-11 17:14:10,055:INFO:Importing untrained model
2025-10-11 17:14:10,060:INFO:Extra Trees Classifier Imported successfully
2025-10-11 17:14:10,067:INFO:Starting cross validation
2025-10-11 17:14:10,073:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-11 17:14:11,438:INFO:Calculating mean and std
2025-10-11 17:14:11,439:INFO:Creating metrics dataframe
2025-10-11 17:14:11,442:INFO:Uploading results into container
2025-10-11 17:14:11,443:INFO:Uploading model into container now
2025-10-11 17:14:11,444:INFO:_master_model_container: 29
2025-10-11 17:14:11,444:INFO:_display_container: 5
2025-10-11 17:14:11,445:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=2025, verbose=0,
                     warm_start=False)
2025-10-11 17:14:11,446:INFO:create_model() successfully completed......................................
2025-10-11 17:14:11,614:INFO:SubProcess create_model() end ==================================
2025-10-11 17:14:11,614:INFO:Creating metrics dataframe
2025-10-11 17:14:11,630:INFO:Initializing Light Gradient Boosting Machine
2025-10-11 17:14:11,630:INFO:Total runtime is 0.38595104614893594 minutes
2025-10-11 17:14:11,636:INFO:SubProcess create_model() called ==================================
2025-10-11 17:14:11,636:INFO:Initializing create_model()
2025-10-11 17:14:11,636:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012C8861A9D0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012C88DE3550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-11 17:14:11,636:INFO:Checking exceptions
2025-10-11 17:14:11,637:INFO:Importing libraries
2025-10-11 17:14:11,637:INFO:Copying training dataset
2025-10-11 17:14:11,643:INFO:Defining folds
2025-10-11 17:14:11,643:INFO:Declaring metric variables
2025-10-11 17:14:11,652:INFO:Importing untrained model
2025-10-11 17:14:11,658:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-11 17:14:11,683:INFO:Starting cross validation
2025-10-11 17:14:11,726:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-11 17:14:12,598:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:14:12,612:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:14:12,649:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:14:12,767:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:14:12,825:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:14:12,917:INFO:Calculating mean and std
2025-10-11 17:14:12,919:INFO:Creating metrics dataframe
2025-10-11 17:14:12,924:INFO:Uploading results into container
2025-10-11 17:14:12,925:INFO:Uploading model into container now
2025-10-11 17:14:12,926:INFO:_master_model_container: 30
2025-10-11 17:14:12,926:INFO:_display_container: 5
2025-10-11 17:14:12,928:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2025, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-11 17:14:12,929:INFO:create_model() successfully completed......................................
2025-10-11 17:14:13,085:INFO:SubProcess create_model() end ==================================
2025-10-11 17:14:13,085:INFO:Creating metrics dataframe
2025-10-11 17:14:13,097:INFO:Initializing Dummy Classifier
2025-10-11 17:14:13,097:INFO:Total runtime is 0.410402250289917 minutes
2025-10-11 17:14:13,102:INFO:SubProcess create_model() called ==================================
2025-10-11 17:14:13,102:INFO:Initializing create_model()
2025-10-11 17:14:13,102:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012C8861A9D0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012C88DE3550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-11 17:14:13,102:INFO:Checking exceptions
2025-10-11 17:14:13,103:INFO:Importing libraries
2025-10-11 17:14:13,103:INFO:Copying training dataset
2025-10-11 17:14:13,108:INFO:Defining folds
2025-10-11 17:14:13,108:INFO:Declaring metric variables
2025-10-11 17:14:13,114:INFO:Importing untrained model
2025-10-11 17:14:13,120:INFO:Dummy Classifier Imported successfully
2025-10-11 17:14:13,131:INFO:Starting cross validation
2025-10-11 17:14:13,138:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-11 17:14:13,712:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:14:13,718:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:14:13,724:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:14:13,748:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:14:13,828:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:14:13,842:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:14:13,844:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:14:13,878:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:14:13,929:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:14:13,945:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 17:14:13,966:INFO:Calculating mean and std
2025-10-11 17:14:13,967:INFO:Creating metrics dataframe
2025-10-11 17:14:13,970:INFO:Uploading results into container
2025-10-11 17:14:13,971:INFO:Uploading model into container now
2025-10-11 17:14:13,972:INFO:_master_model_container: 31
2025-10-11 17:14:13,972:INFO:_display_container: 5
2025-10-11 17:14:13,973:INFO:DummyClassifier(constant=None, random_state=2025, strategy='prior')
2025-10-11 17:14:13,973:INFO:create_model() successfully completed......................................
2025-10-11 17:14:14,125:INFO:SubProcess create_model() end ==================================
2025-10-11 17:14:14,125:INFO:Creating metrics dataframe
2025-10-11 17:14:14,137:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-10-11 17:14:14,149:INFO:Initializing create_model()
2025-10-11 17:14:14,149:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012C8861A9D0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-11 17:14:14,149:INFO:Checking exceptions
2025-10-11 17:14:14,152:INFO:Importing libraries
2025-10-11 17:14:14,152:INFO:Copying training dataset
2025-10-11 17:14:14,156:INFO:Defining folds
2025-10-11 17:14:14,156:INFO:Declaring metric variables
2025-10-11 17:14:14,156:INFO:Importing untrained model
2025-10-11 17:14:14,156:INFO:Declaring custom model
2025-10-11 17:14:14,157:INFO:Decision Tree Classifier Imported successfully
2025-10-11 17:14:14,163:INFO:Cross validation set to False
2025-10-11 17:14:14,163:INFO:Fitting Model
2025-10-11 17:14:14,339:INFO:[LightGBM] [Info] Number of positive: 32, number of negative: 122
2025-10-11 17:14:14,343:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000107 seconds.
2025-10-11 17:14:14,343:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-11 17:14:14,343:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-11 17:14:14,343:INFO:[LightGBM] [Info] Total Bins 186
2025-10-11 17:14:14,343:INFO:[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 14
2025-10-11 17:14:14,343:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.207792 -> initscore=-1.338285
2025-10-11 17:14:14,343:INFO:[LightGBM] [Info] Start training from score -1.338285
2025-10-11 17:14:14,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:14:14,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:14:14,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:14:14,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:14:14,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:14:14,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:14:14,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:14:14,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:14:14,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:14:14,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:14:14,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:14:14,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:14:14,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:14:14,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:14:14,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:14:14,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:14:14,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:14:14,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:14:14,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:14:14,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:14:14,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:14:14,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:14:14,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:14:14,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:14:14,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:14:14,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:14:14,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:14:14,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:14:14,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:14:14,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:14:14,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:14:14,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:14:14,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:14:14,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:14:14,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:14:14,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:14:14,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:14:14,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:14:14,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:14:14,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:14:14,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:14:14,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:14:14,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:14:14,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:14:14,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:14:14,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:14:14,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:14:14,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:14:14,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:14:14,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:14:14,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:14:14,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:14:14,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:14:14,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:14:14,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:14:14,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:14:14,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:14:14,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:14:14,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:14:14,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:14:14,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:14:14,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:14:14,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:14:14,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:14:14,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:14:14,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:14:14,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:14:14,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:14:14,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:14:14,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:14:14,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:14:14,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:14:14,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:14:14,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:14:14,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:14:14,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:14:14,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:14:14,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:14:14,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:14:14,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:14:14,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:14:14,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:14:14,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:14:14,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:14:14,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:14:14,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:14:14,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:14:14,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:14:14,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:14:14,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:14:14,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:14:14,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:14:14,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:14:14,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:14:14,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:14:14,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:14:14,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:14:14,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:14:14,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:14:14,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:14:14,396:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best')
2025-10-11 17:14:14,396:INFO:create_model() successfully completed......................................
2025-10-11 17:14:14,615:INFO:_master_model_container: 31
2025-10-11 17:14:14,616:INFO:_display_container: 5
2025-10-11 17:14:14,617:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best')
2025-10-11 17:14:14,617:INFO:compare_models() successfully completed......................................
2025-10-11 17:15:05,418:INFO:Initializing create_model()
2025-10-11 17:15:05,418:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012C8861A9D0>, estimator=rf, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-11 17:15:05,418:INFO:Checking exceptions
2025-10-11 17:15:05,449:INFO:Importing libraries
2025-10-11 17:15:05,449:INFO:Copying training dataset
2025-10-11 17:15:05,456:INFO:Defining folds
2025-10-11 17:15:05,456:INFO:Declaring metric variables
2025-10-11 17:15:05,463:INFO:Importing untrained model
2025-10-11 17:15:05,470:INFO:Random Forest Classifier Imported successfully
2025-10-11 17:15:05,483:INFO:Starting cross validation
2025-10-11 17:15:05,491:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-11 17:15:07,119:INFO:Calculating mean and std
2025-10-11 17:15:07,119:INFO:Creating metrics dataframe
2025-10-11 17:15:07,128:INFO:Finalizing model
2025-10-11 17:15:07,247:INFO:[LightGBM] [Info] Number of positive: 32, number of negative: 122
2025-10-11 17:15:07,247:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000073 seconds.
2025-10-11 17:15:07,247:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-11 17:15:07,247:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-11 17:15:07,247:INFO:[LightGBM] [Info] Total Bins 186
2025-10-11 17:15:07,247:INFO:[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 14
2025-10-11 17:15:07,247:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.207792 -> initscore=-1.338285
2025-10-11 17:15:07,247:INFO:[LightGBM] [Info] Start training from score -1.338285
2025-10-11 17:15:07,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:15:07,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:15:07,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:15:07,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:15:07,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:15:07,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:15:07,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:15:07,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:15:07,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:15:07,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:15:07,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:15:07,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:15:07,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:15:07,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:15:07,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:15:07,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:15:07,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:15:07,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:15:07,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:15:07,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:15:07,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:15:07,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:15:07,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:15:07,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:15:07,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:15:07,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:15:07,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:15:07,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:15:07,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:15:07,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:15:07,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:15:07,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:15:07,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:15:07,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:15:07,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:15:07,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:15:07,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:15:07,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:15:07,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:15:07,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:15:07,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:15:07,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:15:07,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:15:07,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:15:07,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:15:07,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:15:07,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:15:07,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:15:07,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:15:07,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:15:07,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:15:07,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:15:07,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:15:07,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:15:07,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:15:07,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:15:07,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:15:07,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:15:07,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:15:07,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:15:07,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:15:07,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:15:07,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:15:07,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:15:07,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:15:07,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:15:07,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:15:07,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:15:07,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:15:07,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:15:07,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:15:07,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:15:07,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:15:07,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:15:07,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:15:07,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:15:07,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:15:07,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:15:07,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:15:07,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:15:07,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:15:07,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:15:07,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:15:07,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:15:07,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:15:07,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:15:07,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:15:07,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:15:07,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:15:07,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:15:07,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:15:07,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:15:07,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:15:07,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:15:07,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:15:07,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:15:07,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:15:07,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:15:07,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:15:07,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 17:15:07,509:INFO:Uploading results into container
2025-10-11 17:15:07,510:INFO:Uploading model into container now
2025-10-11 17:15:07,521:INFO:_master_model_container: 32
2025-10-11 17:15:07,521:INFO:_display_container: 6
2025-10-11 17:15:07,522:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=2025, verbose=0,
                       warm_start=False)
2025-10-11 17:15:07,522:INFO:create_model() successfully completed......................................
2025-10-11 17:15:46,776:INFO:Initializing get_config()
2025-10-11 17:15:46,777:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012C8861A9D0>, variable=y_test)
2025-10-11 17:15:46,777:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-10-11 17:15:46,777:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
  warnings.warn(msg)  # print on screen

2025-10-11 17:15:46,779:INFO:Variable:  returned as 10     0
219    0
119    1
24     0
52     0
      ..
120    0
202    0
82     1
3      0
123    0
Name: conversion, Length: 66, dtype: int8
2025-10-11 17:15:46,779:INFO:get_config() successfully completed......................................
2025-10-11 17:16:07,187:INFO:Initializing get_config()
2025-10-11 17:16:07,187:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012C8861A9D0>, variable=y_train)
2025-10-11 17:16:07,187:INFO:Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.
2025-10-11 17:16:07,187:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.
  warnings.warn(msg)  # print on screen

2025-10-11 17:16:07,187:INFO:Variable:  returned as 35     1
36     0
85     0
201    0
163    0
      ..
55     0
191    0
160    1
183    0
1      0
Name: conversion, Length: 154, dtype: int8
2025-10-11 17:16:07,187:INFO:get_config() successfully completed......................................
2025-10-11 17:16:23,811:INFO:Initializing get_config()
2025-10-11 17:16:23,811:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012C8861A9D0>, variable=X_train)
2025-10-11 17:16:23,812:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2025-10-11 17:16:23,812:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
  warnings.warn(msg)  # print on screen

2025-10-11 17:16:23,819:INFO:Variable:  returned as     plataforma segmento  likes  comentarios  engagement duracion_categoria  \
35     YouTube   Adulto    547           49   21.363520              Largo   
36    Facebook    Joven    329           61   17.938786              Medio   
85    Facebook   Senior    718            2   22.485552              Largo   
201  Instagram   Senior    187           32   13.375350              Medio   
163    YouTube   Adulto    345          195   23.108440              Medio   
..         ...      ...    ...          ...         ...                ...   
55    Facebook   Senior     90          135   16.294170              Corto   
191    YouTube   Senior     99          185   18.622566              Corto   
160  Instagram    Joven    732            1   22.669363              Largo   
183  Instagram   Senior    399           41   18.460770              Medio   
1     Facebook   Senior     36           21    7.529940              Largo   

       canal_segmento  
35     YouTube_Adulto  
36     Facebook_Joven  
85    Facebook_Senior  
201  Instagram_Senior  
163    YouTube_Adulto  
..                ...  
55    Facebook_Senior  
191    YouTube_Senior  
160   Instagram_Joven  
183  Instagram_Senior  
1     Facebook_Senior  

[154 rows x 7 columns]
2025-10-11 17:16:23,820:INFO:get_config() successfully completed......................................
2025-10-11 18:17:27,424:INFO:Initializing get_config()
2025-10-11 18:17:27,424:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012C8861A9D0>, variable=X_train_transformed)
2025-10-11 18:17:27,470:INFO:Variable: X_train returned as         likes
35   0.344305
36  -0.415835
85   0.870074
201 -1.007015
163 -0.355236
..        ...
55  -1.505367
191 -1.453371
160  0.911148
183 -0.157267
1   -1.866974

[154 rows x 1 columns]
2025-10-11 18:17:27,470:INFO:get_config() successfully completed......................................
2025-10-11 18:17:50,728:WARNING:C:\Users\ARNALDO\AppData\Local\Temp\ipykernel_27996\3632960152.py:1: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.
  shap.summary_plot(shap_values[1], X_train_transformed)

2025-10-11 18:18:05,003:WARNING:C:\Users\ARNALDO\AppData\Local\Temp\ipykernel_27996\4013774272.py:2: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.
  shap.summary_plot(shap_values[1], X_train_transformed)

2025-10-11 18:21:47,520:INFO:Initializing get_config()
2025-10-11 18:21:47,520:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012C8861A9D0>, variable=X_train_transformed)
2025-10-11 18:21:47,552:INFO:Variable: X_train returned as         likes
35   0.344305
36  -0.415835
85   0.870074
201 -1.007015
163 -0.355236
..        ...
55  -1.505367
191 -1.453371
160  0.911148
183 -0.157267
1   -1.866974

[154 rows x 1 columns]
2025-10-11 18:21:47,552:INFO:get_config() successfully completed......................................
2025-10-11 18:21:51,491:WARNING:C:\Users\ARNALDO\AppData\Local\Temp\ipykernel_27996\1440261186.py:2: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.
  shap.summary_plot(shap_values[1][:, :-1], X_train_transformed)

2025-10-11 18:22:05,657:INFO:PyCaret ClassificationExperiment
2025-10-11 18:22:05,657:INFO:Logging name: clf-default-name
2025-10-11 18:22:05,659:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-10-11 18:22:05,659:INFO:version 3.3.2
2025-10-11 18:22:05,659:INFO:Initializing setup()
2025-10-11 18:22:05,659:INFO:self.USI: 7b51
2025-10-11 18:22:05,659:INFO:self._variable_keys: {'idx', 'fold_shuffle_param', 'y', 'X', 'fold_groups_param', 'fix_imbalance', 'exp_name_log', 'fold_generator', 'gpu_n_jobs_param', 'X_test', 'USI', 'memory', 'gpu_param', 'data', 'html_param', '_ml_usecase', 'is_multiclass', 'seed', 'exp_id', 'pipeline', 'n_jobs_param', 'logging_param', 'log_plots_param', 'X_train', '_available_plots', 'y_test', 'target_param', 'y_train'}
2025-10-11 18:22:05,659:INFO:Checking environment
2025-10-11 18:22:05,659:INFO:python_version: 3.11.0
2025-10-11 18:22:05,659:INFO:python_build: ('main', 'Oct 24 2022 18:26:48')
2025-10-11 18:22:05,659:INFO:machine: AMD64
2025-10-11 18:22:05,659:INFO:platform: Windows-10-10.0.26100-SP0
2025-10-11 18:22:05,662:INFO:Memory: svmem(total=34211835904, available=19666743296, percent=42.5, used=14545092608, free=19666743296)
2025-10-11 18:22:05,662:INFO:Physical Core: 6
2025-10-11 18:22:05,662:INFO:Logical Core: 12
2025-10-11 18:22:05,662:INFO:Checking libraries
2025-10-11 18:22:05,662:INFO:System:
2025-10-11 18:22:05,662:INFO:    python: 3.11.0 (main, Oct 24 2022, 18:26:48) [MSC v.1933 64 bit (AMD64)]
2025-10-11 18:22:05,663:INFO:executable: c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\python.exe
2025-10-11 18:22:05,663:INFO:   machine: Windows-10-10.0.26100-SP0
2025-10-11 18:22:05,663:INFO:PyCaret required dependencies:
2025-10-11 18:22:05,663:INFO:                 pip: 22.3
2025-10-11 18:22:05,663:INFO:          setuptools: 65.5.0
2025-10-11 18:22:05,663:INFO:             pycaret: 3.3.2
2025-10-11 18:22:05,663:INFO:             IPython: 9.6.0
2025-10-11 18:22:05,663:INFO:          ipywidgets: 8.1.7
2025-10-11 18:22:05,663:INFO:                tqdm: 4.67.1
2025-10-11 18:22:05,663:INFO:               numpy: 1.26.4
2025-10-11 18:22:05,663:INFO:              pandas: 2.1.4
2025-10-11 18:22:05,663:INFO:              jinja2: 3.1.6
2025-10-11 18:22:05,663:INFO:               scipy: 1.11.4
2025-10-11 18:22:05,663:INFO:              joblib: 1.3.2
2025-10-11 18:22:05,663:INFO:             sklearn: 1.4.2
2025-10-11 18:22:05,663:INFO:                pyod: 2.0.5
2025-10-11 18:22:05,663:INFO:            imblearn: 0.14.0
2025-10-11 18:22:05,663:INFO:   category_encoders: 2.7.0
2025-10-11 18:22:05,663:INFO:            lightgbm: 4.6.0
2025-10-11 18:22:05,663:INFO:               numba: 0.62.1
2025-10-11 18:22:05,663:INFO:            requests: 2.32.5
2025-10-11 18:22:05,663:INFO:          matplotlib: 3.7.5
2025-10-11 18:22:05,663:INFO:          scikitplot: 0.3.7
2025-10-11 18:22:05,664:INFO:         yellowbrick: 1.5
2025-10-11 18:22:05,664:INFO:              plotly: 6.3.1
2025-10-11 18:22:05,664:INFO:    plotly-resampler: Not installed
2025-10-11 18:22:05,664:INFO:             kaleido: 1.1.0
2025-10-11 18:22:05,664:INFO:           schemdraw: 0.15
2025-10-11 18:22:05,664:INFO:         statsmodels: 0.14.5
2025-10-11 18:22:05,664:INFO:              sktime: 0.26.0
2025-10-11 18:22:05,664:INFO:               tbats: 1.1.3
2025-10-11 18:22:05,664:INFO:            pmdarima: 2.0.4
2025-10-11 18:22:05,664:INFO:              psutil: 7.1.0
2025-10-11 18:22:05,664:INFO:          markupsafe: 3.0.3
2025-10-11 18:22:05,664:INFO:             pickle5: Not installed
2025-10-11 18:22:05,664:INFO:         cloudpickle: 3.1.1
2025-10-11 18:22:05,664:INFO:         deprecation: 2.1.0
2025-10-11 18:22:05,664:INFO:              xxhash: 3.6.0
2025-10-11 18:22:05,664:INFO:           wurlitzer: Not installed
2025-10-11 18:22:05,664:INFO:PyCaret optional dependencies:
2025-10-11 18:22:05,664:INFO:                shap: 0.48.0
2025-10-11 18:22:05,664:INFO:           interpret: Not installed
2025-10-11 18:22:05,664:INFO:                umap: Not installed
2025-10-11 18:22:05,665:INFO:     ydata_profiling: Not installed
2025-10-11 18:22:05,665:INFO:  explainerdashboard: Not installed
2025-10-11 18:22:05,665:INFO:             autoviz: Not installed
2025-10-11 18:22:05,665:INFO:           fairlearn: Not installed
2025-10-11 18:22:05,665:INFO:          deepchecks: Not installed
2025-10-11 18:22:05,665:INFO:             xgboost: Not installed
2025-10-11 18:22:05,665:INFO:            catboost: Not installed
2025-10-11 18:22:05,665:INFO:              kmodes: Not installed
2025-10-11 18:22:05,665:INFO:             mlxtend: Not installed
2025-10-11 18:22:05,665:INFO:       statsforecast: Not installed
2025-10-11 18:22:05,665:INFO:        tune_sklearn: Not installed
2025-10-11 18:22:05,665:INFO:                 ray: Not installed
2025-10-11 18:22:05,665:INFO:            hyperopt: Not installed
2025-10-11 18:22:05,665:INFO:              optuna: Not installed
2025-10-11 18:22:05,665:INFO:               skopt: Not installed
2025-10-11 18:22:05,665:INFO:              mlflow: Not installed
2025-10-11 18:22:05,665:INFO:              gradio: Not installed
2025-10-11 18:22:05,665:INFO:             fastapi: Not installed
2025-10-11 18:22:05,665:INFO:             uvicorn: Not installed
2025-10-11 18:22:05,665:INFO:              m2cgen: Not installed
2025-10-11 18:22:05,665:INFO:           evidently: Not installed
2025-10-11 18:22:05,665:INFO:               fugue: Not installed
2025-10-11 18:22:05,665:INFO:           streamlit: Not installed
2025-10-11 18:22:05,665:INFO:             prophet: Not installed
2025-10-11 18:22:05,665:INFO:None
2025-10-11 18:22:05,665:INFO:Set up data.
2025-10-11 18:22:05,670:INFO:Set up folding strategy.
2025-10-11 18:22:05,670:INFO:Set up train/test split.
2025-10-11 18:22:05,674:INFO:Set up index.
2025-10-11 18:22:05,674:INFO:Assigning column types.
2025-10-11 18:22:05,674:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-11 18:22:05,719:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-11 18:22:05,720:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-11 18:22:05,745:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 18:22:05,746:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 18:22:05,788:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-11 18:22:05,789:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-11 18:22:05,815:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 18:22:05,815:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 18:22:05,815:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-11 18:22:05,859:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-11 18:22:05,885:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 18:22:05,886:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 18:22:05,931:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-11 18:22:05,955:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 18:22:05,955:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 18:22:05,956:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-10-11 18:22:06,019:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 18:22:06,020:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 18:22:06,085:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 18:22:06,085:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 18:22:06,086:INFO:Preparing preprocessing pipeline...
2025-10-11 18:22:06,087:INFO:Set up simple imputation.
2025-10-11 18:22:06,088:INFO:Set up encoding of categorical features.
2025-10-11 18:22:06,089:INFO:Set up removing multicollinearity.
2025-10-11 18:22:06,089:INFO:Set up column transformation.
2025-10-11 18:22:06,089:INFO:Set up feature normalization.
2025-10-11 18:22:06,089:INFO:Set up feature selection.
2025-10-11 18:22:06,154:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 18:22:06,154:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 18:22:06,282:INFO:Finished creating preprocessing pipeline.
2025-10-11 18:22:06,314:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\ARNALDO\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['likes', 'comentarios',
                                             'engagement'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Transf...
                                                                                         learning_rate=0.1,
                                                                                         max_depth=-1,
                                                                                         min_child_samples=20,
                                                                                         min_child_weight=0.001,
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=None,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=1,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf)))],
         verbose=False)
2025-10-11 18:22:06,314:INFO:Creating final display dataframe.
2025-10-11 18:22:06,393:INFO:Setup _display_container:                     Description             Value
0                    Session id              2025
1                        Target        conversion
2                   Target type            Binary
3           Original data shape         (220, 10)
4        Transformed data shape          (220, 2)
5   Transformed train set shape          (154, 2)
6    Transformed test set shape           (66, 2)
7               Ignore features                 2
8              Numeric features                 3
9          Categorical features                 4
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16     Remove multicollinearity              True
17  Multicollinearity threshold               0.9
18               Transformation              True
19        Transformation method       yeo-johnson
20                    Normalize              True
21             Normalize method            zscore
22            Feature selection              True
23     Feature selection method           classic
24  Feature selection estimator          lightgbm
25  Number of features selected               0.2
26               Fold Generator   StratifiedKFold
27                  Fold Number                10
28                     CPU Jobs                -1
29                      Use GPU             False
30               Log Experiment             False
31              Experiment Name  clf-default-name
32                          USI              7b51
2025-10-11 18:22:06,499:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 18:22:06,499:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 18:22:06,562:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 18:22:06,562:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 18:22:06,578:INFO:setup() successfully completed in 0.92s...............
2025-10-11 18:22:06,586:INFO:Initializing compare_models()
2025-10-11 18:22:06,588:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012C88E6B1D0>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=F1, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000012C88E6B1D0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'F1', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-10-11 18:22:06,588:INFO:Checking exceptions
2025-10-11 18:22:06,590:INFO:Preparing display monitor
2025-10-11 18:22:06,613:INFO:Initializing Logistic Regression
2025-10-11 18:22:06,613:INFO:Total runtime is 0.0 minutes
2025-10-11 18:22:06,616:INFO:SubProcess create_model() called ==================================
2025-10-11 18:22:06,616:INFO:Initializing create_model()
2025-10-11 18:22:06,617:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012C88E6B1D0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012C88DF9410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-11 18:22:06,617:INFO:Checking exceptions
2025-10-11 18:22:06,617:INFO:Importing libraries
2025-10-11 18:22:06,617:INFO:Copying training dataset
2025-10-11 18:22:06,620:INFO:Defining folds
2025-10-11 18:22:06,621:INFO:Declaring metric variables
2025-10-11 18:22:06,624:INFO:Importing untrained model
2025-10-11 18:22:06,627:INFO:Logistic Regression Imported successfully
2025-10-11 18:22:06,633:INFO:Starting cross validation
2025-10-11 18:22:06,639:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-11 18:22:13,557:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:22:13,561:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:22:13,563:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:22:13,580:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:22:13,760:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:22:13,760:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:22:13,770:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:22:13,777:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:22:13,792:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:22:13,801:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:22:13,823:INFO:Calculating mean and std
2025-10-11 18:22:13,825:INFO:Creating metrics dataframe
2025-10-11 18:22:13,835:INFO:Uploading results into container
2025-10-11 18:22:13,836:INFO:Uploading model into container now
2025-10-11 18:22:13,838:INFO:_master_model_container: 1
2025-10-11 18:22:13,838:INFO:_display_container: 2
2025-10-11 18:22:13,840:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2025, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-11 18:22:13,840:INFO:create_model() successfully completed......................................
2025-10-11 18:22:14,072:INFO:SubProcess create_model() end ==================================
2025-10-11 18:22:14,072:INFO:Creating metrics dataframe
2025-10-11 18:22:14,079:INFO:Initializing K Neighbors Classifier
2025-10-11 18:22:14,079:INFO:Total runtime is 0.1244265874226888 minutes
2025-10-11 18:22:14,083:INFO:SubProcess create_model() called ==================================
2025-10-11 18:22:14,084:INFO:Initializing create_model()
2025-10-11 18:22:14,084:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012C88E6B1D0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012C88DF9410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-11 18:22:14,084:INFO:Checking exceptions
2025-10-11 18:22:14,084:INFO:Importing libraries
2025-10-11 18:22:14,084:INFO:Copying training dataset
2025-10-11 18:22:14,088:INFO:Defining folds
2025-10-11 18:22:14,088:INFO:Declaring metric variables
2025-10-11 18:22:14,088:INFO:Importing untrained model
2025-10-11 18:22:14,088:INFO:K Neighbors Classifier Imported successfully
2025-10-11 18:22:14,103:INFO:Starting cross validation
2025-10-11 18:22:14,103:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-11 18:22:14,974:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:22:18,650:INFO:Calculating mean and std
2025-10-11 18:22:18,651:INFO:Creating metrics dataframe
2025-10-11 18:22:18,654:INFO:Uploading results into container
2025-10-11 18:22:18,654:INFO:Uploading model into container now
2025-10-11 18:22:18,655:INFO:_master_model_container: 2
2025-10-11 18:22:18,655:INFO:_display_container: 2
2025-10-11 18:22:18,655:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-10-11 18:22:18,656:INFO:create_model() successfully completed......................................
2025-10-11 18:22:18,804:INFO:SubProcess create_model() end ==================================
2025-10-11 18:22:18,804:INFO:Creating metrics dataframe
2025-10-11 18:22:18,812:INFO:Initializing Naive Bayes
2025-10-11 18:22:18,812:INFO:Total runtime is 0.2033091942469279 minutes
2025-10-11 18:22:18,816:INFO:SubProcess create_model() called ==================================
2025-10-11 18:22:18,816:INFO:Initializing create_model()
2025-10-11 18:22:18,817:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012C88E6B1D0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012C88DF9410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-11 18:22:18,817:INFO:Checking exceptions
2025-10-11 18:22:18,817:INFO:Importing libraries
2025-10-11 18:22:18,817:INFO:Copying training dataset
2025-10-11 18:22:18,823:INFO:Defining folds
2025-10-11 18:22:18,823:INFO:Declaring metric variables
2025-10-11 18:22:18,827:INFO:Importing untrained model
2025-10-11 18:22:18,830:INFO:Naive Bayes Imported successfully
2025-10-11 18:22:18,837:INFO:Starting cross validation
2025-10-11 18:22:18,843:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-11 18:22:19,405:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:22:19,504:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:22:19,512:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:22:19,557:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:22:19,592:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:22:19,632:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:22:19,645:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:22:19,690:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:22:19,753:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:22:19,753:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:22:19,774:INFO:Calculating mean and std
2025-10-11 18:22:19,777:INFO:Creating metrics dataframe
2025-10-11 18:22:19,785:INFO:Uploading results into container
2025-10-11 18:22:19,787:INFO:Uploading model into container now
2025-10-11 18:22:19,788:INFO:_master_model_container: 3
2025-10-11 18:22:19,788:INFO:_display_container: 2
2025-10-11 18:22:19,788:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-10-11 18:22:19,788:INFO:create_model() successfully completed......................................
2025-10-11 18:22:19,964:INFO:SubProcess create_model() end ==================================
2025-10-11 18:22:19,964:INFO:Creating metrics dataframe
2025-10-11 18:22:19,984:INFO:Initializing Decision Tree Classifier
2025-10-11 18:22:19,984:INFO:Total runtime is 0.22285115718841553 minutes
2025-10-11 18:22:19,990:INFO:SubProcess create_model() called ==================================
2025-10-11 18:22:19,990:INFO:Initializing create_model()
2025-10-11 18:22:19,990:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012C88E6B1D0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012C88DF9410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-11 18:22:19,990:INFO:Checking exceptions
2025-10-11 18:22:19,990:INFO:Importing libraries
2025-10-11 18:22:19,990:INFO:Copying training dataset
2025-10-11 18:22:20,007:INFO:Defining folds
2025-10-11 18:22:20,007:INFO:Declaring metric variables
2025-10-11 18:22:20,012:INFO:Importing untrained model
2025-10-11 18:22:20,020:INFO:Decision Tree Classifier Imported successfully
2025-10-11 18:22:20,025:INFO:Starting cross validation
2025-10-11 18:22:20,035:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-11 18:22:21,033:INFO:Calculating mean and std
2025-10-11 18:22:21,037:INFO:Creating metrics dataframe
2025-10-11 18:22:21,043:INFO:Uploading results into container
2025-10-11 18:22:21,045:INFO:Uploading model into container now
2025-10-11 18:22:21,047:INFO:_master_model_container: 4
2025-10-11 18:22:21,047:INFO:_display_container: 2
2025-10-11 18:22:21,048:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best')
2025-10-11 18:22:21,048:INFO:create_model() successfully completed......................................
2025-10-11 18:22:21,189:INFO:SubProcess create_model() end ==================================
2025-10-11 18:22:21,189:INFO:Creating metrics dataframe
2025-10-11 18:22:21,203:INFO:Initializing SVM - Linear Kernel
2025-10-11 18:22:21,203:INFO:Total runtime is 0.24315916299819945 minutes
2025-10-11 18:22:21,208:INFO:SubProcess create_model() called ==================================
2025-10-11 18:22:21,208:INFO:Initializing create_model()
2025-10-11 18:22:21,208:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012C88E6B1D0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012C88DF9410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-11 18:22:21,208:INFO:Checking exceptions
2025-10-11 18:22:21,208:INFO:Importing libraries
2025-10-11 18:22:21,208:INFO:Copying training dataset
2025-10-11 18:22:21,216:INFO:Defining folds
2025-10-11 18:22:21,216:INFO:Declaring metric variables
2025-10-11 18:22:21,222:INFO:Importing untrained model
2025-10-11 18:22:21,226:INFO:SVM - Linear Kernel Imported successfully
2025-10-11 18:22:21,231:INFO:Starting cross validation
2025-10-11 18:22:21,240:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-11 18:22:21,988:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:22:22,102:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:22:22,117:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:22:22,128:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:22:22,231:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:22:22,234:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:22:22,244:INFO:Calculating mean and std
2025-10-11 18:22:22,246:INFO:Creating metrics dataframe
2025-10-11 18:22:22,251:INFO:Uploading results into container
2025-10-11 18:22:22,252:INFO:Uploading model into container now
2025-10-11 18:22:22,253:INFO:_master_model_container: 5
2025-10-11 18:22:22,253:INFO:_display_container: 2
2025-10-11 18:22:22,254:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=2025, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-10-11 18:22:22,254:INFO:create_model() successfully completed......................................
2025-10-11 18:22:22,387:INFO:SubProcess create_model() end ==================================
2025-10-11 18:22:22,387:INFO:Creating metrics dataframe
2025-10-11 18:22:22,396:INFO:Initializing Ridge Classifier
2025-10-11 18:22:22,396:INFO:Total runtime is 0.26304484208424883 minutes
2025-10-11 18:22:22,399:INFO:SubProcess create_model() called ==================================
2025-10-11 18:22:22,399:INFO:Initializing create_model()
2025-10-11 18:22:22,399:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012C88E6B1D0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012C88DF9410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-11 18:22:22,399:INFO:Checking exceptions
2025-10-11 18:22:22,399:INFO:Importing libraries
2025-10-11 18:22:22,399:INFO:Copying training dataset
2025-10-11 18:22:22,407:INFO:Defining folds
2025-10-11 18:22:22,407:INFO:Declaring metric variables
2025-10-11 18:22:22,418:INFO:Importing untrained model
2025-10-11 18:22:22,428:INFO:Ridge Classifier Imported successfully
2025-10-11 18:22:22,442:INFO:Starting cross validation
2025-10-11 18:22:22,453:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-11 18:22:23,076:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:22:23,078:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:22:23,096:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:22:23,118:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:22:23,218:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:22:23,227:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:22:23,256:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:22:23,274:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:22:23,281:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:22:23,324:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:22:23,345:INFO:Calculating mean and std
2025-10-11 18:22:23,346:INFO:Creating metrics dataframe
2025-10-11 18:22:23,350:INFO:Uploading results into container
2025-10-11 18:22:23,350:INFO:Uploading model into container now
2025-10-11 18:22:23,352:INFO:_master_model_container: 6
2025-10-11 18:22:23,352:INFO:_display_container: 2
2025-10-11 18:22:23,352:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=2025, solver='auto',
                tol=0.0001)
2025-10-11 18:22:23,352:INFO:create_model() successfully completed......................................
2025-10-11 18:22:23,480:INFO:SubProcess create_model() end ==================================
2025-10-11 18:22:23,480:INFO:Creating metrics dataframe
2025-10-11 18:22:23,490:INFO:Initializing Random Forest Classifier
2025-10-11 18:22:23,490:INFO:Total runtime is 0.28127990563710525 minutes
2025-10-11 18:22:23,502:INFO:SubProcess create_model() called ==================================
2025-10-11 18:22:23,503:INFO:Initializing create_model()
2025-10-11 18:22:23,503:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012C88E6B1D0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012C88DF9410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-11 18:22:23,503:INFO:Checking exceptions
2025-10-11 18:22:23,504:INFO:Importing libraries
2025-10-11 18:22:23,504:INFO:Copying training dataset
2025-10-11 18:22:23,509:INFO:Defining folds
2025-10-11 18:22:23,509:INFO:Declaring metric variables
2025-10-11 18:22:23,513:INFO:Importing untrained model
2025-10-11 18:22:23,514:INFO:Random Forest Classifier Imported successfully
2025-10-11 18:22:23,519:INFO:Starting cross validation
2025-10-11 18:22:23,533:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-11 18:22:25,095:INFO:Calculating mean and std
2025-10-11 18:22:25,099:INFO:Creating metrics dataframe
2025-10-11 18:22:25,104:INFO:Uploading results into container
2025-10-11 18:22:25,106:INFO:Uploading model into container now
2025-10-11 18:22:25,107:INFO:_master_model_container: 7
2025-10-11 18:22:25,107:INFO:_display_container: 2
2025-10-11 18:22:25,108:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=2025, verbose=0,
                       warm_start=False)
2025-10-11 18:22:25,108:INFO:create_model() successfully completed......................................
2025-10-11 18:22:25,250:INFO:SubProcess create_model() end ==================================
2025-10-11 18:22:25,250:INFO:Creating metrics dataframe
2025-10-11 18:22:25,262:INFO:Initializing Quadratic Discriminant Analysis
2025-10-11 18:22:25,262:INFO:Total runtime is 0.3108232537905375 minutes
2025-10-11 18:22:25,268:INFO:SubProcess create_model() called ==================================
2025-10-11 18:22:25,269:INFO:Initializing create_model()
2025-10-11 18:22:25,269:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012C88E6B1D0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012C88DF9410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-11 18:22:25,269:INFO:Checking exceptions
2025-10-11 18:22:25,269:INFO:Importing libraries
2025-10-11 18:22:25,270:INFO:Copying training dataset
2025-10-11 18:22:25,270:INFO:Defining folds
2025-10-11 18:22:25,270:INFO:Declaring metric variables
2025-10-11 18:22:25,280:INFO:Importing untrained model
2025-10-11 18:22:25,286:INFO:Quadratic Discriminant Analysis Imported successfully
2025-10-11 18:22:25,296:INFO:Starting cross validation
2025-10-11 18:22:25,304:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-11 18:22:25,945:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:22:25,958:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:22:25,958:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:22:26,005:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:22:26,010:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:22:26,098:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:22:26,135:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:22:26,152:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:22:26,152:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:22:26,218:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:22:26,232:INFO:Calculating mean and std
2025-10-11 18:22:26,233:INFO:Creating metrics dataframe
2025-10-11 18:22:26,235:INFO:Uploading results into container
2025-10-11 18:22:26,236:INFO:Uploading model into container now
2025-10-11 18:22:26,237:INFO:_master_model_container: 8
2025-10-11 18:22:26,237:INFO:_display_container: 2
2025-10-11 18:22:26,237:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-10-11 18:22:26,237:INFO:create_model() successfully completed......................................
2025-10-11 18:22:26,398:INFO:SubProcess create_model() end ==================================
2025-10-11 18:22:26,398:INFO:Creating metrics dataframe
2025-10-11 18:22:26,410:INFO:Initializing Ada Boost Classifier
2025-10-11 18:22:26,410:INFO:Total runtime is 0.32994332313537594 minutes
2025-10-11 18:22:26,418:INFO:SubProcess create_model() called ==================================
2025-10-11 18:22:26,420:INFO:Initializing create_model()
2025-10-11 18:22:26,420:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012C88E6B1D0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012C88DF9410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-11 18:22:26,420:INFO:Checking exceptions
2025-10-11 18:22:26,420:INFO:Importing libraries
2025-10-11 18:22:26,420:INFO:Copying training dataset
2025-10-11 18:22:26,427:INFO:Defining folds
2025-10-11 18:22:26,428:INFO:Declaring metric variables
2025-10-11 18:22:26,433:INFO:Importing untrained model
2025-10-11 18:22:26,439:INFO:Ada Boost Classifier Imported successfully
2025-10-11 18:22:26,452:INFO:Starting cross validation
2025-10-11 18:22:26,461:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-11 18:22:26,969:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-11 18:22:26,975:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-11 18:22:26,978:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-11 18:22:27,015:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-11 18:22:27,085:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-11 18:22:27,121:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-11 18:22:27,459:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-11 18:22:27,466:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-11 18:22:27,463:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-11 18:22:27,591:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-11 18:22:27,777:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:22:27,835:INFO:Calculating mean and std
2025-10-11 18:22:27,836:INFO:Creating metrics dataframe
2025-10-11 18:22:27,839:INFO:Uploading results into container
2025-10-11 18:22:27,840:INFO:Uploading model into container now
2025-10-11 18:22:27,840:INFO:_master_model_container: 9
2025-10-11 18:22:27,841:INFO:_display_container: 2
2025-10-11 18:22:27,841:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2025)
2025-10-11 18:22:27,841:INFO:create_model() successfully completed......................................
2025-10-11 18:22:28,032:INFO:SubProcess create_model() end ==================================
2025-10-11 18:22:28,032:INFO:Creating metrics dataframe
2025-10-11 18:22:28,050:INFO:Initializing Gradient Boosting Classifier
2025-10-11 18:22:28,050:INFO:Total runtime is 0.3572753508885701 minutes
2025-10-11 18:22:28,050:INFO:SubProcess create_model() called ==================================
2025-10-11 18:22:28,050:INFO:Initializing create_model()
2025-10-11 18:22:28,050:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012C88E6B1D0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012C88DF9410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-11 18:22:28,050:INFO:Checking exceptions
2025-10-11 18:22:28,050:INFO:Importing libraries
2025-10-11 18:22:28,050:INFO:Copying training dataset
2025-10-11 18:22:28,064:INFO:Defining folds
2025-10-11 18:22:28,064:INFO:Declaring metric variables
2025-10-11 18:22:28,070:INFO:Importing untrained model
2025-10-11 18:22:28,070:INFO:Gradient Boosting Classifier Imported successfully
2025-10-11 18:22:28,090:INFO:Starting cross validation
2025-10-11 18:22:28,099:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-11 18:22:29,399:INFO:Calculating mean and std
2025-10-11 18:22:29,401:INFO:Creating metrics dataframe
2025-10-11 18:22:29,401:INFO:Uploading results into container
2025-10-11 18:22:29,401:INFO:Uploading model into container now
2025-10-11 18:22:29,401:INFO:_master_model_container: 10
2025-10-11 18:22:29,401:INFO:_display_container: 2
2025-10-11 18:22:29,401:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2025, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-11 18:22:29,401:INFO:create_model() successfully completed......................................
2025-10-11 18:22:29,542:INFO:SubProcess create_model() end ==================================
2025-10-11 18:22:29,542:INFO:Creating metrics dataframe
2025-10-11 18:22:29,557:INFO:Initializing Linear Discriminant Analysis
2025-10-11 18:22:29,557:INFO:Total runtime is 0.3824037790298461 minutes
2025-10-11 18:22:29,562:INFO:SubProcess create_model() called ==================================
2025-10-11 18:22:29,562:INFO:Initializing create_model()
2025-10-11 18:22:29,562:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012C88E6B1D0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012C88DF9410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-11 18:22:29,562:INFO:Checking exceptions
2025-10-11 18:22:29,562:INFO:Importing libraries
2025-10-11 18:22:29,562:INFO:Copying training dataset
2025-10-11 18:22:29,564:INFO:Defining folds
2025-10-11 18:22:29,564:INFO:Declaring metric variables
2025-10-11 18:22:29,569:INFO:Importing untrained model
2025-10-11 18:22:29,579:INFO:Linear Discriminant Analysis Imported successfully
2025-10-11 18:22:29,590:INFO:Starting cross validation
2025-10-11 18:22:29,596:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-11 18:22:30,286:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:22:30,352:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:22:30,371:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:22:30,484:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:22:30,534:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:22:30,542:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:22:30,588:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:22:30,623:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:22:30,676:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:22:30,686:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:22:30,700:INFO:Calculating mean and std
2025-10-11 18:22:30,702:INFO:Creating metrics dataframe
2025-10-11 18:22:30,705:INFO:Uploading results into container
2025-10-11 18:22:30,706:INFO:Uploading model into container now
2025-10-11 18:22:30,707:INFO:_master_model_container: 11
2025-10-11 18:22:30,707:INFO:_display_container: 2
2025-10-11 18:22:30,708:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-11 18:22:30,708:INFO:create_model() successfully completed......................................
2025-10-11 18:22:30,844:INFO:SubProcess create_model() end ==================================
2025-10-11 18:22:30,844:INFO:Creating metrics dataframe
2025-10-11 18:22:30,855:INFO:Initializing Extra Trees Classifier
2025-10-11 18:22:30,855:INFO:Total runtime is 0.4040279865264892 minutes
2025-10-11 18:22:30,861:INFO:SubProcess create_model() called ==================================
2025-10-11 18:22:30,862:INFO:Initializing create_model()
2025-10-11 18:22:30,862:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012C88E6B1D0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012C88DF9410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-11 18:22:30,862:INFO:Checking exceptions
2025-10-11 18:22:30,862:INFO:Importing libraries
2025-10-11 18:22:30,862:INFO:Copying training dataset
2025-10-11 18:22:30,868:INFO:Defining folds
2025-10-11 18:22:30,869:INFO:Declaring metric variables
2025-10-11 18:22:30,874:INFO:Importing untrained model
2025-10-11 18:22:30,881:INFO:Extra Trees Classifier Imported successfully
2025-10-11 18:22:30,890:INFO:Starting cross validation
2025-10-11 18:22:30,895:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-11 18:22:32,616:INFO:Calculating mean and std
2025-10-11 18:22:32,618:INFO:Creating metrics dataframe
2025-10-11 18:22:32,621:INFO:Uploading results into container
2025-10-11 18:22:32,622:INFO:Uploading model into container now
2025-10-11 18:22:32,623:INFO:_master_model_container: 12
2025-10-11 18:22:32,623:INFO:_display_container: 2
2025-10-11 18:22:32,624:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=2025, verbose=0,
                     warm_start=False)
2025-10-11 18:22:32,624:INFO:create_model() successfully completed......................................
2025-10-11 18:22:32,762:INFO:SubProcess create_model() end ==================================
2025-10-11 18:22:32,762:INFO:Creating metrics dataframe
2025-10-11 18:22:32,778:INFO:Initializing Light Gradient Boosting Machine
2025-10-11 18:22:32,778:INFO:Total runtime is 0.43608691692352286 minutes
2025-10-11 18:22:32,785:INFO:SubProcess create_model() called ==================================
2025-10-11 18:22:32,786:INFO:Initializing create_model()
2025-10-11 18:22:32,786:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012C88E6B1D0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012C88DF9410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-11 18:22:32,786:INFO:Checking exceptions
2025-10-11 18:22:32,786:INFO:Importing libraries
2025-10-11 18:22:32,786:INFO:Copying training dataset
2025-10-11 18:22:32,790:INFO:Defining folds
2025-10-11 18:22:32,790:INFO:Declaring metric variables
2025-10-11 18:22:32,797:INFO:Importing untrained model
2025-10-11 18:22:32,801:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-11 18:22:32,810:INFO:Starting cross validation
2025-10-11 18:22:32,813:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-11 18:22:33,986:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:22:34,108:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:22:34,318:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:22:34,322:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:22:34,470:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:22:34,552:INFO:Calculating mean and std
2025-10-11 18:22:34,554:INFO:Creating metrics dataframe
2025-10-11 18:22:34,559:INFO:Uploading results into container
2025-10-11 18:22:34,564:INFO:Uploading model into container now
2025-10-11 18:22:34,565:INFO:_master_model_container: 13
2025-10-11 18:22:34,565:INFO:_display_container: 2
2025-10-11 18:22:34,567:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2025, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-11 18:22:34,567:INFO:create_model() successfully completed......................................
2025-10-11 18:22:34,730:INFO:SubProcess create_model() end ==================================
2025-10-11 18:22:34,730:INFO:Creating metrics dataframe
2025-10-11 18:22:34,749:INFO:Initializing Dummy Classifier
2025-10-11 18:22:34,749:INFO:Total runtime is 0.46892728408177686 minutes
2025-10-11 18:22:34,754:INFO:SubProcess create_model() called ==================================
2025-10-11 18:22:34,754:INFO:Initializing create_model()
2025-10-11 18:22:34,754:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012C88E6B1D0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012C88DF9410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-11 18:22:34,754:INFO:Checking exceptions
2025-10-11 18:22:34,755:INFO:Importing libraries
2025-10-11 18:22:34,755:INFO:Copying training dataset
2025-10-11 18:22:34,761:INFO:Defining folds
2025-10-11 18:22:34,761:INFO:Declaring metric variables
2025-10-11 18:22:34,761:INFO:Importing untrained model
2025-10-11 18:22:34,773:INFO:Dummy Classifier Imported successfully
2025-10-11 18:22:34,783:INFO:Starting cross validation
2025-10-11 18:22:34,790:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-11 18:22:35,449:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:22:35,458:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:22:35,479:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:22:35,517:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:22:35,562:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:22:35,577:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:22:35,591:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:22:35,652:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:22:35,685:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:22:35,685:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:22:35,706:INFO:Calculating mean and std
2025-10-11 18:22:35,706:INFO:Creating metrics dataframe
2025-10-11 18:22:35,708:INFO:Uploading results into container
2025-10-11 18:22:35,710:INFO:Uploading model into container now
2025-10-11 18:22:35,711:INFO:_master_model_container: 14
2025-10-11 18:22:35,711:INFO:_display_container: 2
2025-10-11 18:22:35,711:INFO:DummyClassifier(constant=None, random_state=2025, strategy='prior')
2025-10-11 18:22:35,711:INFO:create_model() successfully completed......................................
2025-10-11 18:22:35,849:INFO:SubProcess create_model() end ==================================
2025-10-11 18:22:35,849:INFO:Creating metrics dataframe
2025-10-11 18:22:35,870:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-10-11 18:22:35,885:INFO:Initializing create_model()
2025-10-11 18:22:35,885:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012C88E6B1D0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-11 18:22:35,886:INFO:Checking exceptions
2025-10-11 18:22:35,887:INFO:Importing libraries
2025-10-11 18:22:35,887:INFO:Copying training dataset
2025-10-11 18:22:35,891:INFO:Defining folds
2025-10-11 18:22:35,891:INFO:Declaring metric variables
2025-10-11 18:22:35,891:INFO:Importing untrained model
2025-10-11 18:22:35,891:INFO:Declaring custom model
2025-10-11 18:22:35,892:INFO:Decision Tree Classifier Imported successfully
2025-10-11 18:22:35,903:INFO:Cross validation set to False
2025-10-11 18:22:35,903:INFO:Fitting Model
2025-10-11 18:22:36,051:INFO:[LightGBM] [Info] Number of positive: 32, number of negative: 122
2025-10-11 18:22:36,052:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000130 seconds.
2025-10-11 18:22:36,052:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-11 18:22:36,052:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-11 18:22:36,052:INFO:[LightGBM] [Info] Total Bins 186
2025-10-11 18:22:36,052:INFO:[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 14
2025-10-11 18:22:36,052:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.207792 -> initscore=-1.338285
2025-10-11 18:22:36,053:INFO:[LightGBM] [Info] Start training from score -1.338285
2025-10-11 18:22:36,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:36,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:36,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:36,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:36,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:36,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:36,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:36,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:36,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:36,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:36,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:36,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:36,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:36,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:36,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:36,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:36,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:36,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:36,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:36,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:36,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:36,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:36,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:36,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:36,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:36,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:36,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:36,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:36,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:36,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:36,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:36,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:36,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:36,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:36,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:36,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:36,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:36,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:36,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:36,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:36,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:36,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:36,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:36,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:36,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:36,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:36,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:36,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:36,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:36,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:36,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:36,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:36,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:36,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:36,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:36,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:36,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:36,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:36,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:36,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:36,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:36,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:36,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:36,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:36,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:36,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:36,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:36,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:36,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:36,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:36,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:36,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:36,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:36,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:36,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:36,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:36,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:36,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:36,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:36,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:36,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:36,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:36,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:36,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:36,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:36,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:36,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:36,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:36,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:36,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:36,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:36,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:36,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:36,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:36,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:36,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:36,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:36,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:36,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:36,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:36,093:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best')
2025-10-11 18:22:36,093:INFO:create_model() successfully completed......................................
2025-10-11 18:22:36,288:INFO:_master_model_container: 14
2025-10-11 18:22:36,288:INFO:_display_container: 2
2025-10-11 18:22:36,289:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best')
2025-10-11 18:22:36,289:INFO:compare_models() successfully completed......................................
2025-10-11 18:22:36,319:INFO:Initializing tune_model()
2025-10-11 18:22:36,319:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012C88E6B1D0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best'), fold=None, round=4, n_iter=10, custom_grid=None, optimize=F1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-10-11 18:22:36,319:INFO:Checking exceptions
2025-10-11 18:22:36,341:INFO:Copying training dataset
2025-10-11 18:22:36,345:INFO:Checking base model
2025-10-11 18:22:36,346:INFO:Base model : Decision Tree Classifier
2025-10-11 18:22:36,353:INFO:Declaring metric variables
2025-10-11 18:22:36,357:INFO:Defining Hyperparameters
2025-10-11 18:22:36,542:INFO:Tuning with n_jobs=-1
2025-10-11 18:22:36,542:INFO:Initializing RandomizedSearchCV
2025-10-11 18:22:47,309:INFO:best_params: {'actual_estimator__min_samples_split': 9, 'actual_estimator__min_samples_leaf': 5, 'actual_estimator__min_impurity_decrease': 0.002, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 11, 'actual_estimator__criterion': 'gini'}
2025-10-11 18:22:47,309:INFO:Hyperparameter search completed
2025-10-11 18:22:47,309:INFO:SubProcess create_model() called ==================================
2025-10-11 18:22:47,309:INFO:Initializing create_model()
2025-10-11 18:22:47,309:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012C88E6B1D0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012C88F48150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'min_samples_split': 9, 'min_samples_leaf': 5, 'min_impurity_decrease': 0.002, 'max_features': 'sqrt', 'max_depth': 11, 'criterion': 'gini'})
2025-10-11 18:22:47,309:INFO:Checking exceptions
2025-10-11 18:22:47,309:INFO:Importing libraries
2025-10-11 18:22:47,309:INFO:Copying training dataset
2025-10-11 18:22:47,324:INFO:Defining folds
2025-10-11 18:22:47,325:INFO:Declaring metric variables
2025-10-11 18:22:47,334:INFO:Importing untrained model
2025-10-11 18:22:47,334:INFO:Declaring custom model
2025-10-11 18:22:47,338:INFO:Decision Tree Classifier Imported successfully
2025-10-11 18:22:47,346:INFO:Starting cross validation
2025-10-11 18:22:47,351:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-11 18:22:48,062:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:22:48,205:INFO:Calculating mean and std
2025-10-11 18:22:48,210:INFO:Creating metrics dataframe
2025-10-11 18:22:48,222:INFO:Finalizing model
2025-10-11 18:22:48,342:INFO:[LightGBM] [Info] Number of positive: 32, number of negative: 122
2025-10-11 18:22:48,342:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000080 seconds.
2025-10-11 18:22:48,342:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-11 18:22:48,342:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-11 18:22:48,342:INFO:[LightGBM] [Info] Total Bins 186
2025-10-11 18:22:48,342:INFO:[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 14
2025-10-11 18:22:48,342:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.207792 -> initscore=-1.338285
2025-10-11 18:22:48,342:INFO:[LightGBM] [Info] Start training from score -1.338285
2025-10-11 18:22:48,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:48,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:48,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:48,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:48,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:48,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:48,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:48,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:48,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:48,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:48,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:48,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:48,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:48,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:48,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:48,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:48,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:48,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:48,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:48,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:48,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:48,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:48,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:48,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:48,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:48,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:48,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:48,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:48,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:48,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:48,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:48,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:48,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:48,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:48,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:48,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:48,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:48,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:48,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:48,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:48,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:48,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:48,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:48,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:48,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:48,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:48,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:48,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:48,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:48,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:48,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:48,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:48,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:48,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:48,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:48,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:48,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:48,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:48,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:48,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:48,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:48,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:48,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:48,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:48,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:48,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:48,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:48,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:48,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:48,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:48,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:48,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:48,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:48,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:48,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:48,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:48,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:48,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:48,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:48,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:48,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:48,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:48,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:48,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:48,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:48,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:48,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:48,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:48,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:48,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:48,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:48,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:48,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:48,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:48,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:48,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:48,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:48,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:48,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:48,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:48,395:INFO:Uploading results into container
2025-10-11 18:22:48,395:INFO:Uploading model into container now
2025-10-11 18:22:48,395:INFO:_master_model_container: 15
2025-10-11 18:22:48,395:INFO:_display_container: 3
2025-10-11 18:22:48,395:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=11, max_features='sqrt', max_leaf_nodes=None,
                       min_impurity_decrease=0.002, min_samples_leaf=5,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best')
2025-10-11 18:22:48,395:INFO:create_model() successfully completed......................................
2025-10-11 18:22:48,582:INFO:SubProcess create_model() end ==================================
2025-10-11 18:22:48,582:INFO:choose_better activated
2025-10-11 18:22:48,585:INFO:SubProcess create_model() called ==================================
2025-10-11 18:22:48,586:INFO:Initializing create_model()
2025-10-11 18:22:48,586:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012C88E6B1D0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-11 18:22:48,586:INFO:Checking exceptions
2025-10-11 18:22:48,588:INFO:Importing libraries
2025-10-11 18:22:48,588:INFO:Copying training dataset
2025-10-11 18:22:48,593:INFO:Defining folds
2025-10-11 18:22:48,593:INFO:Declaring metric variables
2025-10-11 18:22:48,593:INFO:Importing untrained model
2025-10-11 18:22:48,593:INFO:Declaring custom model
2025-10-11 18:22:48,594:INFO:Decision Tree Classifier Imported successfully
2025-10-11 18:22:48,594:INFO:Starting cross validation
2025-10-11 18:22:48,598:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-11 18:22:49,509:INFO:Calculating mean and std
2025-10-11 18:22:49,510:INFO:Creating metrics dataframe
2025-10-11 18:22:49,511:INFO:Finalizing model
2025-10-11 18:22:49,611:INFO:[LightGBM] [Info] Number of positive: 32, number of negative: 122
2025-10-11 18:22:49,611:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000097 seconds.
2025-10-11 18:22:49,612:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-10-11 18:22:49,612:INFO:[LightGBM] [Info] Total Bins 186
2025-10-11 18:22:49,612:INFO:[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 14
2025-10-11 18:22:49,612:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.207792 -> initscore=-1.338285
2025-10-11 18:22:49,612:INFO:[LightGBM] [Info] Start training from score -1.338285
2025-10-11 18:22:49,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:49,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:49,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:49,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:49,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:49,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:49,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:49,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:49,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:49,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:49,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:49,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:49,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:49,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:49,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:49,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:49,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:49,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:49,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:49,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:49,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:49,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:49,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:49,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:49,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:49,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:49,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:49,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:49,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:49,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:49,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:49,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:49,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:49,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:49,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:49,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:49,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:49,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:49,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:49,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:49,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:49,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:49,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:49,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:49,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:49,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:49,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:49,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:49,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:49,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:49,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:49,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:49,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:49,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:49,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:49,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:49,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:49,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:49,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:49,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:49,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:49,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:49,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:49,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:49,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:49,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:49,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:49,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:49,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:49,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:49,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:49,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:49,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:49,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:49,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:49,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:49,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:49,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:49,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:49,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:49,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:49,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:49,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:49,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:49,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:49,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:49,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:49,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:49,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:49,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:49,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:49,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:49,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:49,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:49,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:49,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:49,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:49,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:49,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:49,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:49,644:INFO:Uploading results into container
2025-10-11 18:22:49,645:INFO:Uploading model into container now
2025-10-11 18:22:49,645:INFO:_master_model_container: 16
2025-10-11 18:22:49,645:INFO:_display_container: 4
2025-10-11 18:22:49,645:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best')
2025-10-11 18:22:49,645:INFO:create_model() successfully completed......................................
2025-10-11 18:22:49,806:INFO:SubProcess create_model() end ==================================
2025-10-11 18:22:49,807:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best') result for F1 is 0.3333
2025-10-11 18:22:49,808:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=11, max_features='sqrt', max_leaf_nodes=None,
                       min_impurity_decrease=0.002, min_samples_leaf=5,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best') result for F1 is 0.24
2025-10-11 18:22:49,808:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best') is best model
2025-10-11 18:22:49,808:INFO:choose_better completed
2025-10-11 18:22:49,808:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-10-11 18:22:49,820:INFO:_master_model_container: 16
2025-10-11 18:22:49,820:INFO:_display_container: 3
2025-10-11 18:22:49,820:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best')
2025-10-11 18:22:49,821:INFO:tune_model() successfully completed......................................
2025-10-11 18:22:49,960:INFO:Initializing plot_model()
2025-10-11 18:22:49,960:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012C88E6B1D0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best'), plot=pr, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-10-11 18:22:49,960:INFO:Checking exceptions
2025-10-11 18:22:49,965:INFO:Preloading libraries
2025-10-11 18:22:49,965:INFO:Copying training dataset
2025-10-11 18:22:49,966:INFO:Plot type: pr
2025-10-11 18:22:50,105:INFO:Fitting Model
2025-10-11 18:22:50,106:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names
  warnings.warn(

2025-10-11 18:22:50,106:INFO:Scoring test/hold-out set
2025-10-11 18:22:50,317:INFO:Visual Rendered Successfully
2025-10-11 18:22:50,452:INFO:plot_model() successfully completed......................................
2025-10-11 18:22:50,453:INFO:Initializing plot_model()
2025-10-11 18:22:50,453:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012C88E6B1D0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best'), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-10-11 18:22:50,453:INFO:Checking exceptions
2025-10-11 18:22:50,457:INFO:Preloading libraries
2025-10-11 18:22:50,457:INFO:Copying training dataset
2025-10-11 18:22:50,458:INFO:Plot type: confusion_matrix
2025-10-11 18:22:50,580:INFO:Fitting Model
2025-10-11 18:22:50,580:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names
  warnings.warn(

2025-10-11 18:22:50,581:INFO:Scoring test/hold-out set
2025-10-11 18:22:50,721:INFO:Visual Rendered Successfully
2025-10-11 18:22:50,870:INFO:plot_model() successfully completed......................................
2025-10-11 18:22:50,893:INFO:Initializing create_model()
2025-10-11 18:22:50,894:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012C88E6B1D0>, estimator=rf, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-11 18:22:50,894:INFO:Checking exceptions
2025-10-11 18:22:50,911:INFO:Importing libraries
2025-10-11 18:22:50,911:INFO:Copying training dataset
2025-10-11 18:22:50,919:INFO:Defining folds
2025-10-11 18:22:50,919:INFO:Declaring metric variables
2025-10-11 18:22:50,922:INFO:Importing untrained model
2025-10-11 18:22:50,925:INFO:Random Forest Classifier Imported successfully
2025-10-11 18:22:50,934:INFO:Starting cross validation
2025-10-11 18:22:50,943:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-11 18:22:52,459:INFO:Calculating mean and std
2025-10-11 18:22:52,462:INFO:Creating metrics dataframe
2025-10-11 18:22:52,485:INFO:Finalizing model
2025-10-11 18:22:52,637:INFO:[LightGBM] [Info] Number of positive: 32, number of negative: 122
2025-10-11 18:22:52,637:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000039 seconds.
2025-10-11 18:22:52,637:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-11 18:22:52,637:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-11 18:22:52,637:INFO:[LightGBM] [Info] Total Bins 186
2025-10-11 18:22:52,637:INFO:[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 14
2025-10-11 18:22:52,637:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.207792 -> initscore=-1.338285
2025-10-11 18:22:52,637:INFO:[LightGBM] [Info] Start training from score -1.338285
2025-10-11 18:22:52,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:52,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:52,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:52,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:52,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:52,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:52,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:52,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:52,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:52,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:52,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:52,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:52,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:52,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:52,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:52,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:52,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:52,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:52,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:52,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:52,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:52,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:52,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:52,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:52,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:52,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:52,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:52,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:52,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:52,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:52,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:52,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:52,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:52,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:52,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:52,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:52,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:52,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:52,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:52,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:52,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:52,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:52,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:52,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:52,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:52,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:52,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:52,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:52,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:52,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:52,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:52,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:52,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:52,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:52,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:52,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:52,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:52,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:52,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:52,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:52,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:52,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:52,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:52,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:52,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:52,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:52,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:52,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:52,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:52,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:52,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:52,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:52,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:52,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:52,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:52,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:52,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:52,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:52,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:52,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:52,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:52,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:52,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:52,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:52,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:52,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:52,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:52,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:52,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:52,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:52,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:52,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:52,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:52,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:52,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:52,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:52,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:52,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:52,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:52,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:22:52,879:INFO:Uploading results into container
2025-10-11 18:22:52,880:INFO:Uploading model into container now
2025-10-11 18:22:52,893:INFO:_master_model_container: 17
2025-10-11 18:22:52,893:INFO:_display_container: 4
2025-10-11 18:22:52,894:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=2025, verbose=0,
                       warm_start=False)
2025-10-11 18:22:52,894:INFO:create_model() successfully completed......................................
2025-10-11 18:22:53,039:INFO:Initializing get_config()
2025-10-11 18:22:53,039:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012C88E6B1D0>, variable=X_train_transformed)
2025-10-11 18:22:53,073:INFO:Variable: X_train returned as         likes
35   0.344305
36  -0.415835
85   0.870074
201 -1.007015
163 -0.355236
..        ...
55  -1.505367
191 -1.453371
160  0.911148
183 -0.157267
1   -1.866974

[154 rows x 1 columns]
2025-10-11 18:22:53,080:INFO:get_config() successfully completed......................................
2025-10-11 18:22:53,096:INFO:Initializing get_config()
2025-10-11 18:22:53,096:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012C88E6B1D0>, variable=X_train_transformed)
2025-10-11 18:22:53,159:INFO:Variable: X_train returned as         likes
35   0.344305
36  -0.415835
85   0.870074
201 -1.007015
163 -0.355236
..        ...
55  -1.505367
191 -1.453371
160  0.911148
183 -0.157267
1   -1.866974

[154 rows x 1 columns]
2025-10-11 18:22:53,159:INFO:get_config() successfully completed......................................
2025-10-11 18:22:53,228:WARNING:C:\Users\ARNALDO\AppData\Local\Temp\ipykernel_27996\1440261186.py:2: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.
  shap.summary_plot(shap_values[1][:, :-1], X_train_transformed)

2025-10-11 18:24:23,780:WARNING:C:\Users\ARNALDO\AppData\Local\Temp\ipykernel_27996\1440261186.py:2: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.
  shap.summary_plot(shap_values[1][:, :-1], X_train_transformed)

2025-10-11 18:28:45,379:INFO:Initializing get_config()
2025-10-11 18:28:45,379:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012C88E6B1D0>, variable=X_train_transformed)
2025-10-11 18:28:45,404:INFO:Variable: X_train returned as         likes
35   0.344305
36  -0.415835
85   0.870074
201 -1.007015
163 -0.355236
..        ...
55  -1.505367
191 -1.453371
160  0.911148
183 -0.157267
1   -1.866974

[154 rows x 1 columns]
2025-10-11 18:28:45,404:INFO:get_config() successfully completed......................................
2025-10-11 18:37:06,344:INFO:PyCaret ClassificationExperiment
2025-10-11 18:37:06,344:INFO:Logging name: clf-default-name
2025-10-11 18:37:06,344:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-10-11 18:37:06,344:INFO:version 3.3.2
2025-10-11 18:37:06,345:INFO:Initializing setup()
2025-10-11 18:37:06,345:INFO:self.USI: 5451
2025-10-11 18:37:06,345:INFO:self._variable_keys: {'idx', 'fold_shuffle_param', 'y', 'X', 'fold_groups_param', 'fix_imbalance', 'exp_name_log', 'fold_generator', 'gpu_n_jobs_param', 'X_test', 'USI', 'memory', 'gpu_param', 'data', 'html_param', '_ml_usecase', 'is_multiclass', 'seed', 'exp_id', 'pipeline', 'n_jobs_param', 'logging_param', 'log_plots_param', 'X_train', '_available_plots', 'y_test', 'target_param', 'y_train'}
2025-10-11 18:37:06,345:INFO:Checking environment
2025-10-11 18:37:06,345:INFO:python_version: 3.11.0
2025-10-11 18:37:06,345:INFO:python_build: ('main', 'Oct 24 2022 18:26:48')
2025-10-11 18:37:06,345:INFO:machine: AMD64
2025-10-11 18:37:06,345:INFO:platform: Windows-10-10.0.26100-SP0
2025-10-11 18:37:06,345:INFO:Memory: svmem(total=34211835904, available=19800498176, percent=42.1, used=14411337728, free=19800498176)
2025-10-11 18:37:06,345:INFO:Physical Core: 6
2025-10-11 18:37:06,345:INFO:Logical Core: 12
2025-10-11 18:37:06,345:INFO:Checking libraries
2025-10-11 18:37:06,345:INFO:System:
2025-10-11 18:37:06,345:INFO:    python: 3.11.0 (main, Oct 24 2022, 18:26:48) [MSC v.1933 64 bit (AMD64)]
2025-10-11 18:37:06,345:INFO:executable: c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\python.exe
2025-10-11 18:37:06,345:INFO:   machine: Windows-10-10.0.26100-SP0
2025-10-11 18:37:06,345:INFO:PyCaret required dependencies:
2025-10-11 18:37:06,345:INFO:                 pip: 22.3
2025-10-11 18:37:06,345:INFO:          setuptools: 65.5.0
2025-10-11 18:37:06,345:INFO:             pycaret: 3.3.2
2025-10-11 18:37:06,345:INFO:             IPython: 9.6.0
2025-10-11 18:37:06,345:INFO:          ipywidgets: 8.1.7
2025-10-11 18:37:06,345:INFO:                tqdm: 4.67.1
2025-10-11 18:37:06,345:INFO:               numpy: 1.26.4
2025-10-11 18:37:06,345:INFO:              pandas: 2.1.4
2025-10-11 18:37:06,345:INFO:              jinja2: 3.1.6
2025-10-11 18:37:06,345:INFO:               scipy: 1.11.4
2025-10-11 18:37:06,345:INFO:              joblib: 1.3.2
2025-10-11 18:37:06,345:INFO:             sklearn: 1.4.2
2025-10-11 18:37:06,345:INFO:                pyod: 2.0.5
2025-10-11 18:37:06,345:INFO:            imblearn: 0.14.0
2025-10-11 18:37:06,345:INFO:   category_encoders: 2.7.0
2025-10-11 18:37:06,345:INFO:            lightgbm: 4.6.0
2025-10-11 18:37:06,345:INFO:               numba: 0.62.1
2025-10-11 18:37:06,345:INFO:            requests: 2.32.5
2025-10-11 18:37:06,345:INFO:          matplotlib: 3.7.5
2025-10-11 18:37:06,345:INFO:          scikitplot: 0.3.7
2025-10-11 18:37:06,345:INFO:         yellowbrick: 1.5
2025-10-11 18:37:06,345:INFO:              plotly: 6.3.1
2025-10-11 18:37:06,345:INFO:    plotly-resampler: Not installed
2025-10-11 18:37:06,345:INFO:             kaleido: 1.1.0
2025-10-11 18:37:06,345:INFO:           schemdraw: 0.15
2025-10-11 18:37:06,345:INFO:         statsmodels: 0.14.5
2025-10-11 18:37:06,345:INFO:              sktime: 0.26.0
2025-10-11 18:37:06,345:INFO:               tbats: 1.1.3
2025-10-11 18:37:06,345:INFO:            pmdarima: 2.0.4
2025-10-11 18:37:06,345:INFO:              psutil: 7.1.0
2025-10-11 18:37:06,345:INFO:          markupsafe: 3.0.3
2025-10-11 18:37:06,345:INFO:             pickle5: Not installed
2025-10-11 18:37:06,345:INFO:         cloudpickle: 3.1.1
2025-10-11 18:37:06,345:INFO:         deprecation: 2.1.0
2025-10-11 18:37:06,345:INFO:              xxhash: 3.6.0
2025-10-11 18:37:06,345:INFO:           wurlitzer: Not installed
2025-10-11 18:37:06,345:INFO:PyCaret optional dependencies:
2025-10-11 18:37:06,345:INFO:                shap: 0.48.0
2025-10-11 18:37:06,345:INFO:           interpret: Not installed
2025-10-11 18:37:06,345:INFO:                umap: Not installed
2025-10-11 18:37:06,345:INFO:     ydata_profiling: Not installed
2025-10-11 18:37:06,345:INFO:  explainerdashboard: Not installed
2025-10-11 18:37:06,345:INFO:             autoviz: Not installed
2025-10-11 18:37:06,345:INFO:           fairlearn: Not installed
2025-10-11 18:37:06,345:INFO:          deepchecks: Not installed
2025-10-11 18:37:06,345:INFO:             xgboost: Not installed
2025-10-11 18:37:06,345:INFO:            catboost: Not installed
2025-10-11 18:37:06,345:INFO:              kmodes: Not installed
2025-10-11 18:37:06,345:INFO:             mlxtend: Not installed
2025-10-11 18:37:06,345:INFO:       statsforecast: Not installed
2025-10-11 18:37:06,345:INFO:        tune_sklearn: Not installed
2025-10-11 18:37:06,345:INFO:                 ray: Not installed
2025-10-11 18:37:06,345:INFO:            hyperopt: Not installed
2025-10-11 18:37:06,345:INFO:              optuna: Not installed
2025-10-11 18:37:06,345:INFO:               skopt: Not installed
2025-10-11 18:37:06,345:INFO:              mlflow: Not installed
2025-10-11 18:37:06,345:INFO:              gradio: Not installed
2025-10-11 18:37:06,345:INFO:             fastapi: Not installed
2025-10-11 18:37:06,345:INFO:             uvicorn: Not installed
2025-10-11 18:37:06,345:INFO:              m2cgen: Not installed
2025-10-11 18:37:06,345:INFO:           evidently: Not installed
2025-10-11 18:37:06,345:INFO:               fugue: Not installed
2025-10-11 18:37:06,345:INFO:           streamlit: Not installed
2025-10-11 18:37:06,345:INFO:             prophet: Not installed
2025-10-11 18:37:06,345:INFO:None
2025-10-11 18:37:06,345:INFO:Set up data.
2025-10-11 18:37:06,345:INFO:Set up folding strategy.
2025-10-11 18:37:06,345:INFO:Set up train/test split.
2025-10-11 18:37:06,360:INFO:Set up index.
2025-10-11 18:37:06,360:INFO:Assigning column types.
2025-10-11 18:37:06,363:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-11 18:37:06,396:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-11 18:37:06,396:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-11 18:37:06,430:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 18:37:06,431:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 18:37:06,463:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-11 18:37:06,463:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-11 18:37:06,498:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 18:37:06,498:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 18:37:06,498:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-11 18:37:06,540:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-11 18:37:06,564:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 18:37:06,565:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 18:37:06,605:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-11 18:37:06,627:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 18:37:06,627:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 18:37:06,627:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-10-11 18:37:06,695:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 18:37:06,695:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 18:37:06,762:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 18:37:06,763:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 18:37:06,764:INFO:Preparing preprocessing pipeline...
2025-10-11 18:37:06,764:INFO:Set up simple imputation.
2025-10-11 18:37:06,766:INFO:Set up encoding of categorical features.
2025-10-11 18:37:06,766:INFO:Set up removing multicollinearity.
2025-10-11 18:37:06,766:INFO:Set up column transformation.
2025-10-11 18:37:06,766:INFO:Set up feature normalization.
2025-10-11 18:37:06,766:INFO:Set up feature selection.
2025-10-11 18:37:06,832:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 18:37:06,832:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 18:37:06,973:INFO:Finished creating preprocessing pipeline.
2025-10-11 18:37:07,002:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\ARNALDO\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['likes', 'comentarios',
                                             'engagement'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Transf...
                                                                                         learning_rate=0.1,
                                                                                         max_depth=-1,
                                                                                         min_child_samples=20,
                                                                                         min_child_weight=0.001,
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=None,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=1,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf)))],
         verbose=False)
2025-10-11 18:37:07,002:INFO:Creating final display dataframe.
2025-10-11 18:37:07,129:INFO:Setup _display_container:                     Description             Value
0                    Session id              2025
1                        Target        conversion
2                   Target type            Binary
3           Original data shape         (220, 10)
4        Transformed data shape          (220, 2)
5   Transformed train set shape          (154, 2)
6    Transformed test set shape           (66, 2)
7               Ignore features                 2
8              Numeric features                 3
9          Categorical features                 4
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16     Remove multicollinearity              True
17  Multicollinearity threshold               0.9
18               Transformation              True
19        Transformation method       yeo-johnson
20                    Normalize              True
21             Normalize method            zscore
22            Feature selection              True
23     Feature selection method           classic
24  Feature selection estimator          lightgbm
25  Number of features selected               0.2
26               Fold Generator   StratifiedKFold
27                  Fold Number                10
28                     CPU Jobs                -1
29                      Use GPU             False
30               Log Experiment             False
31              Experiment Name  clf-default-name
32                          USI              5451
2025-10-11 18:37:07,236:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 18:37:07,236:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 18:37:07,306:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 18:37:07,306:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 18:37:07,307:INFO:setup() successfully completed in 0.98s...............
2025-10-11 18:37:07,312:INFO:Initializing create_model()
2025-10-11 18:37:07,312:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012C83C82DD0>, estimator=rf, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-11 18:37:07,312:INFO:Checking exceptions
2025-10-11 18:37:07,332:INFO:Importing libraries
2025-10-11 18:37:07,333:INFO:Copying training dataset
2025-10-11 18:37:07,338:INFO:Defining folds
2025-10-11 18:37:07,338:INFO:Declaring metric variables
2025-10-11 18:37:07,341:INFO:Importing untrained model
2025-10-11 18:37:07,344:INFO:Random Forest Classifier Imported successfully
2025-10-11 18:37:07,351:INFO:Starting cross validation
2025-10-11 18:37:07,357:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-11 18:37:16,065:INFO:Calculating mean and std
2025-10-11 18:37:16,065:INFO:Creating metrics dataframe
2025-10-11 18:37:16,065:INFO:Finalizing model
2025-10-11 18:37:16,170:INFO:[LightGBM] [Info] Number of positive: 32, number of negative: 122
2025-10-11 18:37:16,171:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000044 seconds.
2025-10-11 18:37:16,171:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-11 18:37:16,171:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-11 18:37:16,171:INFO:[LightGBM] [Info] Total Bins 186
2025-10-11 18:37:16,171:INFO:[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 14
2025-10-11 18:37:16,171:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.207792 -> initscore=-1.338285
2025-10-11 18:37:16,171:INFO:[LightGBM] [Info] Start training from score -1.338285
2025-10-11 18:37:16,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:37:16,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:37:16,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:37:16,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:37:16,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:37:16,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:37:16,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:37:16,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:37:16,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:37:16,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:37:16,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:37:16,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:37:16,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:37:16,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:37:16,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:37:16,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:37:16,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:37:16,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:37:16,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:37:16,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:37:16,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:37:16,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:37:16,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:37:16,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:37:16,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:37:16,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:37:16,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:37:16,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:37:16,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:37:16,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:37:16,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:37:16,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:37:16,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:37:16,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:37:16,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:37:16,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:37:16,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:37:16,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:37:16,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:37:16,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:37:16,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:37:16,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:37:16,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:37:16,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:37:16,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:37:16,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:37:16,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:37:16,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:37:16,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:37:16,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:37:16,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:37:16,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:37:16,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:37:16,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:37:16,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:37:16,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:37:16,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:37:16,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:37:16,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:37:16,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:37:16,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:37:16,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:37:16,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:37:16,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:37:16,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:37:16,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:37:16,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:37:16,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:37:16,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:37:16,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:37:16,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:37:16,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:37:16,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:37:16,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:37:16,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:37:16,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:37:16,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:37:16,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:37:16,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:37:16,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:37:16,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:37:16,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:37:16,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:37:16,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:37:16,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:37:16,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:37:16,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:37:16,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:37:16,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:37:16,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:37:16,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:37:16,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:37:16,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:37:16,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:37:16,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:37:16,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:37:16,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:37:16,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:37:16,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:37:16,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:37:16,398:INFO:Uploading results into container
2025-10-11 18:37:16,398:INFO:Uploading model into container now
2025-10-11 18:37:16,428:INFO:_master_model_container: 1
2025-10-11 18:37:16,428:INFO:_display_container: 2
2025-10-11 18:37:16,429:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=2025, verbose=0,
                       warm_start=False)
2025-10-11 18:37:16,429:INFO:create_model() successfully completed......................................
2025-10-11 18:37:16,576:INFO:Initializing get_config()
2025-10-11 18:37:16,576:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012C83C82DD0>, variable=X_train_transformed)
2025-10-11 18:37:16,609:INFO:Variable: X_train returned as         likes
35   0.344305
36  -0.415835
85   0.870074
201 -1.007015
163 -0.355236
..        ...
55  -1.505367
191 -1.453371
160  0.911148
183 -0.157267
1   -1.866974

[154 rows x 1 columns]
2025-10-11 18:37:16,609:INFO:get_config() successfully completed......................................
2025-10-11 18:37:42,052:WARNING:C:\Users\ARNALDO\AppData\Local\Temp\ipykernel_27996\3143870635.py:5: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.
  shap.summary_plot(shap_values[1][:min_rows], X_train_transformed.iloc[:min_rows])

2025-10-11 18:38:18,215:WARNING:C:\Users\ARNALDO\AppData\Local\Temp\ipykernel_27996\1878261165.py:2: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.
  shap.summary_plot(shap_values[1], X_train_transformed.iloc[:50])

2025-10-11 18:39:09,112:WARNING:C:\Users\ARNALDO\AppData\Local\Temp\ipykernel_27996\2442796322.py:2: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.
  shap.summary_plot(shap_values[1][:, :-1], X_train_transformed)

2025-10-11 18:41:03,336:INFO:Initializing get_config()
2025-10-11 18:41:03,336:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012C83C82DD0>, variable=X_train_transformed)
2025-10-11 18:41:03,374:INFO:Variable: X_train returned as         likes
35   0.344305
36  -0.415835
85   0.870074
201 -1.007015
163 -0.355236
..        ...
55  -1.505367
191 -1.453371
160  0.911148
183 -0.157267
1   -1.866974

[154 rows x 1 columns]
2025-10-11 18:41:03,374:INFO:get_config() successfully completed......................................
2025-10-11 18:41:08,367:WARNING:C:\Users\ARNALDO\AppData\Local\Temp\ipykernel_27996\1327565940.py:3: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.
  shap.summary_plot(shap_values[1][:, :-1], X_train_transformed)

2025-10-11 18:42:06,908:WARNING:C:\Users\ARNALDO\AppData\Local\Temp\ipykernel_27996\1327565940.py:3: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.
  shap.summary_plot(shap_values[1][:, :-1], X_train_transformed)

2025-10-11 18:44:54,147:INFO:PyCaret ClassificationExperiment
2025-10-11 18:44:54,147:INFO:Logging name: clf-default-name
2025-10-11 18:44:54,147:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-10-11 18:44:54,147:INFO:version 3.3.2
2025-10-11 18:44:54,147:INFO:Initializing setup()
2025-10-11 18:44:54,147:INFO:self.USI: 0008
2025-10-11 18:44:54,147:INFO:self._variable_keys: {'idx', 'fold_shuffle_param', 'y', 'X', 'fold_groups_param', 'fix_imbalance', 'exp_name_log', 'fold_generator', 'gpu_n_jobs_param', 'X_test', 'USI', 'memory', 'gpu_param', 'data', 'html_param', '_ml_usecase', 'is_multiclass', 'seed', 'exp_id', 'pipeline', 'n_jobs_param', 'logging_param', 'log_plots_param', 'X_train', '_available_plots', 'y_test', 'target_param', 'y_train'}
2025-10-11 18:44:54,147:INFO:Checking environment
2025-10-11 18:44:54,147:INFO:python_version: 3.11.0
2025-10-11 18:44:54,147:INFO:python_build: ('main', 'Oct 24 2022 18:26:48')
2025-10-11 18:44:54,147:INFO:machine: AMD64
2025-10-11 18:44:54,147:INFO:platform: Windows-10-10.0.26100-SP0
2025-10-11 18:44:54,147:INFO:Memory: svmem(total=34211835904, available=19712729088, percent=42.4, used=14499106816, free=19712729088)
2025-10-11 18:44:54,147:INFO:Physical Core: 6
2025-10-11 18:44:54,147:INFO:Logical Core: 12
2025-10-11 18:44:54,147:INFO:Checking libraries
2025-10-11 18:44:54,147:INFO:System:
2025-10-11 18:44:54,147:INFO:    python: 3.11.0 (main, Oct 24 2022, 18:26:48) [MSC v.1933 64 bit (AMD64)]
2025-10-11 18:44:54,147:INFO:executable: c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\python.exe
2025-10-11 18:44:54,147:INFO:   machine: Windows-10-10.0.26100-SP0
2025-10-11 18:44:54,147:INFO:PyCaret required dependencies:
2025-10-11 18:44:54,147:INFO:                 pip: 22.3
2025-10-11 18:44:54,147:INFO:          setuptools: 65.5.0
2025-10-11 18:44:54,147:INFO:             pycaret: 3.3.2
2025-10-11 18:44:54,147:INFO:             IPython: 9.6.0
2025-10-11 18:44:54,147:INFO:          ipywidgets: 8.1.7
2025-10-11 18:44:54,147:INFO:                tqdm: 4.67.1
2025-10-11 18:44:54,147:INFO:               numpy: 1.26.4
2025-10-11 18:44:54,147:INFO:              pandas: 2.1.4
2025-10-11 18:44:54,147:INFO:              jinja2: 3.1.6
2025-10-11 18:44:54,147:INFO:               scipy: 1.11.4
2025-10-11 18:44:54,147:INFO:              joblib: 1.3.2
2025-10-11 18:44:54,147:INFO:             sklearn: 1.4.2
2025-10-11 18:44:54,147:INFO:                pyod: 2.0.5
2025-10-11 18:44:54,147:INFO:            imblearn: 0.14.0
2025-10-11 18:44:54,147:INFO:   category_encoders: 2.7.0
2025-10-11 18:44:54,157:INFO:            lightgbm: 4.6.0
2025-10-11 18:44:54,157:INFO:               numba: 0.62.1
2025-10-11 18:44:54,157:INFO:            requests: 2.32.5
2025-10-11 18:44:54,157:INFO:          matplotlib: 3.7.5
2025-10-11 18:44:54,157:INFO:          scikitplot: 0.3.7
2025-10-11 18:44:54,157:INFO:         yellowbrick: 1.5
2025-10-11 18:44:54,157:INFO:              plotly: 6.3.1
2025-10-11 18:44:54,157:INFO:    plotly-resampler: Not installed
2025-10-11 18:44:54,157:INFO:             kaleido: 1.1.0
2025-10-11 18:44:54,157:INFO:           schemdraw: 0.15
2025-10-11 18:44:54,157:INFO:         statsmodels: 0.14.5
2025-10-11 18:44:54,158:INFO:              sktime: 0.26.0
2025-10-11 18:44:54,158:INFO:               tbats: 1.1.3
2025-10-11 18:44:54,158:INFO:            pmdarima: 2.0.4
2025-10-11 18:44:54,158:INFO:              psutil: 7.1.0
2025-10-11 18:44:54,158:INFO:          markupsafe: 3.0.3
2025-10-11 18:44:54,158:INFO:             pickle5: Not installed
2025-10-11 18:44:54,158:INFO:         cloudpickle: 3.1.1
2025-10-11 18:44:54,158:INFO:         deprecation: 2.1.0
2025-10-11 18:44:54,158:INFO:              xxhash: 3.6.0
2025-10-11 18:44:54,158:INFO:           wurlitzer: Not installed
2025-10-11 18:44:54,159:INFO:PyCaret optional dependencies:
2025-10-11 18:44:54,159:INFO:                shap: 0.48.0
2025-10-11 18:44:54,159:INFO:           interpret: Not installed
2025-10-11 18:44:54,159:INFO:                umap: Not installed
2025-10-11 18:44:54,159:INFO:     ydata_profiling: Not installed
2025-10-11 18:44:54,159:INFO:  explainerdashboard: Not installed
2025-10-11 18:44:54,159:INFO:             autoviz: Not installed
2025-10-11 18:44:54,159:INFO:           fairlearn: Not installed
2025-10-11 18:44:54,159:INFO:          deepchecks: Not installed
2025-10-11 18:44:54,159:INFO:             xgboost: Not installed
2025-10-11 18:44:54,159:INFO:            catboost: Not installed
2025-10-11 18:44:54,159:INFO:              kmodes: Not installed
2025-10-11 18:44:54,159:INFO:             mlxtend: Not installed
2025-10-11 18:44:54,159:INFO:       statsforecast: Not installed
2025-10-11 18:44:54,160:INFO:        tune_sklearn: Not installed
2025-10-11 18:44:54,160:INFO:                 ray: Not installed
2025-10-11 18:44:54,160:INFO:            hyperopt: Not installed
2025-10-11 18:44:54,160:INFO:              optuna: Not installed
2025-10-11 18:44:54,160:INFO:               skopt: Not installed
2025-10-11 18:44:54,160:INFO:              mlflow: Not installed
2025-10-11 18:44:54,160:INFO:              gradio: Not installed
2025-10-11 18:44:54,160:INFO:             fastapi: Not installed
2025-10-11 18:44:54,160:INFO:             uvicorn: Not installed
2025-10-11 18:44:54,160:INFO:              m2cgen: Not installed
2025-10-11 18:44:54,160:INFO:           evidently: Not installed
2025-10-11 18:44:54,160:INFO:               fugue: Not installed
2025-10-11 18:44:54,160:INFO:           streamlit: Not installed
2025-10-11 18:44:54,161:INFO:             prophet: Not installed
2025-10-11 18:44:54,161:INFO:None
2025-10-11 18:44:54,161:INFO:Set up data.
2025-10-11 18:44:54,170:INFO:Set up folding strategy.
2025-10-11 18:44:54,170:INFO:Set up train/test split.
2025-10-11 18:44:54,180:INFO:Set up index.
2025-10-11 18:44:54,180:INFO:Assigning column types.
2025-10-11 18:44:54,186:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-11 18:44:54,243:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-11 18:44:54,244:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-11 18:44:54,263:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 18:44:54,263:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 18:44:54,310:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-11 18:44:54,310:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-11 18:44:54,343:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 18:44:54,343:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 18:44:54,344:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-11 18:44:54,379:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-11 18:44:54,410:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 18:44:54,410:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 18:44:54,444:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-11 18:44:54,479:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 18:44:54,479:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 18:44:54,479:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-10-11 18:44:54,544:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 18:44:54,544:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 18:44:54,627:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 18:44:54,627:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 18:44:54,627:INFO:Preparing preprocessing pipeline...
2025-10-11 18:44:54,627:INFO:Set up simple imputation.
2025-10-11 18:44:54,627:INFO:Set up encoding of categorical features.
2025-10-11 18:44:54,627:INFO:Set up removing multicollinearity.
2025-10-11 18:44:54,627:INFO:Set up column transformation.
2025-10-11 18:44:54,627:INFO:Set up feature normalization.
2025-10-11 18:44:54,627:INFO:Set up feature selection.
2025-10-11 18:44:54,727:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 18:44:54,727:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 18:44:54,894:INFO:Finished creating preprocessing pipeline.
2025-10-11 18:44:54,916:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\ARNALDO\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['likes', 'comentarios',
                                             'engagement'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Transf...
                                                                                         learning_rate=0.1,
                                                                                         max_depth=-1,
                                                                                         min_child_samples=20,
                                                                                         min_child_weight=0.001,
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=None,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=1,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf)))],
         verbose=False)
2025-10-11 18:44:54,916:INFO:Creating final display dataframe.
2025-10-11 18:44:55,064:INFO:Setup _display_container:                     Description             Value
0                    Session id              2025
1                        Target        conversion
2                   Target type            Binary
3           Original data shape         (220, 10)
4        Transformed data shape          (220, 2)
5   Transformed train set shape          (154, 2)
6    Transformed test set shape           (66, 2)
7               Ignore features                 2
8              Numeric features                 3
9          Categorical features                 4
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16     Remove multicollinearity              True
17  Multicollinearity threshold               0.9
18               Transformation              True
19        Transformation method       yeo-johnson
20                    Normalize              True
21             Normalize method            zscore
22            Feature selection              True
23     Feature selection method           classic
24  Feature selection estimator          lightgbm
25  Number of features selected               0.2
26               Fold Generator   StratifiedKFold
27                  Fold Number                10
28                     CPU Jobs                -1
29                      Use GPU             False
30               Log Experiment             False
31              Experiment Name  clf-default-name
32                          USI              0008
2025-10-11 18:44:55,252:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 18:44:55,252:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 18:44:55,380:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 18:44:55,380:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 18:44:55,381:INFO:setup() successfully completed in 1.24s...............
2025-10-11 18:45:00,807:INFO:Initializing create_model()
2025-10-11 18:45:00,807:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012C88DF2510>, estimator=rf, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-11 18:45:00,807:INFO:Checking exceptions
2025-10-11 18:45:00,827:INFO:Importing libraries
2025-10-11 18:45:00,827:INFO:Copying training dataset
2025-10-11 18:45:00,835:INFO:Defining folds
2025-10-11 18:45:00,835:INFO:Declaring metric variables
2025-10-11 18:45:00,841:INFO:Importing untrained model
2025-10-11 18:45:00,846:INFO:Random Forest Classifier Imported successfully
2025-10-11 18:45:00,855:INFO:Starting cross validation
2025-10-11 18:45:00,863:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-11 18:45:09,744:INFO:Calculating mean and std
2025-10-11 18:45:09,745:INFO:Creating metrics dataframe
2025-10-11 18:45:09,749:INFO:Finalizing model
2025-10-11 18:45:09,845:INFO:[LightGBM] [Info] Number of positive: 32, number of negative: 122
2025-10-11 18:45:09,845:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000044 seconds.
2025-10-11 18:45:09,845:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-11 18:45:09,845:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-11 18:45:09,845:INFO:[LightGBM] [Info] Total Bins 186
2025-10-11 18:45:09,845:INFO:[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 14
2025-10-11 18:45:09,845:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.207792 -> initscore=-1.338285
2025-10-11 18:45:09,845:INFO:[LightGBM] [Info] Start training from score -1.338285
2025-10-11 18:45:09,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:45:09,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:45:09,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:45:09,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:45:09,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:45:09,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:45:09,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:45:09,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:45:09,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:45:09,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:45:09,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:45:09,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:45:09,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:45:09,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:45:09,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:45:09,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:45:09,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:45:09,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:45:09,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:45:09,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:45:09,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:45:09,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:45:09,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:45:09,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:45:09,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:45:09,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:45:09,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:45:09,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:45:09,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:45:09,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:45:09,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:45:09,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:45:09,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:45:09,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:45:09,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:45:09,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:45:09,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:45:09,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:45:09,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:45:09,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:45:09,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:45:09,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:45:09,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:45:09,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:45:09,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:45:09,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:45:09,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:45:09,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:45:09,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:45:09,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:45:09,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:45:09,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:45:09,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:45:09,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:45:09,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:45:09,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:45:09,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:45:09,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:45:09,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:45:09,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:45:09,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:45:09,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:45:09,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:45:09,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:45:09,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:45:09,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:45:09,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:45:09,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:45:09,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:45:09,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:45:09,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:45:09,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:45:09,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:45:09,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:45:09,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:45:09,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:45:09,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:45:09,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:45:09,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:45:09,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:45:09,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:45:09,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:45:09,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:45:09,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:45:09,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:45:09,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:45:09,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:45:09,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:45:09,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:45:09,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:45:09,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:45:09,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:45:09,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:45:09,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:45:09,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:45:09,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:45:09,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:45:09,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:45:09,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:45:09,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-11 18:45:10,054:INFO:Uploading results into container
2025-10-11 18:45:10,054:INFO:Uploading model into container now
2025-10-11 18:45:10,063:INFO:_master_model_container: 1
2025-10-11 18:45:10,063:INFO:_display_container: 2
2025-10-11 18:45:10,063:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=2025, verbose=0,
                       warm_start=False)
2025-10-11 18:45:10,063:INFO:create_model() successfully completed......................................
2025-10-11 18:45:19,669:INFO:Initializing get_config()
2025-10-11 18:45:19,669:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012C88DF2510>, variable=X_train_transformed)
2025-10-11 18:45:19,709:INFO:Variable: X_train returned as         likes
35   0.344305
36  -0.415835
85   0.870074
201 -1.007015
163 -0.355236
..        ...
55  -1.505367
191 -1.453371
160  0.911148
183 -0.157267
1   -1.866974

[154 rows x 1 columns]
2025-10-11 18:45:19,709:INFO:get_config() successfully completed......................................
2025-10-11 18:45:48,030:WARNING:C:\Users\ARNALDO\AppData\Local\Temp\ipykernel_27996\1167014756.py:3: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.
  shap.summary_plot(shap_values_fixed[:min_rows], X_train_transformed.iloc[:min_rows])

2025-10-11 18:47:04,007:INFO:Initializing get_config()
2025-10-11 18:47:04,007:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012C88DF2510>, variable=X_train_transformed)
2025-10-11 18:47:04,070:INFO:Variable: X_train returned as         likes
35   0.344305
36  -0.415835
85   0.870074
201 -1.007015
163 -0.355236
..        ...
55  -1.505367
191 -1.453371
160  0.911148
183 -0.157267
1   -1.866974

[154 rows x 1 columns]
2025-10-11 18:47:04,070:INFO:get_config() successfully completed......................................
2025-10-11 18:51:49,907:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-11 18:51:49,907:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-11 18:51:49,907:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-11 18:51:49,907:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-11 18:51:51,396:INFO:PyCaret ClassificationExperiment
2025-10-11 18:51:51,396:INFO:Logging name: clf-default-name
2025-10-11 18:51:51,396:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-10-11 18:51:51,396:INFO:version 3.3.2
2025-10-11 18:51:51,396:INFO:Initializing setup()
2025-10-11 18:51:51,396:INFO:self.USI: 5fd8
2025-10-11 18:51:51,396:INFO:self._variable_keys: {'exp_name_log', '_available_plots', 'target_param', 'X_train', 'y', 'pipeline', 'data', 'is_multiclass', 'gpu_n_jobs_param', 'logging_param', 'n_jobs_param', 'gpu_param', 'memory', 'fold_shuffle_param', 'USI', 'fold_generator', 'X_test', 'seed', 'exp_id', 'fix_imbalance', 'fold_groups_param', 'idx', 'y_test', 'y_train', 'log_plots_param', '_ml_usecase', 'X', 'html_param'}
2025-10-11 18:51:51,396:INFO:Checking environment
2025-10-11 18:51:51,396:INFO:python_version: 3.11.0
2025-10-11 18:51:51,396:INFO:python_build: ('main', 'Oct 24 2022 18:26:48')
2025-10-11 18:51:51,396:INFO:machine: AMD64
2025-10-11 18:51:51,396:INFO:platform: Windows-10-10.0.26100-SP0
2025-10-11 18:51:51,400:INFO:Memory: svmem(total=34211835904, available=19355713536, percent=43.4, used=14856122368, free=19355713536)
2025-10-11 18:51:51,400:INFO:Physical Core: 6
2025-10-11 18:51:51,400:INFO:Logical Core: 12
2025-10-11 18:51:51,400:INFO:Checking libraries
2025-10-11 18:51:51,400:INFO:System:
2025-10-11 18:51:51,400:INFO:    python: 3.11.0 (main, Oct 24 2022, 18:26:48) [MSC v.1933 64 bit (AMD64)]
2025-10-11 18:51:51,401:INFO:executable: c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\python.exe
2025-10-11 18:51:51,401:INFO:   machine: Windows-10-10.0.26100-SP0
2025-10-11 18:51:51,401:INFO:PyCaret required dependencies:
2025-10-11 18:51:51,435:INFO:                 pip: 22.3
2025-10-11 18:51:51,435:INFO:          setuptools: 65.5.0
2025-10-11 18:51:51,435:INFO:             pycaret: 3.3.2
2025-10-11 18:51:51,435:INFO:             IPython: 9.6.0
2025-10-11 18:51:51,435:INFO:          ipywidgets: 8.1.7
2025-10-11 18:51:51,435:INFO:                tqdm: 4.67.1
2025-10-11 18:51:51,435:INFO:               numpy: 1.26.4
2025-10-11 18:51:51,435:INFO:              pandas: 2.1.4
2025-10-11 18:51:51,435:INFO:              jinja2: 3.1.6
2025-10-11 18:51:51,435:INFO:               scipy: 1.11.4
2025-10-11 18:51:51,435:INFO:              joblib: 1.3.2
2025-10-11 18:51:51,435:INFO:             sklearn: 1.4.2
2025-10-11 18:51:51,435:INFO:                pyod: 2.0.5
2025-10-11 18:51:51,435:INFO:            imblearn: 0.14.0
2025-10-11 18:51:51,435:INFO:   category_encoders: 2.7.0
2025-10-11 18:51:51,435:INFO:            lightgbm: 4.6.0
2025-10-11 18:51:51,435:INFO:               numba: 0.62.1
2025-10-11 18:51:51,435:INFO:            requests: 2.32.5
2025-10-11 18:51:51,435:INFO:          matplotlib: 3.7.5
2025-10-11 18:51:51,435:INFO:          scikitplot: 0.3.7
2025-10-11 18:51:51,435:INFO:         yellowbrick: 1.5
2025-10-11 18:51:51,435:INFO:              plotly: 6.3.1
2025-10-11 18:51:51,435:INFO:    plotly-resampler: Not installed
2025-10-11 18:51:51,435:INFO:             kaleido: 1.1.0
2025-10-11 18:51:51,435:INFO:           schemdraw: 0.15
2025-10-11 18:51:51,435:INFO:         statsmodels: 0.14.5
2025-10-11 18:51:51,435:INFO:              sktime: 0.26.0
2025-10-11 18:51:51,435:INFO:               tbats: 1.1.3
2025-10-11 18:51:51,435:INFO:            pmdarima: 2.0.4
2025-10-11 18:51:51,435:INFO:              psutil: 7.1.0
2025-10-11 18:51:51,435:INFO:          markupsafe: 3.0.3
2025-10-11 18:51:51,435:INFO:             pickle5: Not installed
2025-10-11 18:51:51,435:INFO:         cloudpickle: 3.1.1
2025-10-11 18:51:51,435:INFO:         deprecation: 2.1.0
2025-10-11 18:51:51,435:INFO:              xxhash: 3.6.0
2025-10-11 18:51:51,435:INFO:           wurlitzer: Not installed
2025-10-11 18:51:51,435:INFO:PyCaret optional dependencies:
2025-10-11 18:51:51,444:INFO:                shap: 0.48.0
2025-10-11 18:51:51,444:INFO:           interpret: Not installed
2025-10-11 18:51:51,444:INFO:                umap: Not installed
2025-10-11 18:51:51,444:INFO:     ydata_profiling: Not installed
2025-10-11 18:51:51,444:INFO:  explainerdashboard: Not installed
2025-10-11 18:51:51,444:INFO:             autoviz: Not installed
2025-10-11 18:51:51,444:INFO:           fairlearn: Not installed
2025-10-11 18:51:51,444:INFO:          deepchecks: Not installed
2025-10-11 18:51:51,444:INFO:             xgboost: Not installed
2025-10-11 18:51:51,444:INFO:            catboost: Not installed
2025-10-11 18:51:51,444:INFO:              kmodes: Not installed
2025-10-11 18:51:51,444:INFO:             mlxtend: Not installed
2025-10-11 18:51:51,444:INFO:       statsforecast: Not installed
2025-10-11 18:51:51,444:INFO:        tune_sklearn: Not installed
2025-10-11 18:51:51,444:INFO:                 ray: Not installed
2025-10-11 18:51:51,444:INFO:            hyperopt: Not installed
2025-10-11 18:51:51,444:INFO:              optuna: Not installed
2025-10-11 18:51:51,444:INFO:               skopt: Not installed
2025-10-11 18:51:51,444:INFO:              mlflow: Not installed
2025-10-11 18:51:51,444:INFO:              gradio: Not installed
2025-10-11 18:51:51,444:INFO:             fastapi: Not installed
2025-10-11 18:51:51,444:INFO:             uvicorn: Not installed
2025-10-11 18:51:51,444:INFO:              m2cgen: Not installed
2025-10-11 18:51:51,444:INFO:           evidently: Not installed
2025-10-11 18:51:51,444:INFO:               fugue: Not installed
2025-10-11 18:51:51,444:INFO:           streamlit: Not installed
2025-10-11 18:51:51,444:INFO:             prophet: Not installed
2025-10-11 18:51:51,444:INFO:None
2025-10-11 18:51:51,444:INFO:Set up data.
2025-10-11 18:51:51,462:INFO:Set up folding strategy.
2025-10-11 18:51:51,462:INFO:Set up train/test split.
2025-10-11 18:51:51,469:INFO:Set up index.
2025-10-11 18:51:51,469:INFO:Assigning column types.
2025-10-11 18:51:51,472:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-11 18:51:51,518:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-11 18:51:51,521:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-11 18:51:51,540:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 18:51:51,540:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 18:51:51,592:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-11 18:51:51,592:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-11 18:51:51,623:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 18:51:51,623:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 18:51:51,623:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-11 18:51:51,668:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-11 18:51:51,691:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 18:51:51,691:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 18:51:51,726:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-11 18:51:51,757:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 18:51:51,757:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 18:51:51,757:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-10-11 18:51:51,823:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 18:51:51,823:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 18:51:51,893:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 18:51:51,893:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 18:51:51,893:INFO:Preparing preprocessing pipeline...
2025-10-11 18:51:51,893:INFO:Set up simple imputation.
2025-10-11 18:51:51,908:INFO:Set up encoding of categorical features.
2025-10-11 18:51:51,908:INFO:Set up column transformation.
2025-10-11 18:51:51,908:INFO:Set up feature normalization.
2025-10-11 18:51:52,024:INFO:Finished creating preprocessing pipeline.
2025-10-11 18:51:52,040:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\ARNALDO\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['likes', 'comentarios',
                                             'engagement'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Transf...
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2025-10-11 18:51:52,040:INFO:Creating final display dataframe.
2025-10-11 18:51:52,259:INFO:Setup _display_container:                     Description             Value
0                    Session id              2025
1                        Target        conversion
2                   Target type            Binary
3           Original data shape         (220, 10)
4        Transformed data shape         (220, 22)
5   Transformed train set shape         (154, 22)
6    Transformed test set shape          (66, 22)
7               Ignore features                 2
8              Numeric features                 3
9          Categorical features                 4
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Transformation              True
17        Transformation method       yeo-johnson
18                    Normalize              True
19             Normalize method            zscore
20               Fold Generator   StratifiedKFold
21                  Fold Number                10
22                     CPU Jobs                -1
23                      Use GPU             False
24               Log Experiment             False
25              Experiment Name  clf-default-name
26                          USI              5fd8
2025-10-11 18:51:52,346:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 18:51:52,346:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 18:51:52,417:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 18:51:52,417:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 18:51:52,420:INFO:setup() successfully completed in 1.03s...............
2025-10-11 18:51:52,427:INFO:Initializing create_model()
2025-10-11 18:51:52,427:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000191A8299750>, estimator=rf, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-11 18:51:52,427:INFO:Checking exceptions
2025-10-11 18:51:52,444:INFO:Importing libraries
2025-10-11 18:51:52,444:INFO:Copying training dataset
2025-10-11 18:51:52,450:INFO:Defining folds
2025-10-11 18:51:52,450:INFO:Declaring metric variables
2025-10-11 18:51:52,453:INFO:Importing untrained model
2025-10-11 18:51:52,457:INFO:Random Forest Classifier Imported successfully
2025-10-11 18:51:52,464:INFO:Starting cross validation
2025-10-11 18:51:52,467:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-11 18:51:59,516:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:51:59,543:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:51:59,575:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:51:59,607:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:51:59,713:INFO:Calculating mean and std
2025-10-11 18:51:59,713:INFO:Creating metrics dataframe
2025-10-11 18:51:59,722:INFO:Finalizing model
2025-10-11 18:51:59,971:INFO:Uploading results into container
2025-10-11 18:51:59,972:INFO:Uploading model into container now
2025-10-11 18:51:59,973:INFO:_master_model_container: 1
2025-10-11 18:51:59,973:INFO:_display_container: 2
2025-10-11 18:51:59,973:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=2025, verbose=0,
                       warm_start=False)
2025-10-11 18:51:59,973:INFO:create_model() successfully completed......................................
2025-10-11 18:52:00,083:INFO:Initializing get_config()
2025-10-11 18:52:00,083:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000191A8299750>, variable=X_train_transformed)
2025-10-11 18:52:00,161:INFO:Variable: X_train returned as      plataforma_YouTube  plataforma_Facebook  plataforma_Instagram  \
35             1.486046            -0.734847             -0.714006   
36            -0.672927             1.360828             -0.714006   
85            -0.672927             1.360828             -0.714006   
201           -0.672927            -0.734847              1.400549   
163            1.486046            -0.734847             -0.714006   
..                  ...                  ...                   ...   
55            -0.672927             1.360828             -0.714006   
191            1.486046            -0.734847             -0.714006   
160           -0.672927            -0.734847              1.400549   
183           -0.672927            -0.734847              1.400549   
1             -0.672927             1.360828             -0.714006   

     segmento_Adulto  segmento_Joven  segmento_Senior     likes  comentarios  \
35          1.442221       -0.724398        -0.703666  0.344305    -0.831866   
36         -0.693375        1.380457        -0.703666 -0.415835    -0.617158   
85         -0.693375       -0.724398         1.421129  0.870074    -1.933885   
201        -0.693375       -0.724398         1.421129 -1.007015    -1.162359   
163         1.442221       -0.724398        -0.703666 -0.355236     1.326928   
..               ...             ...              ...       ...          ...   
55         -0.693375       -0.724398         1.421129 -1.505367     0.526268   
191        -0.693375       -0.724398         1.421129 -1.453371     1.198702   
160        -0.693375        1.380457        -0.703666  0.911148    -1.975510   
183        -0.693375       -0.724398         1.421129 -0.157267    -0.982809   
1          -0.693375       -0.724398         1.421129 -1.866974    -1.401412   

     engagement  duracion_categoria_Largo  ...  duracion_categoria_Corto  \
35    -0.117069                  0.937043  ...                 -0.502028   
36    -0.746743                 -1.067187  ...                 -0.502028   
85     0.104500                  0.937043  ...                 -0.502028   
201   -1.471121                 -1.067187  ...                 -0.502028   
163    0.230677                 -1.067187  ...                 -0.502028   
..          ...                       ...  ...                       ...   
55    -1.023350                 -1.067187  ...                  1.991919   
191   -0.626743                 -1.067187  ...                  1.991919   
160    0.141500                  0.937043  ...                 -0.502028   
183   -0.655399                 -1.067187  ...                 -0.502028   
1     -2.188672                  0.937043  ...                 -0.502028   

     canal_segmento_YouTube_Adulto  canal_segmento_Facebook_Joven  \
35                        2.838807                      -0.352261   
36                       -0.352261                       2.838807   
85                       -0.352261                      -0.352261   
201                      -0.352261                      -0.352261   
163                       2.838807                      -0.352261   
..                             ...                            ...   
55                       -0.352261                      -0.352261   
191                      -0.352261                      -0.352261   
160                      -0.352261                      -0.352261   
183                      -0.352261                      -0.352261   
1                        -0.352261                      -0.352261   

     canal_segmento_Facebook_Senior  canal_segmento_Instagram_Senior  \
35                        -0.386334                        -0.328502   
36                        -0.386334                        -0.328502   
85                         2.588436                        -0.328502   
201                       -0.386334                         3.044120   
163                       -0.386334                        -0.328502   
..                              ...                              ...   
55                         2.588436                        -0.328502   
191                       -0.386334                        -0.328502   
160                       -0.386334                        -0.328502   
183                       -0.386334                         3.044120   
1                          2.588436                        -0.328502   

     canal_segmento_Instagram_Joven  canal_segmento_Facebook_Adulto  \
35                        -0.397360                       -0.352261   
36                        -0.397360                       -0.352261   
85                        -0.397360                       -0.352261   
201                       -0.397360                       -0.352261   
163                       -0.397360                       -0.352261   
..                              ...                             ...   
55                        -0.397360                       -0.352261   
191                       -0.397360                       -0.352261   
160                        2.516611                       -0.352261   
183                       -0.397360                       -0.352261   
1                         -0.397360                       -0.352261   

     canal_segmento_YouTube_Joven  canal_segmento_Instagram_Adulto  \
35                      -0.328502                        -0.340503   
36                      -0.328502                        -0.340503   
85                      -0.328502                        -0.340503   
201                     -0.328502                        -0.340503   
163                     -0.328502                        -0.340503   
..                            ...                              ...   
55                      -0.328502                        -0.340503   
191                     -0.328502                        -0.340503   
160                     -0.328502                        -0.340503   
183                     -0.328502                        -0.340503   
1                       -0.328502                        -0.340503   

     canal_segmento_YouTube_Senior  
35                       -0.340503  
36                       -0.340503  
85                       -0.340503  
201                      -0.340503  
163                      -0.340503  
..                             ...  
55                       -0.340503  
191                       2.936835  
160                      -0.340503  
183                      -0.340503  
1                        -0.340503  

[154 rows x 21 columns]
2025-10-11 18:52:00,161:INFO:get_config() successfully completed......................................
2025-10-11 18:52:29,033:INFO:Initializing get_config()
2025-10-11 18:52:29,047:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000191A8299750>, variable=X_train_transformed)
2025-10-11 18:52:29,114:INFO:Variable: X_train returned as      plataforma_YouTube  plataforma_Facebook  plataforma_Instagram  \
35             1.486046            -0.734847             -0.714006   
36            -0.672927             1.360828             -0.714006   
85            -0.672927             1.360828             -0.714006   
201           -0.672927            -0.734847              1.400549   
163            1.486046            -0.734847             -0.714006   
..                  ...                  ...                   ...   
55            -0.672927             1.360828             -0.714006   
191            1.486046            -0.734847             -0.714006   
160           -0.672927            -0.734847              1.400549   
183           -0.672927            -0.734847              1.400549   
1             -0.672927             1.360828             -0.714006   

     segmento_Adulto  segmento_Joven  segmento_Senior     likes  comentarios  \
35          1.442221       -0.724398        -0.703666  0.344305    -0.831866   
36         -0.693375        1.380457        -0.703666 -0.415835    -0.617158   
85         -0.693375       -0.724398         1.421129  0.870074    -1.933885   
201        -0.693375       -0.724398         1.421129 -1.007015    -1.162359   
163         1.442221       -0.724398        -0.703666 -0.355236     1.326928   
..               ...             ...              ...       ...          ...   
55         -0.693375       -0.724398         1.421129 -1.505367     0.526268   
191        -0.693375       -0.724398         1.421129 -1.453371     1.198702   
160        -0.693375        1.380457        -0.703666  0.911148    -1.975510   
183        -0.693375       -0.724398         1.421129 -0.157267    -0.982809   
1          -0.693375       -0.724398         1.421129 -1.866974    -1.401412   

     engagement  duracion_categoria_Largo  ...  duracion_categoria_Corto  \
35    -0.117069                  0.937043  ...                 -0.502028   
36    -0.746743                 -1.067187  ...                 -0.502028   
85     0.104500                  0.937043  ...                 -0.502028   
201   -1.471121                 -1.067187  ...                 -0.502028   
163    0.230677                 -1.067187  ...                 -0.502028   
..          ...                       ...  ...                       ...   
55    -1.023350                 -1.067187  ...                  1.991919   
191   -0.626743                 -1.067187  ...                  1.991919   
160    0.141500                  0.937043  ...                 -0.502028   
183   -0.655399                 -1.067187  ...                 -0.502028   
1     -2.188672                  0.937043  ...                 -0.502028   

     canal_segmento_YouTube_Adulto  canal_segmento_Facebook_Joven  \
35                        2.838807                      -0.352261   
36                       -0.352261                       2.838807   
85                       -0.352261                      -0.352261   
201                      -0.352261                      -0.352261   
163                       2.838807                      -0.352261   
..                             ...                            ...   
55                       -0.352261                      -0.352261   
191                      -0.352261                      -0.352261   
160                      -0.352261                      -0.352261   
183                      -0.352261                      -0.352261   
1                        -0.352261                      -0.352261   

     canal_segmento_Facebook_Senior  canal_segmento_Instagram_Senior  \
35                        -0.386334                        -0.328502   
36                        -0.386334                        -0.328502   
85                         2.588436                        -0.328502   
201                       -0.386334                         3.044120   
163                       -0.386334                        -0.328502   
..                              ...                              ...   
55                         2.588436                        -0.328502   
191                       -0.386334                        -0.328502   
160                       -0.386334                        -0.328502   
183                       -0.386334                         3.044120   
1                          2.588436                        -0.328502   

     canal_segmento_Instagram_Joven  canal_segmento_Facebook_Adulto  \
35                        -0.397360                       -0.352261   
36                        -0.397360                       -0.352261   
85                        -0.397360                       -0.352261   
201                       -0.397360                       -0.352261   
163                       -0.397360                       -0.352261   
..                              ...                             ...   
55                        -0.397360                       -0.352261   
191                       -0.397360                       -0.352261   
160                        2.516611                       -0.352261   
183                       -0.397360                       -0.352261   
1                         -0.397360                       -0.352261   

     canal_segmento_YouTube_Joven  canal_segmento_Instagram_Adulto  \
35                      -0.328502                        -0.340503   
36                      -0.328502                        -0.340503   
85                      -0.328502                        -0.340503   
201                     -0.328502                        -0.340503   
163                     -0.328502                        -0.340503   
..                            ...                              ...   
55                      -0.328502                        -0.340503   
191                     -0.328502                        -0.340503   
160                     -0.328502                        -0.340503   
183                     -0.328502                        -0.340503   
1                       -0.328502                        -0.340503   

     canal_segmento_YouTube_Senior  
35                       -0.340503  
36                       -0.340503  
85                       -0.340503  
201                      -0.340503  
163                      -0.340503  
..                             ...  
55                       -0.340503  
191                       2.936835  
160                      -0.340503  
183                      -0.340503  
1                        -0.340503  

[154 rows x 21 columns]
2025-10-11 18:52:29,114:INFO:get_config() successfully completed......................................
2025-10-11 18:52:32,619:WARNING:C:\Users\ARNALDO\AppData\Local\Temp\ipykernel_16576\1046044395.py:3: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.
  shap.summary_plot(shap_values_fixed[:min_rows], X_train_transformed.iloc[:min_rows])

2025-10-11 18:52:37,316:INFO:Initializing get_config()
2025-10-11 18:52:37,316:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000191A8299750>, variable=X_train_transformed)
2025-10-11 18:52:37,382:INFO:Variable: X_train returned as      plataforma_YouTube  plataforma_Facebook  plataforma_Instagram  \
35             1.486046            -0.734847             -0.714006   
36            -0.672927             1.360828             -0.714006   
85            -0.672927             1.360828             -0.714006   
201           -0.672927            -0.734847              1.400549   
163            1.486046            -0.734847             -0.714006   
..                  ...                  ...                   ...   
55            -0.672927             1.360828             -0.714006   
191            1.486046            -0.734847             -0.714006   
160           -0.672927            -0.734847              1.400549   
183           -0.672927            -0.734847              1.400549   
1             -0.672927             1.360828             -0.714006   

     segmento_Adulto  segmento_Joven  segmento_Senior     likes  comentarios  \
35          1.442221       -0.724398        -0.703666  0.344305    -0.831866   
36         -0.693375        1.380457        -0.703666 -0.415835    -0.617158   
85         -0.693375       -0.724398         1.421129  0.870074    -1.933885   
201        -0.693375       -0.724398         1.421129 -1.007015    -1.162359   
163         1.442221       -0.724398        -0.703666 -0.355236     1.326928   
..               ...             ...              ...       ...          ...   
55         -0.693375       -0.724398         1.421129 -1.505367     0.526268   
191        -0.693375       -0.724398         1.421129 -1.453371     1.198702   
160        -0.693375        1.380457        -0.703666  0.911148    -1.975510   
183        -0.693375       -0.724398         1.421129 -0.157267    -0.982809   
1          -0.693375       -0.724398         1.421129 -1.866974    -1.401412   

     engagement  duracion_categoria_Largo  ...  duracion_categoria_Corto  \
35    -0.117069                  0.937043  ...                 -0.502028   
36    -0.746743                 -1.067187  ...                 -0.502028   
85     0.104500                  0.937043  ...                 -0.502028   
201   -1.471121                 -1.067187  ...                 -0.502028   
163    0.230677                 -1.067187  ...                 -0.502028   
..          ...                       ...  ...                       ...   
55    -1.023350                 -1.067187  ...                  1.991919   
191   -0.626743                 -1.067187  ...                  1.991919   
160    0.141500                  0.937043  ...                 -0.502028   
183   -0.655399                 -1.067187  ...                 -0.502028   
1     -2.188672                  0.937043  ...                 -0.502028   

     canal_segmento_YouTube_Adulto  canal_segmento_Facebook_Joven  \
35                        2.838807                      -0.352261   
36                       -0.352261                       2.838807   
85                       -0.352261                      -0.352261   
201                      -0.352261                      -0.352261   
163                       2.838807                      -0.352261   
..                             ...                            ...   
55                       -0.352261                      -0.352261   
191                      -0.352261                      -0.352261   
160                      -0.352261                      -0.352261   
183                      -0.352261                      -0.352261   
1                        -0.352261                      -0.352261   

     canal_segmento_Facebook_Senior  canal_segmento_Instagram_Senior  \
35                        -0.386334                        -0.328502   
36                        -0.386334                        -0.328502   
85                         2.588436                        -0.328502   
201                       -0.386334                         3.044120   
163                       -0.386334                        -0.328502   
..                              ...                              ...   
55                         2.588436                        -0.328502   
191                       -0.386334                        -0.328502   
160                       -0.386334                        -0.328502   
183                       -0.386334                         3.044120   
1                          2.588436                        -0.328502   

     canal_segmento_Instagram_Joven  canal_segmento_Facebook_Adulto  \
35                        -0.397360                       -0.352261   
36                        -0.397360                       -0.352261   
85                        -0.397360                       -0.352261   
201                       -0.397360                       -0.352261   
163                       -0.397360                       -0.352261   
..                              ...                             ...   
55                        -0.397360                       -0.352261   
191                       -0.397360                       -0.352261   
160                        2.516611                       -0.352261   
183                       -0.397360                       -0.352261   
1                         -0.397360                       -0.352261   

     canal_segmento_YouTube_Joven  canal_segmento_Instagram_Adulto  \
35                      -0.328502                        -0.340503   
36                      -0.328502                        -0.340503   
85                      -0.328502                        -0.340503   
201                     -0.328502                        -0.340503   
163                     -0.328502                        -0.340503   
..                            ...                              ...   
55                      -0.328502                        -0.340503   
191                     -0.328502                        -0.340503   
160                     -0.328502                        -0.340503   
183                     -0.328502                        -0.340503   
1                       -0.328502                        -0.340503   

     canal_segmento_YouTube_Senior  
35                       -0.340503  
36                       -0.340503  
85                       -0.340503  
201                      -0.340503  
163                      -0.340503  
..                             ...  
55                       -0.340503  
191                       2.936835  
160                      -0.340503  
183                      -0.340503  
1                        -0.340503  

[154 rows x 21 columns]
2025-10-11 18:52:37,382:INFO:get_config() successfully completed......................................
2025-10-11 18:53:01,458:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-11 18:53:01,458:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-11 18:53:01,458:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-11 18:53:01,458:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-11 18:53:02,594:INFO:PyCaret ClassificationExperiment
2025-10-11 18:53:02,594:INFO:Logging name: clf-default-name
2025-10-11 18:53:02,594:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-10-11 18:53:02,594:INFO:version 3.3.2
2025-10-11 18:53:02,594:INFO:Initializing setup()
2025-10-11 18:53:02,594:INFO:self.USI: 0a7a
2025-10-11 18:53:02,594:INFO:self._variable_keys: {'y_test', 'exp_name_log', 'is_multiclass', '_available_plots', 'exp_id', 'seed', 'pipeline', 'target_param', 'y_train', 'memory', 'fold_groups_param', 'idx', 'logging_param', 'log_plots_param', '_ml_usecase', 'X_train', 'fix_imbalance', 'data', 'X', 'X_test', 'gpu_param', 'n_jobs_param', 'gpu_n_jobs_param', 'USI', 'y', 'fold_generator', 'html_param', 'fold_shuffle_param'}
2025-10-11 18:53:02,594:INFO:Checking environment
2025-10-11 18:53:02,594:INFO:python_version: 3.11.0
2025-10-11 18:53:02,594:INFO:python_build: ('main', 'Oct 24 2022 18:26:48')
2025-10-11 18:53:02,594:INFO:machine: AMD64
2025-10-11 18:53:02,594:INFO:platform: Windows-10-10.0.26100-SP0
2025-10-11 18:53:02,594:INFO:Memory: svmem(total=34211835904, available=19308756992, percent=43.6, used=14903078912, free=19308756992)
2025-10-11 18:53:02,594:INFO:Physical Core: 6
2025-10-11 18:53:02,594:INFO:Logical Core: 12
2025-10-11 18:53:02,594:INFO:Checking libraries
2025-10-11 18:53:02,594:INFO:System:
2025-10-11 18:53:02,594:INFO:    python: 3.11.0 (main, Oct 24 2022, 18:26:48) [MSC v.1933 64 bit (AMD64)]
2025-10-11 18:53:02,594:INFO:executable: c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\python.exe
2025-10-11 18:53:02,594:INFO:   machine: Windows-10-10.0.26100-SP0
2025-10-11 18:53:02,594:INFO:PyCaret required dependencies:
2025-10-11 18:53:02,621:INFO:                 pip: 22.3
2025-10-11 18:53:02,621:INFO:          setuptools: 65.5.0
2025-10-11 18:53:02,621:INFO:             pycaret: 3.3.2
2025-10-11 18:53:02,621:INFO:             IPython: 9.6.0
2025-10-11 18:53:02,621:INFO:          ipywidgets: 8.1.7
2025-10-11 18:53:02,621:INFO:                tqdm: 4.67.1
2025-10-11 18:53:02,621:INFO:               numpy: 1.26.4
2025-10-11 18:53:02,621:INFO:              pandas: 2.1.4
2025-10-11 18:53:02,621:INFO:              jinja2: 3.1.6
2025-10-11 18:53:02,621:INFO:               scipy: 1.11.4
2025-10-11 18:53:02,621:INFO:              joblib: 1.3.2
2025-10-11 18:53:02,621:INFO:             sklearn: 1.4.2
2025-10-11 18:53:02,621:INFO:                pyod: 2.0.5
2025-10-11 18:53:02,621:INFO:            imblearn: 0.14.0
2025-10-11 18:53:02,621:INFO:   category_encoders: 2.7.0
2025-10-11 18:53:02,621:INFO:            lightgbm: 4.6.0
2025-10-11 18:53:02,621:INFO:               numba: 0.62.1
2025-10-11 18:53:02,621:INFO:            requests: 2.32.5
2025-10-11 18:53:02,621:INFO:          matplotlib: 3.7.5
2025-10-11 18:53:02,621:INFO:          scikitplot: 0.3.7
2025-10-11 18:53:02,621:INFO:         yellowbrick: 1.5
2025-10-11 18:53:02,621:INFO:              plotly: 6.3.1
2025-10-11 18:53:02,621:INFO:    plotly-resampler: Not installed
2025-10-11 18:53:02,621:INFO:             kaleido: 1.1.0
2025-10-11 18:53:02,621:INFO:           schemdraw: 0.15
2025-10-11 18:53:02,621:INFO:         statsmodels: 0.14.5
2025-10-11 18:53:02,621:INFO:              sktime: 0.26.0
2025-10-11 18:53:02,621:INFO:               tbats: 1.1.3
2025-10-11 18:53:02,621:INFO:            pmdarima: 2.0.4
2025-10-11 18:53:02,621:INFO:              psutil: 7.1.0
2025-10-11 18:53:02,621:INFO:          markupsafe: 3.0.3
2025-10-11 18:53:02,621:INFO:             pickle5: Not installed
2025-10-11 18:53:02,621:INFO:         cloudpickle: 3.1.1
2025-10-11 18:53:02,621:INFO:         deprecation: 2.1.0
2025-10-11 18:53:02,621:INFO:              xxhash: 3.6.0
2025-10-11 18:53:02,621:INFO:           wurlitzer: Not installed
2025-10-11 18:53:02,621:INFO:PyCaret optional dependencies:
2025-10-11 18:53:02,637:INFO:                shap: 0.48.0
2025-10-11 18:53:02,637:INFO:           interpret: Not installed
2025-10-11 18:53:02,637:INFO:                umap: Not installed
2025-10-11 18:53:02,637:INFO:     ydata_profiling: Not installed
2025-10-11 18:53:02,637:INFO:  explainerdashboard: Not installed
2025-10-11 18:53:02,637:INFO:             autoviz: Not installed
2025-10-11 18:53:02,637:INFO:           fairlearn: Not installed
2025-10-11 18:53:02,637:INFO:          deepchecks: Not installed
2025-10-11 18:53:02,637:INFO:             xgboost: Not installed
2025-10-11 18:53:02,637:INFO:            catboost: Not installed
2025-10-11 18:53:02,637:INFO:              kmodes: Not installed
2025-10-11 18:53:02,637:INFO:             mlxtend: Not installed
2025-10-11 18:53:02,637:INFO:       statsforecast: Not installed
2025-10-11 18:53:02,637:INFO:        tune_sklearn: Not installed
2025-10-11 18:53:02,637:INFO:                 ray: Not installed
2025-10-11 18:53:02,637:INFO:            hyperopt: Not installed
2025-10-11 18:53:02,637:INFO:              optuna: Not installed
2025-10-11 18:53:02,637:INFO:               skopt: Not installed
2025-10-11 18:53:02,637:INFO:              mlflow: Not installed
2025-10-11 18:53:02,637:INFO:              gradio: Not installed
2025-10-11 18:53:02,637:INFO:             fastapi: Not installed
2025-10-11 18:53:02,637:INFO:             uvicorn: Not installed
2025-10-11 18:53:02,637:INFO:              m2cgen: Not installed
2025-10-11 18:53:02,637:INFO:           evidently: Not installed
2025-10-11 18:53:02,637:INFO:               fugue: Not installed
2025-10-11 18:53:02,637:INFO:           streamlit: Not installed
2025-10-11 18:53:02,637:INFO:             prophet: Not installed
2025-10-11 18:53:02,637:INFO:None
2025-10-11 18:53:02,637:INFO:Set up data.
2025-10-11 18:53:02,637:INFO:Set up folding strategy.
2025-10-11 18:53:02,637:INFO:Set up train/test split.
2025-10-11 18:53:02,653:INFO:Set up index.
2025-10-11 18:53:02,653:INFO:Assigning column types.
2025-10-11 18:53:02,653:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-11 18:53:02,684:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-11 18:53:02,700:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-11 18:53:02,732:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 18:53:02,732:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 18:53:02,771:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-11 18:53:02,772:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-11 18:53:02,791:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 18:53:02,791:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 18:53:02,791:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-11 18:53:02,825:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-11 18:53:02,857:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 18:53:02,857:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 18:53:02,889:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-11 18:53:02,925:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 18:53:02,925:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 18:53:02,925:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-10-11 18:53:02,987:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 18:53:02,987:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 18:53:03,050:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 18:53:03,050:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 18:53:03,050:INFO:Preparing preprocessing pipeline...
2025-10-11 18:53:03,050:INFO:Set up simple imputation.
2025-10-11 18:53:03,050:INFO:Set up encoding of categorical features.
2025-10-11 18:53:03,050:INFO:Set up column transformation.
2025-10-11 18:53:03,050:INFO:Set up feature normalization.
2025-10-11 18:53:03,178:INFO:Finished creating preprocessing pipeline.
2025-10-11 18:53:03,178:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\ARNALDO\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['likes', 'comentarios',
                                             'engagement'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Transf...
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2025-10-11 18:53:03,178:INFO:Creating final display dataframe.
2025-10-11 18:53:03,406:INFO:Setup _display_container:                     Description             Value
0                    Session id              2025
1                        Target        conversion
2                   Target type            Binary
3           Original data shape         (220, 10)
4        Transformed data shape         (220, 22)
5   Transformed train set shape         (154, 22)
6    Transformed test set shape          (66, 22)
7               Ignore features                 2
8              Numeric features                 3
9          Categorical features                 4
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Transformation              True
17        Transformation method       yeo-johnson
18                    Normalize              True
19             Normalize method            zscore
20               Fold Generator   StratifiedKFold
21                  Fold Number                10
22                     CPU Jobs                -1
23                      Use GPU             False
24               Log Experiment             False
25              Experiment Name  clf-default-name
26                          USI              0a7a
2025-10-11 18:53:03,472:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 18:53:03,472:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 18:53:03,539:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 18:53:03,539:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 18:53:03,539:INFO:setup() successfully completed in 0.94s...............
2025-10-11 18:53:03,549:INFO:Initializing create_model()
2025-10-11 18:53:03,549:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020207B65310>, estimator=rf, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-11 18:53:03,549:INFO:Checking exceptions
2025-10-11 18:53:03,569:INFO:Importing libraries
2025-10-11 18:53:03,569:INFO:Copying training dataset
2025-10-11 18:53:03,573:INFO:Defining folds
2025-10-11 18:53:03,573:INFO:Declaring metric variables
2025-10-11 18:53:03,576:INFO:Importing untrained model
2025-10-11 18:53:03,580:INFO:Random Forest Classifier Imported successfully
2025-10-11 18:53:03,586:INFO:Starting cross validation
2025-10-11 18:53:03,589:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-11 18:53:10,736:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:53:10,766:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:53:10,861:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:53:10,893:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:53:11,078:INFO:Calculating mean and std
2025-10-11 18:53:11,080:INFO:Creating metrics dataframe
2025-10-11 18:53:11,084:INFO:Finalizing model
2025-10-11 18:53:11,328:INFO:Uploading results into container
2025-10-11 18:53:11,328:INFO:Uploading model into container now
2025-10-11 18:53:11,337:INFO:_master_model_container: 1
2025-10-11 18:53:11,337:INFO:_display_container: 2
2025-10-11 18:53:11,337:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=2025, verbose=0,
                       warm_start=False)
2025-10-11 18:53:11,337:INFO:create_model() successfully completed......................................
2025-10-11 18:53:11,757:INFO:Initializing get_config()
2025-10-11 18:53:11,757:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020207B65310>, variable=X_train_transformed)
2025-10-11 18:53:11,820:INFO:Variable: X_train returned as      plataforma_YouTube  plataforma_Facebook  plataforma_Instagram  \
35             1.486046            -0.734847             -0.714006   
36            -0.672927             1.360828             -0.714006   
85            -0.672927             1.360828             -0.714006   
201           -0.672927            -0.734847              1.400549   
163            1.486046            -0.734847             -0.714006   
..                  ...                  ...                   ...   
55            -0.672927             1.360828             -0.714006   
191            1.486046            -0.734847             -0.714006   
160           -0.672927            -0.734847              1.400549   
183           -0.672927            -0.734847              1.400549   
1             -0.672927             1.360828             -0.714006   

     segmento_Adulto  segmento_Joven  segmento_Senior     likes  comentarios  \
35          1.442221       -0.724398        -0.703666  0.344305    -0.831866   
36         -0.693375        1.380457        -0.703666 -0.415835    -0.617158   
85         -0.693375       -0.724398         1.421129  0.870074    -1.933885   
201        -0.693375       -0.724398         1.421129 -1.007015    -1.162359   
163         1.442221       -0.724398        -0.703666 -0.355236     1.326928   
..               ...             ...              ...       ...          ...   
55         -0.693375       -0.724398         1.421129 -1.505367     0.526268   
191        -0.693375       -0.724398         1.421129 -1.453371     1.198702   
160        -0.693375        1.380457        -0.703666  0.911148    -1.975510   
183        -0.693375       -0.724398         1.421129 -0.157267    -0.982809   
1          -0.693375       -0.724398         1.421129 -1.866974    -1.401412   

     engagement  duracion_categoria_Largo  ...  duracion_categoria_Corto  \
35    -0.117069                  0.937043  ...                 -0.502028   
36    -0.746743                 -1.067187  ...                 -0.502028   
85     0.104500                  0.937043  ...                 -0.502028   
201   -1.471121                 -1.067187  ...                 -0.502028   
163    0.230677                 -1.067187  ...                 -0.502028   
..          ...                       ...  ...                       ...   
55    -1.023350                 -1.067187  ...                  1.991919   
191   -0.626743                 -1.067187  ...                  1.991919   
160    0.141500                  0.937043  ...                 -0.502028   
183   -0.655399                 -1.067187  ...                 -0.502028   
1     -2.188672                  0.937043  ...                 -0.502028   

     canal_segmento_YouTube_Adulto  canal_segmento_Facebook_Joven  \
35                        2.838807                      -0.352261   
36                       -0.352261                       2.838807   
85                       -0.352261                      -0.352261   
201                      -0.352261                      -0.352261   
163                       2.838807                      -0.352261   
..                             ...                            ...   
55                       -0.352261                      -0.352261   
191                      -0.352261                      -0.352261   
160                      -0.352261                      -0.352261   
183                      -0.352261                      -0.352261   
1                        -0.352261                      -0.352261   

     canal_segmento_Facebook_Senior  canal_segmento_Instagram_Senior  \
35                        -0.386334                        -0.328502   
36                        -0.386334                        -0.328502   
85                         2.588436                        -0.328502   
201                       -0.386334                         3.044120   
163                       -0.386334                        -0.328502   
..                              ...                              ...   
55                         2.588436                        -0.328502   
191                       -0.386334                        -0.328502   
160                       -0.386334                        -0.328502   
183                       -0.386334                         3.044120   
1                          2.588436                        -0.328502   

     canal_segmento_Instagram_Joven  canal_segmento_Facebook_Adulto  \
35                        -0.397360                       -0.352261   
36                        -0.397360                       -0.352261   
85                        -0.397360                       -0.352261   
201                       -0.397360                       -0.352261   
163                       -0.397360                       -0.352261   
..                              ...                             ...   
55                        -0.397360                       -0.352261   
191                       -0.397360                       -0.352261   
160                        2.516611                       -0.352261   
183                       -0.397360                       -0.352261   
1                         -0.397360                       -0.352261   

     canal_segmento_YouTube_Joven  canal_segmento_Instagram_Adulto  \
35                      -0.328502                        -0.340503   
36                      -0.328502                        -0.340503   
85                      -0.328502                        -0.340503   
201                     -0.328502                        -0.340503   
163                     -0.328502                        -0.340503   
..                            ...                              ...   
55                      -0.328502                        -0.340503   
191                     -0.328502                        -0.340503   
160                     -0.328502                        -0.340503   
183                     -0.328502                        -0.340503   
1                       -0.328502                        -0.340503   

     canal_segmento_YouTube_Senior  
35                       -0.340503  
36                       -0.340503  
85                       -0.340503  
201                      -0.340503  
163                      -0.340503  
..                             ...  
55                       -0.340503  
191                       2.936835  
160                      -0.340503  
183                      -0.340503  
1                        -0.340503  

[154 rows x 21 columns]
2025-10-11 18:53:11,820:INFO:get_config() successfully completed......................................
2025-10-11 18:53:11,971:WARNING:C:\Users\ARNALDO\AppData\Local\Temp\ipykernel_1520\1046044395.py:3: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.
  shap.summary_plot(shap_values_fixed[:min_rows], X_train_transformed.iloc[:min_rows])

2025-10-11 18:53:37,399:INFO:Initializing get_config()
2025-10-11 18:53:37,399:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020207B65310>, variable=X_train_transformed)
2025-10-11 18:53:37,466:INFO:Variable: X_train returned as      plataforma_YouTube  plataforma_Facebook  plataforma_Instagram  \
35             1.486046            -0.734847             -0.714006   
36            -0.672927             1.360828             -0.714006   
85            -0.672927             1.360828             -0.714006   
201           -0.672927            -0.734847              1.400549   
163            1.486046            -0.734847             -0.714006   
..                  ...                  ...                   ...   
55            -0.672927             1.360828             -0.714006   
191            1.486046            -0.734847             -0.714006   
160           -0.672927            -0.734847              1.400549   
183           -0.672927            -0.734847              1.400549   
1             -0.672927             1.360828             -0.714006   

     segmento_Adulto  segmento_Joven  segmento_Senior     likes  comentarios  \
35          1.442221       -0.724398        -0.703666  0.344305    -0.831866   
36         -0.693375        1.380457        -0.703666 -0.415835    -0.617158   
85         -0.693375       -0.724398         1.421129  0.870074    -1.933885   
201        -0.693375       -0.724398         1.421129 -1.007015    -1.162359   
163         1.442221       -0.724398        -0.703666 -0.355236     1.326928   
..               ...             ...              ...       ...          ...   
55         -0.693375       -0.724398         1.421129 -1.505367     0.526268   
191        -0.693375       -0.724398         1.421129 -1.453371     1.198702   
160        -0.693375        1.380457        -0.703666  0.911148    -1.975510   
183        -0.693375       -0.724398         1.421129 -0.157267    -0.982809   
1          -0.693375       -0.724398         1.421129 -1.866974    -1.401412   

     engagement  duracion_categoria_Largo  ...  duracion_categoria_Corto  \
35    -0.117069                  0.937043  ...                 -0.502028   
36    -0.746743                 -1.067187  ...                 -0.502028   
85     0.104500                  0.937043  ...                 -0.502028   
201   -1.471121                 -1.067187  ...                 -0.502028   
163    0.230677                 -1.067187  ...                 -0.502028   
..          ...                       ...  ...                       ...   
55    -1.023350                 -1.067187  ...                  1.991919   
191   -0.626743                 -1.067187  ...                  1.991919   
160    0.141500                  0.937043  ...                 -0.502028   
183   -0.655399                 -1.067187  ...                 -0.502028   
1     -2.188672                  0.937043  ...                 -0.502028   

     canal_segmento_YouTube_Adulto  canal_segmento_Facebook_Joven  \
35                        2.838807                      -0.352261   
36                       -0.352261                       2.838807   
85                       -0.352261                      -0.352261   
201                      -0.352261                      -0.352261   
163                       2.838807                      -0.352261   
..                             ...                            ...   
55                       -0.352261                      -0.352261   
191                      -0.352261                      -0.352261   
160                      -0.352261                      -0.352261   
183                      -0.352261                      -0.352261   
1                        -0.352261                      -0.352261   

     canal_segmento_Facebook_Senior  canal_segmento_Instagram_Senior  \
35                        -0.386334                        -0.328502   
36                        -0.386334                        -0.328502   
85                         2.588436                        -0.328502   
201                       -0.386334                         3.044120   
163                       -0.386334                        -0.328502   
..                              ...                              ...   
55                         2.588436                        -0.328502   
191                       -0.386334                        -0.328502   
160                       -0.386334                        -0.328502   
183                       -0.386334                         3.044120   
1                          2.588436                        -0.328502   

     canal_segmento_Instagram_Joven  canal_segmento_Facebook_Adulto  \
35                        -0.397360                       -0.352261   
36                        -0.397360                       -0.352261   
85                        -0.397360                       -0.352261   
201                       -0.397360                       -0.352261   
163                       -0.397360                       -0.352261   
..                              ...                             ...   
55                        -0.397360                       -0.352261   
191                       -0.397360                       -0.352261   
160                        2.516611                       -0.352261   
183                       -0.397360                       -0.352261   
1                         -0.397360                       -0.352261   

     canal_segmento_YouTube_Joven  canal_segmento_Instagram_Adulto  \
35                      -0.328502                        -0.340503   
36                      -0.328502                        -0.340503   
85                      -0.328502                        -0.340503   
201                     -0.328502                        -0.340503   
163                     -0.328502                        -0.340503   
..                            ...                              ...   
55                      -0.328502                        -0.340503   
191                     -0.328502                        -0.340503   
160                     -0.328502                        -0.340503   
183                     -0.328502                        -0.340503   
1                       -0.328502                        -0.340503   

     canal_segmento_YouTube_Senior  
35                       -0.340503  
36                       -0.340503  
85                       -0.340503  
201                      -0.340503  
163                      -0.340503  
..                             ...  
55                       -0.340503  
191                       2.936835  
160                      -0.340503  
183                      -0.340503  
1                        -0.340503  

[154 rows x 21 columns]
2025-10-11 18:53:37,466:INFO:get_config() successfully completed......................................
2025-10-11 18:55:55,679:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-11 18:55:55,679:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-11 18:55:55,679:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-11 18:55:55,679:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-11 18:56:07,778:INFO:PyCaret ClassificationExperiment
2025-10-11 18:56:07,778:INFO:Logging name: clf-default-name
2025-10-11 18:56:07,778:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-10-11 18:56:07,778:INFO:version 3.3.2
2025-10-11 18:56:07,778:INFO:Initializing setup()
2025-10-11 18:56:07,778:INFO:self.USI: 6f26
2025-10-11 18:56:07,778:INFO:self._variable_keys: {'X_test', 'log_plots_param', 'memory', 'idx', 'exp_id', 'target_param', 'y_test', 'X_train', 'gpu_param', 'data', 'n_jobs_param', 'y_train', 'exp_name_log', 'gpu_n_jobs_param', 'fold_generator', 'fold_shuffle_param', 'pipeline', 'logging_param', 'seed', 'USI', 'y', '_available_plots', 'fold_groups_param', 'is_multiclass', 'X', 'fix_imbalance', 'html_param', '_ml_usecase'}
2025-10-11 18:56:07,778:INFO:Checking environment
2025-10-11 18:56:07,778:INFO:python_version: 3.11.0
2025-10-11 18:56:07,778:INFO:python_build: ('main', 'Oct 24 2022 18:26:48')
2025-10-11 18:56:07,778:INFO:machine: AMD64
2025-10-11 18:56:07,779:INFO:platform: Windows-10-10.0.26100-SP0
2025-10-11 18:56:07,782:INFO:Memory: svmem(total=34211835904, available=19412299776, percent=43.3, used=14799536128, free=19412299776)
2025-10-11 18:56:07,782:INFO:Physical Core: 6
2025-10-11 18:56:07,782:INFO:Logical Core: 12
2025-10-11 18:56:07,782:INFO:Checking libraries
2025-10-11 18:56:07,782:INFO:System:
2025-10-11 18:56:07,782:INFO:    python: 3.11.0 (main, Oct 24 2022, 18:26:48) [MSC v.1933 64 bit (AMD64)]
2025-10-11 18:56:07,782:INFO:executable: c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\python.exe
2025-10-11 18:56:07,782:INFO:   machine: Windows-10-10.0.26100-SP0
2025-10-11 18:56:07,782:INFO:PyCaret required dependencies:
2025-10-11 18:56:07,810:INFO:                 pip: 22.3
2025-10-11 18:56:07,810:INFO:          setuptools: 65.5.0
2025-10-11 18:56:07,810:INFO:             pycaret: 3.3.2
2025-10-11 18:56:07,810:INFO:             IPython: 9.6.0
2025-10-11 18:56:07,810:INFO:          ipywidgets: 8.1.7
2025-10-11 18:56:07,810:INFO:                tqdm: 4.67.1
2025-10-11 18:56:07,810:INFO:               numpy: 1.26.4
2025-10-11 18:56:07,810:INFO:              pandas: 2.1.4
2025-10-11 18:56:07,810:INFO:              jinja2: 3.1.6
2025-10-11 18:56:07,811:INFO:               scipy: 1.11.4
2025-10-11 18:56:07,811:INFO:              joblib: 1.3.2
2025-10-11 18:56:07,811:INFO:             sklearn: 1.4.2
2025-10-11 18:56:07,811:INFO:                pyod: 2.0.5
2025-10-11 18:56:07,811:INFO:            imblearn: 0.14.0
2025-10-11 18:56:07,811:INFO:   category_encoders: 2.7.0
2025-10-11 18:56:07,811:INFO:            lightgbm: 4.6.0
2025-10-11 18:56:07,811:INFO:               numba: 0.62.1
2025-10-11 18:56:07,811:INFO:            requests: 2.32.5
2025-10-11 18:56:07,811:INFO:          matplotlib: 3.7.5
2025-10-11 18:56:07,811:INFO:          scikitplot: 0.3.7
2025-10-11 18:56:07,811:INFO:         yellowbrick: 1.5
2025-10-11 18:56:07,811:INFO:              plotly: 6.3.1
2025-10-11 18:56:07,811:INFO:    plotly-resampler: Not installed
2025-10-11 18:56:07,811:INFO:             kaleido: 1.1.0
2025-10-11 18:56:07,811:INFO:           schemdraw: 0.15
2025-10-11 18:56:07,811:INFO:         statsmodels: 0.14.5
2025-10-11 18:56:07,811:INFO:              sktime: 0.26.0
2025-10-11 18:56:07,811:INFO:               tbats: 1.1.3
2025-10-11 18:56:07,811:INFO:            pmdarima: 2.0.4
2025-10-11 18:56:07,811:INFO:              psutil: 7.1.0
2025-10-11 18:56:07,811:INFO:          markupsafe: 3.0.3
2025-10-11 18:56:07,811:INFO:             pickle5: Not installed
2025-10-11 18:56:07,811:INFO:         cloudpickle: 3.1.1
2025-10-11 18:56:07,811:INFO:         deprecation: 2.1.0
2025-10-11 18:56:07,811:INFO:              xxhash: 3.6.0
2025-10-11 18:56:07,811:INFO:           wurlitzer: Not installed
2025-10-11 18:56:07,812:INFO:PyCaret optional dependencies:
2025-10-11 18:56:07,837:INFO:                shap: 0.48.0
2025-10-11 18:56:07,837:INFO:           interpret: Not installed
2025-10-11 18:56:07,837:INFO:                umap: Not installed
2025-10-11 18:56:07,837:INFO:     ydata_profiling: Not installed
2025-10-11 18:56:07,837:INFO:  explainerdashboard: Not installed
2025-10-11 18:56:07,837:INFO:             autoviz: Not installed
2025-10-11 18:56:07,837:INFO:           fairlearn: Not installed
2025-10-11 18:56:07,837:INFO:          deepchecks: Not installed
2025-10-11 18:56:07,837:INFO:             xgboost: Not installed
2025-10-11 18:56:07,837:INFO:            catboost: Not installed
2025-10-11 18:56:07,837:INFO:              kmodes: Not installed
2025-10-11 18:56:07,837:INFO:             mlxtend: Not installed
2025-10-11 18:56:07,837:INFO:       statsforecast: Not installed
2025-10-11 18:56:07,839:INFO:        tune_sklearn: Not installed
2025-10-11 18:56:07,839:INFO:                 ray: Not installed
2025-10-11 18:56:07,839:INFO:            hyperopt: Not installed
2025-10-11 18:56:07,839:INFO:              optuna: Not installed
2025-10-11 18:56:07,839:INFO:               skopt: Not installed
2025-10-11 18:56:07,839:INFO:              mlflow: Not installed
2025-10-11 18:56:07,839:INFO:              gradio: Not installed
2025-10-11 18:56:07,839:INFO:             fastapi: Not installed
2025-10-11 18:56:07,839:INFO:             uvicorn: Not installed
2025-10-11 18:56:07,839:INFO:              m2cgen: Not installed
2025-10-11 18:56:07,839:INFO:           evidently: Not installed
2025-10-11 18:56:07,839:INFO:               fugue: Not installed
2025-10-11 18:56:07,839:INFO:           streamlit: Not installed
2025-10-11 18:56:07,839:INFO:             prophet: Not installed
2025-10-11 18:56:07,839:INFO:None
2025-10-11 18:56:07,839:INFO:Set up data.
2025-10-11 18:56:07,843:INFO:Set up folding strategy.
2025-10-11 18:56:07,843:INFO:Set up train/test split.
2025-10-11 18:56:07,843:INFO:Set up index.
2025-10-11 18:56:07,843:INFO:Assigning column types.
2025-10-11 18:56:07,859:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-11 18:56:07,895:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-11 18:56:07,895:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-11 18:56:07,926:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 18:56:07,926:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 18:56:07,976:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-11 18:56:07,976:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-11 18:56:07,995:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 18:56:07,995:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 18:56:07,995:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-11 18:56:08,026:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-11 18:56:08,059:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 18:56:08,059:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 18:56:08,097:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-11 18:56:08,126:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 18:56:08,126:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 18:56:08,126:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-10-11 18:56:08,193:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 18:56:08,194:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 18:56:08,243:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 18:56:08,258:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 18:56:08,259:INFO:Preparing preprocessing pipeline...
2025-10-11 18:56:08,259:INFO:Set up simple imputation.
2025-10-11 18:56:08,259:INFO:Set up encoding of categorical features.
2025-10-11 18:56:08,259:INFO:Set up column transformation.
2025-10-11 18:56:08,259:INFO:Set up feature normalization.
2025-10-11 18:56:08,377:INFO:Finished creating preprocessing pipeline.
2025-10-11 18:56:08,377:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\ARNALDO\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['likes', 'comentarios',
                                             'engagement'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Transf...
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2025-10-11 18:56:08,377:INFO:Creating final display dataframe.
2025-10-11 18:56:08,612:INFO:Setup _display_container:                     Description             Value
0                    Session id              2025
1                        Target        conversion
2                   Target type            Binary
3           Original data shape         (220, 10)
4        Transformed data shape         (220, 22)
5   Transformed train set shape         (154, 22)
6    Transformed test set shape          (66, 22)
7               Ignore features                 2
8              Numeric features                 3
9          Categorical features                 4
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Transformation              True
17        Transformation method       yeo-johnson
18                    Normalize              True
19             Normalize method            zscore
20               Fold Generator   StratifiedKFold
21                  Fold Number                10
22                     CPU Jobs                -1
23                      Use GPU             False
24               Log Experiment             False
25              Experiment Name  clf-default-name
26                          USI              6f26
2025-10-11 18:56:08,676:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 18:56:08,676:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 18:56:08,728:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 18:56:08,728:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-11 18:56:08,743:INFO:setup() successfully completed in 0.98s...............
2025-10-11 18:56:38,606:INFO:Initializing compare_models()
2025-10-11 18:56:38,606:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027832CFC290>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000027832CFC290>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-10-11 18:56:38,606:INFO:Checking exceptions
2025-10-11 18:56:38,606:INFO:Preparing display monitor
2025-10-11 18:56:38,644:INFO:Initializing Logistic Regression
2025-10-11 18:56:38,645:INFO:Total runtime is 0.0 minutes
2025-10-11 18:56:38,648:INFO:SubProcess create_model() called ==================================
2025-10-11 18:56:38,649:INFO:Initializing create_model()
2025-10-11 18:56:38,649:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027832CFC290>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027832CFD1D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-11 18:56:38,649:INFO:Checking exceptions
2025-10-11 18:56:38,649:INFO:Importing libraries
2025-10-11 18:56:38,649:INFO:Copying training dataset
2025-10-11 18:56:38,653:INFO:Defining folds
2025-10-11 18:56:38,653:INFO:Declaring metric variables
2025-10-11 18:56:38,657:INFO:Importing untrained model
2025-10-11 18:56:38,662:INFO:Logistic Regression Imported successfully
2025-10-11 18:56:38,671:INFO:Starting cross validation
2025-10-11 18:56:38,674:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-11 18:56:45,636:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:56:45,931:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:56:45,952:INFO:Calculating mean and std
2025-10-11 18:56:45,954:INFO:Creating metrics dataframe
2025-10-11 18:56:45,954:INFO:Uploading results into container
2025-10-11 18:56:45,954:INFO:Uploading model into container now
2025-10-11 18:56:45,954:INFO:_master_model_container: 1
2025-10-11 18:56:45,954:INFO:_display_container: 2
2025-10-11 18:56:45,954:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2025, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-11 18:56:45,954:INFO:create_model() successfully completed......................................
2025-10-11 18:56:46,051:INFO:SubProcess create_model() end ==================================
2025-10-11 18:56:46,051:INFO:Creating metrics dataframe
2025-10-11 18:56:46,068:INFO:Initializing K Neighbors Classifier
2025-10-11 18:56:46,068:INFO:Total runtime is 0.12373207410176595 minutes
2025-10-11 18:56:46,068:INFO:SubProcess create_model() called ==================================
2025-10-11 18:56:46,068:INFO:Initializing create_model()
2025-10-11 18:56:46,068:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027832CFC290>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027832CFD1D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-11 18:56:46,068:INFO:Checking exceptions
2025-10-11 18:56:46,068:INFO:Importing libraries
2025-10-11 18:56:46,068:INFO:Copying training dataset
2025-10-11 18:56:46,068:INFO:Defining folds
2025-10-11 18:56:46,068:INFO:Declaring metric variables
2025-10-11 18:56:46,084:INFO:Importing untrained model
2025-10-11 18:56:46,087:INFO:K Neighbors Classifier Imported successfully
2025-10-11 18:56:46,087:INFO:Starting cross validation
2025-10-11 18:56:46,087:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-11 18:56:49,379:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:56:49,392:INFO:Calculating mean and std
2025-10-11 18:56:49,393:INFO:Creating metrics dataframe
2025-10-11 18:56:49,395:INFO:Uploading results into container
2025-10-11 18:56:49,395:INFO:Uploading model into container now
2025-10-11 18:56:49,396:INFO:_master_model_container: 2
2025-10-11 18:56:49,396:INFO:_display_container: 2
2025-10-11 18:56:49,396:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-10-11 18:56:49,396:INFO:create_model() successfully completed......................................
2025-10-11 18:56:49,494:INFO:SubProcess create_model() end ==================================
2025-10-11 18:56:49,495:INFO:Creating metrics dataframe
2025-10-11 18:56:49,503:INFO:Initializing Naive Bayes
2025-10-11 18:56:49,503:INFO:Total runtime is 0.18098374605178832 minutes
2025-10-11 18:56:49,508:INFO:SubProcess create_model() called ==================================
2025-10-11 18:56:49,508:INFO:Initializing create_model()
2025-10-11 18:56:49,508:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027832CFC290>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027832CFD1D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-11 18:56:49,508:INFO:Checking exceptions
2025-10-11 18:56:49,509:INFO:Importing libraries
2025-10-11 18:56:49,509:INFO:Copying training dataset
2025-10-11 18:56:49,514:INFO:Defining folds
2025-10-11 18:56:49,514:INFO:Declaring metric variables
2025-10-11 18:56:49,518:INFO:Importing untrained model
2025-10-11 18:56:49,518:INFO:Naive Bayes Imported successfully
2025-10-11 18:56:49,525:INFO:Starting cross validation
2025-10-11 18:56:49,525:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-11 18:56:49,805:INFO:Calculating mean and std
2025-10-11 18:56:49,805:INFO:Creating metrics dataframe
2025-10-11 18:56:49,805:INFO:Uploading results into container
2025-10-11 18:56:49,805:INFO:Uploading model into container now
2025-10-11 18:56:49,805:INFO:_master_model_container: 3
2025-10-11 18:56:49,805:INFO:_display_container: 2
2025-10-11 18:56:49,805:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-10-11 18:56:49,805:INFO:create_model() successfully completed......................................
2025-10-11 18:56:49,881:INFO:SubProcess create_model() end ==================================
2025-10-11 18:56:49,881:INFO:Creating metrics dataframe
2025-10-11 18:56:49,897:INFO:Initializing Decision Tree Classifier
2025-10-11 18:56:49,897:INFO:Total runtime is 0.1875398794809977 minutes
2025-10-11 18:56:49,897:INFO:SubProcess create_model() called ==================================
2025-10-11 18:56:49,897:INFO:Initializing create_model()
2025-10-11 18:56:49,897:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027832CFC290>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027832CFD1D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-11 18:56:49,897:INFO:Checking exceptions
2025-10-11 18:56:49,897:INFO:Importing libraries
2025-10-11 18:56:49,897:INFO:Copying training dataset
2025-10-11 18:56:49,897:INFO:Defining folds
2025-10-11 18:56:49,897:INFO:Declaring metric variables
2025-10-11 18:56:49,897:INFO:Importing untrained model
2025-10-11 18:56:49,912:INFO:Decision Tree Classifier Imported successfully
2025-10-11 18:56:49,923:INFO:Starting cross validation
2025-10-11 18:56:49,925:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-11 18:56:50,184:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:56:50,206:INFO:Calculating mean and std
2025-10-11 18:56:50,206:INFO:Creating metrics dataframe
2025-10-11 18:56:50,206:INFO:Uploading results into container
2025-10-11 18:56:50,206:INFO:Uploading model into container now
2025-10-11 18:56:50,206:INFO:_master_model_container: 4
2025-10-11 18:56:50,206:INFO:_display_container: 2
2025-10-11 18:56:50,210:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best')
2025-10-11 18:56:50,210:INFO:create_model() successfully completed......................................
2025-10-11 18:56:50,281:INFO:SubProcess create_model() end ==================================
2025-10-11 18:56:50,281:INFO:Creating metrics dataframe
2025-10-11 18:56:50,297:INFO:Initializing SVM - Linear Kernel
2025-10-11 18:56:50,297:INFO:Total runtime is 0.1942070444424947 minutes
2025-10-11 18:56:50,302:INFO:SubProcess create_model() called ==================================
2025-10-11 18:56:50,302:INFO:Initializing create_model()
2025-10-11 18:56:50,302:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027832CFC290>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027832CFD1D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-11 18:56:50,302:INFO:Checking exceptions
2025-10-11 18:56:50,302:INFO:Importing libraries
2025-10-11 18:56:50,302:INFO:Copying training dataset
2025-10-11 18:56:50,302:INFO:Defining folds
2025-10-11 18:56:50,302:INFO:Declaring metric variables
2025-10-11 18:56:50,302:INFO:Importing untrained model
2025-10-11 18:56:50,312:INFO:SVM - Linear Kernel Imported successfully
2025-10-11 18:56:50,320:INFO:Starting cross validation
2025-10-11 18:56:50,320:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-11 18:56:50,555:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:56:50,566:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:56:50,596:INFO:Calculating mean and std
2025-10-11 18:56:50,596:INFO:Creating metrics dataframe
2025-10-11 18:56:50,601:INFO:Uploading results into container
2025-10-11 18:56:50,601:INFO:Uploading model into container now
2025-10-11 18:56:50,601:INFO:_master_model_container: 5
2025-10-11 18:56:50,601:INFO:_display_container: 2
2025-10-11 18:56:50,608:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=2025, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-10-11 18:56:50,609:INFO:create_model() successfully completed......................................
2025-10-11 18:56:50,681:INFO:SubProcess create_model() end ==================================
2025-10-11 18:56:50,681:INFO:Creating metrics dataframe
2025-10-11 18:56:50,697:INFO:Initializing Ridge Classifier
2025-10-11 18:56:50,697:INFO:Total runtime is 0.200878103574117 minutes
2025-10-11 18:56:50,697:INFO:SubProcess create_model() called ==================================
2025-10-11 18:56:50,697:INFO:Initializing create_model()
2025-10-11 18:56:50,697:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027832CFC290>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027832CFD1D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-11 18:56:50,697:INFO:Checking exceptions
2025-10-11 18:56:50,697:INFO:Importing libraries
2025-10-11 18:56:50,697:INFO:Copying training dataset
2025-10-11 18:56:50,713:INFO:Defining folds
2025-10-11 18:56:50,713:INFO:Declaring metric variables
2025-10-11 18:56:50,713:INFO:Importing untrained model
2025-10-11 18:56:50,713:INFO:Ridge Classifier Imported successfully
2025-10-11 18:56:50,727:INFO:Starting cross validation
2025-10-11 18:56:50,732:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-11 18:56:50,975:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:56:50,975:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:56:50,985:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:56:51,005:INFO:Calculating mean and std
2025-10-11 18:56:51,005:INFO:Creating metrics dataframe
2025-10-11 18:56:51,005:INFO:Uploading results into container
2025-10-11 18:56:51,005:INFO:Uploading model into container now
2025-10-11 18:56:51,005:INFO:_master_model_container: 6
2025-10-11 18:56:51,005:INFO:_display_container: 2
2025-10-11 18:56:51,010:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=2025, solver='auto',
                tol=0.0001)
2025-10-11 18:56:51,010:INFO:create_model() successfully completed......................................
2025-10-11 18:56:51,085:INFO:SubProcess create_model() end ==================================
2025-10-11 18:56:51,085:INFO:Creating metrics dataframe
2025-10-11 18:56:51,100:INFO:Initializing Random Forest Classifier
2025-10-11 18:56:51,100:INFO:Total runtime is 0.20759264230728147 minutes
2025-10-11 18:56:51,100:INFO:SubProcess create_model() called ==================================
2025-10-11 18:56:51,100:INFO:Initializing create_model()
2025-10-11 18:56:51,100:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027832CFC290>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027832CFD1D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-11 18:56:51,100:INFO:Checking exceptions
2025-10-11 18:56:51,100:INFO:Importing libraries
2025-10-11 18:56:51,100:INFO:Copying training dataset
2025-10-11 18:56:51,100:INFO:Defining folds
2025-10-11 18:56:51,100:INFO:Declaring metric variables
2025-10-11 18:56:51,116:INFO:Importing untrained model
2025-10-11 18:56:51,116:INFO:Random Forest Classifier Imported successfully
2025-10-11 18:56:51,126:INFO:Starting cross validation
2025-10-11 18:56:51,126:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-11 18:56:51,761:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:56:51,805:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:56:51,807:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:56:51,821:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:56:51,841:INFO:Calculating mean and std
2025-10-11 18:56:51,841:INFO:Creating metrics dataframe
2025-10-11 18:56:51,841:INFO:Uploading results into container
2025-10-11 18:56:51,841:INFO:Uploading model into container now
2025-10-11 18:56:51,841:INFO:_master_model_container: 7
2025-10-11 18:56:51,841:INFO:_display_container: 2
2025-10-11 18:56:51,846:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=2025, verbose=0,
                       warm_start=False)
2025-10-11 18:56:51,846:INFO:create_model() successfully completed......................................
2025-10-11 18:56:51,929:INFO:SubProcess create_model() end ==================================
2025-10-11 18:56:51,929:INFO:Creating metrics dataframe
2025-10-11 18:56:51,939:INFO:Initializing Quadratic Discriminant Analysis
2025-10-11 18:56:51,939:INFO:Total runtime is 0.22157047589619952 minutes
2025-10-11 18:56:51,943:INFO:SubProcess create_model() called ==================================
2025-10-11 18:56:51,943:INFO:Initializing create_model()
2025-10-11 18:56:51,943:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027832CFC290>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027832CFD1D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-11 18:56:51,944:INFO:Checking exceptions
2025-10-11 18:56:51,944:INFO:Importing libraries
2025-10-11 18:56:51,944:INFO:Copying training dataset
2025-10-11 18:56:51,948:INFO:Defining folds
2025-10-11 18:56:51,948:INFO:Declaring metric variables
2025-10-11 18:56:51,952:INFO:Importing untrained model
2025-10-11 18:56:51,956:INFO:Quadratic Discriminant Analysis Imported successfully
2025-10-11 18:56:51,963:INFO:Starting cross validation
2025-10-11 18:56:51,967:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-11 18:56:52,184:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-11 18:56:52,184:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-11 18:56:52,184:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-11 18:56:52,184:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-11 18:56:52,184:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-11 18:56:52,184:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-11 18:56:52,184:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-11 18:56:52,184:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-11 18:56:52,254:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:56:52,267:INFO:Calculating mean and std
2025-10-11 18:56:52,267:INFO:Creating metrics dataframe
2025-10-11 18:56:52,270:INFO:Uploading results into container
2025-10-11 18:56:52,270:INFO:Uploading model into container now
2025-10-11 18:56:52,270:INFO:_master_model_container: 8
2025-10-11 18:56:52,270:INFO:_display_container: 2
2025-10-11 18:56:52,272:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-10-11 18:56:52,272:INFO:create_model() successfully completed......................................
2025-10-11 18:56:52,347:INFO:SubProcess create_model() end ==================================
2025-10-11 18:56:52,347:INFO:Creating metrics dataframe
2025-10-11 18:56:52,363:INFO:Initializing Ada Boost Classifier
2025-10-11 18:56:52,363:INFO:Total runtime is 0.22864115635553994 minutes
2025-10-11 18:56:52,363:INFO:SubProcess create_model() called ==================================
2025-10-11 18:56:52,363:INFO:Initializing create_model()
2025-10-11 18:56:52,363:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027832CFC290>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027832CFD1D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-11 18:56:52,363:INFO:Checking exceptions
2025-10-11 18:56:52,363:INFO:Importing libraries
2025-10-11 18:56:52,363:INFO:Copying training dataset
2025-10-11 18:56:52,363:INFO:Defining folds
2025-10-11 18:56:52,363:INFO:Declaring metric variables
2025-10-11 18:56:52,363:INFO:Importing untrained model
2025-10-11 18:56:52,379:INFO:Ada Boost Classifier Imported successfully
2025-10-11 18:56:52,388:INFO:Starting cross validation
2025-10-11 18:56:52,391:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-11 18:56:52,550:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-11 18:56:52,562:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-11 18:56:52,574:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-11 18:56:52,576:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-11 18:56:52,578:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-11 18:56:52,581:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-11 18:56:52,584:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-11 18:56:52,586:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-11 18:56:52,593:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-11 18:56:52,597:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-11 18:56:52,797:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:56:52,856:INFO:Calculating mean and std
2025-10-11 18:56:52,856:INFO:Creating metrics dataframe
2025-10-11 18:56:52,856:INFO:Uploading results into container
2025-10-11 18:56:52,866:INFO:Uploading model into container now
2025-10-11 18:56:52,869:INFO:_master_model_container: 9
2025-10-11 18:56:52,869:INFO:_display_container: 2
2025-10-11 18:56:52,871:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2025)
2025-10-11 18:56:52,871:INFO:create_model() successfully completed......................................
2025-10-11 18:56:52,970:INFO:SubProcess create_model() end ==================================
2025-10-11 18:56:52,970:INFO:Creating metrics dataframe
2025-10-11 18:56:52,971:INFO:Initializing Gradient Boosting Classifier
2025-10-11 18:56:52,971:INFO:Total runtime is 0.23876982927322385 minutes
2025-10-11 18:56:52,981:INFO:SubProcess create_model() called ==================================
2025-10-11 18:56:52,982:INFO:Initializing create_model()
2025-10-11 18:56:52,982:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027832CFC290>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027832CFD1D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-11 18:56:52,982:INFO:Checking exceptions
2025-10-11 18:56:52,982:INFO:Importing libraries
2025-10-11 18:56:52,982:INFO:Copying training dataset
2025-10-11 18:56:52,986:INFO:Defining folds
2025-10-11 18:56:52,986:INFO:Declaring metric variables
2025-10-11 18:56:52,987:INFO:Importing untrained model
2025-10-11 18:56:52,987:INFO:Gradient Boosting Classifier Imported successfully
2025-10-11 18:56:53,004:INFO:Starting cross validation
2025-10-11 18:56:53,009:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-11 18:56:53,489:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:56:53,512:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:56:53,541:INFO:Calculating mean and std
2025-10-11 18:56:53,541:INFO:Creating metrics dataframe
2025-10-11 18:56:53,544:INFO:Uploading results into container
2025-10-11 18:56:53,544:INFO:Uploading model into container now
2025-10-11 18:56:53,544:INFO:_master_model_container: 10
2025-10-11 18:56:53,544:INFO:_display_container: 2
2025-10-11 18:56:53,546:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2025, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-11 18:56:53,547:INFO:create_model() successfully completed......................................
2025-10-11 18:56:53,630:INFO:SubProcess create_model() end ==================================
2025-10-11 18:56:53,630:INFO:Creating metrics dataframe
2025-10-11 18:56:53,637:INFO:Initializing Linear Discriminant Analysis
2025-10-11 18:56:53,637:INFO:Total runtime is 0.24988356033960976 minutes
2025-10-11 18:56:53,637:INFO:SubProcess create_model() called ==================================
2025-10-11 18:56:53,637:INFO:Initializing create_model()
2025-10-11 18:56:53,637:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027832CFC290>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027832CFD1D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-11 18:56:53,637:INFO:Checking exceptions
2025-10-11 18:56:53,637:INFO:Importing libraries
2025-10-11 18:56:53,637:INFO:Copying training dataset
2025-10-11 18:56:53,649:INFO:Defining folds
2025-10-11 18:56:53,649:INFO:Declaring metric variables
2025-10-11 18:56:53,653:INFO:Importing untrained model
2025-10-11 18:56:53,653:INFO:Linear Discriminant Analysis Imported successfully
2025-10-11 18:56:53,663:INFO:Starting cross validation
2025-10-11 18:56:53,665:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-11 18:56:53,951:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:56:53,961:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:56:53,988:INFO:Calculating mean and std
2025-10-11 18:56:53,988:INFO:Creating metrics dataframe
2025-10-11 18:56:53,996:INFO:Uploading results into container
2025-10-11 18:56:53,998:INFO:Uploading model into container now
2025-10-11 18:56:53,999:INFO:_master_model_container: 11
2025-10-11 18:56:53,999:INFO:_display_container: 2
2025-10-11 18:56:54,000:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-11 18:56:54,001:INFO:create_model() successfully completed......................................
2025-10-11 18:56:54,086:INFO:SubProcess create_model() end ==================================
2025-10-11 18:56:54,086:INFO:Creating metrics dataframe
2025-10-11 18:56:54,097:INFO:Initializing Extra Trees Classifier
2025-10-11 18:56:54,098:INFO:Total runtime is 0.2575682997703552 minutes
2025-10-11 18:56:54,102:INFO:SubProcess create_model() called ==================================
2025-10-11 18:56:54,102:INFO:Initializing create_model()
2025-10-11 18:56:54,102:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027832CFC290>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027832CFD1D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-11 18:56:54,103:INFO:Checking exceptions
2025-10-11 18:56:54,103:INFO:Importing libraries
2025-10-11 18:56:54,103:INFO:Copying training dataset
2025-10-11 18:56:54,103:INFO:Defining folds
2025-10-11 18:56:54,103:INFO:Declaring metric variables
2025-10-11 18:56:54,110:INFO:Importing untrained model
2025-10-11 18:56:54,118:INFO:Extra Trees Classifier Imported successfully
2025-10-11 18:56:54,120:INFO:Starting cross validation
2025-10-11 18:56:54,120:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-11 18:56:54,735:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:56:54,814:INFO:Calculating mean and std
2025-10-11 18:56:54,816:INFO:Creating metrics dataframe
2025-10-11 18:56:54,823:INFO:Uploading results into container
2025-10-11 18:56:54,823:INFO:Uploading model into container now
2025-10-11 18:56:54,823:INFO:_master_model_container: 12
2025-10-11 18:56:54,823:INFO:_display_container: 2
2025-10-11 18:56:54,823:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=2025, verbose=0,
                     warm_start=False)
2025-10-11 18:56:54,823:INFO:create_model() successfully completed......................................
2025-10-11 18:56:54,901:INFO:SubProcess create_model() end ==================================
2025-10-11 18:56:54,901:INFO:Creating metrics dataframe
2025-10-11 18:56:54,917:INFO:Initializing Light Gradient Boosting Machine
2025-10-11 18:56:54,917:INFO:Total runtime is 0.2712056120236715 minutes
2025-10-11 18:56:54,917:INFO:SubProcess create_model() called ==================================
2025-10-11 18:56:54,917:INFO:Initializing create_model()
2025-10-11 18:56:54,917:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027832CFC290>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027832CFD1D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-11 18:56:54,917:INFO:Checking exceptions
2025-10-11 18:56:54,917:INFO:Importing libraries
2025-10-11 18:56:54,917:INFO:Copying training dataset
2025-10-11 18:56:54,931:INFO:Defining folds
2025-10-11 18:56:54,931:INFO:Declaring metric variables
2025-10-11 18:56:54,931:INFO:Importing untrained model
2025-10-11 18:56:54,939:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-11 18:56:54,950:INFO:Starting cross validation
2025-10-11 18:56:54,953:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-11 18:56:55,765:INFO:Calculating mean and std
2025-10-11 18:56:55,767:INFO:Creating metrics dataframe
2025-10-11 18:56:55,771:INFO:Uploading results into container
2025-10-11 18:56:55,773:INFO:Uploading model into container now
2025-10-11 18:56:55,773:INFO:_master_model_container: 13
2025-10-11 18:56:55,773:INFO:_display_container: 2
2025-10-11 18:56:55,775:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2025, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-11 18:56:55,775:INFO:create_model() successfully completed......................................
2025-10-11 18:56:55,880:INFO:SubProcess create_model() end ==================================
2025-10-11 18:56:55,880:INFO:Creating metrics dataframe
2025-10-11 18:56:55,885:INFO:Initializing Dummy Classifier
2025-10-11 18:56:55,885:INFO:Total runtime is 0.2873510241508484 minutes
2025-10-11 18:56:55,885:INFO:SubProcess create_model() called ==================================
2025-10-11 18:56:55,885:INFO:Initializing create_model()
2025-10-11 18:56:55,885:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027832CFC290>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027832CFD1D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-11 18:56:55,897:INFO:Checking exceptions
2025-10-11 18:56:55,897:INFO:Importing libraries
2025-10-11 18:56:55,897:INFO:Copying training dataset
2025-10-11 18:56:55,902:INFO:Defining folds
2025-10-11 18:56:55,902:INFO:Declaring metric variables
2025-10-11 18:56:55,905:INFO:Importing untrained model
2025-10-11 18:56:55,905:INFO:Dummy Classifier Imported successfully
2025-10-11 18:56:55,919:INFO:Starting cross validation
2025-10-11 18:56:55,919:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-11 18:56:56,218:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:56:56,223:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:56:56,234:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:56:56,234:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:56:56,243:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:56:56,244:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:56:56,244:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:56:56,249:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:56:56,254:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:56:56,254:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:56:56,264:INFO:Calculating mean and std
2025-10-11 18:56:56,268:INFO:Creating metrics dataframe
2025-10-11 18:56:56,272:INFO:Uploading results into container
2025-10-11 18:56:56,272:INFO:Uploading model into container now
2025-10-11 18:56:56,272:INFO:_master_model_container: 14
2025-10-11 18:56:56,272:INFO:_display_container: 2
2025-10-11 18:56:56,272:INFO:DummyClassifier(constant=None, random_state=2025, strategy='prior')
2025-10-11 18:56:56,272:INFO:create_model() successfully completed......................................
2025-10-11 18:56:56,346:INFO:SubProcess create_model() end ==================================
2025-10-11 18:56:56,346:INFO:Creating metrics dataframe
2025-10-11 18:56:56,407:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-10-11 18:56:56,420:INFO:Initializing create_model()
2025-10-11 18:56:56,420:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027832CFC290>, estimator=DummyClassifier(constant=None, random_state=2025, strategy='prior'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-11 18:56:56,420:INFO:Checking exceptions
2025-10-11 18:56:56,424:INFO:Importing libraries
2025-10-11 18:56:56,424:INFO:Copying training dataset
2025-10-11 18:56:56,424:INFO:Defining folds
2025-10-11 18:56:56,424:INFO:Declaring metric variables
2025-10-11 18:56:56,424:INFO:Importing untrained model
2025-10-11 18:56:56,424:INFO:Declaring custom model
2025-10-11 18:56:56,424:INFO:Dummy Classifier Imported successfully
2025-10-11 18:56:56,424:INFO:Cross validation set to False
2025-10-11 18:56:56,424:INFO:Fitting Model
2025-10-11 18:56:56,512:INFO:DummyClassifier(constant=None, random_state=2025, strategy='prior')
2025-10-11 18:56:56,512:INFO:create_model() successfully completed......................................
2025-10-11 18:56:56,620:INFO:_master_model_container: 14
2025-10-11 18:56:56,620:INFO:_display_container: 2
2025-10-11 18:56:56,620:INFO:DummyClassifier(constant=None, random_state=2025, strategy='prior')
2025-10-11 18:56:56,620:INFO:compare_models() successfully completed......................................
2025-10-11 18:58:28,733:INFO:Initializing create_model()
2025-10-11 18:58:28,733:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027832CFC290>, estimator=gbc, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-11 18:58:28,733:INFO:Checking exceptions
2025-10-11 18:58:28,748:INFO:Importing libraries
2025-10-11 18:58:28,756:INFO:Copying training dataset
2025-10-11 18:58:28,761:INFO:Defining folds
2025-10-11 18:58:28,761:INFO:Declaring metric variables
2025-10-11 18:58:28,765:INFO:Importing untrained model
2025-10-11 18:58:28,770:INFO:Gradient Boosting Classifier Imported successfully
2025-10-11 18:58:28,786:INFO:Starting cross validation
2025-10-11 18:58:28,789:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-11 18:58:29,297:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:58:29,312:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:58:29,359:INFO:Calculating mean and std
2025-10-11 18:58:29,359:INFO:Creating metrics dataframe
2025-10-11 18:58:29,359:INFO:Finalizing model
2025-10-11 18:58:29,570:INFO:Uploading results into container
2025-10-11 18:58:29,570:INFO:Uploading model into container now
2025-10-11 18:58:29,582:INFO:_master_model_container: 15
2025-10-11 18:58:29,582:INFO:_display_container: 3
2025-10-11 18:58:29,583:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2025, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-11 18:58:29,583:INFO:create_model() successfully completed......................................
2025-10-11 18:58:34,030:INFO:Initializing create_model()
2025-10-11 18:58:34,030:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027832CFC290>, estimator=gbc, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-11 18:58:34,030:INFO:Checking exceptions
2025-10-11 18:58:34,049:INFO:Importing libraries
2025-10-11 18:58:34,049:INFO:Copying training dataset
2025-10-11 18:58:34,056:INFO:Defining folds
2025-10-11 18:58:34,056:INFO:Declaring metric variables
2025-10-11 18:58:34,060:INFO:Importing untrained model
2025-10-11 18:58:34,065:INFO:Gradient Boosting Classifier Imported successfully
2025-10-11 18:58:34,073:INFO:Starting cross validation
2025-10-11 18:58:34,076:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-11 18:58:34,611:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:58:34,623:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 18:58:34,643:INFO:Calculating mean and std
2025-10-11 18:58:34,643:INFO:Creating metrics dataframe
2025-10-11 18:58:34,647:INFO:Finalizing model
2025-10-11 18:58:34,861:INFO:Uploading results into container
2025-10-11 18:58:34,861:INFO:Uploading model into container now
2025-10-11 18:58:34,866:INFO:_master_model_container: 16
2025-10-11 18:58:34,866:INFO:_display_container: 4
2025-10-11 18:58:34,866:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2025, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-11 18:58:34,866:INFO:create_model() successfully completed......................................
2025-10-11 18:58:56,838:INFO:Initializing get_config()
2025-10-11 18:58:56,838:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027832CFC290>, variable=X_train_transformed)
2025-10-11 18:58:56,917:INFO:Variable: X_train returned as      plataforma_YouTube  plataforma_Facebook  plataforma_Instagram  \
35             1.486046            -0.734847             -0.714006   
36            -0.672927             1.360828             -0.714006   
85            -0.672927             1.360828             -0.714006   
201           -0.672927            -0.734847              1.400549   
163            1.486046            -0.734847             -0.714006   
..                  ...                  ...                   ...   
55            -0.672927             1.360828             -0.714006   
191            1.486046            -0.734847             -0.714006   
160           -0.672927            -0.734847              1.400549   
183           -0.672927            -0.734847              1.400549   
1             -0.672927             1.360828             -0.714006   

     segmento_Adulto  segmento_Joven  segmento_Senior     likes  comentarios  \
35          1.442221       -0.724398        -0.703666  0.344305    -0.831866   
36         -0.693375        1.380457        -0.703666 -0.415835    -0.617158   
85         -0.693375       -0.724398         1.421129  0.870074    -1.933885   
201        -0.693375       -0.724398         1.421129 -1.007015    -1.162359   
163         1.442221       -0.724398        -0.703666 -0.355236     1.326928   
..               ...             ...              ...       ...          ...   
55         -0.693375       -0.724398         1.421129 -1.505367     0.526268   
191        -0.693375       -0.724398         1.421129 -1.453371     1.198702   
160        -0.693375        1.380457        -0.703666  0.911148    -1.975510   
183        -0.693375       -0.724398         1.421129 -0.157267    -0.982809   
1          -0.693375       -0.724398         1.421129 -1.866974    -1.401412   

     engagement  duracion_categoria_Largo  ...  duracion_categoria_Corto  \
35    -0.117069                  0.937043  ...                 -0.502028   
36    -0.746743                 -1.067187  ...                 -0.502028   
85     0.104500                  0.937043  ...                 -0.502028   
201   -1.471121                 -1.067187  ...                 -0.502028   
163    0.230677                 -1.067187  ...                 -0.502028   
..          ...                       ...  ...                       ...   
55    -1.023350                 -1.067187  ...                  1.991919   
191   -0.626743                 -1.067187  ...                  1.991919   
160    0.141500                  0.937043  ...                 -0.502028   
183   -0.655399                 -1.067187  ...                 -0.502028   
1     -2.188672                  0.937043  ...                 -0.502028   

     canal_segmento_YouTube_Adulto  canal_segmento_Facebook_Joven  \
35                        2.838807                      -0.352261   
36                       -0.352261                       2.838807   
85                       -0.352261                      -0.352261   
201                      -0.352261                      -0.352261   
163                       2.838807                      -0.352261   
..                             ...                            ...   
55                       -0.352261                      -0.352261   
191                      -0.352261                      -0.352261   
160                      -0.352261                      -0.352261   
183                      -0.352261                      -0.352261   
1                        -0.352261                      -0.352261   

     canal_segmento_Facebook_Senior  canal_segmento_Instagram_Senior  \
35                        -0.386334                        -0.328502   
36                        -0.386334                        -0.328502   
85                         2.588436                        -0.328502   
201                       -0.386334                         3.044120   
163                       -0.386334                        -0.328502   
..                              ...                              ...   
55                         2.588436                        -0.328502   
191                       -0.386334                        -0.328502   
160                       -0.386334                        -0.328502   
183                       -0.386334                         3.044120   
1                          2.588436                        -0.328502   

     canal_segmento_Instagram_Joven  canal_segmento_Facebook_Adulto  \
35                        -0.397360                       -0.352261   
36                        -0.397360                       -0.352261   
85                        -0.397360                       -0.352261   
201                       -0.397360                       -0.352261   
163                       -0.397360                       -0.352261   
..                              ...                             ...   
55                        -0.397360                       -0.352261   
191                       -0.397360                       -0.352261   
160                        2.516611                       -0.352261   
183                       -0.397360                       -0.352261   
1                         -0.397360                       -0.352261   

     canal_segmento_YouTube_Joven  canal_segmento_Instagram_Adulto  \
35                      -0.328502                        -0.340503   
36                      -0.328502                        -0.340503   
85                      -0.328502                        -0.340503   
201                     -0.328502                        -0.340503   
163                     -0.328502                        -0.340503   
..                            ...                              ...   
55                      -0.328502                        -0.340503   
191                     -0.328502                        -0.340503   
160                     -0.328502                        -0.340503   
183                     -0.328502                        -0.340503   
1                       -0.328502                        -0.340503   

     canal_segmento_YouTube_Senior  
35                       -0.340503  
36                       -0.340503  
85                       -0.340503  
201                      -0.340503  
163                      -0.340503  
..                             ...  
55                       -0.340503  
191                       2.936835  
160                      -0.340503  
183                      -0.340503  
1                        -0.340503  

[154 rows x 21 columns]
2025-10-11 18:58:56,917:INFO:get_config() successfully completed......................................
2025-10-11 19:00:24,191:INFO:Initializing finalize_model()
2025-10-11 19:00:24,191:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027832CFC290>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2025, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-10-11 19:00:24,192:INFO:Finalizing GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2025, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-11 19:00:24,197:INFO:Initializing create_model()
2025-10-11 19:00:24,197:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027832CFC290>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2025, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-10-11 19:00:24,197:INFO:Checking exceptions
2025-10-11 19:00:24,199:INFO:Importing libraries
2025-10-11 19:00:24,200:INFO:Copying training dataset
2025-10-11 19:00:24,200:INFO:Defining folds
2025-10-11 19:00:24,200:INFO:Declaring metric variables
2025-10-11 19:00:24,200:INFO:Importing untrained model
2025-10-11 19:00:24,201:INFO:Declaring custom model
2025-10-11 19:00:24,202:INFO:Gradient Boosting Classifier Imported successfully
2025-10-11 19:00:24,203:INFO:Cross validation set to False
2025-10-11 19:00:24,204:INFO:Fitting Model
2025-10-11 19:00:24,416:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['likes', 'comentarios',
                                             'engagement'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['plataf...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='log_loss',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=2025, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2025-10-11 19:00:24,416:INFO:create_model() successfully completed......................................
2025-10-11 19:00:24,516:INFO:_master_model_container: 16
2025-10-11 19:00:24,517:INFO:_display_container: 4
2025-10-11 19:00:24,517:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['likes', 'comentarios',
                                             'engagement'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['plataf...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='log_loss',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=2025, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2025-10-11 19:00:24,517:INFO:finalize_model() successfully completed......................................
2025-10-11 19:00:55,209:INFO:Initializing create_model()
2025-10-11 19:00:55,209:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027832CFC290>, estimator=gbc, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-11 19:00:55,209:INFO:Checking exceptions
2025-10-11 19:00:55,229:INFO:Importing libraries
2025-10-11 19:00:55,229:INFO:Copying training dataset
2025-10-11 19:00:55,236:INFO:Defining folds
2025-10-11 19:00:55,236:INFO:Declaring metric variables
2025-10-11 19:00:55,240:INFO:Importing untrained model
2025-10-11 19:00:55,244:INFO:Gradient Boosting Classifier Imported successfully
2025-10-11 19:00:55,251:INFO:Starting cross validation
2025-10-11 19:00:55,255:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-11 19:00:55,744:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 19:00:55,745:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 19:00:55,772:INFO:Calculating mean and std
2025-10-11 19:00:55,772:INFO:Creating metrics dataframe
2025-10-11 19:00:55,778:INFO:Finalizing model
2025-10-11 19:00:55,962:INFO:Uploading results into container
2025-10-11 19:00:55,962:INFO:Uploading model into container now
2025-10-11 19:00:55,970:INFO:_master_model_container: 17
2025-10-11 19:00:55,970:INFO:_display_container: 5
2025-10-11 19:00:55,970:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2025, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-11 19:00:55,971:INFO:create_model() successfully completed......................................
2025-10-11 19:01:54,052:INFO:Initializing create_model()
2025-10-11 19:01:54,052:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027832CFC290>, estimator=gbc, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-11 19:01:54,056:INFO:Checking exceptions
2025-10-11 19:01:54,081:INFO:Importing libraries
2025-10-11 19:01:54,082:INFO:Copying training dataset
2025-10-11 19:01:54,090:INFO:Defining folds
2025-10-11 19:01:54,091:INFO:Declaring metric variables
2025-10-11 19:01:54,098:INFO:Importing untrained model
2025-10-11 19:01:54,105:INFO:Gradient Boosting Classifier Imported successfully
2025-10-11 19:01:54,121:INFO:Starting cross validation
2025-10-11 19:01:54,126:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-11 19:01:54,751:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 19:01:54,871:WARNING:c:\Users\ARNALDO\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-11 19:01:54,948:INFO:Calculating mean and std
2025-10-11 19:01:54,948:INFO:Creating metrics dataframe
2025-10-11 19:01:54,951:INFO:Finalizing model
2025-10-11 19:01:55,222:INFO:Uploading results into container
2025-10-11 19:01:55,223:INFO:Uploading model into container now
2025-10-11 19:01:55,223:INFO:_master_model_container: 18
2025-10-11 19:01:55,223:INFO:_display_container: 6
2025-10-11 19:01:55,223:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2025, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-11 19:01:55,223:INFO:create_model() successfully completed......................................
2025-10-11 19:01:57,390:INFO:Initializing get_config()
2025-10-11 19:01:57,390:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027832CFC290>, variable=X_train_transformed)
2025-10-11 19:01:57,456:INFO:Variable: X_train returned as      plataforma_YouTube  plataforma_Facebook  plataforma_Instagram  \
35             1.486046            -0.734847             -0.714006   
36            -0.672927             1.360828             -0.714006   
85            -0.672927             1.360828             -0.714006   
201           -0.672927            -0.734847              1.400549   
163            1.486046            -0.734847             -0.714006   
..                  ...                  ...                   ...   
55            -0.672927             1.360828             -0.714006   
191            1.486046            -0.734847             -0.714006   
160           -0.672927            -0.734847              1.400549   
183           -0.672927            -0.734847              1.400549   
1             -0.672927             1.360828             -0.714006   

     segmento_Adulto  segmento_Joven  segmento_Senior     likes  comentarios  \
35          1.442221       -0.724398        -0.703666  0.344305    -0.831866   
36         -0.693375        1.380457        -0.703666 -0.415835    -0.617158   
85         -0.693375       -0.724398         1.421129  0.870074    -1.933885   
201        -0.693375       -0.724398         1.421129 -1.007015    -1.162359   
163         1.442221       -0.724398        -0.703666 -0.355236     1.326928   
..               ...             ...              ...       ...          ...   
55         -0.693375       -0.724398         1.421129 -1.505367     0.526268   
191        -0.693375       -0.724398         1.421129 -1.453371     1.198702   
160        -0.693375        1.380457        -0.703666  0.911148    -1.975510   
183        -0.693375       -0.724398         1.421129 -0.157267    -0.982809   
1          -0.693375       -0.724398         1.421129 -1.866974    -1.401412   

     engagement  duracion_categoria_Largo  ...  duracion_categoria_Corto  \
35    -0.117069                  0.937043  ...                 -0.502028   
36    -0.746743                 -1.067187  ...                 -0.502028   
85     0.104500                  0.937043  ...                 -0.502028   
201   -1.471121                 -1.067187  ...                 -0.502028   
163    0.230677                 -1.067187  ...                 -0.502028   
..          ...                       ...  ...                       ...   
55    -1.023350                 -1.067187  ...                  1.991919   
191   -0.626743                 -1.067187  ...                  1.991919   
160    0.141500                  0.937043  ...                 -0.502028   
183   -0.655399                 -1.067187  ...                 -0.502028   
1     -2.188672                  0.937043  ...                 -0.502028   

     canal_segmento_YouTube_Adulto  canal_segmento_Facebook_Joven  \
35                        2.838807                      -0.352261   
36                       -0.352261                       2.838807   
85                       -0.352261                      -0.352261   
201                      -0.352261                      -0.352261   
163                       2.838807                      -0.352261   
..                             ...                            ...   
55                       -0.352261                      -0.352261   
191                      -0.352261                      -0.352261   
160                      -0.352261                      -0.352261   
183                      -0.352261                      -0.352261   
1                        -0.352261                      -0.352261   

     canal_segmento_Facebook_Senior  canal_segmento_Instagram_Senior  \
35                        -0.386334                        -0.328502   
36                        -0.386334                        -0.328502   
85                         2.588436                        -0.328502   
201                       -0.386334                         3.044120   
163                       -0.386334                        -0.328502   
..                              ...                              ...   
55                         2.588436                        -0.328502   
191                       -0.386334                        -0.328502   
160                       -0.386334                        -0.328502   
183                       -0.386334                         3.044120   
1                          2.588436                        -0.328502   

     canal_segmento_Instagram_Joven  canal_segmento_Facebook_Adulto  \
35                        -0.397360                       -0.352261   
36                        -0.397360                       -0.352261   
85                        -0.397360                       -0.352261   
201                       -0.397360                       -0.352261   
163                       -0.397360                       -0.352261   
..                              ...                             ...   
55                        -0.397360                       -0.352261   
191                       -0.397360                       -0.352261   
160                        2.516611                       -0.352261   
183                       -0.397360                       -0.352261   
1                         -0.397360                       -0.352261   

     canal_segmento_YouTube_Joven  canal_segmento_Instagram_Adulto  \
35                      -0.328502                        -0.340503   
36                      -0.328502                        -0.340503   
85                      -0.328502                        -0.340503   
201                     -0.328502                        -0.340503   
163                     -0.328502                        -0.340503   
..                            ...                              ...   
55                      -0.328502                        -0.340503   
191                     -0.328502                        -0.340503   
160                     -0.328502                        -0.340503   
183                     -0.328502                        -0.340503   
1                       -0.328502                        -0.340503   

     canal_segmento_YouTube_Senior  
35                       -0.340503  
36                       -0.340503  
85                       -0.340503  
201                      -0.340503  
163                      -0.340503  
..                             ...  
55                       -0.340503  
191                       2.936835  
160                      -0.340503  
183                      -0.340503  
1                        -0.340503  

[154 rows x 21 columns]
2025-10-11 19:01:57,456:INFO:get_config() successfully completed......................................
2025-10-11 19:45:29,936:WARNING:C:\Users\ARNALDO\AppData\Local\Temp\ipykernel_29340\200469259.py:17: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.
  shap.summary_plot(shap_values_fixed[:min_rows], X_train_transformed.iloc[:min_rows])

2025-10-19 13:52:15,678:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-19 13:52:15,783:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-19 13:52:15,783:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-19 13:52:15,784:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-19 13:53:56,446:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-19 13:53:56,446:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-19 13:53:56,446:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-19 13:53:56,446:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-19 17:17:06,206:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-19 17:17:06,206:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-19 17:17:06,206:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-19 17:17:06,206:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-19 17:19:11,286:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-19 17:19:11,286:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-19 17:19:11,286:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-19 17:19:11,286:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-19 17:24:31,843:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-19 17:24:31,843:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-19 17:24:31,843:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-19 17:24:31,843:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-19 17:31:32,445:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-19 17:31:32,445:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-19 17:31:32,446:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-19 17:31:32,446:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-19 20:23:59,850:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-19 20:23:59,851:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-19 20:23:59,851:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-19 20:23:59,851:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-19 20:34:50,017:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-19 20:34:50,017:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-19 20:34:50,017:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-19 20:34:50,017:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-19 20:44:45,216:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-19 20:44:45,216:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-19 20:44:45,216:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-19 20:44:45,216:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-19 21:02:35,756:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-19 21:02:35,756:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-19 21:02:35,757:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-19 21:02:35,757:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-19 21:02:47,272:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-19 21:02:47,272:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-19 21:02:47,272:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-19 21:02:47,272:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-19 22:14:01,491:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-19 22:14:01,491:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-19 22:14:01,491:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-19 22:14:01,491:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-19 22:54:47,770:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-19 22:54:47,770:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-19 22:54:47,770:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-19 22:54:47,770:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-19 23:26:35,090:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-19 23:26:35,091:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-19 23:26:35,091:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-19 23:26:35,091:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-20 00:06:50,507:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-20 00:06:50,605:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-20 00:06:50,605:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-20 00:06:50,605:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
